cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
aten::to,208,"[[], [], [], [], [], []]",aten::copy_,211,"[[], [], []]",Memcpy HtoD (Pageable -> Device),380871,0,1.0011363636363637
aten::layer_norm,215,"[[2048, 4, 6144], [], [6144], [6144], [], []]",aten::native_layer_norm,216,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",380893,19904,191.5375
aten::layer_norm,222,"[[2048, 4, 6144], [], [6144], [6144], [], []]",aten::native_layer_norm,223,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",380915,690.6666666666666,192.08863636363637
aten::linear,232,"[[2048, 4, 6144], [4608, 6144], [4608]]",aten::addmm,237,"[[4608], [8192, 6144], [6144, 4608], [], []]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_relu_f2f_stages_64x3_tn,380934,1868,1837.1022727272727
aten::to,259,"[[2048, 1, 1, 24], [], [], [], [], [], [], []]",aten::copy_,262,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),380952,1415,5.013636363636364
aten::to,263,"[[2048, 1, 1, 24], [], [], [], [], [], [], []]",aten::copy_,266,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),380962,11670,5.0034090909090905
None,None,None,None,None,None,kernel_0,380975,26557.333333333332,15.177272727272728
None,None,None,None,None,None,kernel_1,380987,3267,12.82159090909091
None,None,None,None,None,None,kernel_0,380999,8430.666666666666,16.520454545454545
None,None,None,None,None,None,kernel_1,381011,1657.6666666666667,12.588636363636363
aten::cat,308,"[[], []]",aten::cat,308,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",381019,7283.666666666667,106.75795454545455
aten::cat,309,"[[], []]",aten::cat,309,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",381028,749,107.33068181818182
aten::baddbmm,319,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",aten::baddbmm,319,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,381046,467,680.6420454545455
ScaledUpperTriangMaskedSoftmax,322,"[[64, 2048, 2048]]",ScaledUpperTriangMaskedSoftmax,322,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",381055,484,681.9965909090909
aten::bmm,339,"[[64, 2048, 2048], [64, 2048, 96]]",aten::bmm,339,"[[64, 2048, 2048], [64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,381101,467.6666666666667,493.0056818181818
aten::contiguous,343,"[[2048, 4, 16, 96], []]",aten::copy_,347,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",381112,479.3333333333333,63.467045454545456
aten::linear,349,"[[2048, 4, 1536], [6144, 1536], []]",aten::mm,356,"[[8192, 1536], [1536, 6144]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn,381129,1929.3333333333333,658.9681818181818
aten::add,361,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,361,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",381140,475,228.51704545454547
aten::linear,366,"[[2048, 4, 6144], [6144, 6144], []]",aten::mm,373,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),381153,461,2351.4386363636363
None,None,None,None,None,None,kernel_2,381166,482,172.0625
aten::linear,381,"[[2048, 4, 6144], [6144, 6144], []]",aten::mm,388,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),381178,473,2346.8681818181817
aten::add,393,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,393,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",381186,471.3333333333333,224.6909090909091
aten::add,395,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,395,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",381194,472,223.1784090909091
_ReduceFromModelParallelRegion,396,"[[2048, 4, 6144]]",nccl:all_reduce,399,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",381212,634.3333333333334,761.025
aten::add,403,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,403,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",381251,488,224.0772727272727