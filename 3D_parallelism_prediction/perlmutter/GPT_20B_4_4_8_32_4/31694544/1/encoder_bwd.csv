cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
aten::zeros,498771,"[[], [], [], [], []]",aten::fill_,498774,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",1627958,0,8.997777777777777
aten::to,498780,"[[], [], [], [], [], []]",aten::copy_,498783,"[[], [], []]",Memcpy HtoD (Pageable -> Device),1627990,44353.333333333336,1.0
aten::layer_norm,498787,"[[2048, 4, 6144], [], [6144], [6144], [], []]",aten::native_layer_norm,498788,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",1628012,20525.333333333332,191.0511111111111
aten::layer_norm,498794,"[[2048, 4, 6144], [], [6144], [6144], [], []]",aten::native_layer_norm,498795,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",1628034,906.6666666666666,191.7288888888889
aten::linear,498804,"[[2048, 4, 6144], [4608, 6144], [4608]]",aten::addmm,498809,"[[4608], [8192, 6144], [6144, 4608], [], []]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_relu_f2f_stages_64x3_tn,1628053,2037.3333333333333,1834.7688888888888
aten::to,498831,"[[2048, 1, 1, 24], [], [], [], [], [], [], []]",aten::copy_,498834,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),1628071,1548.3333333333333,5.003333333333333
aten::to,498835,"[[2048, 1, 1, 24], [], [], [], [], [], [], []]",aten::copy_,498838,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),1628081,11561.0,5.003333333333333
apply_rotary_pos_emb,498839,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]",aten::neg,498848,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1628089,24505.666666666668,15.456666666666667
apply_rotary_pos_emb,498839,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]",aten::cat,498860,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",1628098,8927.0,29.33222222222222
None,None,None,None,None,None,kernel_1,1628111,2662.3333333333335,12.414444444444445
apply_rotary_pos_emb,498839,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]",aten::neg,498871,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1628118,9971.333333333334,18.033333333333335
apply_rotary_pos_emb,498839,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]",aten::cat,498882,"[[2048, 4, 16, 24], [], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",1628127,6423.333333333333,28.934444444444445
None,None,None,None,None,None,kernel_1,1628140,1853.0,12.248888888888889
aten::cat,498889,"[[], []]",aten::cat,498889,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",1628148,9371.0,106.09666666666666
aten::cat,498890,"[[], []]",aten::cat,498890,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",1628157,496.0,106.91555555555556
aten::baddbmm,498900,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",aten::baddbmm,498900,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,1628175,491.0,677.7488888888889
ScaledUpperTriangMaskedSoftmax,498903,"[[64, 2048, 2048]]",ScaledUpperTriangMaskedSoftmax,498903,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",1628184,504.6666666666667,682.49
aten::bmm,498920,"[[64, 2048, 2048], [64, 2048, 96]]",aten::bmm,498920,"[[64, 2048, 2048], [64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,1628230,505.6666666666667,493.2988888888889
aten::clone,498925,"[[2048, 4, 16, 96], []]",aten::copy_,498928,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1628241,505.3333333333333,63.19777777777778
aten::linear,498930,"[[2048, 4, 1536], [6144, 1536], []]",aten::mm,498937,"[[8192, 1536], [1536, 6144]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn,1628258,2099.3333333333335,656.4233333333333
aten::add,498942,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,498942,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",1628269,499.0,227.19
aten::linear,498947,"[[2048, 4, 6144], [6144, 6144], []]",aten::mm,498954,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),1628282,518.3333333333334,2337.0266666666666
None,None,None,None,None,None,kernel_2,1628295,516.6666666666666,171.44333333333333
aten::linear,498962,"[[2048, 4, 6144], [6144, 6144], []]",aten::mm,498969,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),1628307,485.0,2328.6566666666668
aten::add,498974,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,498974,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",1628315,512.6666666666666,222.84
aten::add,498976,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,498976,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1628323,486.6666666666667,223.3022222222222
_ReduceFromModelParallelRegion,498977,"[[2048, 4, 6144]]",nccl:all_reduce,498980,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",1628341,647.0,763.7944444444445
aten::add,498984,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,498984,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1628380,759.6666666666666,223.76555555555555
autograd::engine::evaluate_function: ExpandBackward0,498994,,aten::sum,498996,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",1628435,1687.0,97.32
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,498998,,aten::add_,499000,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1628442,499.0,3.331111111111111
autograd::engine::evaluate_function: MmBackward0,499005,,aten::mm,499010,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,1628465,1980.3333333333333,2301.928888888889
autograd::engine::evaluate_function: MmBackward0,499005,,aten::mm,499017,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),1628485,498.0,2282.8444444444444
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,499027,,aten::add_,499029,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1628496,493.3333333333333,158.84333333333333
None,None,None,None,None,None,kernel_3,1628515,550.3333333333334,237.10111111111112
autograd::engine::evaluate_function: GeLUFunctionBackward,499030,,aten::sum,499037,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",1628541,1675.0,97.74333333333334
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,499039,,aten::add_,499041,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1628548,497.6666666666667,3.3133333333333335
autograd::engine::evaluate_function: MmBackward0,499046,,aten::mm,499051,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,1628571,1988.0,2299.0755555555556
autograd::engine::evaluate_function: MmBackward0,499046,,aten::mm,499058,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),1628591,492.6666666666667,2282.463333333333
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,499068,,aten::add_,499070,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1628602,549.3333333333334,158.9388888888889
autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward,499071,,nccl:all_reduce,499075,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",1628622,842.0,802.4466666666667
autograd::engine::evaluate_function: ExpandBackward0,499079,,aten::sum,499081,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",1628684,2068.6666666666665,99.74222222222222
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,499083,,aten::add_,499085,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1628691,558.6666666666666,3.473333333333333
autograd::engine::evaluate_function: MmBackward0,499090,,aten::mm,499095,"[[6144, 8192], [8192, 1536]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,1628714,1716.0,571.1222222222223
autograd::engine::evaluate_function: MmBackward0,499090,,aten::mm,499102,"[[8192, 6144], [6144, 1536]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,1628732,499.6666666666667,610.7433333333333
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,499112,,aten::add_,499114,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1628743,508.3333333333333,34.96222222222222
autograd::engine::evaluate_function: BmmBackward0,499129,,aten::bmm,499133,"[[64, 2048, 2048], [64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,1628769,438.6666666666667,450.8122222222222
autograd::engine::evaluate_function: BmmBackward0,499129,,aten::bmm,499136,"[[64, 2048, 96], [64, 96, 2048]]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,1628785,488.0,685.0155555555556
autograd::engine::evaluate_function: ScaledUpperTriangMaskedSoftmaxBackward,499153,,ScaledUpperTriangMaskedSoftmaxBackward,499154,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",1628799,494.0,949.2733333333333
autograd::engine::evaluate_function: BaddbmmBackward0,499167,,aten::bmm,499171,"[[64, 2048, 2048], [64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,1628819,500.6666666666667,484.75888888888886
autograd::engine::evaluate_function: BaddbmmBackward0,499167,,aten::mul,499173,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",1628831,489.3333333333333,31.142222222222223
autograd::engine::evaluate_function: BaddbmmBackward0,499167,,aten::bmm,499176,"[[64, 96, 2048], [64, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,1628846,538.3333333333334,439.6066666666667
autograd::engine::evaluate_function: BaddbmmBackward0,499167,,aten::mul,499178,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",1628858,504.3333333333333,32.324444444444445
autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward,499215,,aten::mul,499218,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",1628886,466.6666666666667,20.09888888888889
autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward,499215,,aten::mul,499222,"[[], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",1628898,510.0,18.676666666666666
autograd::engine::evaluate_function: NegBackward0,499223,,aten::neg,499225,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1628912,483.0,9.245555555555555
autograd::engine::evaluate_function: SliceBackward0,499226,,aten::fill_,499232,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1628929,514.0,7.021111111111111
autograd::engine::evaluate_function: SliceBackward0,499226,,aten::copy_,499235,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1628935,563.0,23.20888888888889
autograd::engine::evaluate_function: SliceBackward0,499226,,aten::add,499236,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",1628949,493.0,42.58111111111111
autograd::engine::evaluate_function: SliceBackward0,499237,,aten::fill_,499243,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1628967,494.6666666666667,7.02
autograd::engine::evaluate_function: SliceBackward0,499237,,aten::copy_,499246,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1628973,552.3333333333334,23.623333333333335
autograd::engine::evaluate_function: SliceBackward0,499237,,aten::add,499247,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",1628987,482.6666666666667,41.812222222222225
autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward,499248,,aten::mul,499251,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",1629002,505.0,21.354444444444443
autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward,499248,,aten::mul,499255,"[[], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",1629014,518.3333333333334,18.683333333333334
autograd::engine::evaluate_function: NegBackward0,499256,,aten::neg,499258,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1629028,471.0,11.916666666666666
autograd::engine::evaluate_function: SliceBackward0,499259,,aten::fill_,499265,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1629045,445.6666666666667,7.092222222222222
autograd::engine::evaluate_function: SliceBackward0,499259,,aten::copy_,499268,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1629051,546.3333333333334,10.077777777777778
autograd::engine::evaluate_function: SliceBackward0,499259,,aten::add,499269,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",1629065,541.3333333333334,18.294444444444444
autograd::engine::evaluate_function: SliceBackward0,499270,,aten::fill_,499276,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1629083,504.0,7.013333333333334
autograd::engine::evaluate_function: SliceBackward0,499270,,aten::copy_,499279,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1629089,554.3333333333334,12.084444444444445
autograd::engine::evaluate_function: SliceBackward0,499270,,aten::add,499280,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",1629103,516.6666666666666,17.626666666666665
autograd::engine::evaluate_function: SliceBackward0,499281,,aten::fill_,499287,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1629121,476.6666666666667,21.09111111111111
autograd::engine::evaluate_function: SliceBackward0,499281,,aten::copy_,499290,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1629127,507.3333333333333,111.06111111111112
autograd::engine::evaluate_function: SliceBackward0,499291,,aten::fill_,499297,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1629145,497.3333333333333,24.245555555555555
autograd::engine::evaluate_function: SliceBackward0,499291,,aten::copy_,499300,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1629151,520.3333333333334,40.89
autograd::engine::evaluate_function: SliceBackward0,499291,,aten::add,499301,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1629165,483.0,55.18888888888889
autograd::engine::evaluate_function: SliceBackward0,499302,,aten::zero_,499307,"[[2048, 4, 16, 96]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1629183,499.0,21.72
autograd::engine::evaluate_function: SliceBackward0,499302,,aten::copy_,499311,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1629189,475.0,61.916666666666664
autograd::engine::evaluate_function: SliceBackward0,499312,,aten::fill_,499318,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1629207,493.6666666666667,24.58111111111111
autograd::engine::evaluate_function: SliceBackward0,499312,,aten::copy_,499321,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1629213,485.3333333333333,25.774444444444445
autograd::engine::evaluate_function: SliceBackward0,499312,,aten::add,499322,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1629227,487.0,55.276666666666664
autograd::engine::evaluate_function: SplitBackward0,499323,,aten::cat,499325,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",1629243,501.3333333333333,256.6511111111111
autograd::engine::evaluate_function: AddmmBackward0,499334,,aten::mm,499339,"[[8192, 4608], [4608, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),1629266,555.0,1750.2188888888888
autograd::engine::evaluate_function: AddmmBackward0,499334,,aten::mm,499343,"[[4608, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,1629285,1740.0,1705.6833333333334
autograd::engine::evaluate_function: AddmmBackward0,499334,,aten::sum,499347,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",1629315,1699.0,76.6211111111111
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,499349,,aten::add_,499351,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1629322,510.0,3.658888888888889
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,499361,,aten::add_,499363,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1629333,447.6666666666667,114.35777777777778
autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward,499364,,nccl:all_reduce,499368,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",1629353,1056.0,757.3222222222222
autograd::engine::evaluate_function: NativeLayerNormBackward0,499370,,aten::native_layer_norm_backward,499372,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",1629420,771.0,425.9277777777778
autograd::engine::evaluate_function: NativeLayerNormBackward0,499370,,aten::native_layer_norm_backward,499372,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",1629422,486.6666666666667,223.9622222222222
autograd::engine::evaluate_function: NativeLayerNormBackward0,499370,,aten::add,499376,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1629443,500.0,212.19
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,499377,,aten::add_,499379,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1629451,502.6666666666667,3.9555555555555557
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,499380,,aten::add_,499382,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1629458,397.3333333333333,3.216666666666667
autograd::engine::evaluate_function: NativeLayerNormBackward0,499383,,aten::native_layer_norm_backward,499385,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",1629500,554.6666666666666,420.9066666666667
autograd::engine::evaluate_function: NativeLayerNormBackward0,499383,,aten::native_layer_norm_backward,499385,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",1629502,495.3333333333333,225.00666666666666
autograd::engine::evaluate_function: NativeLayerNormBackward0,499383,,aten::add,499389,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1629525,498.3333333333333,212.18333333333334
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,499394,,aten::add_,499396,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1629535,500.6666666666667,3.8855555555555554
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,499397,,aten::add_,499399,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1629542,405.0,3.161111111111111
