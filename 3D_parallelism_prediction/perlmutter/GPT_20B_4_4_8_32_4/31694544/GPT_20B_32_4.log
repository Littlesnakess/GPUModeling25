[2024-10-10 05:51:06,458] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
NeoXArgs.from_ymls() ['/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/configs/GPT_20B_4_4_8.yml', '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/configs/local_setup.yml']
INFO:root:NeoXArgs.calculate_derived() Total number of GPUs determined to be: 128
-------------------- arguments --------------------
  attention_config ................ ['global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global']updated
  batch_size ...................... 4...........................updated
  bias_gelu_fusion ................ True........................updated
  checkpoint_activations .......... True........................updated
  checkpoint_factor ............... 500.........................updated
  config_files .................... {'GPT_20B_4_4_8.yml': '# DISCLAIMER: This is the configuration file for the GPT-NeoX-20B model as it was trained on 96x 40GB A100\n# GPUs. Depending on your system configuration, you may need to change some parameters in order to fit\n# the model in memory.\n\n{\n  # Tokenizer /  checkpoint settings - you will need to change these to the location you have them saved in\n  # "vocab_file": "./20B_checkpoints/20B_tokenizer.json",\n  # "save": "./20B_checkpoints",\n  # "load": "./20B_checkpoints",\n\n  # If finetuning, edit the following to the location of your finetuning dataset:\n  # "data_path": "./data/pile_20B_tokenizer/pile_20B_tokenizer_text_document",\n\n  # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\n  # across the node boundaries )\n  "pipe_parallel_size": 4,\n  "model_parallel_size": 4,\n\n  # model settings\n  "num_layers": 44,\n  "hidden_size": 6144,\n  "num_attention_heads": 64,\n  "seq_length": 2048,\n  "max_position_embeddings": 2048,\n  "norm": "layernorm",\n  "pos_emb": "rotary",\n  "rotary_pct": 0.25,\n  "no_weight_tying": true,\n  "gpt_j_residual": true,\n  "output_layer_parallelism": "column",\n  "scaled_upper_triang_masked_softmax_fusion": true,\n  "bias_gelu_fusion": true,\n  "rope_fusion": false,\n  "layernorm_fusion": false,\n\n  # init methods\n  "init_method": "small_init",\n  "output_layer_init_method": "wang_init",\n\n  # optimizer settings\n  "optimizer": {\n    "type": "Adam",\n    "params": {\n      "lr": 0.97e-4,\n      "betas": [0.9, 0.95],\n      "eps": 1.0e-8,\n      }\n      },\n\n  "min_lr": 0.97e-5,\n\n  # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training\n  "zero_optimization": {\n  "stage": 1,\n  "allgather_partitions": True,\n  "allgather_bucket_size": 1260000000,\n  "overlap_comm": True,\n  "reduce_scatter": True,\n  "reduce_bucket_size": 1260000000,\n  "contiguous_gradients": True,\n  },\n\n  # batch / data settings (assuming 96 GPUs)\n  "train_micro_batch_size_per_gpu": 4,\n  "gradient_accumulation_steps": 16,\n  "data_impl": "mmap",\n  "split": "995,4,1",\n\n  # activation checkpointing\n  "checkpoint_activations": true,\n  "checkpoint_num_layers": 1,\n  "partition_activations": false,\n  "synchronize_each_layer": true,\n\n  # regularization\n  "gradient_clipping": 1.0,\n  "weight_decay": 0.01,\n  "hidden_dropout": 0,\n  "attention_dropout": 0,\n\n  # precision settings\n  "fp16": {\n    "fp16": true,\n    "enabled": true,\n    "loss_scale": 0,\n    "loss_scale_window": 1000,\n    "initial_scale_power": 12,\n    "hysteresis": 2,\n    "min_loss_scale": 1\n    },\n\n  # misc. training settings\n  "train_iters": 8,\n  "lr_decay_iters": 8,\n\n  "distributed_backend": "nccl",\n  "lr_decay_style": "cosine",\n  "warmup": 0.01,\n  "checkpoint_factor": 500, # this variable previously called `save-interval`\n  "eval_interval": 1000,\n  "eval_iters": 10,\n\n  # logging\n  "log_interval": 1,\n  "steps_per_print": 1,\n  "wall_clock_breakdown": true,\n\n  ### NEW DATA: ####\n  # "tokenizer_type": "HFTokenizer",\n  # "tensorboard-dir": "./tensorboard",\n  # "log_dir": "./logs",\n\n  # distributed training settings\n  # "launcher": "slurm",\n  # "deepspeed_slurm": true,\n\n  # profiling settings\n  "profile": True,\n  "profile_step_start": 2,\n  "profile_step_stop": 7,\n}', 'local_setup.yml': '# Suggested data paths when using GPT-NeoX locally\n{\n  # "data_path": "/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/data/pile_text_document",\n  # "data_path": "/pscratch/sd/z/zhaozh/data/pile/processed/pile_text_document",\n\n  "data-path": "/pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document",\n\n  # or for weighted datasets:\n  # "train-data-paths": ["data/enwik8/enwik8_text_document", "data/enwik8/enwik8_text_document"],\n  # "test-data-paths": ["data/enwik8/enwik8_text_document", "data/enwik8/enwik8_text_document"],\n  # "valid-data-paths": ["data/enwik8/enwik8_text_document", "data/enwik8/enwik8_text_document"],\n  # "train-data-weights": [1., 2.],\n  # "test-data-weights": [2., 1.],\n  # "valid-data-weights": [0.5, 0.4],\n\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\n  # WARNING: setting this to True will override any user provided weights\n  # "weight_by_num_documents": false,\n  # "weighted_sampler_alpha": 0.3,\n\n  "vocab_file": "/pscratch/sd/z/zhaozh/data/pile/gpt2-vocab.json",\n  "merge_file": "/pscratch/sd/z/zhaozh/data/pile/gpt2-merges.txt",\n\n  "save": "checkpoints-test",\n  "load": "checkpoints-test2",\n  "checkpoint_validation_with_forward_pass": False,\n\n  "tensorboard_dir": "tensorboard",\n  "log_dir": "logs",\n  "use_wandb": True,\n  "wandb_host": "https://api.wandb.ai",\n  "wandb_project": "neox"\n}\n'}updated
  data_impl ....................... mmap........................updated
  data_path ....................... /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_documentupdated
  dynamic_loss_scale .............. True........................updated
  eval_iters ...................... 10..........................updated
  fp16 ............................ {'fp16': True, 'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 12, 'hysteresis': 2, 'min_loss_scale': 1}updated
  global_num_gpus ................. 128.........................updated
  gpt_j_residual .................. True........................updated
  gradient_accumulation_steps ..... 16..........................updated
  hidden_size ..................... 6144........................updated
  init_method ..................... small_init..................updated
  is_pipe_parallel ................ True........................updated
  load ............................ checkpoints-test2...........updated
  log_dir ......................... logs........................updated
  log_interval .................... 1...........................updated
  lr .............................. 9.7e-05.....................updated
  lr_decay_iters .................. 8...........................updated
  lr_decay_style .................. cosine......................updated
  max_position_embeddings ......... 2048........................updated
  merge_file ...................... /pscratch/sd/z/zhaozh/data/pile/gpt2-merges.txtupdated
  min_lr .......................... 9.7e-06.....................updated
  model_parallel_size ............. 4...........................updated
  no_weight_tying ................. True........................updated
  num_attention_heads ............. 64..........................updated
  num_layers ...................... 44..........................updated
  optimizer ....................... {'type': 'Adam', 'params': {'lr': 9.7e-05, 'betas': [0.9, 0.95], 'eps': 1e-08}}updated
  optimizer_type .................. Adam........................updated
  output_layer_init_method ........ wang_init...................updated
  pipe_parallel_size .............. 4...........................updated
  pos_emb ......................... rotary......................updated
  precision ....................... fp16........................updated
  profile ......................... True........................updated
  profile_step_start .............. 2...........................updated
  profile_step_stop ............... 7...........................updated
  rotary_pct ...................... 0.25........................updated
  save ............................ checkpoints-test............updated
  save_iters ...................... []..........................updated
  scaled_upper_triang_masked_softmax_fusion  True...............updated
  seq_length ...................... 2048........................updated
  sparsity_config ................. {}..........................updated
  split ........................... 995,4,1.....................updated
  steps_per_print ................. 1...........................updated
  synchronize_each_layer .......... True........................updated
  tensorboard_dir ................. tensorboard.................updated
  text_gen_type ................... unconditional...............updated
  train_batch_size ................ 512.........................updated
  train_iters ..................... 8...........................updated
  train_micro_batch_size_per_gpu .. 4...........................updated
  use_wandb ....................... True........................updated
  user_script ..................... /pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/train_profiling.pyupdated
  vocab_file ...................... /pscratch/sd/z/zhaozh/data/pile/gpt2-vocab.jsonupdated
  wall_clock_breakdown ............ True........................updated
  wandb_group ..................... crjai6vc_lw7qypmw...........updated
  weight_decay .................... 0.01........................updated
  zero_allgather_bucket_size ...... 1260000000..................updated
  zero_contiguous_gradients ....... True........................updated
  zero_optimization ............... {'stage': 1, 'allgather_partitions': True, 'allgather_bucket_size': 1260000000, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 1260000000, 'contiguous_gradients': True}updated
  zero_reduce_bucket_size ......... 1260000000..................updated
  zero_reduce_scatter ............. True........................updated
  zero_stage ...................... 1...........................updated
  account ......................... None........................default
  activation ...................... gelu........................default
  activation_checkpointing ........ None........................default
  adlr_autoresume ................. False.......................default
  adlr_autoresume_interval ........ 1000........................default
  allow_chopped ................... True........................default
  amp ............................. None........................default
  apply_query_key_layer_scaling ... False.......................default
  attention_dropout ............... 0...........................default
  attention_softmax_in_fp32 ....... False.......................default
  autotuning ...................... None........................default
  autotuning_run .................. None........................default
  base_shapes_file ................ None........................default
  bf16 ............................ None........................default
  bias_dropout_fusion ............. False.......................default
  char_level_ppl .................. False.......................default
  checkpoint ...................... None........................default
  checkpoint_in_cpu ............... False.......................default
  checkpoint_num_layers ........... 1...........................default
  checkpoint_scale ................ linear......................default
  checkpoint_validation_with_forward_pass  False................default
  clip_grad ....................... 1.0.........................default
  comet_experiment_name ........... None........................default
  comet_others .................... None........................default
  comet_project ................... None........................default
  comet_tags ...................... None........................default
  comet_workspace ................. None........................default
  comment ......................... None........................default
  comms_logger .................... None........................default
  communication_data_type ......... None........................default
  compression_training ............ None........................default
  contiguous_checkpointing ........ False.......................default
  coord_check ..................... False.......................default
  create_moe_param_group .......... True........................default
  csv_monitor ..................... None........................default
  curriculum_learning ............. None........................default
  curriculum_seqlen ............... 0...........................default
  data_efficiency ................. None........................default
  data_types ...................... None........................default
  dataset_impl .................... gpt2........................default
  deepscale ....................... False.......................default
  deepscale_config ................ None........................default
  deepspeed ....................... True........................default
  deepspeed_activation_checkpointing  True......................default
  deepspeed_extra_args ............ None........................default
  deepspeed_mpi ................... False.......................default
  deepspeed_slurm ................. False.......................default
  detect_nvlink_pairs ............. False.......................default
  distributed_backend ............. nccl........................default
  do_test ......................... None........................default
  do_train ........................ None........................default
  do_valid ........................ None........................default
  dpo_beta ........................ 0.1.........................default
  dpo_fp32 ........................ True........................default
  dpo_reference_free .............. False.......................default
  dump_state ...................... False.......................default
  elasticity ...................... None........................default
  enable_expert_tensor_parallelism  False.......................default
  eod_mask_loss ................... False.......................default
  eval_interval ................... 1000........................default
  eval_results_prefix ............. ............................default
  eval_tasks ...................... None........................default
  exclude ......................... None........................default
  exit_interval ................... None........................default
  expansion_factor ................ None........................default
  expert_interval ................. 2...........................default
  extra_save_iters ................ None........................default
  finetune ........................ False.......................default
  flops_profiler .................. None........................default
  force_multi ..................... False.......................default
  fp16_lm_cross_entropy ........... False.......................default
  fp32_allreduce .................. False.......................default
  git_hash ........................ d79c5331....................default
  gmlp_attn_dim ................... 64..........................default
  gpt_j_tied ...................... False.......................default
  gradient_clipping ............... 1.0.........................default
  gradient_noise_scale_cpu_offload  False.......................default
  gradient_noise_scale_n_batches .. 5...........................default
  gradient_predivide_factor ....... 1.0.........................default
  hidden_dropout .................. 0...........................default
  hostfile ........................ None........................default
  hysteresis ...................... 2...........................default
  include ......................... None........................default
  init_method_std ................. 0.02........................default
  intermediate_size ............... None........................default
  iteration ....................... None........................default
  keep_last_n_checkpoints ......... None........................default
  kto_beta ........................ 0.1.........................default
  kto_desirable_weight ............ 1.0.........................default
  kto_fp32 ........................ True........................default
  kto_undesirable_weight .......... 1.0.........................default
  launcher ........................ pdsh........................default
  layernorm_epsilon ............... 1e-05.......................default
  layernorm_fusion ................ False.......................default
  lazy_mpu_init ................... False.......................default
  local_rank ...................... None........................default
  log_grad_norm ................... False.......................default
  log_grad_pct_zeros .............. False.......................default
  log_gradient_noise_scale ........ False.......................default
  log_optimizer_states ............ False.......................default
  log_param_norm .................. False.......................default
  loss_scale ...................... None........................default
  loss_scale_window ............... 1000.0......................default
  make_vocab_size_divisible_by .... 128.........................default
  mamba_causal_conv_fusion ........ False.......................default
  mamba_inner_func_fusion ......... False.......................default
  mamba_selective_fp32_params ..... True........................default
  mamba_selective_scan_fusion ..... False.......................default
  mamba_use_bias_in_conv .......... True........................default
  mamba_use_bias_in_linears ....... False.......................default
  master_addr ..................... None........................default
  master_port ..................... 29500.......................default
  maximum_tokens .................. 64..........................default
  memory_profiling ................ False.......................default
  memory_profiling_path ........... None........................default
  min_scale ....................... 1.0.........................default
  mlp_multiple_of ................. 1...........................default
  mmap_warmup ..................... False.......................default
  moe_eval_capacity_factor ........ 1.0.........................default
  moe_expert_parallel_size ........ 1...........................default
  moe_glu ......................... False.......................default
  moe_jitter_eps .................. None........................default
  moe_lbl_in_fp32 ................. False.......................default
  moe_loss_coeff .................. 0.1.........................default
  moe_min_capacity ................ 4...........................default
  moe_num_experts ................. 1...........................default
  moe_token_dropping .............. False.......................default
  moe_top_k ....................... 1...........................default
  moe_train_capacity_factor ....... 1.0.........................default
  moe_type ........................ megablocks..................default
  moe_use_residual ................ True........................default
  mup_attn_temp ................... 1.0.........................default
  mup_embedding_mult .............. 1.0.........................default
  mup_init_scale .................. 1.0.........................default
  mup_output_temp ................. 1.0.........................default
  mup_rp_embedding_mult ........... 1.0.........................default
  mup_width_scale ................. 2...........................default
  neg_test_data_paths ............. None........................default
  neg_test_label_data_paths ....... None........................default
  neg_train_data_paths ............ None........................default
  neg_train_label_data_paths ...... None........................default
  neg_valid_data_paths ............ None........................default
  neg_valid_label_data_paths ...... None........................default
  no_load_optim ................... False.......................default
  no_load_rng ..................... False.......................default
  no_save_optim ................... False.......................default
  no_save_rng ..................... False.......................default
  no_ssh_check .................... False.......................default
  norm ............................ layernorm...................default
  num_gpus ........................ None........................default
  num_kv_heads .................... None........................default
  num_nodes ....................... -1..........................default
  num_samples ..................... 1...........................default
  num_unique_layers ............... None........................default
  num_workers ..................... 2...........................default
  onnx_safe ....................... False.......................default
  opt_pos_emb_offset .............. 0...........................default
  output_layer_parallelism ........ column......................default
  override_lr_scheduler ........... False.......................default
  pack_impl ....................... packed......................default
  padded_vocab_size ............... None........................default
  param_sharing_style ............. grouped.....................default
  partition_activations ........... False.......................default
  pipe_partition_method ........... type:transformer|mlp........default
  pos_test_data_paths ............. None........................default
  pos_test_label_data_paths ....... None........................default
  pos_train_data_paths ............ None........................default
  pos_train_label_data_paths ...... None........................default
  pos_valid_data_paths ............ None........................default
  pos_valid_label_data_paths ...... None........................default
  precompute_model_name ........... None........................default
  prescale_gradients .............. False.......................default
  profile_backward ................ False.......................default
  prompt_end ...................... 
...........................default
  rank ............................ None........................default
  recompute ....................... False.......................default
  return_logits ................... False.......................default
  rms_norm_epsilon ................ 1e-08.......................default
  rmsnorm_fusion .................. False.......................default
  rope_fusion ..................... False.......................default
  rotary_emb_base ................. 10000.......................default
  rotary_save_freqs_buffer ........ False.......................default
  rpe_max_distance ................ 128.........................default
  rpe_num_buckets ................. 32..........................default
  s3_chunk_size ................... 104857600...................default
  s3_path ......................... None........................default
  sample_input_file ............... None........................default
  sample_output_file .............. samples.txt.................default
  save_base_shapes ................ False.......................default
  scaled_masked_softmax_fusion .... False.......................default
  scalenorm_epsilon ............... 1e-08.......................default
  scheduler ....................... None........................default
  seed ............................ 1234........................default
  sequence_parallel ............... False.......................default
  short_seq_prob .................. 0.1.........................default
  sliding_window_width ............ None........................default
  soft_prompt_tuning .............. None........................default
  sparse_attention ................ None........................default
  sparse_gradients ................ False.......................default
  temperature ..................... 0.0.........................default
  tensorboard ..................... None........................default
  test_data_paths ................. None........................default
  test_data_weights ............... None........................default
  test_label_data_paths ........... None........................default
  test_reward_data_paths .......... None........................default
  tokenizer_type .................. GPT2BPETokenizer............default
  top_k ........................... 0...........................default
  top_p ........................... 0.0.........................default
  train_data_paths ................ None........................default
  train_data_weights .............. None........................default
  train_impl ...................... normal......................default
  train_label_data_paths .......... None........................default
  train_reward_data_paths ......... None........................default
  use_bias_in_attn_linear ......... True........................default
  use_bias_in_mlp ................. True........................default
  use_bias_in_norms ............... True........................default
  use_bnb_optimizer ............... False.......................default
  use_checkpoint_lr_scheduler ..... False.......................default
  use_comet ....................... None........................default
  use_cpu_initialization .......... False.......................default
  use_flashattn_swiglu ............ False.......................default
  use_mup ......................... False.......................default
  use_qk_layernorm ................ False.......................default
  use_shared_fs ................... True........................default
  use_tutel ....................... False.......................default
  valid_data_paths ................ None........................default
  valid_data_weights .............. None........................default
  valid_label_data_paths .......... None........................default
  valid_reward_data_paths ......... None........................default
  wandb ........................... None........................default
  wandb_host ...................... https://api.wandb.ai........default
  wandb_init_all_ranks ............ False.......................default
  wandb_project ................... neox........................default
  wandb_team ...................... None........................default
  warmup .......................... 0.01........................default
  weight_by_num_documents ......... False.......................default
  weighted_sampler_alpha .......... 1.0.........................default
  world_size ...................... None........................default
---------------- end of arguments ----------------
NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 4 
[2024-10-10 05:51:30,176] [INFO] [multinode_runner.py:73:get_cmd] Running on the following workers: nid001412,nid001413,nid001416,nid001417,nid001589,nid001592,nid001593,nid001596,nid001597,nid001600,nid001601,nid001604,nid001605,nid001608,nid001609,nid001612,nid001613,nid001616,nid001617,nid001620,nid003692,nid003693,nid003696,nid003697,nid003700,nid003701,nid003704,nid003705,nid003708,nid003709,nid003712,nid003713
[2024-10-10 05:51:30,176] [INFO] [runner.py:586:main] cmd = pdsh -S -f 1024 -w nid001412,nid001413,nid001416,nid001417,nid001589,nid001592,nid001593,nid001596,nid001597,nid001600,nid001601,nid001604,nid001605,nid001608,nid001609,nid001612,nid001613,nid001616,nid001617,nid001620,nid003692,nid003693,nid003696,nid003697,nid003700,nid003701,nid003704,nid003705,nid003708,nid003709,nid003712,nid003713 export PYTHONPATH=/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/slurms:/opt/nersc/pymon; export NCCL_NET_GDR_LEVEL=PHB; export NCCL_SOCKET_IFNAME=hsn;  cd /pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/slurms; /pscratch/sd/z/zby2022/envs/gpt_neox_20240914/bin/python -u -m deepspeed.launcher.launch --world_info=eyJuaWQwMDE0MTIiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE0MTMiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE0MTYiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE0MTciOiBbMCwgMSwgMiwgM10sICJuaWQwMDE1ODkiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE1OTIiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE1OTMiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE1OTYiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE1OTciOiBbMCwgMSwgMiwgM10sICJuaWQwMDE2MDAiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE2MDEiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE2MDQiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE2MDUiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE2MDgiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE2MDkiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE2MTIiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE2MTMiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE2MTYiOiBbMCwgMSwgMiwgM10sICJuaWQwMDE2MTciOiBbMCwgMSwgMiwgM10sICJuaWQwMDE2MjAiOiBbMCwgMSwgMiwgM10sICJuaWQwMDM2OTIiOiBbMCwgMSwgMiwgM10sICJuaWQwMDM2OTMiOiBbMCwgMSwgMiwgM10sICJuaWQwMDM2OTYiOiBbMCwgMSwgMiwgM10sICJuaWQwMDM2OTciOiBbMCwgMSwgMiwgM10sICJuaWQwMDM3MDAiOiBbMCwgMSwgMiwgM10sICJuaWQwMDM3MDEiOiBbMCwgMSwgMiwgM10sICJuaWQwMDM3MDQiOiBbMCwgMSwgMiwgM10sICJuaWQwMDM3MDUiOiBbMCwgMSwgMiwgM10sICJuaWQwMDM3MDgiOiBbMCwgMSwgMiwgM10sICJuaWQwMDM3MDkiOiBbMCwgMSwgMiwgM10sICJuaWQwMDM3MTIiOiBbMCwgMSwgMiwgM10sICJuaWQwMDM3MTMiOiBbMCwgMSwgMiwgM119 --node_rank=%n --master_addr=nid001412 --master_port=29500 /pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/train_profiling.py --deepspeed_config 'eyJ0cmFpbl9iYXRjaF9zaXplIjogNTEyLCAidHJhaW5fbWljcm9fYmF0Y2hfc2l6ZV9wZXJfZ3B1IjogNCwgImdyYWRpZW50X2FjY3VtdWxhdGlvbl9zdGVwcyI6IDE2LCAib3B0aW1pemVyIjogeyJ0eXBlIjogIkFkYW0iLCAicGFyYW1zIjogeyJsciI6IDkuN2UtMDUsICJiZXRhcyI6IFswLjksIDAuOTVdLCAiZXBzIjogMWUtMDh9fSwgImZwMTYiOiB7ImZwMTYiOiB0cnVlLCAiZW5hYmxlZCI6IHRydWUsICJsb3NzX3NjYWxlIjogMCwgImxvc3Nfc2NhbGVfd2luZG93IjogMTAwMCwgImluaXRpYWxfc2NhbGVfcG93ZXIiOiAxMiwgImh5c3RlcmVzaXMiOiAyLCAibWluX2xvc3Nfc2NhbGUiOiAxfSwgInplcm9fb3B0aW1pemF0aW9uIjogeyJzdGFnZSI6IDEsICJhbGxnYXRoZXJfcGFydGl0aW9ucyI6IHRydWUsICJhbGxnYXRoZXJfYnVja2V0X3NpemUiOiAxMjYwMDAwMDAwLCAib3ZlcmxhcF9jb21tIjogdHJ1ZSwgInJlZHVjZV9zY2F0dGVyIjogdHJ1ZSwgInJlZHVjZV9idWNrZXRfc2l6ZSI6IDEyNjAwMDAwMDAsICJjb250aWd1b3VzX2dyYWRpZW50cyI6IHRydWV9LCAic3RlcHNfcGVyX3ByaW50IjogMSwgIndhbGxfY2xvY2tfYnJlYWtkb3duIjogdHJ1ZX0=' --megatron_config '{"train_batch_size": 512, "train_micro_batch_size_per_gpu": 4, "gradient_accumulation_steps": 16, "optimizer": {"type": "Adam", "params": {"lr": 9.7e-05, "betas": [0.9, 0.95], "eps": 1e-08}}, "fp16": {"fp16": true, "enabled": true, "loss_scale": 0, "loss_scale_window": 1000, "initial_scale_power": 12, "hysteresis": 2, "min_loss_scale": 1}, "zero_optimization": {"stage": 1, "allgather_partitions": true, "allgather_bucket_size": 1260000000, "overlap_comm": true, "reduce_scatter": true, "reduce_bucket_size": 1260000000, "contiguous_gradients": true}, "steps_per_print": 1, "wall_clock_breakdown": true, "precision": "fp16", "num_layers": 44, "hidden_size": 6144, "num_attention_heads": 64, "seq_length": 2048, "max_position_embeddings": 2048, "pos_emb": "rotary", "no_weight_tying": true, "attention_config": ["global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global"], "sparsity_config": {}, "scaled_upper_triang_masked_softmax_fusion": true, "bias_gelu_fusion": true, "rotary_pct": 0.25, "init_method": "small_init", "output_layer_init_method": "wang_init", "gpt_j_residual": true, "lr_decay_style": "cosine", "lr_decay_iters": 8, "min_lr": 9.7e-06, "optimizer_type": "Adam", "zero_stage": 1, "zero_reduce_scatter": true, "zero_contiguous_gradients": true, "zero_reduce_bucket_size": 1260000000, "zero_allgather_bucket_size": 1260000000, "lr": 9.7e-05, "data_path": "/pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document", "data_impl": "mmap", "save": "checkpoints-test", "config_files": {"GPT_20B_4_4_8.yml": "# DISCLAIMER: This is the configuration file for the GPT-NeoX-20B model as it was trained on 96x 40GB A100\n# GPUs. Depending on your system configuration, you may need to change some parameters in order to fit\n# the model in memory.\n\n{\n  # Tokenizer /  checkpoint settings - you will need to change these to the location you have them saved in\n  # \"vocab_file\": \"./20B_checkpoints/20B_tokenizer.json\",\n  # \"save\": \"./20B_checkpoints\",\n  # \"load\": \"./20B_checkpoints\",\n\n  # If finetuning, edit the following to the location of your finetuning dataset:\n  # \"data_path\": \"./data/pile_20B_tokenizer/pile_20B_tokenizer_text_document\",\n\n  # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\n  # across the node boundaries )\n  \"pipe_parallel_size\": 4,\n  \"model_parallel_size\": 4,\n\n  # model settings\n  \"num_layers\": 44,\n  \"hidden_size\": 6144,\n  \"num_attention_heads\": 64,\n  \"seq_length\": 2048,\n  \"max_position_embeddings\": 2048,\n  \"norm\": \"layernorm\",\n  \"pos_emb\": \"rotary\",\n  \"rotary_pct\": 0.25,\n  \"no_weight_tying\": true,\n  \"gpt_j_residual\": true,\n  \"output_layer_parallelism\": \"column\",\n  \"scaled_upper_triang_masked_softmax_fusion\": true,\n  \"bias_gelu_fusion\": true,\n  \"rope_fusion\": false,\n  \"layernorm_fusion\": false,\n\n  # init methods\n  \"init_method\": \"small_init\",\n  \"output_layer_init_method\": \"wang_init\",\n\n  # optimizer settings\n  \"optimizer\": {\n    \"type\": \"Adam\",\n    \"params\": {\n      \"lr\": 0.97e-4,\n      \"betas\": [0.9, 0.95],\n      \"eps\": 1.0e-8,\n      }\n      },\n\n  \"min_lr\": 0.97e-5,\n\n  # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training\n  \"zero_optimization\": {\n  \"stage\": 1,\n  \"allgather_partitions\": True,\n  \"allgather_bucket_size\": 1260000000,\n  \"overlap_comm\": True,\n  \"reduce_scatter\": True,\n  \"reduce_bucket_size\": 1260000000,\n  \"contiguous_gradients\": True,\n  },\n\n  # batch / data settings (assuming 96 GPUs)\n  \"train_micro_batch_size_per_gpu\": 4,\n  \"gradient_accumulation_steps\": 16,\n  \"data_impl\": \"mmap\",\n  \"split\": \"995,4,1\",\n\n  # activation checkpointing\n  \"checkpoint_activations\": true,\n  \"checkpoint_num_layers\": 1,\n  \"partition_activations\": false,\n  \"synchronize_each_layer\": true,\n\n  # regularization\n  \"gradient_clipping\": 1.0,\n  \"weight_decay\": 0.01,\n  \"hidden_dropout\": 0,\n  \"attention_dropout\": 0,\n\n  # precision settings\n  \"fp16\": {\n    \"fp16\": true,\n    \"enabled\": true,\n    \"loss_scale\": 0,\n    \"loss_scale_window\": 1000,\n    \"initial_scale_power\": 12,\n    \"hysteresis\": 2,\n    \"min_loss_scale\": 1\n    },\n\n  # misc. training settings\n  \"train_iters\": 8,\n  \"lr_decay_iters\": 8,\n\n  \"distributed_backend\": \"nccl\",\n  \"lr_decay_style\": \"cosine\",\n  \"warmup\": 0.01,\n  \"checkpoint_factor\": 500, # this variable previously called `save-interval`\n  \"eval_interval\": 1000,\n  \"eval_iters\": 10,\n\n  # logging\n  \"log_interval\": 1,\n  \"steps_per_print\": 1,\n  \"wall_clock_breakdown\": true,\n\n  ### NEW DATA: ####\n  # \"tokenizer_type\": \"HFTokenizer\",\n  # \"tensorboard-dir\": \"./tensorboard\",\n  # \"log_dir\": \"./logs\",\n\n  # distributed training settings\n  # \"launcher\": \"slurm\",\n  # \"deepspeed_slurm\": true,\n\n  # profiling settings\n  \"profile\": True,\n  \"profile_step_start\": 2,\n  \"profile_step_stop\": 7,\n}", "local_setup.yml": "# Suggested data paths when using GPT-NeoX locally\n{\n  # \"data_path\": \"/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/data/pile_text_document\",\n  # \"data_path\": \"/pscratch/sd/z/zhaozh/data/pile/processed/pile_text_document\",\n\n  \"data-path\": \"/pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document\",\n\n  # or for weighted datasets:\n  # \"train-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"test-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"valid-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"train-data-weights\": [1., 2.],\n  # \"test-data-weights\": [2., 1.],\n  # \"valid-data-weights\": [0.5, 0.4],\n\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\n  # WARNING: setting this to True will override any user provided weights\n  # \"weight_by_num_documents\": false,\n  # \"weighted_sampler_alpha\": 0.3,\n\n  \"vocab_file\": \"/pscratch/sd/z/zhaozh/data/pile/gpt2-vocab.json\",\n  \"merge_file\": \"/pscratch/sd/z/zhaozh/data/pile/gpt2-merges.txt\",\n\n  \"save\": \"checkpoints-test\",\n  \"load\": \"checkpoints-test2\",\n  \"checkpoint_validation_with_forward_pass\": False,\n\n  \"tensorboard_dir\": \"tensorboard\",\n  \"log_dir\": \"logs\",\n  \"use_wandb\": True,\n  \"wandb_host\": \"https://api.wandb.ai\",\n  \"wandb_project\": \"neox\"\n}\n"}, "load": "checkpoints-test2", "checkpoint_factor": 500, "batch_size": 4, "train_iters": 8, "eval_iters": 10, "split": "995,4,1", "vocab_file": "/pscratch/sd/z/zhaozh/data/pile/gpt2-vocab.json", "merge_file": "/pscratch/sd/z/zhaozh/data/pile/gpt2-merges.txt", "weight_decay": 0.01, "checkpoint_activations": true, "synchronize_each_layer": true, "dynamic_loss_scale": true, "pipe_parallel_size": 4, "model_parallel_size": 4, "world_size": 1, "is_pipe_parallel": true, "use_wandb": true, "wandb_group": "crjai6vc_lw7qypmw", "log_dir": "logs", "tensorboard_dir": "tensorboard", "log_interval": 1, "profile": true, "profile_step_start": 2, "profile_step_stop": 7, "text_gen_type": "unconditional", "local_rank": 0, "rank": 0, "user_script": "/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/train_profiling.py", "save_iters": [], "global_num_gpus": 128}'
nid001413: ***************************************************************************
nid001413:                           NOTICE TO USERS
nid001413: 
nid001413: Lawrence Berkeley National Laboratory operates this computer system under 
nid001413: contract to the U.S. Department of Energy.  This computer system is the 
nid001413: property of the United States Government and is for authorized use only.
nid001413: Users (authorized or unauthorized) have no explicit or implicit 
nid001413: expectation of privacy.
nid001413: 
nid001413: Any or all uses of this system and all files on this system may be
nid001413: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001413: to authorized site, Department of Energy, and law enforcement personnel,
nid001413: as well as authorized officials of other agencies, both domestic and foreign.
nid001413: By using this system, the user consents to such interception, monitoring,
nid001413: recording, copying, auditing, inspection, and disclosure at the discretion
nid001413: of authorized site or Department of Energy personnel.
nid001413: 
nid001413: Unauthorized or improper use of this system may result in administrative
nid001413: disciplinary action and civil and criminal penalties. By continuing to use
nid001413: this system you indicate your awareness of and consent to these terms and
nid001413: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001413: stated in this warning.
nid001413: 
nid001413: *****************************************************************************
nid001413: 
nid001413: Login connection to host x1001c4s7b0n1:
nid001413: 
nid001412: ***************************************************************************
nid001412:                           NOTICE TO USERS
nid001412: 
nid001412: Lawrence Berkeley National Laboratory operates this computer system under 
nid001412: contract to the U.S. Department of Energy.  This computer system is the 
nid001412: property of the United States Government and is for authorized use only.
nid001412: Users (authorized or unauthorized) have no explicit or implicit 
nid001412: expectation of privacy.
nid001412: 
nid001412: Any or all uses of this system and all files on this system may be
nid001412: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001412: to authorized site, Department of Energy, and law enforcement personnel,
nid001412: as well as authorized officials of other agencies, both domestic and foreign.
nid001412: By using this system, the user consents to such interception, monitoring,
nid001412: recording, copying, auditing, inspection, and disclosure at the discretion
nid001412: of authorized site or Department of Energy personnel.
nid001412: 
nid001412: Unauthorized or improper use of this system may result in administrative
nid001412: disciplinary action and civil and criminal penalties. By continuing to use
nid001412: this system you indicate your awareness of and consent to these terms and
nid001412: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001412: stated in this warning.
nid001412: 
nid001412: *****************************************************************************
nid001412: 
nid001412: Login connection to host x1001c4s7b0n0:
nid001412: 
nid001597: ***************************************************************************
nid001597:                           NOTICE TO USERS
nid001597: 
nid001597: Lawrence Berkeley National Laboratory operates this computer system under 
nid001597: contract to the U.S. Department of Energy.  This computer system is the 
nid001597: property of the United States Government and is for authorized use only.
nid001597: Users (authorized or unauthorized) have no explicit or implicit 
nid001597: expectation of privacy.
nid001597: 
nid001597: Any or all uses of this system and all files on this system may be
nid001597: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001597: to authorized site, Department of Energy, and law enforcement personnel,
nid001597: as well as authorized officials of other agencies, both domestic and foreign.
nid001597: By using this system, the user consents to such interception, monitoring,
nid001597: recording, copying, auditing, inspection, and disclosure at the discretion
nid001597: of authorized site or Department of Energy personnel.
nid001597: 
nid001597: Unauthorized or improper use of this system may result in administrative
nid001597: disciplinary action and civil and criminal penalties. By continuing to use
nid001597: this system you indicate your awareness of and consent to these terms and
nid001597: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001597: stated in this warning.
nid001597: 
nid001597: *****************************************************************************
nid001597: 
nid001597: Login connection to host x1002c2s5b0n1:
nid001597: 
nid003700: ***************************************************************************
nid003700:                           NOTICE TO USERS
nid003700: 
nid003700: Lawrence Berkeley National Laboratory operates this computer system under 
nid003700: contract to the U.S. Department of Energy.  This computer system is the 
nid003700: property of the United States Government and is for authorized use only.
nid003700: Users (authorized or unauthorized) have no explicit or implicit 
nid003700: expectation of privacy.
nid003700: 
nid003700: Any or all uses of this system and all files on this system may be
nid003700: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid003700: to authorized site, Department of Energy, and law enforcement personnel,
nid003700: as well as authorized officials of other agencies, both domestic and foreign.
nid003700: By using this system, the user consents to such interception, monitoring,
nid003700: recording, copying, auditing, inspection, and disclosure at the discretion
nid003700: of authorized site or Department of Energy personnel.
nid003700: 
nid003700: Unauthorized or improper use of this system may result in administrative
nid003700: disciplinary action and civil and criminal penalties. By continuing to use
nid003700: this system you indicate your awareness of and consent to these terms and
nid003700: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid003700: stated in this warning.
nid003700: 
nid003700: *****************************************************************************
nid003700: 
nid003700: Login connection to host x1202c4s3b0n0:
nid003700: 
nid001608: ***************************************************************************
nid001608:                           NOTICE TO USERS
nid001608: 
nid001608: Lawrence Berkeley National Laboratory operates this computer system under 
nid001608: contract to the U.S. Department of Energy.  This computer system is the 
nid001608: property of the United States Government and is for authorized use only.
nid001608: Users (authorized or unauthorized) have no explicit or implicit 
nid001608: expectation of privacy.
nid001608: 
nid001608: Any or all uses of this system and all files on this system may be
nid001608: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001608: to authorized site, Department of Energy, and law enforcement personnel,
nid001608: as well as authorized officials of other agencies, both domestic and foreign.
nid001608: By using this system, the user consents to such interception, monitoring,
nid001608: recording, copying, auditing, inspection, and disclosure at the discretion
nid001608: of authorized site or Department of Energy personnel.
nid001608: 
nid001608: Unauthorized or improper use of this system may result in administrative
nid001608: disciplinary action and civil and criminal penalties. By continuing to use
nid001608: this system you indicate your awareness of and consent to these terms and
nid001608: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001608: stated in this warning.
nid001608: 
nid001608: *****************************************************************************
nid001608: 
nid001608: Login connection to host x1002c3s0b0n0:
nid001608: 
nid001617: ***************************************************************************
nid001617:                           NOTICE TO USERS
nid001617: 
nid001617: Lawrence Berkeley National Laboratory operates this computer system under 
nid001617: contract to the U.S. Department of Energy.  This computer system is the 
nid001617: property of the United States Government and is for authorized use only.
nid001617: Users (authorized or unauthorized) have no explicit or implicit 
nid001617: expectation of privacy.
nid001617: 
nid001617: Any or all uses of this system and all files on this system may be
nid001617: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001617: to authorized site, Department of Energy, and law enforcement personnel,
nid001617: as well as authorized officials of other agencies, both domestic and foreign.
nid001617: By using this system, the user consents to such interception, monitoring,
nid001617: recording, copying, auditing, inspection, and disclosure at the discretion
nid001617: of authorized site or Department of Energy personnel.
nid001617: 
nid001617: Unauthorized or improper use of this system may result in administrative
nid001617: disciplinary action and civil and criminal penalties. By continuing to use
nid001617: this system you indicate your awareness of and consent to these terms and
nid001617: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001617: stated in this warning.
nid001617: 
nid001617: *****************************************************************************
nid001617: 
nid001617: Login connection to host x1002c3s2b0n1:
nid001617: 
nid003696: ***************************************************************************
nid003696:                           NOTICE TO USERS
nid003696: 
nid003696: Lawrence Berkeley National Laboratory operates this computer system under 
nid003696: contract to the U.S. Department of Energy.  This computer system is the 
nid003696: property of the United States Government and is for authorized use only.
nid003696: Users (authorized or unauthorized) have no explicit or implicit 
nid003696: expectation of privacy.
nid003696: 
nid003696: Any or all uses of this system and all files on this system may be
nid003696: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid003696: to authorized site, Department of Energy, and law enforcement personnel,
nid003696: as well as authorized officials of other agencies, both domestic and foreign.
nid003696: By using this system, the user consents to such interception, monitoring,
nid003696: recording, copying, auditing, inspection, and disclosure at the discretion
nid003696: of authorized site or Department of Energy personnel.
nid003696: 
nid003696: Unauthorized or improper use of this system may result in administrative
nid003696: disciplinary action and civil and criminal penalties. By continuing to use
nid003696: this system you indicate your awareness of and consent to these terms and
nid003696: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid003696: stated in this warning.
nid003696: 
nid003696: *****************************************************************************
nid003696: 
nid003696: Login connection to host x1202c4s2b0n0:
nid003696: 
nid001417: ***************************************************************************
nid001417:                           NOTICE TO USERS
nid001417: 
nid001417: Lawrence Berkeley National Laboratory operates this computer system under 
nid001417: contract to the U.S. Department of Energy.  This computer system is the 
nid001417: property of the United States Government and is for authorized use only.
nid001417: Users (authorized or unauthorized) have no explicit or implicit 
nid001417: expectation of privacy.
nid001417: 
nid001417: Any or all uses of this system and all files on this system may be
nid001417: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001417: to authorized site, Department of Energy, and law enforcement personnel,
nid001417: as well as authorized officials of other agencies, both domestic and foreign.
nid001417: By using this system, the user consents to such interception, monitoring,
nid001417: recording, copying, auditing, inspection, and disclosure at the discretion
nid001417: of authorized site or Department of Energy personnel.
nid001417: 
nid001417: Unauthorized or improper use of this system may result in administrative
nid001417: disciplinary action and civil and criminal penalties. By continuing to use
nid001417: this system you indicate your awareness of and consent to these terms and
nid001417: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001417: stated in this warning.
nid001417: 
nid001417: *****************************************************************************
nid001417: 
nid001417: Login connection to host x1001c5s0b0n1:
nid001417: 
nid001592: ***************************************************************************
nid001592:                           NOTICE TO USERS
nid001592: 
nid001592: Lawrence Berkeley National Laboratory operates this computer system under 
nid001592: contract to the U.S. Department of Energy.  This computer system is the 
nid001592: property of the United States Government and is for authorized use only.
nid001592: Users (authorized or unauthorized) have no explicit or implicit 
nid001592: expectation of privacy.
nid001592: 
nid001592: Any or all uses of this system and all files on this system may be
nid001592: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001592: to authorized site, Department of Energy, and law enforcement personnel,
nid001592: as well as authorized officials of other agencies, both domestic and foreign.
nid001592: By using this system, the user consents to such interception, monitoring,
nid001592: recording, copying, auditing, inspection, and disclosure at the discretion
nid001592: of authorized site or Department of Energy personnel.
nid001592: 
nid001592: Unauthorized or improper use of this system may result in administrative
nid001592: disciplinary action and civil and criminal penalties. By continuing to use
nid001592: this system you indicate your awareness of and consent to these terms and
nid001592: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001592: stated in this warning.
nid001592: 
nid001592: *****************************************************************************
nid001592: 
nid001592: Login connection to host x1002c2s4b0n0:
nid001592: 
nid003701: ***************************************************************************
nid003701:                           NOTICE TO USERS
nid003701: 
nid003701: Lawrence Berkeley National Laboratory operates this computer system under 
nid003701: contract to the U.S. Department of Energy.  This computer system is the 
nid003701: property of the United States Government and is for authorized use only.
nid003701: Users (authorized or unauthorized) have no explicit or implicit 
nid003701: expectation of privacy.
nid003701: 
nid003701: Any or all uses of this system and all files on this system may be
nid003701: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid003701: to authorized site, Department of Energy, and law enforcement personnel,
nid003701: as well as authorized officials of other agencies, both domestic and foreign.
nid003701: By using this system, the user consents to such interception, monitoring,
nid003701: recording, copying, auditing, inspection, and disclosure at the discretion
nid003701: of authorized site or Department of Energy personnel.
nid003701: 
nid003701: Unauthorized or improper use of this system may result in administrative
nid003701: disciplinary action and civil and criminal penalties. By continuing to use
nid003701: this system you indicate your awareness of and consent to these terms and
nid003701: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid003701: stated in this warning.
nid003701: 
nid003701: *****************************************************************************
nid003701: 
nid003701: Login connection to host x1202c4s3b0n1:
nid003701: 
nid003697: ***************************************************************************
nid003697:                           NOTICE TO USERS
nid003697: 
nid003697: Lawrence Berkeley National Laboratory operates this computer system under 
nid003697: contract to the U.S. Department of Energy.  This computer system is the 
nid003697: property of the United States Government and is for authorized use only.
nid003697: Users (authorized or unauthorized) have no explicit or implicit 
nid003697: expectation of privacy.
nid003697: 
nid003697: Any or all uses of this system and all files on this system may be
nid003697: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid003697: to authorized site, Department of Energy, and law enforcement personnel,
nid003697: as well as authorized officials of other agencies, both domestic and foreign.
nid003697: By using this system, the user consents to such interception, monitoring,
nid003697: recording, copying, auditing, inspection, and disclosure at the discretion
nid003697: of authorized site or Department of Energy personnel.
nid003697: 
nid003697: Unauthorized or improper use of this system may result in administrative
nid003697: disciplinary action and civil and criminal penalties. By continuing to use
nid003697: this system you indicate your awareness of and consent to these terms and
nid003697: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid003697: stated in this warning.
nid003697: 
nid003697: *****************************************************************************
nid003697: 
nid003697: Login connection to host x1202c4s2b0n1:
nid003697: 
nid001589: ***************************************************************************
nid001589:                           NOTICE TO USERS
nid001589: 
nid001589: Lawrence Berkeley National Laboratory operates this computer system under 
nid001589: contract to the U.S. Department of Energy.  This computer system is the 
nid001589: property of the United States Government and is for authorized use only.
nid001589: Users (authorized or unauthorized) have no explicit or implicit 
nid001589: expectation of privacy.
nid001589: 
nid001589: Any or all uses of this system and all files on this system may be
nid001589: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001589: to authorized site, Department of Energy, and law enforcement personnel,
nid001589: as well as authorized officials of other agencies, both domestic and foreign.
nid001589: By using this system, the user consents to such interception, monitoring,
nid001589: recording, copying, auditing, inspection, and disclosure at the discretion
nid001589: of authorized site or Department of Energy personnel.
nid001589: 
nid001589: Unauthorized or improper use of this system may result in administrative
nid001589: disciplinary action and civil and criminal penalties. By continuing to use
nid001589: this system you indicate your awareness of and consent to these terms and
nid001589: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001589: stated in this warning.
nid001589: 
nid001589: *****************************************************************************
nid001589: 
nid001589: Login connection to host x1002c2s3b0n1:
nid001589: 
nid003713: ***************************************************************************
nid003713:                           NOTICE TO USERS
nid003713: 
nid003713: Lawrence Berkeley National Laboratory operates this computer system under 
nid003713: contract to the U.S. Department of Energy.  This computer system is the 
nid003713: property of the United States Government and is for authorized use only.
nid003713: Users (authorized or unauthorized) have no explicit or implicit 
nid003713: expectation of privacy.
nid003713: 
nid003713: Any or all uses of this system and all files on this system may be
nid003713: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid003713: to authorized site, Department of Energy, and law enforcement personnel,
nid003713: as well as authorized officials of other agencies, both domestic and foreign.
nid003713: By using this system, the user consents to such interception, monitoring,
nid003713: recording, copying, auditing, inspection, and disclosure at the discretion
nid003713: of authorized site or Department of Energy personnel.
nid003713: 
nid003713: Unauthorized or improper use of this system may result in administrative
nid003713: disciplinary action and civil and criminal penalties. By continuing to use
nid003713: this system you indicate your awareness of and consent to these terms and
nid003713: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid003713: stated in this warning.
nid003713: 
nid003713: *****************************************************************************
nid003713: 
nid003713: Login connection to host x1202c4s6b0n1:
nid003713: 
nid003709: ***************************************************************************
nid003709:                           NOTICE TO USERS
nid003709: 
nid003709: Lawrence Berkeley National Laboratory operates this computer system under 
nid003709: contract to the U.S. Department of Energy.  This computer system is the 
nid003709: property of the United States Government and is for authorized use only.
nid003709: Users (authorized or unauthorized) have no explicit or implicit 
nid003709: expectation of privacy.
nid003709: 
nid003709: Any or all uses of this system and all files on this system may be
nid003709: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid003709: to authorized site, Department of Energy, and law enforcement personnel,
nid003709: as well as authorized officials of other agencies, both domestic and foreign.
nid003709: By using this system, the user consents to such interception, monitoring,
nid003709: recording, copying, auditing, inspection, and disclosure at the discretion
nid003709: of authorized site or Department of Energy personnel.
nid003709: 
nid003709: Unauthorized or improper use of this system may result in administrative
nid003709: disciplinary action and civil and criminal penalties. By continuing to use
nid003709: this system you indicate your awareness of and consent to these terms and
nid003709: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid003709: stated in this warning.
nid003709: 
nid003709: *****************************************************************************
nid003709: 
nid003709: Login connection to host x1202c4s5b0n1:
nid003709: 
nid001416: ***************************************************************************
nid001416:                           NOTICE TO USERS
nid001416: 
nid001416: Lawrence Berkeley National Laboratory operates this computer system under 
nid001416: contract to the U.S. Department of Energy.  This computer system is the 
nid001416: property of the United States Government and is for authorized use only.
nid001416: Users (authorized or unauthorized) have no explicit or implicit 
nid001416: expectation of privacy.
nid001416: 
nid001416: Any or all uses of this system and all files on this system may be
nid001416: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001416: to authorized site, Department of Energy, and law enforcement personnel,
nid001416: as well as authorized officials of other agencies, both domestic and foreign.
nid001416: By using this system, the user consents to such interception, monitoring,
nid001416: recording, copying, auditing, inspection, and disclosure at the discretion
nid001416: of authorized site or Department of Energy personnel.
nid001416: 
nid001416: Unauthorized or improper use of this system may result in administrative
nid001416: disciplinary action and civil and criminal penalties. By continuing to use
nid001416: this system you indicate your awareness of and consent to these terms and
nid001416: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001416: stated in this warning.
nid001416: 
nid001416: *****************************************************************************
nid001416: 
nid001416: Login connection to host x1001c5s0b0n0:
nid001416: 
nid001600: ***************************************************************************
nid001600:                           NOTICE TO USERS
nid001600: 
nid001600: Lawrence Berkeley National Laboratory operates this computer system under 
nid001600: contract to the U.S. Department of Energy.  This computer system is the 
nid001600: property of the United States Government and is for authorized use only.
nid001600: Users (authorized or unauthorized) have no explicit or implicit 
nid001600: expectation of privacy.
nid001600: 
nid001600: Any or all uses of this system and all files on this system may be
nid001600: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001600: to authorized site, Department of Energy, and law enforcement personnel,
nid001600: as well as authorized officials of other agencies, both domestic and foreign.
nid001600: By using this system, the user consents to such interception, monitoring,
nid001600: recording, copying, auditing, inspection, and disclosure at the discretion
nid001600: of authorized site or Department of Energy personnel.
nid001600: 
nid001600: Unauthorized or improper use of this system may result in administrative
nid001600: disciplinary action and civil and criminal penalties. By continuing to use
nid001600: this system you indicate your awareness of and consent to these terms and
nid001600: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001600: stated in this warning.
nid001600: 
nid001600: *****************************************************************************
nid001600: 
nid001600: Login connection to host x1002c2s6b0n0:
nid001600: 
nid003704: ***************************************************************************
nid003704:                           NOTICE TO USERS
nid003704: 
nid003704: Lawrence Berkeley National Laboratory operates this computer system under 
nid003704: contract to the U.S. Department of Energy.  This computer system is the 
nid003704: property of the United States Government and is for authorized use only.
nid003704: Users (authorized or unauthorized) have no explicit or implicit 
nid003704: expectation of privacy.
nid003704: 
nid003704: Any or all uses of this system and all files on this system may be
nid003704: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid003704: to authorized site, Department of Energy, and law enforcement personnel,
nid003704: as well as authorized officials of other agencies, both domestic and foreign.
nid003704: By using this system, the user consents to such interception, monitoring,
nid003704: recording, copying, auditing, inspection, and disclosure at the discretion
nid003704: of authorized site or Department of Energy personnel.
nid003704: 
nid003704: Unauthorized or improper use of this system may result in administrative
nid003704: disciplinary action and civil and criminal penalties. By continuing to use
nid003704: this system you indicate your awareness of and consent to these terms and
nid003704: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid003704: stated in this warning.
nid003704: 
nid003704: *****************************************************************************
nid003704: 
nid003704: Login connection to host x1202c4s4b0n0:
nid003704: 
nid001620: ***************************************************************************
nid001620:                           NOTICE TO USERS
nid001620: 
nid001620: Lawrence Berkeley National Laboratory operates this computer system under 
nid001620: contract to the U.S. Department of Energy.  This computer system is the 
nid001620: property of the United States Government and is for authorized use only.
nid001620: Users (authorized or unauthorized) have no explicit or implicit 
nid001620: expectation of privacy.
nid001620: 
nid001620: Any or all uses of this system and all files on this system may be
nid001620: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001620: to authorized site, Department of Energy, and law enforcement personnel,
nid001620: as well as authorized officials of other agencies, both domestic and foreign.
nid001620: By using this system, the user consents to such interception, monitoring,
nid001620: recording, copying, auditing, inspection, and disclosure at the discretion
nid001620: of authorized site or Department of Energy personnel.
nid001620: 
nid001620: Unauthorized or improper use of this system may result in administrative
nid001620: disciplinary action and civil and criminal penalties. By continuing to use
nid001620: this system you indicate your awareness of and consent to these terms and
nid001620: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001620: stated in this warning.
nid001620: 
nid001620: *****************************************************************************
nid001620: 
nid001620: Login connection to host x1002c3s3b0n0:
nid001620: 
nid003692: ***************************************************************************
nid003692:                           NOTICE TO USERS
nid003692: 
nid003692: Lawrence Berkeley National Laboratory operates this computer system under 
nid003692: contract to the U.S. Department of Energy.  This computer system is the 
nid003692: property of the United States Government and is for authorized use only.
nid003692: Users (authorized or unauthorized) have no explicit or implicit 
nid003692: expectation of privacy.
nid003692: 
nid003692: Any or all uses of this system and all files on this system may be
nid003692: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid003692: to authorized site, Department of Energy, and law enforcement personnel,
nid003692: as well as authorized officials of other agencies, both domestic and foreign.
nid003692: By using this system, the user consents to such interception, monitoring,
nid003692: recording, copying, auditing, inspection, and disclosure at the discretion
nid003692: of authorized site or Department of Energy personnel.
nid003692: 
nid003692: Unauthorized or improper use of this system may result in administrative
nid003692: disciplinary action and civil and criminal penalties. By continuing to use
nid003692: this system you indicate your awareness of and consent to these terms and
nid003692: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid003692: stated in this warning.
nid003692: 
nid003692: *****************************************************************************
nid003692: 
nid003692: Login connection to host x1202c4s1b0n0:
nid003692: 
nid001612: ***************************************************************************
nid001612:                           NOTICE TO USERS
nid001612: 
nid001612: Lawrence Berkeley National Laboratory operates this computer system under 
nid001612: contract to the U.S. Department of Energy.  This computer system is the 
nid001612: property of the United States Government and is for authorized use only.
nid001612: Users (authorized or unauthorized) have no explicit or implicit 
nid001612: expectation of privacy.
nid001612: 
nid001612: Any or all uses of this system and all files on this system may be
nid001612: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001612: to authorized site, Department of Energy, and law enforcement personnel,
nid001612: as well as authorized officials of other agencies, both domestic and foreign.
nid001612: By using this system, the user consents to such interception, monitoring,
nid001612: recording, copying, auditing, inspection, and disclosure at the discretion
nid001612: of authorized site or Department of Energy personnel.
nid001612: 
nid001612: Unauthorized or improper use of this system may result in administrative
nid001612: disciplinary action and civil and criminal penalties. By continuing to use
nid001612: this system you indicate your awareness of and consent to these terms and
nid001612: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001612: stated in this warning.
nid001612: 
nid001612: *****************************************************************************
nid001612: 
nid001612: Login connection to host x1002c3s1b0n0:
nid001612: 
nid003693: ***************************************************************************
nid003693:                           NOTICE TO USERS
nid003693: 
nid003693: Lawrence Berkeley National Laboratory operates this computer system under 
nid003693: contract to the U.S. Department of Energy.  This computer system is the 
nid003693: property of the United States Government and is for authorized use only.
nid003693: Users (authorized or unauthorized) have no explicit or implicit 
nid003693: expectation of privacy.
nid003693: 
nid003693: Any or all uses of this system and all files on this system may be
nid003693: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid003693: to authorized site, Department of Energy, and law enforcement personnel,
nid003693: as well as authorized officials of other agencies, both domestic and foreign.
nid003693: By using this system, the user consents to such interception, monitoring,
nid003693: recording, copying, auditing, inspection, and disclosure at the discretion
nid003693: of authorized site or Department of Energy personnel.
nid003693: 
nid003693: Unauthorized or improper use of this system may result in administrative
nid003693: disciplinary action and civil and criminal penalties. By continuing to use
nid003693: this system you indicate your awareness of and consent to these terms and
nid003693: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid003693: stated in this warning.
nid003693: 
nid003693: *****************************************************************************
nid003693: 
nid003693: Login connection to host x1202c4s1b0n1:
nid003693: 
nid001601: ***************************************************************************
nid001601:                           NOTICE TO USERS
nid001601: 
nid001601: Lawrence Berkeley National Laboratory operates this computer system under 
nid001601: contract to the U.S. Department of Energy.  This computer system is the 
nid001601: property of the United States Government and is for authorized use only.
nid001601: Users (authorized or unauthorized) have no explicit or implicit 
nid001601: expectation of privacy.
nid001601: 
nid001601: Any or all uses of this system and all files on this system may be
nid001601: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001601: to authorized site, Department of Energy, and law enforcement personnel,
nid001601: as well as authorized officials of other agencies, both domestic and foreign.
nid001601: By using this system, the user consents to such interception, monitoring,
nid001601: recording, copying, auditing, inspection, and disclosure at the discretion
nid001601: of authorized site or Department of Energy personnel.
nid001601: 
nid001601: Unauthorized or improper use of this system may result in administrative
nid001601: disciplinary action and civil and criminal penalties. By continuing to use
nid001601: this system you indicate your awareness of and consent to these terms and
nid001601: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001601: stated in this warning.
nid001601: 
nid001601: *****************************************************************************
nid001601: 
nid001601: Login connection to host x1002c2s6b0n1:
nid001601: 
nid001593: ***************************************************************************
nid001593:                           NOTICE TO USERS
nid001593: 
nid001593: Lawrence Berkeley National Laboratory operates this computer system under 
nid001593: contract to the U.S. Department of Energy.  This computer system is the 
nid001593: property of the United States Government and is for authorized use only.
nid001593: Users (authorized or unauthorized) have no explicit or implicit 
nid001593: expectation of privacy.
nid001593: 
nid001593: Any or all uses of this system and all files on this system may be
nid001593: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001593: to authorized site, Department of Energy, and law enforcement personnel,
nid001593: as well as authorized officials of other agencies, both domestic and foreign.
nid001593: By using this system, the user consents to such interception, monitoring,
nid001593: recording, copying, auditing, inspection, and disclosure at the discretion
nid001593: of authorized site or Department of Energy personnel.
nid001593: 
nid001593: Unauthorized or improper use of this system may result in administrative
nid001593: disciplinary action and civil and criminal penalties. By continuing to use
nid001593: this system you indicate your awareness of and consent to these terms and
nid001593: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001593: stated in this warning.
nid001593: 
nid001593: *****************************************************************************
nid001593: 
nid001593: Login connection to host x1002c2s4b0n1:
nid001593: 
nid001616: ***************************************************************************
nid001616:                           NOTICE TO USERS
nid001616: 
nid001616: Lawrence Berkeley National Laboratory operates this computer system under 
nid001616: contract to the U.S. Department of Energy.  This computer system is the 
nid001616: property of the United States Government and is for authorized use only.
nid001616: Users (authorized or unauthorized) have no explicit or implicit 
nid001616: expectation of privacy.
nid001616: 
nid001616: Any or all uses of this system and all files on this system may be
nid001616: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001616: to authorized site, Department of Energy, and law enforcement personnel,
nid001616: as well as authorized officials of other agencies, both domestic and foreign.
nid001616: By using this system, the user consents to such interception, monitoring,
nid001616: recording, copying, auditing, inspection, and disclosure at the discretion
nid001616: of authorized site or Department of Energy personnel.
nid001616: 
nid001616: Unauthorized or improper use of this system may result in administrative
nid001616: disciplinary action and civil and criminal penalties. By continuing to use
nid001616: this system you indicate your awareness of and consent to these terms and
nid001616: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001616: stated in this warning.
nid001616: 
nid001616: *****************************************************************************
nid001616: 
nid001616: Login connection to host x1002c3s2b0n0:
nid001616: 
nid001605: ***************************************************************************
nid001605:                           NOTICE TO USERS
nid001605: 
nid001605: Lawrence Berkeley National Laboratory operates this computer system under 
nid001605: contract to the U.S. Department of Energy.  This computer system is the 
nid001605: property of the United States Government and is for authorized use only.
nid001605: Users (authorized or unauthorized) have no explicit or implicit 
nid001605: expectation of privacy.
nid001605: 
nid001605: Any or all uses of this system and all files on this system may be
nid001605: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001605: to authorized site, Department of Energy, and law enforcement personnel,
nid001605: as well as authorized officials of other agencies, both domestic and foreign.
nid001605: By using this system, the user consents to such interception, monitoring,
nid001605: recording, copying, auditing, inspection, and disclosure at the discretion
nid001605: of authorized site or Department of Energy personnel.
nid001605: 
nid001605: Unauthorized or improper use of this system may result in administrative
nid001605: disciplinary action and civil and criminal penalties. By continuing to use
nid001605: this system you indicate your awareness of and consent to these terms and
nid001605: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001605: stated in this warning.
nid001605: 
nid001605: *****************************************************************************
nid001605: 
nid001605: Login connection to host x1002c2s7b0n1:
nid001605: 
nid003708: ***************************************************************************
nid003708:                           NOTICE TO USERS
nid003708: 
nid003708: Lawrence Berkeley National Laboratory operates this computer system under 
nid003708: contract to the U.S. Department of Energy.  This computer system is the 
nid003708: property of the United States Government and is for authorized use only.
nid003708: Users (authorized or unauthorized) have no explicit or implicit 
nid003708: expectation of privacy.
nid003708: 
nid003708: Any or all uses of this system and all files on this system may be
nid003708: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid003708: to authorized site, Department of Energy, and law enforcement personnel,
nid003708: as well as authorized officials of other agencies, both domestic and foreign.
nid003708: By using this system, the user consents to such interception, monitoring,
nid003708: recording, copying, auditing, inspection, and disclosure at the discretion
nid003708: of authorized site or Department of Energy personnel.
nid003708: 
nid003708: Unauthorized or improper use of this system may result in administrative
nid003708: disciplinary action and civil and criminal penalties. By continuing to use
nid003708: this system you indicate your awareness of and consent to these terms and
nid003708: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid003708: stated in this warning.
nid003708: 
nid003708: *****************************************************************************
nid003708: 
nid003708: Login connection to host x1202c4s5b0n0:
nid003708: 
nid003705: ***************************************************************************
nid003705:                           NOTICE TO USERS
nid003705: 
nid003705: Lawrence Berkeley National Laboratory operates this computer system under 
nid003705: contract to the U.S. Department of Energy.  This computer system is the 
nid003705: property of the United States Government and is for authorized use only.
nid003705: Users (authorized or unauthorized) have no explicit or implicit 
nid003705: expectation of privacy.
nid003705: 
nid003705: Any or all uses of this system and all files on this system may be
nid003705: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid003705: to authorized site, Department of Energy, and law enforcement personnel,
nid003705: as well as authorized officials of other agencies, both domestic and foreign.
nid003705: By using this system, the user consents to such interception, monitoring,
nid003705: recording, copying, auditing, inspection, and disclosure at the discretion
nid003705: of authorized site or Department of Energy personnel.
nid003705: 
nid003705: Unauthorized or improper use of this system may result in administrative
nid003705: disciplinary action and civil and criminal penalties. By continuing to use
nid003705: this system you indicate your awareness of and consent to these terms and
nid003705: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid003705: stated in this warning.
nid003705: 
nid003705: *****************************************************************************
nid003705: 
nid003705: Login connection to host x1202c4s4b0n1:
nid003705: 
nid003712: ***************************************************************************
nid003712:                           NOTICE TO USERS
nid003712: 
nid003712: Lawrence Berkeley National Laboratory operates this computer system under 
nid003712: contract to the U.S. Department of Energy.  This computer system is the 
nid003712: property of the United States Government and is for authorized use only.
nid003712: Users (authorized or unauthorized) have no explicit or implicit 
nid003712: expectation of privacy.
nid003712: 
nid003712: Any or all uses of this system and all files on this system may be
nid003712: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid003712: to authorized site, Department of Energy, and law enforcement personnel,
nid003712: as well as authorized officials of other agencies, both domestic and foreign.
nid003712: By using this system, the user consents to such interception, monitoring,
nid003712: recording, copying, auditing, inspection, and disclosure at the discretion
nid003712: of authorized site or Department of Energy personnel.
nid003712: 
nid003712: Unauthorized or improper use of this system may result in administrative
nid003712: disciplinary action and civil and criminal penalties. By continuing to use
nid003712: this system you indicate your awareness of and consent to these terms and
nid003712: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid003712: stated in this warning.
nid003712: 
nid003712: *****************************************************************************
nid003712: 
nid003712: Login connection to host x1202c4s6b0n0:
nid003712: 
nid001613: ***************************************************************************
nid001613:                           NOTICE TO USERS
nid001613: 
nid001613: Lawrence Berkeley National Laboratory operates this computer system under 
nid001613: contract to the U.S. Department of Energy.  This computer system is the 
nid001613: property of the United States Government and is for authorized use only.
nid001613: Users (authorized or unauthorized) have no explicit or implicit 
nid001613: expectation of privacy.
nid001613: 
nid001613: Any or all uses of this system and all files on this system may be
nid001613: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001613: to authorized site, Department of Energy, and law enforcement personnel,
nid001613: as well as authorized officials of other agencies, both domestic and foreign.
nid001613: By using this system, the user consents to such interception, monitoring,
nid001613: recording, copying, auditing, inspection, and disclosure at the discretion
nid001613: of authorized site or Department of Energy personnel.
nid001613: 
nid001613: Unauthorized or improper use of this system may result in administrative
nid001613: disciplinary action and civil and criminal penalties. By continuing to use
nid001613: this system you indicate your awareness of and consent to these terms and
nid001613: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001613: stated in this warning.
nid001613: 
nid001613: *****************************************************************************
nid001613: 
nid001613: Login connection to host x1002c3s1b0n1:
nid001613: 
nid001609: ***************************************************************************
nid001609:                           NOTICE TO USERS
nid001609: 
nid001609: Lawrence Berkeley National Laboratory operates this computer system under 
nid001609: contract to the U.S. Department of Energy.  This computer system is the 
nid001609: property of the United States Government and is for authorized use only.
nid001609: Users (authorized or unauthorized) have no explicit or implicit 
nid001609: expectation of privacy.
nid001609: 
nid001609: Any or all uses of this system and all files on this system may be
nid001609: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001609: to authorized site, Department of Energy, and law enforcement personnel,
nid001609: as well as authorized officials of other agencies, both domestic and foreign.
nid001609: By using this system, the user consents to such interception, monitoring,
nid001609: recording, copying, auditing, inspection, and disclosure at the discretion
nid001609: of authorized site or Department of Energy personnel.
nid001609: 
nid001609: Unauthorized or improper use of this system may result in administrative
nid001609: disciplinary action and civil and criminal penalties. By continuing to use
nid001609: this system you indicate your awareness of and consent to these terms and
nid001609: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001609: stated in this warning.
nid001609: 
nid001609: *****************************************************************************
nid001609: 
nid001609: Login connection to host x1002c3s0b0n1:
nid001609: 
nid001596: ***************************************************************************
nid001596:                           NOTICE TO USERS
nid001596: 
nid001596: Lawrence Berkeley National Laboratory operates this computer system under 
nid001596: contract to the U.S. Department of Energy.  This computer system is the 
nid001596: property of the United States Government and is for authorized use only.
nid001596: Users (authorized or unauthorized) have no explicit or implicit 
nid001596: expectation of privacy.
nid001596: 
nid001596: Any or all uses of this system and all files on this system may be
nid001596: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001596: to authorized site, Department of Energy, and law enforcement personnel,
nid001596: as well as authorized officials of other agencies, both domestic and foreign.
nid001596: By using this system, the user consents to such interception, monitoring,
nid001596: recording, copying, auditing, inspection, and disclosure at the discretion
nid001596: of authorized site or Department of Energy personnel.
nid001596: 
nid001596: Unauthorized or improper use of this system may result in administrative
nid001596: disciplinary action and civil and criminal penalties. By continuing to use
nid001596: this system you indicate your awareness of and consent to these terms and
nid001596: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001596: stated in this warning.
nid001596: 
nid001596: *****************************************************************************
nid001596: 
nid001596: Login connection to host x1002c2s5b0n0:
nid001596: 
nid001604: ***************************************************************************
nid001604:                           NOTICE TO USERS
nid001604: 
nid001604: Lawrence Berkeley National Laboratory operates this computer system under 
nid001604: contract to the U.S. Department of Energy.  This computer system is the 
nid001604: property of the United States Government and is for authorized use only.
nid001604: Users (authorized or unauthorized) have no explicit or implicit 
nid001604: expectation of privacy.
nid001604: 
nid001604: Any or all uses of this system and all files on this system may be
nid001604: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid001604: to authorized site, Department of Energy, and law enforcement personnel,
nid001604: as well as authorized officials of other agencies, both domestic and foreign.
nid001604: By using this system, the user consents to such interception, monitoring,
nid001604: recording, copying, auditing, inspection, and disclosure at the discretion
nid001604: of authorized site or Department of Energy personnel.
nid001604: 
nid001604: Unauthorized or improper use of this system may result in administrative
nid001604: disciplinary action and civil and criminal penalties. By continuing to use
nid001604: this system you indicate your awareness of and consent to these terms and
nid001604: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid001604: stated in this warning.
nid001604: 
nid001604: *****************************************************************************
nid001604: 
nid001604: Login connection to host x1002c2s7b0n0:
nid001604: 
nid001412: [2024-10-10 05:51:45,043] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001412: [2024-10-10 05:51:46,946] [INFO] [launch.py:138:main] 0 NCCL_NET_GDR_LEVEL=PHB
nid001412: [2024-10-10 05:51:46,946] [INFO] [launch.py:138:main] 0 NCCL_SOCKET_IFNAME=hsn
nid001412: [2024-10-10 05:51:46,946] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001412: [2024-10-10 05:51:46,946] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=0
nid001412: [2024-10-10 05:51:46,946] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001412: [2024-10-10 05:51:46,946] [INFO] [launch.py:163:main] dist_world_size=128
nid001412: [2024-10-10 05:51:46,946] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001620: [2024-10-10 05:51:48,074] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001600: [2024-10-10 05:51:48,319] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001613: [2024-10-10 05:51:48,618] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001609: [2024-10-10 05:51:48,778] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003700: [2024-10-10 05:51:48,786] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003712: [2024-10-10 05:51:48,807] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001412: [2024-10-10 05:51:48,850] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001412: [2024-10-10 05:51:48,865] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001412: [2024-10-10 05:51:48,869] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001412: [2024-10-10 05:51:48,872] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003705: [2024-10-10 05:51:49,095] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001416: [2024-10-10 05:51:49,716] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003701: [2024-10-10 05:51:49,796] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001608: [2024-10-10 05:51:49,798] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001601: [2024-10-10 05:51:49,871] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003709: [2024-10-10 05:51:49,893] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003713: [2024-10-10 05:51:50,086] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001596: [2024-10-10 05:51:50,109] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001589: [2024-10-10 05:51:50,112] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001605: [2024-10-10 05:51:50,150] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001604: [2024-10-10 05:51:50,170] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001597: [2024-10-10 05:51:50,209] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003697: [2024-10-10 05:51:50,335] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003704: [2024-10-10 05:51:50,364] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003696: [2024-10-10 05:51:50,533] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003693: [2024-10-10 05:51:50,580] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001612: [2024-10-10 05:51:50,607] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003692: [2024-10-10 05:51:50,682] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001413: [2024-10-10 05:51:50,715] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003708: [2024-10-10 05:51:50,813] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001417: [2024-10-10 05:51:51,049] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001593: [2024-10-10 05:51:51,109] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001616: [2024-10-10 05:51:51,122] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001620: [2024-10-10 05:51:52,012] [INFO] [launch.py:138:main] 19 NCCL_NET_GDR_LEVEL=PHB
nid001620: [2024-10-10 05:51:52,012] [INFO] [launch.py:138:main] 19 NCCL_SOCKET_IFNAME=hsn
nid001620: [2024-10-10 05:51:52,012] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001620: [2024-10-10 05:51:52,012] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=19
nid001620: [2024-10-10 05:51:52,012] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001620: [2024-10-10 05:51:52,012] [INFO] [launch.py:163:main] dist_world_size=128
nid001620: [2024-10-10 05:51:52,012] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001617: [2024-10-10 05:51:52,013] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001592: [2024-10-10 05:51:52,060] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001412: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001412: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001412: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001412: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001412: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001412: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001412: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001412: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001412: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001412: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001412: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001412: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001600: [2024-10-10 05:51:52,226] [INFO] [launch.py:138:main] 9 NCCL_NET_GDR_LEVEL=PHB
nid001600: [2024-10-10 05:51:52,226] [INFO] [launch.py:138:main] 9 NCCL_SOCKET_IFNAME=hsn
nid001600: [2024-10-10 05:51:52,226] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001600: [2024-10-10 05:51:52,226] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=9
nid001600: [2024-10-10 05:51:52,226] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001600: [2024-10-10 05:51:52,226] [INFO] [launch.py:163:main] dist_world_size=128
nid001600: [2024-10-10 05:51:52,226] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001412: STAGE:2024-10-10 05:51:52 560033:560033 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001412: STAGE:2024-10-10 05:51:52 560029:560029 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001412: STAGE:2024-10-10 05:51:52 560030:560030 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001412: STAGE:2024-10-10 05:51:52 560038:560038 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001613: [2024-10-10 05:51:52,586] [INFO] [launch.py:138:main] 16 NCCL_NET_GDR_LEVEL=PHB
nid001613: [2024-10-10 05:51:52,586] [INFO] [launch.py:138:main] 16 NCCL_SOCKET_IFNAME=hsn
nid001613: [2024-10-10 05:51:52,586] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001613: [2024-10-10 05:51:52,586] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=16
nid001613: [2024-10-10 05:51:52,586] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001613: [2024-10-10 05:51:52,586] [INFO] [launch.py:163:main] dist_world_size=128
nid001613: [2024-10-10 05:51:52,586] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001609: [2024-10-10 05:51:52,681] [INFO] [launch.py:138:main] 14 NCCL_NET_GDR_LEVEL=PHB
nid001609: [2024-10-10 05:51:52,681] [INFO] [launch.py:138:main] 14 NCCL_SOCKET_IFNAME=hsn
nid001609: [2024-10-10 05:51:52,681] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001609: [2024-10-10 05:51:52,681] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=14
nid003700: [2024-10-10 05:51:52,681] [INFO] [launch.py:138:main] 24 NCCL_NET_GDR_LEVEL=PHB
nid003700: [2024-10-10 05:51:52,681] [INFO] [launch.py:138:main] 24 NCCL_SOCKET_IFNAME=hsn
nid003700: [2024-10-10 05:51:52,681] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid003700: [2024-10-10 05:51:52,681] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=24
nid003700: [2024-10-10 05:51:52,681] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid003700: [2024-10-10 05:51:52,681] [INFO] [launch.py:163:main] dist_world_size=128
nid003700: [2024-10-10 05:51:52,682] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001609: [2024-10-10 05:51:52,681] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001609: [2024-10-10 05:51:52,681] [INFO] [launch.py:163:main] dist_world_size=128
nid001609: [2024-10-10 05:51:52,681] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid003712: [2024-10-10 05:51:52,767] [INFO] [launch.py:138:main] 30 NCCL_NET_GDR_LEVEL=PHB
nid003712: [2024-10-10 05:51:52,767] [INFO] [launch.py:138:main] 30 NCCL_SOCKET_IFNAME=hsn
nid003712: [2024-10-10 05:51:52,767] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid003712: [2024-10-10 05:51:52,767] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=30
nid003712: [2024-10-10 05:51:52,767] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid003712: [2024-10-10 05:51:52,767] [INFO] [launch.py:163:main] dist_world_size=128
nid003712: [2024-10-10 05:51:52,767] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid003705: [2024-10-10 05:51:53,181] [INFO] [launch.py:138:main] 27 NCCL_NET_GDR_LEVEL=PHB
nid003705: [2024-10-10 05:51:53,181] [INFO] [launch.py:138:main] 27 NCCL_SOCKET_IFNAME=hsn
nid003705: [2024-10-10 05:51:53,181] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid003705: [2024-10-10 05:51:53,181] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=27
nid003705: [2024-10-10 05:51:53,181] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid003705: [2024-10-10 05:51:53,181] [INFO] [launch.py:163:main] dist_world_size=128
nid003705: [2024-10-10 05:51:53,181] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001412: STAGE:2024-10-10 05:51:53 560029:560029 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:51:53 560038:560038 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:51:53 560033:560033 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001412: 
nid001412: 
nid001412: STAGE:2024-10-10 05:51:53 560030:560030 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001412: NeoXArgs.configure_distributed_args() using world size: 128 and model-parallel size: 4 
nid001412: > building GPT2BPETokenizer tokenizer ...
nid001412:  > padded vocab (size: 50257) with 431 dummy tokens (new size: 50688)
nid001412: [2024-10-10 05:51:53,695] [INFO] [comm.py:637:init_distributed] cdb=None
nid001412: > setting up tensorboard ...
nid001416: [2024-10-10 05:51:53,716] [INFO] [launch.py:138:main] 2 NCCL_NET_GDR_LEVEL=PHB
nid001416: [2024-10-10 05:51:53,716] [INFO] [launch.py:138:main] 2 NCCL_SOCKET_IFNAME=hsn
nid001416: [2024-10-10 05:51:53,716] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001416: [2024-10-10 05:51:53,716] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=2
nid001416: [2024-10-10 05:51:53,716] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001416: [2024-10-10 05:51:53,716] [INFO] [launch.py:163:main] dist_world_size=128
nid001416: [2024-10-10 05:51:53,717] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001608: [2024-10-10 05:51:53,717] [INFO] [launch.py:138:main] 13 NCCL_NET_GDR_LEVEL=PHB
nid001608: [2024-10-10 05:51:53,717] [INFO] [launch.py:138:main] 13 NCCL_SOCKET_IFNAME=hsn
nid001608: [2024-10-10 05:51:53,717] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001608: [2024-10-10 05:51:53,717] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=13
nid001608: [2024-10-10 05:51:53,717] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001608: [2024-10-10 05:51:53,717] [INFO] [launch.py:163:main] dist_world_size=128
nid001608: [2024-10-10 05:51:53,717] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001412: Detected CUDA files, patching ldflags
nid001412: Emitting ninja build file /pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/fused_kernels/build/build.ninja...
nid001412: Building extension module scaled_upper_triang_masked_softmax_cuda...
nid001412: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
nid001412: ninja: no work to do.
nid001412: Loading extension module scaled_upper_triang_masked_softmax_cuda...
nid001412: Detected CUDA files, patching ldflags
nid001412: Emitting ninja build file /pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/fused_kernels/build/build.ninja...
nid001412: Building extension module scaled_masked_softmax_cuda...
nid001412: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
nid001412: ninja: no work to do.
nid001412: Loading extension module scaled_masked_softmax_cuda...
nid003709: [2024-10-10 05:51:53,878] [INFO] [launch.py:138:main] 29 NCCL_NET_GDR_LEVEL=PHB
nid003709: [2024-10-10 05:51:53,878] [INFO] [launch.py:138:main] 29 NCCL_SOCKET_IFNAME=hsn
nid003709: [2024-10-10 05:51:53,878] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid003709: [2024-10-10 05:51:53,878] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=29
nid003709: [2024-10-10 05:51:53,879] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid003709: [2024-10-10 05:51:53,879] [INFO] [launch.py:163:main] dist_world_size=128
nid003709: [2024-10-10 05:51:53,879] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001412: Detected CUDA files, patching ldflags
nid001412: Emitting ninja build file /pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/fused_kernels/build/build.ninja...
nid001412: Building extension module fused_rotary_positional_embedding...
nid001412: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
nid003701: [2024-10-10 05:51:53,923] [INFO] [launch.py:138:main] 25 NCCL_NET_GDR_LEVEL=PHB
nid003701: [2024-10-10 05:51:53,923] [INFO] [launch.py:138:main] 25 NCCL_SOCKET_IFNAME=hsn
nid003701: [2024-10-10 05:51:53,923] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid003701: [2024-10-10 05:51:53,923] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=25
nid003701: [2024-10-10 05:51:53,923] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid003701: [2024-10-10 05:51:53,923] [INFO] [launch.py:163:main] dist_world_size=128
nid003701: [2024-10-10 05:51:53,923] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001412: ninja: no work to do.
nid001412: Loading extension module fused_rotary_positional_embedding...
nid001412: > initializing torch distributed ...
nid001412: [2024-10-10 05:51:53,928] [INFO] [comm.py:637:init_distributed] cdb=None
nid001412: [2024-10-10 05:51:53,928] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
nid001601: [2024-10-10 05:51:53,967] [INFO] [launch.py:138:main] 10 NCCL_NET_GDR_LEVEL=PHB
nid001601: [2024-10-10 05:51:53,967] [INFO] [launch.py:138:main] 10 NCCL_SOCKET_IFNAME=hsn
nid001601: [2024-10-10 05:51:53,967] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001601: [2024-10-10 05:51:53,967] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=10
nid001601: [2024-10-10 05:51:53,967] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001601: [2024-10-10 05:51:53,967] [INFO] [launch.py:163:main] dist_world_size=128
nid001601: [2024-10-10 05:51:53,967] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid003713: [2024-10-10 05:51:53,969] [INFO] [launch.py:138:main] 31 NCCL_NET_GDR_LEVEL=PHB
nid003713: [2024-10-10 05:51:53,969] [INFO] [launch.py:138:main] 31 NCCL_SOCKET_IFNAME=hsn
nid003713: [2024-10-10 05:51:53,969] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid003713: [2024-10-10 05:51:53,969] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=31
nid003713: [2024-10-10 05:51:53,969] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid003713: [2024-10-10 05:51:53,969] [INFO] [launch.py:163:main] dist_world_size=128
nid003713: [2024-10-10 05:51:53,969] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001596: [2024-10-10 05:51:53,992] [INFO] [launch.py:138:main] 7 NCCL_NET_GDR_LEVEL=PHB
nid001596: [2024-10-10 05:51:53,992] [INFO] [launch.py:138:main] 7 NCCL_SOCKET_IFNAME=hsn
nid001596: [2024-10-10 05:51:53,992] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001596: [2024-10-10 05:51:53,992] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=7
nid001596: [2024-10-10 05:51:53,992] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001596: [2024-10-10 05:51:53,992] [INFO] [launch.py:163:main] dist_world_size=128
nid001596: [2024-10-10 05:51:53,992] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001589: [2024-10-10 05:51:54,050] [INFO] [launch.py:138:main] 4 NCCL_NET_GDR_LEVEL=PHB
nid001589: [2024-10-10 05:51:54,050] [INFO] [launch.py:138:main] 4 NCCL_SOCKET_IFNAME=hsn
nid001589: [2024-10-10 05:51:54,050] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001589: [2024-10-10 05:51:54,050] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=4
nid001589: [2024-10-10 05:51:54,050] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001589: [2024-10-10 05:51:54,050] [INFO] [launch.py:163:main] dist_world_size=128
nid001589: [2024-10-10 05:51:54,050] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001620: [2024-10-10 05:51:54,062] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001620: [2024-10-10 05:51:54,095] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001620: [2024-10-10 05:51:54,101] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001620: [2024-10-10 05:51:54,102] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001412: [2024-10-10 05:51:54,118] [INFO] [comm.py:637:init_distributed] cdb=None
nid001604: [2024-10-10 05:51:54,147] [INFO] [launch.py:138:main] 11 NCCL_NET_GDR_LEVEL=PHB
nid001604: [2024-10-10 05:51:54,147] [INFO] [launch.py:138:main] 11 NCCL_SOCKET_IFNAME=hsn
nid001604: [2024-10-10 05:51:54,147] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001604: [2024-10-10 05:51:54,147] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=11
nid001604: [2024-10-10 05:51:54,147] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001604: [2024-10-10 05:51:54,147] [INFO] [launch.py:163:main] dist_world_size=128
nid001604: [2024-10-10 05:51:54,147] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001597: [2024-10-10 05:51:54,153] [INFO] [launch.py:138:main] 8 NCCL_NET_GDR_LEVEL=PHB
nid001597: [2024-10-10 05:51:54,153] [INFO] [launch.py:138:main] 8 NCCL_SOCKET_IFNAME=hsn
nid001597: [2024-10-10 05:51:54,153] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001597: [2024-10-10 05:51:54,153] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=8
nid001597: [2024-10-10 05:51:54,153] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001597: [2024-10-10 05:51:54,153] [INFO] [launch.py:163:main] dist_world_size=128
nid001597: [2024-10-10 05:51:54,153] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001605: [2024-10-10 05:51:54,154] [INFO] [launch.py:138:main] 12 NCCL_NET_GDR_LEVEL=PHB
nid001605: [2024-10-10 05:51:54,154] [INFO] [launch.py:138:main] 12 NCCL_SOCKET_IFNAME=hsn
nid001605: [2024-10-10 05:51:54,154] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001605: [2024-10-10 05:51:54,154] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=12
nid001605: [2024-10-10 05:51:54,154] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001605: [2024-10-10 05:51:54,154] [INFO] [launch.py:163:main] dist_world_size=128
nid001605: [2024-10-10 05:51:54,154] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001600: [2024-10-10 05:51:54,231] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001412: [2024-10-10 05:51:54,247] [INFO] [comm.py:637:init_distributed] cdb=None
nid001600: [2024-10-10 05:51:54,271] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001600: [2024-10-10 05:51:54,277] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001600: [2024-10-10 05:51:54,278] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003696: [2024-10-10 05:51:54,413] [INFO] [launch.py:138:main] 22 NCCL_NET_GDR_LEVEL=PHB
nid003696: [2024-10-10 05:51:54,413] [INFO] [launch.py:138:main] 22 NCCL_SOCKET_IFNAME=hsn
nid003696: [2024-10-10 05:51:54,413] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid003696: [2024-10-10 05:51:54,413] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=22
nid003696: [2024-10-10 05:51:54,414] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid003696: [2024-10-10 05:51:54,414] [INFO] [launch.py:163:main] dist_world_size=128
nid003696: [2024-10-10 05:51:54,414] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid003697: [2024-10-10 05:51:54,536] [INFO] [launch.py:138:main] 23 NCCL_NET_GDR_LEVEL=PHB
nid003697: [2024-10-10 05:51:54,536] [INFO] [launch.py:138:main] 23 NCCL_SOCKET_IFNAME=hsn
nid003697: [2024-10-10 05:51:54,536] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid003697: [2024-10-10 05:51:54,536] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=23
nid003697: [2024-10-10 05:51:54,536] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid003697: [2024-10-10 05:51:54,536] [INFO] [launch.py:163:main] dist_world_size=128
nid003697: [2024-10-10 05:51:54,536] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid003704: [2024-10-10 05:51:54,556] [INFO] [launch.py:138:main] 26 NCCL_NET_GDR_LEVEL=PHB
nid003704: [2024-10-10 05:51:54,556] [INFO] [launch.py:138:main] 26 NCCL_SOCKET_IFNAME=hsn
nid003704: [2024-10-10 05:51:54,556] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid003704: [2024-10-10 05:51:54,556] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=26
nid003704: [2024-10-10 05:51:54,556] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid003704: [2024-10-10 05:51:54,556] [INFO] [launch.py:163:main] dist_world_size=128
nid003704: [2024-10-10 05:51:54,556] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid003693: [2024-10-10 05:51:54,559] [INFO] [launch.py:138:main] 21 NCCL_NET_GDR_LEVEL=PHB
nid003693: [2024-10-10 05:51:54,559] [INFO] [launch.py:138:main] 21 NCCL_SOCKET_IFNAME=hsn
nid003693: [2024-10-10 05:51:54,559] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid003693: [2024-10-10 05:51:54,559] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=21
nid003693: [2024-10-10 05:51:54,559] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid003693: [2024-10-10 05:51:54,559] [INFO] [launch.py:163:main] dist_world_size=128
nid003693: [2024-10-10 05:51:54,559] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid003692: [2024-10-10 05:51:54,610] [INFO] [launch.py:138:main] 20 NCCL_NET_GDR_LEVEL=PHB
nid003692: [2024-10-10 05:51:54,610] [INFO] [launch.py:138:main] 20 NCCL_SOCKET_IFNAME=hsn
nid003692: [2024-10-10 05:51:54,610] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid003692: [2024-10-10 05:51:54,610] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=20
nid003692: [2024-10-10 05:51:54,610] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid003692: [2024-10-10 05:51:54,610] [INFO] [launch.py:163:main] dist_world_size=128
nid003692: [2024-10-10 05:51:54,610] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001613: [2024-10-10 05:51:54,621] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001612: [2024-10-10 05:51:54,631] [INFO] [launch.py:138:main] 15 NCCL_NET_GDR_LEVEL=PHB
nid001612: [2024-10-10 05:51:54,631] [INFO] [launch.py:138:main] 15 NCCL_SOCKET_IFNAME=hsn
nid001612: [2024-10-10 05:51:54,631] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001612: [2024-10-10 05:51:54,631] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=15
nid001612: [2024-10-10 05:51:54,631] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001612: [2024-10-10 05:51:54,631] [INFO] [launch.py:163:main] dist_world_size=128
nid001612: [2024-10-10 05:51:54,631] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001613: [2024-10-10 05:51:54,655] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001613: [2024-10-10 05:51:54,661] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001613: [2024-10-10 05:51:54,662] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001413: [2024-10-10 05:51:54,676] [INFO] [launch.py:138:main] 1 NCCL_NET_GDR_LEVEL=PHB
nid001413: [2024-10-10 05:51:54,676] [INFO] [launch.py:138:main] 1 NCCL_SOCKET_IFNAME=hsn
nid001413: [2024-10-10 05:51:54,676] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001413: [2024-10-10 05:51:54,676] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=1
nid001413: [2024-10-10 05:51:54,676] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001413: [2024-10-10 05:51:54,676] [INFO] [launch.py:163:main] dist_world_size=128
nid001413: [2024-10-10 05:51:54,676] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid003700: [2024-10-10 05:51:54,715] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003708: [2024-10-10 05:51:54,718] [INFO] [launch.py:138:main] 28 NCCL_NET_GDR_LEVEL=PHB
nid003708: [2024-10-10 05:51:54,719] [INFO] [launch.py:138:main] 28 NCCL_SOCKET_IFNAME=hsn
nid003708: [2024-10-10 05:51:54,719] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid003708: [2024-10-10 05:51:54,719] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=28
nid003708: [2024-10-10 05:51:54,719] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid003708: [2024-10-10 05:51:54,719] [INFO] [launch.py:163:main] dist_world_size=128
nid003708: [2024-10-10 05:51:54,719] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001609: [2024-10-10 05:51:54,734] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003700: [2024-10-10 05:51:54,755] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003700: [2024-10-10 05:51:54,762] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003700: [2024-10-10 05:51:54,764] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001609: [2024-10-10 05:51:54,767] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001609: [2024-10-10 05:51:54,773] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001609: [2024-10-10 05:51:54,787] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003712: [2024-10-10 05:51:54,813] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003712: [2024-10-10 05:51:54,821] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003712: [2024-10-10 05:51:54,824] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003712: [2024-10-10 05:51:54,828] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001417: [2024-10-10 05:51:54,979] [INFO] [launch.py:138:main] 3 NCCL_NET_GDR_LEVEL=PHB
nid001417: [2024-10-10 05:51:54,979] [INFO] [launch.py:138:main] 3 NCCL_SOCKET_IFNAME=hsn
nid001417: [2024-10-10 05:51:54,979] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001417: [2024-10-10 05:51:54,979] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=3
nid001417: [2024-10-10 05:51:54,979] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001417: [2024-10-10 05:51:54,979] [INFO] [launch.py:163:main] dist_world_size=128
nid001417: [2024-10-10 05:51:54,979] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001616: [2024-10-10 05:51:54,982] [INFO] [launch.py:138:main] 17 NCCL_NET_GDR_LEVEL=PHB
nid001616: [2024-10-10 05:51:54,982] [INFO] [launch.py:138:main] 17 NCCL_SOCKET_IFNAME=hsn
nid001616: [2024-10-10 05:51:54,982] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001616: [2024-10-10 05:51:54,982] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=17
nid001616: [2024-10-10 05:51:54,982] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001616: [2024-10-10 05:51:54,982] [INFO] [launch.py:163:main] dist_world_size=128
nid001616: [2024-10-10 05:51:54,982] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid003705: [2024-10-10 05:51:55,203] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003705: [2024-10-10 05:51:55,214] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003705: [2024-10-10 05:51:55,219] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003705: [2024-10-10 05:51:55,219] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001593: [2024-10-10 05:51:55,363] [INFO] [launch.py:138:main] 6 NCCL_NET_GDR_LEVEL=PHB
nid001593: [2024-10-10 05:51:55,363] [INFO] [launch.py:138:main] 6 NCCL_SOCKET_IFNAME=hsn
nid001593: [2024-10-10 05:51:55,363] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001593: [2024-10-10 05:51:55,363] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=6
nid001593: [2024-10-10 05:51:55,363] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001593: [2024-10-10 05:51:55,363] [INFO] [launch.py:163:main] dist_world_size=128
nid001593: [2024-10-10 05:51:55,363] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001608: [2024-10-10 05:51:55,763] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001416: [2024-10-10 05:51:55,766] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001608: [2024-10-10 05:51:55,777] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001608: [2024-10-10 05:51:55,783] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001608: [2024-10-10 05:51:55,784] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001416: [2024-10-10 05:51:55,786] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001416: [2024-10-10 05:51:55,790] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001416: [2024-10-10 05:51:55,793] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003709: [2024-10-10 05:51:55,898] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003709: [2024-10-10 05:51:55,936] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003709: [2024-10-10 05:51:55,955] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003709: [2024-10-10 05:51:55,956] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001601: [2024-10-10 05:51:56,010] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001601: [2024-10-10 05:51:56,014] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003713: [2024-10-10 05:51:56,017] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001601: [2024-10-10 05:51:56,019] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001601: [2024-10-10 05:51:56,020] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003701: [2024-10-10 05:51:56,026] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003701: [2024-10-10 05:51:56,031] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003701: [2024-10-10 05:51:56,033] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003701: [2024-10-10 05:51:56,036] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003713: [2024-10-10 05:51:56,045] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003713: [2024-10-10 05:51:56,058] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003713: [2024-10-10 05:51:56,059] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001596: [2024-10-10 05:51:56,068] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001596: [2024-10-10 05:51:56,096] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001617: [2024-10-10 05:51:56,097] [INFO] [launch.py:138:main] 18 NCCL_NET_GDR_LEVEL=PHB
nid001617: [2024-10-10 05:51:56,097] [INFO] [launch.py:138:main] 18 NCCL_SOCKET_IFNAME=hsn
nid001617: [2024-10-10 05:51:56,097] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001617: [2024-10-10 05:51:56,097] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=18
nid001617: [2024-10-10 05:51:56,098] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001617: [2024-10-10 05:51:56,098] [INFO] [launch.py:163:main] dist_world_size=128
nid001617: [2024-10-10 05:51:56,098] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001596: [2024-10-10 05:51:56,103] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001596: [2024-10-10 05:51:56,107] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001589: [2024-10-10 05:51:56,123] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001589: [2024-10-10 05:51:56,130] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001589: [2024-10-10 05:51:56,135] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001589: [2024-10-10 05:51:56,137] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001597: [2024-10-10 05:51:56,166] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001597: [2024-10-10 05:51:56,180] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001597: [2024-10-10 05:51:56,184] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001597: [2024-10-10 05:51:56,188] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001604: [2024-10-10 05:51:56,222] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001604: [2024-10-10 05:51:56,227] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001604: [2024-10-10 05:51:56,229] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001605: [2024-10-10 05:51:56,250] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001605: [2024-10-10 05:51:56,266] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001605: [2024-10-10 05:51:56,267] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001605: [2024-10-10 05:51:56,269] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001592: [2024-10-10 05:51:56,271] [INFO] [launch.py:138:main] 5 NCCL_NET_GDR_LEVEL=PHB
nid001592: [2024-10-10 05:51:56,272] [INFO] [launch.py:138:main] 5 NCCL_SOCKET_IFNAME=hsn
nid001592: [2024-10-10 05:51:56,272] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid001412': [0, 1, 2, 3], 'nid001413': [0, 1, 2, 3], 'nid001416': [0, 1, 2, 3], 'nid001417': [0, 1, 2, 3], 'nid001589': [0, 1, 2, 3], 'nid001592': [0, 1, 2, 3], 'nid001593': [0, 1, 2, 3], 'nid001596': [0, 1, 2, 3], 'nid001597': [0, 1, 2, 3], 'nid001600': [0, 1, 2, 3], 'nid001601': [0, 1, 2, 3], 'nid001604': [0, 1, 2, 3], 'nid001605': [0, 1, 2, 3], 'nid001608': [0, 1, 2, 3], 'nid001609': [0, 1, 2, 3], 'nid001612': [0, 1, 2, 3], 'nid001613': [0, 1, 2, 3], 'nid001616': [0, 1, 2, 3], 'nid001617': [0, 1, 2, 3], 'nid001620': [0, 1, 2, 3], 'nid003692': [0, 1, 2, 3], 'nid003693': [0, 1, 2, 3], 'nid003696': [0, 1, 2, 3], 'nid003697': [0, 1, 2, 3], 'nid003700': [0, 1, 2, 3], 'nid003701': [0, 1, 2, 3], 'nid003704': [0, 1, 2, 3], 'nid003705': [0, 1, 2, 3], 'nid003708': [0, 1, 2, 3], 'nid003709': [0, 1, 2, 3], 'nid003712': [0, 1, 2, 3], 'nid003713': [0, 1, 2, 3]}
nid001592: [2024-10-10 05:51:56,272] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=5
nid001592: [2024-10-10 05:51:56,272] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid001412': [0, 1, 2, 3], 'nid001413': [4, 5, 6, 7], 'nid001416': [8, 9, 10, 11], 'nid001417': [12, 13, 14, 15], 'nid001589': [16, 17, 18, 19], 'nid001592': [20, 21, 22, 23], 'nid001593': [24, 25, 26, 27], 'nid001596': [28, 29, 30, 31], 'nid001597': [32, 33, 34, 35], 'nid001600': [36, 37, 38, 39], 'nid001601': [40, 41, 42, 43], 'nid001604': [44, 45, 46, 47], 'nid001605': [48, 49, 50, 51], 'nid001608': [52, 53, 54, 55], 'nid001609': [56, 57, 58, 59], 'nid001612': [60, 61, 62, 63], 'nid001613': [64, 65, 66, 67], 'nid001616': [68, 69, 70, 71], 'nid001617': [72, 73, 74, 75], 'nid001620': [76, 77, 78, 79], 'nid003692': [80, 81, 82, 83], 'nid003693': [84, 85, 86, 87], 'nid003696': [88, 89, 90, 91], 'nid003697': [92, 93, 94, 95], 'nid003700': [96, 97, 98, 99], 'nid003701': [100, 101, 102, 103], 'nid003704': [104, 105, 106, 107], 'nid003705': [108, 109, 110, 111], 'nid003708': [112, 113, 114, 115], 'nid003709': [116, 117, 118, 119], 'nid003712': [120, 121, 122, 123], 'nid003713': [124, 125, 126, 127]})
nid001592: [2024-10-10 05:51:56,272] [INFO] [launch.py:163:main] dist_world_size=128
nid001592: [2024-10-10 05:51:56,272] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid001604: [2024-10-10 05:51:56,411] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003696: [2024-10-10 05:51:56,486] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003696: [2024-10-10 05:51:56,494] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003696: [2024-10-10 05:51:56,503] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003696: [2024-10-10 05:51:56,505] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003697: [2024-10-10 05:51:56,594] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003693: [2024-10-10 05:51:56,597] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003697: [2024-10-10 05:51:56,602] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003697: [2024-10-10 05:51:56,604] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003697: [2024-10-10 05:51:56,605] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003692: [2024-10-10 05:51:56,625] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003693: [2024-10-10 05:51:56,626] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003693: [2024-10-10 05:51:56,629] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003693: [2024-10-10 05:51:56,632] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003704: [2024-10-10 05:51:56,639] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003704: [2024-10-10 05:51:56,661] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003692: [2024-10-10 05:51:56,667] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003704: [2024-10-10 05:51:56,667] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003704: [2024-10-10 05:51:56,668] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003692: [2024-10-10 05:51:56,673] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003692: [2024-10-10 05:51:56,674] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001612: [2024-10-10 05:51:56,678] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001612: [2024-10-10 05:51:56,697] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001612: [2024-10-10 05:51:56,701] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001612: [2024-10-10 05:51:56,704] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001413: [2024-10-10 05:51:56,718] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001413: [2024-10-10 05:51:56,728] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001413: [2024-10-10 05:51:56,733] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001413: [2024-10-10 05:51:56,735] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003708: [2024-10-10 05:51:56,763] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003708: [2024-10-10 05:51:56,784] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003708: [2024-10-10 05:51:56,797] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid003708: [2024-10-10 05:51:56,804] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001417: [2024-10-10 05:51:57,005] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001616: [2024-10-10 05:51:57,007] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001616: [2024-10-10 05:51:57,015] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001616: [2024-10-10 05:51:57,021] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001616: [2024-10-10 05:51:57,022] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001417: [2024-10-10 05:51:57,047] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001417: [2024-10-10 05:51:57,052] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001417: [2024-10-10 05:51:57,053] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001593: [2024-10-10 05:51:57,416] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001593: [2024-10-10 05:51:57,423] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001593: [2024-10-10 05:51:57,427] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001593: [2024-10-10 05:51:57,430] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001620: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001620: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001620: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001620: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001620: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001620: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001620: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001620: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001620: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001620: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001620: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001620: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001620: STAGE:2024-10-10 05:51:57 568918:568918 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001620: STAGE:2024-10-10 05:51:57 568917:568917 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001620: STAGE:2024-10-10 05:51:57 568919:568919 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001620: STAGE:2024-10-10 05:51:57 568916:568916 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001600: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001600: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001600: 
nid001600: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001600: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001600: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001600: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001600: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001600: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001600: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001600: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001600: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001617: [2024-10-10 05:51:58,149] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001617: [2024-10-10 05:51:58,187] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001617: [2024-10-10 05:51:58,190] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001617: [2024-10-10 05:51:58,194] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001600: STAGE:2024-10-10 05:51:58 1374896:1374896 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001600: STAGE:2024-10-10 05:51:58 1374898:1374898 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001600: STAGE:2024-10-10 05:51:58 1374895:1374895 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001600: STAGE:2024-10-10 05:51:58 1374897:1374897 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001592: [2024-10-10 05:51:58,301] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001592: [2024-10-10 05:51:58,312] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001592: [2024-10-10 05:51:58,316] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001592: [2024-10-10 05:51:58,319] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid001609: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001609: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001609: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001609: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001609: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001609: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001609: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001609: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001609: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001609: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001609: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001609: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003700: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003700: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003700: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003700: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003700: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003700: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003700: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003700: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003700: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003700: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003700: 
nid003700: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001613: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001613: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001613: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001613: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001613: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001613: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003712: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003712: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003712: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003712: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003712: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003712: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003712: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003712: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003712: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003712: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003712: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003712: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001609: STAGE:2024-10-10 05:51:58 2027452:2027452 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:51:58 2027453:2027453 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001609: 
nid001609: STAGE:2024-10-10 05:51:58 2027451:2027451 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001609: STAGE:2024-10-10 05:51:58 2027450:2027450 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001613: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001613: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001613: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001613: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001613: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001613: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001613: STAGE:2024-10-10 05:51:58 512191:512191 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:51:58 512192:512192 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001613: 
nid003700: STAGE:2024-10-10 05:51:58 1155240:1155240 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:51:58 1155238:1155238 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:51:58 1155239:1155239 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003700: 
nid003700: 
nid003700: STAGE:2024-10-10 05:51:58 1155241:1155241 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003712: STAGE:2024-10-10 05:51:58 1863056:1863056 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:51:58 1863053:1863053 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003712: 
nid003712: STAGE:2024-10-10 05:51:58 1863054:1863054 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003712: STAGE:2024-10-10 05:51:58 1863055:1863055 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003705: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003705: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003705: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003705: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003705: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003705: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001613: STAGE:2024-10-10 05:51:58 512190:512190 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001613: STAGE:2024-10-10 05:51:58 512189:512189 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003705: STAGE:2024-10-10 05:51:58 1060207:1060207 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:51:58 1060208:1060208 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003705: 
nid001620: STAGE:2024-10-10 05:51:59 568918:568918 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:51:59 568919:568919 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001620: 
nid001620: STAGE:2024-10-10 05:51:59 568917:568917 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:51:59 568916:568916 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001620: 
nid003705: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003705: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003705: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003705: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003705: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003705: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001600: STAGE:2024-10-10 05:51:59 1374897:1374897 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:51:59 1374896:1374896 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001600: STAGE:2024-10-10 05:51:59 1374895:1374895 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:51:59 1374898:1374898 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001600: 
nid001600: 
nid003705: STAGE:2024-10-10 05:51:59 1060210:1060210 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003705: STAGE:2024-10-10 05:51:59 1060209:1060209 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001620: [2024-10-10 05:51:59,354] [INFO] [comm.py:637:init_distributed] cdb=None
nid001620: [2024-10-10 05:51:59,554] [INFO] [comm.py:637:init_distributed] cdb=None
nid001416: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001416: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001416: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001416: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001416: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001416: 
nid001416: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001416: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001416: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001416: 
nid001416: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001416: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001620: [2024-10-10 05:51:59,685] [INFO] [comm.py:637:init_distributed] cdb=None
nid003709: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003709: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003709: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003709: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003709: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003709: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003709: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003709: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003709: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003709: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003709: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003709: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001620: [2024-10-10 05:51:59,722] [INFO] [comm.py:637:init_distributed] cdb=None
nid001416: STAGE:2024-10-10 05:51:59 1371972:1371972 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:51:59 1371975:1371975 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001416: 
nid001416: STAGE:2024-10-10 05:51:59 1371973:1371973 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001416: STAGE:2024-10-10 05:51:59 1371974:1371974 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001601: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001601: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001601: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001601: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001601: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001601: 
nid001601: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001601: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001601: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001601: 
nid001601: 
nid001601: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001608: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001608: 
nid001608: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001608: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001608: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001608: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001608: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001608: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001608: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001608: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001608: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001608: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003700: STAGE:2024-10-10 05:51:59 1155241:1155241 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:51:59 1155239:1155239 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003700: 
nid003700: STAGE:2024-10-10 05:51:59 1155240:1155240 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003709: STAGE:2024-10-10 05:51:59 157806:157806 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:51:59 157807:157807 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003709: STAGE:2024-10-10 05:51:59 157808:157808 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003709: STAGE:2024-10-10 05:51:59 157809:157809 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003709: 
nid003700: STAGE:2024-10-10 05:51:59 1155238:1155238 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003713: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003713: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003713: 
nid003713: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003713: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003713: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003713: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003713: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003713: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003713: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003713: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003713: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001597: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001597: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001597: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001597: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001597: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001597: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001597: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001597: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001597: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001597: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001597: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001597: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001600: [2024-10-10 05:51:59,900] [INFO] [comm.py:637:init_distributed] cdb=None
nid001589: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001589: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001589: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001589: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001589: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001589: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001589: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001589: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001589: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001589: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001589: 
nid001589: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001596: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001596: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001596: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001596: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001596: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001596: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001596: 
nid001596: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001596: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001596: 
nid001596: 
nid001596: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003701: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003701: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003701: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003701: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003701: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003701: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003701: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003701: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003701: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003701: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003701: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003701: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001609: STAGE:2024-10-10 05:51:59 2027450:2027450 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001609: STAGE:2024-10-10 05:51:59 2027452:2027452 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:51:59 2027451:2027451 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:51:59 2027453:2027453 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001609: 
nid001609: 
nid001608: STAGE:2024-10-10 05:51:59 1027467:1027467 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:51:59 1027469:1027469 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001608: STAGE:2024-10-10 05:51:59 1027468:1027468 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:51:59 1027470:1027470 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001608: 
nid001608: 
nid001601: STAGE:2024-10-10 05:51:59 1202360:1202360 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:51:59 1202361:1202361 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:51:59 1202362:1202362 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001601: 
nid001601: STAGE:2024-10-10 05:51:59 1202359:1202359 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001601: 
nid001604: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001604: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001604: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001604: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001604: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001604: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001604: 
nid001604: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001604: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001604: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001604: 
nid001604: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003712: STAGE:2024-10-10 05:52:00 1863056:1863056 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:00 1863053:1863053 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:00 1863054:1863054 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:00 1863055:1863055 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003712: 
nid003712: 
nid003712: 
nid001613: STAGE:2024-10-10 05:52:00 512192:512192 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:00 512191:512191 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001613: 
nid003713: STAGE:2024-10-10 05:52:00 699015:699015 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 699016:699016 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003713: STAGE:2024-10-10 05:52:00 699014:699014 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003713: STAGE:2024-10-10 05:52:00 699013:699013 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003713: 
nid001597: STAGE:2024-10-10 05:52:00 1888491:1888491 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001597: STAGE:2024-10-10 05:52:00 1888490:1888490 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001597: STAGE:2024-10-10 05:52:00 1888492:1888492 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 1888493:1888493 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001597: 
nid001613: STAGE:2024-10-10 05:52:00 512190:512190 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001613: STAGE:2024-10-10 05:52:00 512189:512189 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001596: STAGE:2024-10-10 05:52:00 733224:733224 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 733222:733222 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 733221:733221 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001596: 
nid001596: 
nid001596: STAGE:2024-10-10 05:52:00 733223:733223 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003701: STAGE:2024-10-10 05:52:00 1677294:1677294 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 1677297:1677297 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 1677295:1677295 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003701: 
nid003701: 
nid003701: STAGE:2024-10-10 05:52:00 1677296:1677296 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003705: STAGE:2024-10-10 05:52:00 1060207:1060207 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:00 1060208:1060208 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003705: 
nid001604: STAGE:2024-10-10 05:52:00 556101:556101 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 556100:556100 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001604: 
nid001604: STAGE:2024-10-10 05:52:00 556098:556098 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001604: STAGE:2024-10-10 05:52:00 556099:556099 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001605: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001605: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001605: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001605: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001605: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001605: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001605: 
nid001605: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001605: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001605: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001605: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001605: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001589: STAGE:2024-10-10 05:52:00 1528675:1528675 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 1528678:1528678 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001589: 
nid001589: STAGE:2024-10-10 05:52:00 1528677:1528677 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001589: STAGE:2024-10-10 05:52:00 1528676:1528676 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003705: STAGE:2024-10-10 05:52:00 1060209:1060209 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003705: STAGE:2024-10-10 05:52:00 1060210:1060210 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001609: [2024-10-10 05:52:00,268] [INFO] [comm.py:637:init_distributed] cdb=None
nid001605: STAGE:2024-10-10 05:52:00 694284:694284 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 694281:694281 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001605: 
nid001605: STAGE:2024-10-10 05:52:00 694283:694283 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001605: STAGE:2024-10-10 05:52:00 694282:694282 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003696: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003696: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003696: 
nid003696: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003696: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003696: 
nid003696: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003696: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003696: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003696: 
nid003696: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003696: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003693: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003693: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003693: 
nid003693: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003693: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003693: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003693: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003693: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003693: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003693: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003693: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003693: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001413: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001413: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001413: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001413: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003704: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003704: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003704: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003704: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001413: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001413: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001413: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001413: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001413: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001413: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001413: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001413: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003704: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003704: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003704: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003704: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003704: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003704: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003704: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003704: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003705: [2024-10-10 05:52:00,478] [INFO] [comm.py:637:init_distributed] cdb=None
nid003696: STAGE:2024-10-10 05:52:00 198607:198607 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 198606:198606 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003696: 
nid003696: STAGE:2024-10-10 05:52:00 198609:198609 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003696: STAGE:2024-10-10 05:52:00 198608:198608 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001612: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001612: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001612: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001612: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001612: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001612: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001612: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001612: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001612: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001612: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001612: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001612: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003692: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003692: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003692: 
nid003692: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003692: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003692: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003692: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003692: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003692: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003692: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003692: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003692: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003697: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003697: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003697: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003697: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003693: STAGE:2024-10-10 05:52:00 1571143:1571143 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 1571145:1571145 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003693: 
nid003693: STAGE:2024-10-10 05:52:00 1571144:1571144 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003693: STAGE:2024-10-10 05:52:00 1571142:1571142 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003697: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003697: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003697: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003697: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003697: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003697: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003697: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003697: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003705: [2024-10-10 05:52:00,587] [INFO] [comm.py:637:init_distributed] cdb=None
nid003708: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003708: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003708: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003708: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid003708: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003708: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003708: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003708: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid003708: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003708: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003708: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003708: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003704: STAGE:2024-10-10 05:52:00 1046108:1046108 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 1046109:1046109 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003704: 
nid003704: STAGE:2024-10-10 05:52:00 1046106:1046106 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003704: STAGE:2024-10-10 05:52:00 1046107:1046107 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003692: STAGE:2024-10-10 05:52:00 108032:108032 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003692: STAGE:2024-10-10 05:52:00 108033:108033 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003692: STAGE:2024-10-10 05:52:00 108034:108034 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003692: STAGE:2024-10-10 05:52:00 108035:108035 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003697: STAGE:2024-10-10 05:52:00 254595:254595 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 254593:254593 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003697: 
nid003697: STAGE:2024-10-10 05:52:00 254592:254592 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003697: STAGE:2024-10-10 05:52:00 254594:254594 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001413: STAGE:2024-10-10 05:52:00 1932896:1932896 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001413: STAGE:2024-10-10 05:52:00 1932897:1932897 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001413: STAGE:2024-10-10 05:52:00 1932894:1932894 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 1932895:1932895 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001413: 
nid003705: [2024-10-10 05:52:00,769] [INFO] [comm.py:637:init_distributed] cdb=None
nid001612: STAGE:2024-10-10 05:52:00 934292:934292 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001612: STAGE:2024-10-10 05:52:00 934290:934290 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001612: STAGE:2024-10-10 05:52:00 934291:934291 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001612: STAGE:2024-10-10 05:52:00 934293:934293 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001616: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001616: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001616: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001616: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001616: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001616: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001616: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001616: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001616: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001416: STAGE:2024-10-10 05:52:00 1371973:1371973 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:00 1371974:1371974 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001616: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001616: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001416: 
nid001416: STAGE:2024-10-10 05:52:00 1371972:1371972 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001416: STAGE:2024-10-10 05:52:00 1371975:1371975 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001616: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003709: STAGE:2024-10-10 05:52:00 157809:157809 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:00 157806:157806 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:00 157808:157808 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003709: 
nid003709: STAGE:2024-10-10 05:52:00 157807:157807 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003709: 
nid003708: STAGE:2024-10-10 05:52:00 1658996:1658996 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003708: STAGE:2024-10-10 05:52:00 1658993:1658993 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003708: STAGE:2024-10-10 05:52:00 1658995:1658995 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003708: STAGE:2024-10-10 05:52:00 1658994:1658994 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001417: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001417: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001417: 
nid001417: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001417: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001417: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001417: 
nid001417: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001417: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001417: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001417: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001417: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003705: [2024-10-10 05:52:00,966] [INFO] [comm.py:637:init_distributed] cdb=None
nid001616: STAGE:2024-10-10 05:52:00 1981247:1981247 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 1981246:1981246 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:00 1981245:1981245 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001616: 
nid001616: 
nid001616: STAGE:2024-10-10 05:52:00 1981248:1981248 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001608: STAGE:2024-10-10 05:52:01 1027470:1027470 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001608: STAGE:2024-10-10 05:52:01 1027467:1027467 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 1027468:1027468 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001608: 
nid001608: STAGE:2024-10-10 05:52:01 1027469:1027469 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001417: STAGE:2024-10-10 05:52:01 2337822:2337822 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001417: STAGE:2024-10-10 05:52:01 2337823:2337823 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001417: STAGE:2024-10-10 05:52:01 2337820:2337820 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001601: STAGE:2024-10-10 05:52:01 1202361:1202361 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001601: STAGE:2024-10-10 05:52:01 1202362:1202362 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 1202360:1202360 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001601: 
nid001601: STAGE:2024-10-10 05:52:01 1202359:1202359 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001417: STAGE:2024-10-10 05:52:01 2337821:2337821 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001597: STAGE:2024-10-10 05:52:01 1888491:1888491 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 1888490:1888490 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 1888493:1888493 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001597: 
nid001597: 
nid001597: STAGE:2024-10-10 05:52:01 1888492:1888492 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001604: STAGE:2024-10-10 05:52:01 556099:556099 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 556098:556098 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001604: STAGE:2024-10-10 05:52:01 556101:556101 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001604: 
nid001604: STAGE:2024-10-10 05:52:01 556100:556100 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003713: STAGE:2024-10-10 05:52:01 699015:699015 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 699016:699016 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003713: 
nid003713: STAGE:2024-10-10 05:52:01 699014:699014 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003713: STAGE:2024-10-10 05:52:01 699013:699013 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001593: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001593: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001593: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001593: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001593: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001593: 
nid001593: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001593: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001593: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001593: 
nid001593: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001593: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid003712: [2024-10-10 05:52:01,180] [INFO] [comm.py:637:init_distributed] cdb=None
nid001596: STAGE:2024-10-10 05:52:01 733221:733221 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001596: STAGE:2024-10-10 05:52:01 733222:733222 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001596: STAGE:2024-10-10 05:52:01 733224:733224 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 733223:733223 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001596: 
nid003701: STAGE:2024-10-10 05:52:01 1677295:1677295 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 1677297:1677297 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003701: 
nid003701: STAGE:2024-10-10 05:52:01 1677296:1677296 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003701: STAGE:2024-10-10 05:52:01 1677294:1677294 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001589: STAGE:2024-10-10 05:52:01 1528675:1528675 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 1528678:1528678 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001589: 
nid001589: STAGE:2024-10-10 05:52:01 1528677:1528677 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001589: STAGE:2024-10-10 05:52:01 1528676:1528676 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001605: STAGE:2024-10-10 05:52:01 694281:694281 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001605: STAGE:2024-10-10 05:52:01 694282:694282 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 694284:694284 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 694283:694283 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001605: 
nid001605: 
nid001593: STAGE:2024-10-10 05:52:01 215627:215627 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001593: STAGE:2024-10-10 05:52:01 215624:215624 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001593: STAGE:2024-10-10 05:52:01 215626:215626 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001593: STAGE:2024-10-10 05:52:01 215625:215625 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001597: [2024-10-10 05:52:01,402] [INFO] [comm.py:637:init_distributed] cdb=None
nid003696: STAGE:2024-10-10 05:52:01 198606:198606 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003696: STAGE:2024-10-10 05:52:01 198607:198607 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 198609:198609 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003696: STAGE:2024-10-10 05:52:01 198608:198608 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003696: 
nid001600: [2024-10-10 05:52:01,570] [INFO] [comm.py:637:init_distributed] cdb=None
nid001600: [2024-10-10 05:52:01,570] [INFO] [comm.py:637:init_distributed] cdb=None
nid001600: [2024-10-10 05:52:01,570] [INFO] [comm.py:637:init_distributed] cdb=None
nid003693: STAGE:2024-10-10 05:52:01 1571145:1571145 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 1571143:1571143 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003693: 
nid003693: STAGE:2024-10-10 05:52:01 1571144:1571144 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 1571142:1571142 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003693: 
nid001605: [2024-10-10 05:52:01,641] [INFO] [comm.py:637:init_distributed] cdb=None
nid003704: STAGE:2024-10-10 05:52:01 1046109:1046109 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003704: STAGE:2024-10-10 05:52:01 1046108:1046108 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003704: STAGE:2024-10-10 05:52:01 1046107:1046107 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 1046106:1046106 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003704: 
nid001413: STAGE:2024-10-10 05:52:01 1932896:1932896 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 1932895:1932895 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001413: 
nid001413: STAGE:2024-10-10 05:52:01 1932894:1932894 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001413: STAGE:2024-10-10 05:52:01 1932897:1932897 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001609: [2024-10-10 05:52:01,779] [INFO] [comm.py:637:init_distributed] cdb=None
nid003692: STAGE:2024-10-10 05:52:01 108032:108032 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 108034:108034 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003692: STAGE:2024-10-10 05:52:01 108033:108033 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003692: 
nid003692: STAGE:2024-10-10 05:52:01 108035:108035 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003697: STAGE:2024-10-10 05:52:01 254595:254595 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 254592:254592 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003697: STAGE:2024-10-10 05:52:01 254594:254594 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003697: 
nid003697: STAGE:2024-10-10 05:52:01 254593:254593 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001612: STAGE:2024-10-10 05:52:01 934291:934291 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001612: STAGE:2024-10-10 05:52:01 934290:934290 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001612: STAGE:2024-10-10 05:52:01 934293:934293 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001612: STAGE:2024-10-10 05:52:01 934292:934292 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003708: STAGE:2024-10-10 05:52:01 1658994:1658994 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003708: STAGE:2024-10-10 05:52:01 1658996:1658996 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 1658993:1658993 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 1658995:1658995 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003708: 
nid003708: 
nid001597: [2024-10-10 05:52:01,929] [INFO] [comm.py:637:init_distributed] cdb=None
nid001616: STAGE:2024-10-10 05:52:01 1981248:1981248 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:01 1981247:1981247 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001616: STAGE:2024-10-10 05:52:01 1981245:1981245 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001616: 
nid001616: STAGE:2024-10-10 05:52:01 1981246:1981246 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001417: STAGE:2024-10-10 05:52:02 2337822:2337822 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001417: STAGE:2024-10-10 05:52:02 2337820:2337820 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001417: STAGE:2024-10-10 05:52:02 2337821:2337821 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:02 2337823:2337823 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001417: 
nid001609: [2024-10-10 05:52:02,123] [INFO] [comm.py:637:init_distributed] cdb=None
nid001617: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001617: 
nid001617: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001617: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001617: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001617: 
nid001617: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001617: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001617: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001617: 
nid001617: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001617: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001592: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001592: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001592: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001592: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid001592: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001592: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001592: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001592: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid001592: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001592: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001592: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001592: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid001604: [2024-10-10 05:52:02,291] [INFO] [comm.py:637:init_distributed] cdb=None
nid001613: [2024-10-10 05:52:02,292] [INFO] [comm.py:637:init_distributed] cdb=None
nid001613: [2024-10-10 05:52:02,292] [INFO] [comm.py:637:init_distributed] cdb=None
nid001613: [2024-10-10 05:52:02,292] [INFO] [comm.py:637:init_distributed] cdb=None
nid001613: [2024-10-10 05:52:02,292] [INFO] [comm.py:637:init_distributed] cdb=None
nid001617: STAGE:2024-10-10 05:52:02 757211:757211 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001617: STAGE:2024-10-10 05:52:02 757213:757213 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001617: STAGE:2024-10-10 05:52:02 757214:757214 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001617: STAGE:2024-10-10 05:52:02 757212:757212 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001597: [2024-10-10 05:52:02,364] [INFO] [comm.py:637:init_distributed] cdb=None
nid001592: STAGE:2024-10-10 05:52:02 1654258:1654258 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 05:52:02 1654260:1654260 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001592: STAGE:2024-10-10 05:52:02 1654257:1654257 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001592: 
nid001592: STAGE:2024-10-10 05:52:02 1654259:1654259 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001593: STAGE:2024-10-10 05:52:02 215627:215627 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:02 215624:215624 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:02 215625:215625 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001593: 
nid001593: 
nid001593: STAGE:2024-10-10 05:52:02 215626:215626 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001413: [2024-10-10 05:52:02,538] [INFO] [comm.py:637:init_distributed] cdb=None
nid003697: [2024-10-10 05:52:02,675] [INFO] [comm.py:637:init_distributed] cdb=None
nid001589: [2024-10-10 05:52:02,765] [INFO] [comm.py:637:init_distributed] cdb=None
nid001589: [2024-10-10 05:52:02,778] [INFO] [comm.py:637:init_distributed] cdb=None
nid001589: [2024-10-10 05:52:02,779] [INFO] [comm.py:637:init_distributed] cdb=None
nid001589: [2024-10-10 05:52:02,779] [INFO] [comm.py:637:init_distributed] cdb=None
nid003701: [2024-10-10 05:52:02,782] [INFO] [comm.py:637:init_distributed] cdb=None
nid003701: [2024-10-10 05:52:02,782] [INFO] [comm.py:637:init_distributed] cdb=None
nid003701: [2024-10-10 05:52:02,783] [INFO] [comm.py:637:init_distributed] cdb=None
nid003701: [2024-10-10 05:52:02,783] [INFO] [comm.py:637:init_distributed] cdb=None
nid003696: [2024-10-10 05:52:02,873] [INFO] [comm.py:637:init_distributed] cdb=None
nid003696: [2024-10-10 05:52:02,882] [INFO] [comm.py:637:init_distributed] cdb=None
nid003696: [2024-10-10 05:52:02,882] [INFO] [comm.py:637:init_distributed] cdb=None
nid003696: [2024-10-10 05:52:02,885] [INFO] [comm.py:637:init_distributed] cdb=None
nid001616: [2024-10-10 05:52:02,892] [INFO] [comm.py:637:init_distributed] cdb=None
nid001616: [2024-10-10 05:52:02,892] [INFO] [comm.py:637:init_distributed] cdb=None
nid001616: [2024-10-10 05:52:02,892] [INFO] [comm.py:637:init_distributed] cdb=None
nid001616: [2024-10-10 05:52:02,892] [INFO] [comm.py:637:init_distributed] cdb=None
nid003712: [2024-10-10 05:52:02,965] [INFO] [comm.py:637:init_distributed] cdb=None
nid003712: [2024-10-10 05:52:02,991] [INFO] [comm.py:637:init_distributed] cdb=None
nid003712: [2024-10-10 05:52:02,991] [INFO] [comm.py:637:init_distributed] cdb=None
nid001597: [2024-10-10 05:52:02,995] [INFO] [comm.py:637:init_distributed] cdb=None
nid003693: [2024-10-10 05:52:03,154] [INFO] [comm.py:637:init_distributed] cdb=None
nid003692: [2024-10-10 05:52:03,154] [INFO] [comm.py:637:init_distributed] cdb=None
nid003692: [2024-10-10 05:52:03,154] [INFO] [comm.py:637:init_distributed] cdb=None
nid003692: [2024-10-10 05:52:03,154] [INFO] [comm.py:637:init_distributed] cdb=None
nid003692: [2024-10-10 05:52:03,154] [INFO] [comm.py:637:init_distributed] cdb=None
nid003713: [2024-10-10 05:52:03,155] [INFO] [comm.py:637:init_distributed] cdb=None
nid003713: [2024-10-10 05:52:03,155] [INFO] [comm.py:637:init_distributed] cdb=None
nid003713: [2024-10-10 05:52:03,155] [INFO] [comm.py:637:init_distributed] cdb=None
nid003713: [2024-10-10 05:52:03,155] [INFO] [comm.py:637:init_distributed] cdb=None
nid001609: [2024-10-10 05:52:03,157] [INFO] [comm.py:637:init_distributed] cdb=None
nid003700: [2024-10-10 05:52:03,166] [INFO] [comm.py:637:init_distributed] cdb=None
nid003700: [2024-10-10 05:52:03,166] [INFO] [comm.py:637:init_distributed] cdb=None
nid003700: [2024-10-10 05:52:03,166] [INFO] [comm.py:637:init_distributed] cdb=None
nid003700: [2024-10-10 05:52:03,166] [INFO] [comm.py:637:init_distributed] cdb=None
nid003704: [2024-10-10 05:52:03,328] [INFO] [comm.py:637:init_distributed] cdb=None
nid001617: STAGE:2024-10-10 05:52:03 757212:757212 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001617: STAGE:2024-10-10 05:52:03 757213:757213 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001617: STAGE:2024-10-10 05:52:03 757214:757214 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001617: STAGE:2024-10-10 05:52:03 757211:757211 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001592: STAGE:2024-10-10 05:52:03 1654258:1654258 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001592: STAGE:2024-10-10 05:52:03 1654257:1654257 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 05:52:03 1654259:1654259 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001592: 
nid001592: STAGE:2024-10-10 05:52:03 1654260:1654260 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001416: [2024-10-10 05:52:03,476] [INFO] [comm.py:637:init_distributed] cdb=None
nid003708: [2024-10-10 05:52:03,477] [INFO] [comm.py:637:init_distributed] cdb=None
nid003708: [2024-10-10 05:52:03,477] [INFO] [comm.py:637:init_distributed] cdb=None
nid003708: [2024-10-10 05:52:03,477] [INFO] [comm.py:637:init_distributed] cdb=None
nid003708: [2024-10-10 05:52:03,477] [INFO] [comm.py:637:init_distributed] cdb=None
nid001608: [2024-10-10 05:52:03,477] [INFO] [comm.py:637:init_distributed] cdb=None
nid001608: [2024-10-10 05:52:03,477] [INFO] [comm.py:637:init_distributed] cdb=None
nid001608: [2024-10-10 05:52:03,477] [INFO] [comm.py:637:init_distributed] cdb=None
nid001608: [2024-10-10 05:52:03,477] [INFO] [comm.py:637:init_distributed] cdb=None
nid003709: [2024-10-10 05:52:03,478] [INFO] [comm.py:637:init_distributed] cdb=None
nid003709: [2024-10-10 05:52:03,478] [INFO] [comm.py:637:init_distributed] cdb=None
nid003709: [2024-10-10 05:52:03,478] [INFO] [comm.py:637:init_distributed] cdb=None
nid001617: [2024-10-10 05:52:03,709] [INFO] [comm.py:637:init_distributed] cdb=None
nid003693: [2024-10-10 05:52:03,804] [INFO] [comm.py:637:init_distributed] cdb=None
nid003693: [2024-10-10 05:52:03,804] [INFO] [comm.py:637:init_distributed] cdb=None
nid003693: [2024-10-10 05:52:03,877] [INFO] [comm.py:637:init_distributed] cdb=None
nid003709: [2024-10-10 05:52:03,880] [INFO] [comm.py:637:init_distributed] cdb=None
nid001617: [2024-10-10 05:52:04,023] [INFO] [comm.py:637:init_distributed] cdb=None
nid001605: [2024-10-10 05:52:04,169] [INFO] [comm.py:637:init_distributed] cdb=None
nid003704: [2024-10-10 05:52:04,251] [INFO] [comm.py:637:init_distributed] cdb=None
nid003697: [2024-10-10 05:52:04,259] [INFO] [comm.py:637:init_distributed] cdb=None
nid003697: [2024-10-10 05:52:04,259] [INFO] [comm.py:637:init_distributed] cdb=None
nid003697: [2024-10-10 05:52:04,259] [INFO] [comm.py:637:init_distributed] cdb=None
nid003704: [2024-10-10 05:52:04,278] [INFO] [comm.py:637:init_distributed] cdb=None
nid003704: [2024-10-10 05:52:04,278] [INFO] [comm.py:637:init_distributed] cdb=None
nid001596: [2024-10-10 05:52:04,286] [INFO] [comm.py:637:init_distributed] cdb=None
nid001596: [2024-10-10 05:52:04,286] [INFO] [comm.py:637:init_distributed] cdb=None
nid001596: [2024-10-10 05:52:04,286] [INFO] [comm.py:637:init_distributed] cdb=None
nid001596: [2024-10-10 05:52:04,286] [INFO] [comm.py:637:init_distributed] cdb=None
nid001617: [2024-10-10 05:52:04,356] [INFO] [comm.py:637:init_distributed] cdb=None
nid001617: [2024-10-10 05:52:04,386] [INFO] [comm.py:637:init_distributed] cdb=None
nid001601: [2024-10-10 05:52:04,481] [INFO] [comm.py:637:init_distributed] cdb=None
nid001601: [2024-10-10 05:52:04,488] [INFO] [comm.py:637:init_distributed] cdb=None
nid001601: [2024-10-10 05:52:04,488] [INFO] [comm.py:637:init_distributed] cdb=None
nid001601: [2024-10-10 05:52:04,491] [INFO] [comm.py:637:init_distributed] cdb=None
nid001592: [2024-10-10 05:52:04,662] [INFO] [comm.py:637:init_distributed] cdb=None
nid001592: [2024-10-10 05:52:04,769] [INFO] [comm.py:637:init_distributed] cdb=None
nid001592: [2024-10-10 05:52:04,801] [INFO] [comm.py:637:init_distributed] cdb=None
nid001592: [2024-10-10 05:52:04,801] [INFO] [comm.py:637:init_distributed] cdb=None
nid001593: [2024-10-10 05:52:04,819] [INFO] [comm.py:637:init_distributed] cdb=None
nid001417: [2024-10-10 05:52:04,906] [INFO] [comm.py:637:init_distributed] cdb=None
nid001417: [2024-10-10 05:52:04,918] [INFO] [comm.py:637:init_distributed] cdb=None
nid001417: [2024-10-10 05:52:04,918] [INFO] [comm.py:637:init_distributed] cdb=None
nid001593: [2024-10-10 05:52:04,993] [INFO] [comm.py:637:init_distributed] cdb=None
nid001593: [2024-10-10 05:52:05,022] [INFO] [comm.py:637:init_distributed] cdb=None
nid001593: [2024-10-10 05:52:05,022] [INFO] [comm.py:637:init_distributed] cdb=None
nid001605: [2024-10-10 05:52:05,114] [INFO] [comm.py:637:init_distributed] cdb=None
nid001605: [2024-10-10 05:52:05,138] [INFO] [comm.py:637:init_distributed] cdb=None
nid001416: [2024-10-10 05:52:05,143] [INFO] [comm.py:637:init_distributed] cdb=None
nid001416: [2024-10-10 05:52:05,143] [INFO] [comm.py:637:init_distributed] cdb=None
nid001416: [2024-10-10 05:52:05,143] [INFO] [comm.py:637:init_distributed] cdb=None
nid001612: [2024-10-10 05:52:05,235] [INFO] [comm.py:637:init_distributed] cdb=None
nid001612: [2024-10-10 05:52:05,247] [INFO] [comm.py:637:init_distributed] cdb=None
nid001612: [2024-10-10 05:52:05,247] [INFO] [comm.py:637:init_distributed] cdb=None
nid001612: [2024-10-10 05:52:05,247] [INFO] [comm.py:637:init_distributed] cdb=None
nid001417: [2024-10-10 05:52:05,248] [INFO] [comm.py:637:init_distributed] cdb=None
nid001413: [2024-10-10 05:52:05,256] [INFO] [comm.py:637:init_distributed] cdb=None
nid001413: [2024-10-10 05:52:05,329] [INFO] [comm.py:637:init_distributed] cdb=None
nid001604: [2024-10-10 05:52:05,358] [INFO] [comm.py:637:init_distributed] cdb=None
nid001413: [2024-10-10 05:52:05,358] [INFO] [comm.py:637:init_distributed] cdb=None
nid001604: [2024-10-10 05:52:05,358] [INFO] [comm.py:637:init_distributed] cdb=None
nid001604: [2024-10-10 05:52:05,358] [INFO] [comm.py:637:init_distributed] cdb=None
nid001412: > initializing model parallel with size 4
nid001412: MPU DP: [0, 4, 8, 12, 16, 20, 24, 28]
nid001412: MPU DP: [1, 5, 9, 13, 17, 21, 25, 29]
nid001412: MPU DP: [2, 6, 10, 14, 18, 22, 26, 30]
nid001412: MPU DP: [3, 7, 11, 15, 19, 23, 27, 31]
nid001412: MPU DP: [32, 36, 40, 44, 48, 52, 56, 60]
nid001412: MPU DP: [33, 37, 41, 45, 49, 53, 57, 61]
nid001412: MPU DP: [34, 38, 42, 46, 50, 54, 58, 62]
nid001412: MPU DP: [35, 39, 43, 47, 51, 55, 59, 63]
nid001412: MPU DP: [64, 68, 72, 76, 80, 84, 88, 92]
nid001412: MPU DP: [65, 69, 73, 77, 81, 85, 89, 93]
nid001412: MPU DP: [66, 70, 74, 78, 82, 86, 90, 94]
nid001412: MPU DP: [67, 71, 75, 79, 83, 87, 91, 95]
nid001412: MPU DP: [96, 100, 104, 108, 112, 116, 120, 124]
nid001412: MPU DP: [97, 101, 105, 109, 113, 117, 121, 125]
nid001412: MPU DP: [98, 102, 106, 110, 114, 118, 122, 126]
nid001412: MPU DP: [99, 103, 107, 111, 115, 119, 123, 127]
nid001412: MPU PP: [0, 32, 64, 96]
nid001412: MPU PP: [1, 33, 65, 97]
nid001412: MPU PP: [2, 34, 66, 98]
nid001412: MPU PP: [3, 35, 67, 99]
nid001412: MPU PP: [4, 36, 68, 100]
nid001412: MPU PP: [5, 37, 69, 101]
nid001412: MPU PP: [6, 38, 70, 102]
nid001412: MPU PP: [7, 39, 71, 103]
nid001412: MPU PP: [8, 40, 72, 104]
nid001412: MPU PP: [9, 41, 73, 105]
nid001412: MPU PP: [10, 42, 74, 106]
nid001412: MPU PP: [11, 43, 75, 107]
nid001412: MPU PP: [12, 44, 76, 108]
nid001412: MPU PP: [13, 45, 77, 109]
nid001412: MPU PP: [14, 46, 78, 110]
nid001412: MPU PP: [15, 47, 79, 111]
nid001412: MPU PP: [16, 48, 80, 112]
nid001412: MPU PP: [17, 49, 81, 113]
nid001412: MPU PP: [18, 50, 82, 114]
nid001412: MPU PP: [19, 51, 83, 115]
nid001412: MPU PP: [20, 52, 84, 116]
nid001412: MPU PP: [21, 53, 85, 117]
nid001412: MPU PP: [22, 54, 86, 118]
nid001412: MPU PP: [23, 55, 87, 119]
nid001412: MPU PP: [24, 56, 88, 120]
nid001412: MPU PP: [25, 57, 89, 121]
nid001412: MPU PP: [26, 58, 90, 122]
nid001412: MPU PP: [27, 59, 91, 123]
nid001412: MPU PP: [28, 60, 92, 124]
nid001412: MPU PP: [29, 61, 93, 125]
nid001412: MPU PP: [30, 62, 94, 126]
nid001412: MPU PP: [31, 63, 95, 127]
nid001412: MPU IO: [0, 4, 8, 12, 16, 20, 24, 28, 96, 100, 104, 108, 112, 116, 120, 124]
nid001412: MPU MP: [0, 1, 2, 3]
nid001412: MPU MP: [4, 5, 6, 7]
nid001412: MPU MP: [8, 9, 10, 11]
nid001412: MPU MP: [12, 13, 14, 15]
nid001412: MPU MP: [16, 17, 18, 19]
nid001412: MPU MP: [20, 21, 22, 23]
nid001412: MPU MP: [24, 25, 26, 27]
nid001412: MPU MP: [28, 29, 30, 31]
nid001412: MPU MP: [32, 33, 34, 35]
nid001412: MPU MP: [36, 37, 38, 39]
nid001412: MPU MP: [40, 41, 42, 43]
nid001412: MPU MP: [44, 45, 46, 47]
nid001412: MPU MP: [48, 49, 50, 51]
nid001412: MPU MP: [52, 53, 54, 55]
nid001412: MPU MP: [56, 57, 58, 59]
nid001412: MPU MP: [60, 61, 62, 63]
nid001412: MPU MP: [64, 65, 66, 67]
nid001412: MPU MP: [68, 69, 70, 71]
nid001412: MPU MP: [72, 73, 74, 75]
nid001412: MPU MP: [76, 77, 78, 79]
nid001412: MPU MP: [80, 81, 82, 83]
nid001412: MPU MP: [84, 85, 86, 87]
nid001412: MPU MP: [88, 89, 90, 91]
nid001412: MPU MP: [92, 93, 94, 95]
nid001412: MPU MP: [96, 97, 98, 99]
nid001412: MPU MP: [100, 101, 102, 103]
nid001412: MPU MP: [104, 105, 106, 107]
nid001412: MPU MP: [108, 109, 110, 111]
nid001412: MPU MP: [112, 113, 114, 115]
nid001412: MPU MP: [116, 117, 118, 119]
nid001412: MPU MP: [120, 121, 122, 123]
nid001412: MPU MP: [124, 125, 126, 127]
nid001412: > setting random seeds to 1234 ...
nid001417: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001613: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001417: make: Nothing to be done for 'default'.
nid001417: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001589: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001597: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001613: make: Nothing to be done for 'default'.
nid001613: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001612: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001589: make: Nothing to be done for 'default'.
nid001589: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001413: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001620: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001597: make: Nothing to be done for 'default'.
nid001597: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001609: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003701: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001612: make: Nothing to be done for 'default'.
nid001612: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001605: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001601: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001413: make: Nothing to be done for 'default'.
nid001413: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001620: make: Nothing to be done for 'default'.
nid001620: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001416: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001609: make: Nothing to be done for 'default'.
nid001609: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003701: make: Nothing to be done for 'default'.
nid003701: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001605: make: Nothing to be done for 'default'.
nid001605: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003709: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001601: make: Nothing to be done for 'default'.
nid001601: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001592: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003704: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003712: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003700: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003693: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001416: make: Nothing to be done for 'default'.
nid001416: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003709: make: Nothing to be done for 'default'.
nid003709: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001608: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001604: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001593: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001592: make: Nothing to be done for 'default'.
nid001592: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001596: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003708: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001412: [2024-10-10 05:52:11,591] [INFO] [checkpointing.py:227:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
nid003705: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003704: make: Nothing to be done for 'default'.
nid003704: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003712: make: Nothing to be done for 'default'.
nid003712: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003697: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003693: make: Nothing to be done for 'default'.
nid003693: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003700: make: Nothing to be done for 'default'.
nid003700: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003692: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001608: make: Nothing to be done for 'default'.
nid001608: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001412: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001616: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001604: make: Nothing to be done for 'default'.
nid001604: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001593: make: Nothing to be done for 'default'.
nid001593: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001596: make: Nothing to be done for 'default'.
nid001596: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003708: make: Nothing to be done for 'default'.
nid003708: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003705: make: Nothing to be done for 'default'.
nid003705: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003697: make: Nothing to be done for 'default'.
nid003697: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001617: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001600: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003692: make: Nothing to be done for 'default'.
nid003692: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001412: make: Nothing to be done for 'default'.
nid001412: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001616: make: Nothing to be done for 'default'.
nid001616: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003696: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001617: make: Nothing to be done for 'default'.
nid001617: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003713: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001600: make: Nothing to be done for 'default'.
nid001600: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003696: make: Nothing to be done for 'default'.
nid003696: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid003713: make: Nothing to be done for 'default'.
nid003713: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid001412: building GPT2 model ...
nid001412: SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
nid001412: Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=0, model=1): 1, ProcessCoord(pipe=0, data=0, model=2): 2, ProcessCoord(pipe=0, data=0, model=3): 3, ProcessCoord(pipe=0, data=1, model=0): 4, ProcessCoord(pipe=0, data=1, model=1): 5, ProcessCoord(pipe=0, data=1, model=2): 6, ProcessCoord(pipe=0, data=1, model=3): 7, ProcessCoord(pipe=0, data=2, model=0): 8, ProcessCoord(pipe=0, data=2, model=1): 9, ProcessCoord(pipe=0, data=2, model=2): 10, ProcessCoord(pipe=0, data=2, model=3): 11, ProcessCoord(pipe=0, data=3, model=0): 12, ProcessCoord(pipe=0, data=3, model=1): 13, ProcessCoord(pipe=0, data=3, model=2): 14, ProcessCoord(pipe=0, data=3, model=3): 15, ProcessCoord(pipe=0, data=4, model=0): 16, ProcessCoord(pipe=0, data=4, model=1): 17, ProcessCoord(pipe=0, data=4, model=2): 18, ProcessCoord(pipe=0, data=4, model=3): 19, ProcessCoord(pipe=0, data=5, model=0): 20, ProcessCoord(pipe=0, data=5, model=1): 21, ProcessCoord(pipe=0, data=5, model=2): 22, ProcessCoord(pipe=0, data=5, model=3): 23, ProcessCoord(pipe=0, data=6, model=0): 24, ProcessCoord(pipe=0, data=6, model=1): 25, ProcessCoord(pipe=0, data=6, model=2): 26, ProcessCoord(pipe=0, data=6, model=3): 27, ProcessCoord(pipe=0, data=7, model=0): 28, ProcessCoord(pipe=0, data=7, model=1): 29, ProcessCoord(pipe=0, data=7, model=2): 30, ProcessCoord(pipe=0, data=7, model=3): 31, ProcessCoord(pipe=1, data=0, model=0): 32, ProcessCoord(pipe=1, data=0, model=1): 33, ProcessCoord(pipe=1, data=0, model=2): 34, ProcessCoord(pipe=1, data=0, model=3): 35, ProcessCoord(pipe=1, data=1, model=0): 36, ProcessCoord(pipe=1, data=1, model=1): 37, ProcessCoord(pipe=1, data=1, model=2): 38, ProcessCoord(pipe=1, data=1, model=3): 39, ProcessCoord(pipe=1, data=2, model=0): 40, ProcessCoord(pipe=1, data=2, model=1): 41, ProcessCoord(pipe=1, data=2, model=2): 42, ProcessCoord(pipe=1, data=2, model=3): 43, ProcessCoord(pipe=1, data=3, model=0): 44, ProcessCoord(pipe=1, data=3, model=1): 45, ProcessCoord(pipe=1, data=3, model=2): 46, ProcessCoord(pipe=1, data=3, model=3): 47, ProcessCoord(pipe=1, data=4, model=0): 48, ProcessCoord(pipe=1, data=4, model=1): 49, ProcessCoord(pipe=1, data=4, model=2): 50, ProcessCoord(pipe=1, data=4, model=3): 51, ProcessCoord(pipe=1, data=5, model=0): 52, ProcessCoord(pipe=1, data=5, model=1): 53, ProcessCoord(pipe=1, data=5, model=2): 54, ProcessCoord(pipe=1, data=5, model=3): 55, ProcessCoord(pipe=1, data=6, model=0): 56, ProcessCoord(pipe=1, data=6, model=1): 57, ProcessCoord(pipe=1, data=6, model=2): 58, ProcessCoord(pipe=1, data=6, model=3): 59, ProcessCoord(pipe=1, data=7, model=0): 60, ProcessCoord(pipe=1, data=7, model=1): 61, ProcessCoord(pipe=1, data=7, model=2): 62, ProcessCoord(pipe=1, data=7, model=3): 63, ProcessCoord(pipe=2, data=0, model=0): 64, ProcessCoord(pipe=2, data=0, model=1): 65, ProcessCoord(pipe=2, data=0, model=2): 66, ProcessCoord(pipe=2, data=0, model=3): 67, ProcessCoord(pipe=2, data=1, model=0): 68, ProcessCoord(pipe=2, data=1, model=1): 69, ProcessCoord(pipe=2, data=1, model=2): 70, ProcessCoord(pipe=2, data=1, model=3): 71, ProcessCoord(pipe=2, data=2, model=0): 72, ProcessCoord(pipe=2, data=2, model=1): 73, ProcessCoord(pipe=2, data=2, model=2): 74, ProcessCoord(pipe=2, data=2, model=3): 75, ProcessCoord(pipe=2, data=3, model=0): 76, ProcessCoord(pipe=2, data=3, model=1): 77, ProcessCoord(pipe=2, data=3, model=2): 78, ProcessCoord(pipe=2, data=3, model=3): 79, ProcessCoord(pipe=2, data=4, model=0): 80, ProcessCoord(pipe=2, data=4, model=1): 81, ProcessCoord(pipe=2, data=4, model=2): 82, ProcessCoord(pipe=2, data=4, model=3): 83, ProcessCoord(pipe=2, data=5, model=0): 84, ProcessCoord(pipe=2, data=5, model=1): 85, ProcessCoord(pipe=2, data=5, model=2): 86, ProcessCoord(pipe=2, data=5, model=3): 87, ProcessCoord(pipe=2, data=6, model=0): 88, ProcessCoord(pipe=2, data=6, model=1): 89, ProcessCoord(pipe=2, data=6, model=2): 90, ProcessCoord(pipe=2, data=6, model=3): 91, ProcessCoord(pipe=2, data=7, model=0): 92, ProcessCoord(pipe=2, data=7, model=1): 93, ProcessCoord(pipe=2, data=7, model=2): 94, ProcessCoord(pipe=2, data=7, model=3): 95, ProcessCoord(pipe=3, data=0, model=0): 96, ProcessCoord(pipe=3, data=0, model=1): 97, ProcessCoord(pipe=3, data=0, model=2): 98, ProcessCoord(pipe=3, data=0, model=3): 99, ProcessCoord(pipe=3, data=1, model=0): 100, ProcessCoord(pipe=3, data=1, model=1): 101, ProcessCoord(pipe=3, data=1, model=2): 102, ProcessCoord(pipe=3, data=1, model=3): 103, ProcessCoord(pipe=3, data=2, model=0): 104, ProcessCoord(pipe=3, data=2, model=1): 105, ProcessCoord(pipe=3, data=2, model=2): 106, ProcessCoord(pipe=3, data=2, model=3): 107, ProcessCoord(pipe=3, data=3, model=0): 108, ProcessCoord(pipe=3, data=3, model=1): 109, ProcessCoord(pipe=3, data=3, model=2): 110, ProcessCoord(pipe=3, data=3, model=3): 111, ProcessCoord(pipe=3, data=4, model=0): 112, ProcessCoord(pipe=3, data=4, model=1): 113, ProcessCoord(pipe=3, data=4, model=2): 114, ProcessCoord(pipe=3, data=4, model=3): 115, ProcessCoord(pipe=3, data=5, model=0): 116, ProcessCoord(pipe=3, data=5, model=1): 117, ProcessCoord(pipe=3, data=5, model=2): 118, ProcessCoord(pipe=3, data=5, model=3): 119, ProcessCoord(pipe=3, data=6, model=0): 120, ProcessCoord(pipe=3, data=6, model=1): 121, ProcessCoord(pipe=3, data=6, model=2): 122, ProcessCoord(pipe=3, data=6, model=3): 123, ProcessCoord(pipe=3, data=7, model=0): 124, ProcessCoord(pipe=3, data=7, model=1): 125, ProcessCoord(pipe=3, data=7, model=2): 126, ProcessCoord(pipe=3, data=7, model=3): 127}
nid001412: [2024-10-10 05:52:12,893] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer|mlp
nid001412: stage=0 layers=13
nid001412:      0: EmbeddingPipe
nid001412:      1: _pre_transformer_block
nid001412:      2: ParallelTransformerLayerPipe
nid001412:      3: ParallelTransformerLayerPipe
nid001412:      4: ParallelTransformerLayerPipe
nid001412:      5: ParallelTransformerLayerPipe
nid001412:      6: ParallelTransformerLayerPipe
nid001412:      7: ParallelTransformerLayerPipe
nid001412:      8: ParallelTransformerLayerPipe
nid001412:      9: ParallelTransformerLayerPipe
nid001412:     10: ParallelTransformerLayerPipe
nid001412:     11: ParallelTransformerLayerPipe
nid001412:     12: ParallelTransformerLayerPipe
nid001412: stage=1 layers=12
nid001412:     13: ParallelTransformerLayerPipe
nid001412:     14: ParallelTransformerLayerPipe
nid001412:     15: ParallelTransformerLayerPipe
nid001412:     16: ParallelTransformerLayerPipe
nid001412:     17: ParallelTransformerLayerPipe
nid001412:     18: ParallelTransformerLayerPipe
nid001412:     19: ParallelTransformerLayerPipe
nid001412:     20: ParallelTransformerLayerPipe
nid001412:     21: ParallelTransformerLayerPipe
nid001412:     22: ParallelTransformerLayerPipe
nid001412:     23: ParallelTransformerLayerPipe
nid001412:     24: ParallelTransformerLayerPipe
nid001412: stage=2 layers=12
nid001412:     25: ParallelTransformerLayerPipe
nid001412:     26: ParallelTransformerLayerPipe
nid001412:     27: ParallelTransformerLayerPipe
nid001412:     28: ParallelTransformerLayerPipe
nid001412:     29: ParallelTransformerLayerPipe
nid001412:     30: ParallelTransformerLayerPipe
nid001412:     31: ParallelTransformerLayerPipe
nid001412:     32: ParallelTransformerLayerPipe
nid001412:     33: ParallelTransformerLayerPipe
nid001412:     34: ParallelTransformerLayerPipe
nid001412:     35: ParallelTransformerLayerPipe
nid001412:     36: ParallelTransformerLayerPipe
nid001412: stage=3 layers=12
nid001412:     37: ParallelTransformerLayerPipe
nid001412:     38: ParallelTransformerLayerPipe
nid001412:     39: ParallelTransformerLayerPipe
nid001412:     40: ParallelTransformerLayerPipe
nid001412:     41: ParallelTransformerLayerPipe
nid001412:     42: ParallelTransformerLayerPipe
nid001412:     43: ParallelTransformerLayerPipe
nid001412:     44: ParallelTransformerLayerPipe
nid001412:     45: ParallelTransformerLayerPipe
nid001412:     46: _post_transformer_block
nid001412:     47: NormPipe
nid001412:     48: ParallelLinearPipe
nid001412:   loss: partial
nid003712: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003708: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003712: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003709: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003704: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003701: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003708: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003700: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003705: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003692: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003713: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003697: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001605: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003709: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001608: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003701: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003696: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001612: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001609: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003704: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001616: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003700: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003705: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003692: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003713: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003697: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001613: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001605: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001608: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003696: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001612: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001593: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001609: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001616: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001413: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001596: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001613: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001416: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001417: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001589: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003693: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001592: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001593: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001600: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001413: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001596: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001416: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001417: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001589: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003693: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001592: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001617: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001597: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001600: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001601: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001620: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001617: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001597: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001412: Configuring Optimizer type: Adam with params: {'lr': 9.7e-05, 'betas': [0.9, 0.95], 'eps': 1e-08}
nid001601: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001412: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001620: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001604: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001412: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001604: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003712: Detected CUDA files, patching ldflags
nid003712: Emitting ninja build file /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117/fused_adam/build.ninja...
nid003712: Building extension module fused_adam...
nid003712: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
nid003712: ninja: no work to do.
nid003712: Loading extension module fused_adam...
nid003712: Time to load fused_adam op: 0.30246758460998535 seconds
nid003708: Loading extension module fused_adam...
nid003709: Loading extension module fused_adam...
nid003701: Loading extension module fused_adam...
nid003704: Loading extension module fused_adam...
nid003700: Loading extension module fused_adam...
nid003705: Loading extension module fused_adam...
nid003692: Loading extension module fused_adam...
nid003697: Loading extension module fused_adam...
nid003708: Time to load fused_adam op: 0.3171849250793457 seconds
nid003713: Loading extension module fused_adam...
nid003709: Time to load fused_adam op: 0.31652402877807617 seconds
nid001605: Loading extension module fused_adam...
nid001608: Loading extension module fused_adam...
nid003701: Time to load fused_adam op: 0.31642746925354004 seconds
nid003696: Loading extension module fused_adam...
nid001612: Loading extension module fused_adam...
nid001609: Loading extension module fused_adam...
nid003704: Time to load fused_adam op: 0.31617069244384766 seconds
nid001616: Loading extension module fused_adam...
nid003705: Time to load fused_adam op: 0.3167262077331543 seconds
nid001613: Loading extension module fused_adam...
nid003700: Time to load fused_adam op: 0.3180696964263916 seconds
nid003692: Time to load fused_adam op: 0.319918155670166 seconds
nid001608: Time to load fused_adam op: 0.31694459915161133 seconds
nid003697: Time to load fused_adam op: 0.3211338520050049 seconds
nid001593: Loading extension module fused_adam...
nid003696: Time to load fused_adam op: 0.31783175468444824 seconds
nid003713: Time to load fused_adam op: 0.32279443740844727 seconds
nid001609: Time to load fused_adam op: 0.3179757595062256 seconds
nid001413: Loading extension module fused_adam...
nid001605: Time to load fused_adam op: 0.3207087516784668 seconds
nid001596: Loading extension module fused_adam...
nid001416: Loading extension module fused_adam...
nid001613: Time to load fused_adam op: 0.31754565238952637 seconds
nid001616: Time to load fused_adam op: 0.3196096420288086 seconds
nid001417: Loading extension module fused_adam...
nid001612: Time to load fused_adam op: 0.32218003273010254 seconds
nid003693: Loading extension module fused_adam...
nid001589: Loading extension module fused_adam...
nid001592: Loading extension module fused_adam...
nid001593: Time to load fused_adam op: 0.3165910243988037 seconds
nid001600: Loading extension module fused_adam...
nid001413: Time to load fused_adam op: 0.3150653839111328 seconds
nid001596: Time to load fused_adam op: 0.3146250247955322 seconds
nid001416: Time to load fused_adam op: 0.3150644302368164 seconds
nid001417: Time to load fused_adam op: 0.3143317699432373 seconds
nid001589: Time to load fused_adam op: 0.31471896171569824 seconds
nid003693: Time to load fused_adam op: 0.3154785633087158 seconds
nid001592: Time to load fused_adam op: 0.31589818000793457 seconds
nid001617: Loading extension module fused_adam...
nid001597: Loading extension module fused_adam...
nid001600: Time to load fused_adam op: 0.3164641857147217 seconds
nid001601: Loading extension module fused_adam...
nid001617: Time to load fused_adam op: 0.31426525115966797 seconds
nid001597: Time to load fused_adam op: 0.314373254776001 seconds
nid001620: Loading extension module fused_adam...
nid001601: Time to load fused_adam op: 0.31412768363952637 seconds
nid001620: Time to load fused_adam op: 0.31442809104919434 seconds
nid001412: Loading extension module fused_adam...
nid001604: Loading extension module fused_adam...
nid001412: Time to load fused_adam op: 0.3155815601348877 seconds
nid001412: > learning rate decay style: cosine
nid001412: DeepSpeed is enabled.
nid001412: [2024-10-10 05:52:13,420] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4+02e2ebf, git-hash=02e2ebf, git-branch=HEAD
nid001604: Time to load fused_adam op: 0.31612133979797363 seconds
nid001412: [2024-10-10 05:52:13,857] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
nid001412: [2024-10-10 05:52:13,858] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
nid001412: [2024-10-10 05:52:13,858] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
nid001412: [2024-10-10 05:52:13,860] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
nid001412: [2024-10-10 05:52:13,860] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
nid001412: [2024-10-10 05:52:13,860] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer
nid001412: [2024-10-10 05:52:13,860] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 1260000000
nid001412: [2024-10-10 05:52:13,860] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 1260000000
nid001412: [2024-10-10 05:52:13,861] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
nid001412: [2024-10-10 05:52:13,861] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
nid001416: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001416: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003700: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003704: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003700: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001416: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003704: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001416: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001413: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001413: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003692: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003704: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001416: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003704: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003700: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001416: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003692: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003700: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001608: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003700: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003704: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003700: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003704: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001608: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001413: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001413: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001612: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001612: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001612: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001612: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003709: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003705: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003708: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003705: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001413: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001604: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003709: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001413: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003708: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001604: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003692: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003708: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003705: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003697: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001616: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003692: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003708: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001608: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003705: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001608: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001616: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003709: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003692: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001605: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003709: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003692: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001608: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001612: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003712: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001608: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001612: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003697: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003705: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003712: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001605: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003705: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003709: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003709: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001609: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003708: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001604: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001609: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003708: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001604: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001597: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001605: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001616: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001592: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001597: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001605: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003713: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001616: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001617: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003713: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003712: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001593: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003712: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001416: Detected CUDA files, patching ldflags
nid001416: Emitting ninja build file /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117/fused_adam/build.ninja...
nid001617: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001604: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001592: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001616: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003713: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001604: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001609: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001416: Building extension module fused_adam...
nid001416: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
nid001616: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001593: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003713: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001609: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003712: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001605: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003713: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003712: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003693: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003713: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001605: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001609: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003693: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001609: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001592: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001597: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001592: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001597: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003697: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001617: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003697: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001617: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003693: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003697: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001593: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001617: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003693: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003697: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001617: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001593: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001597: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001597: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001593: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001593: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003701: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001592: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001592: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003693: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001596: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003701: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003693: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001596: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001416: ninja: no work to do.
nid001604: Loading extension module fused_adam...
nid001416: Loading extension module fused_adam...
nid001416: Time to load fused_adam op: 0.2746603488922119 seconds
nid001596: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001604: Time to load fused_adam op: 0.10572576522827148 seconds
nid001596: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003701: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001596: Loading extension module fused_adam...
nid001596: Time to load fused_adam op: 0.005673408508300781 seconds
nid001616: Loading extension module fused_adam...
nid001605: Loading extension module fused_adam...
nid001597: Loading extension module fused_adam...
nid001417: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003700: Loading extension module fused_adam...
nid003701: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001616: Time to load fused_adam op: 0.10528349876403809 seconds
nid001605: Time to load fused_adam op: 0.10585331916809082 seconds
nid001597: Time to load fused_adam op: 0.10843753814697266 seconds
nid003700: Time to load fused_adam op: 0.20469212532043457 seconds
nid003701: Loading extension module fused_adam...
nid003704: Loading extension module fused_adam...
nid003701: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003701: Time to load fused_adam op: 0.004832029342651367 seconds
nid003704: Time to load fused_adam op: 0.20529747009277344 seconds
nid003701: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001417: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003713: Loading extension module fused_adam...
nid001413: Loading extension module fused_adam...
nid003701: Loading extension module fused_adam...
nid001596: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001608: Loading extension module fused_adam...
nid003713: Time to load fused_adam op: 0.10859394073486328 seconds
nid001413: Time to load fused_adam op: 0.20519590377807617 seconds
nid003701: Time to load fused_adam op: 0.0038924217224121094 seconds
nid003712: Loading extension module fused_adam...
nid001608: Time to load fused_adam op: 0.2144160270690918 seconds
nid003712: Time to load fused_adam op: 0.10474133491516113 seconds
nid001596: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001589: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001412: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001417: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001589: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001412: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001417: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001416: Loading extension module fused_adam...
nid001416: Time to load fused_adam op: 0.30587005615234375 seconds
nid001601: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001601: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001589: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001589: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001417: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001620: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001417: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001601: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001620: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001589: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001601: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001412: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001589: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001416: Loading extension module fused_adam...
nid001412: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001412: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001416: Time to load fused_adam op: 0.30466222763061523 seconds
nid001412: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001620: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001620: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001601: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001601: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003696: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001600: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003696: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001600: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001600: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001600: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001600: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003696: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001600: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003696: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001620: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001620: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid003696: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid003696: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001613: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001613: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001613: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001613: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001613: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid001613: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid001417: Detected CUDA files, patching ldflags
nid001417: Emitting ninja build file /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117/fused_adam/build.ninja...
nid001417: Building extension module fused_adam...
nid001417: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
nid001417: ninja: no work to do.
nid001601: Loading extension module fused_adam...
nid001417: Loading extension module fused_adam...
nid001597: Loading extension module fused_adam...
nid003692: Loading extension module fused_adam...
nid001608: Loading extension module fused_adam...
nid001589: Loading extension module fused_adam...
nid001601: Time to load fused_adam op: 0.20900940895080566 seconds
nid001417: Time to load fused_adam op: 0.2618255615234375 seconds
nid003709: Loading extension module fused_adam...
nid001616: Loading extension module fused_adam...
nid001608: Time to load fused_adam op: 0.4112513065338135 seconds
nid001589: Time to load fused_adam op: 0.2055208683013916 seconds
nid001597: Time to load fused_adam op: 0.30852413177490234 seconds
nid003692: Time to load fused_adam op: 0.4068639278411865 seconds
nid001616: Time to load fused_adam op: 0.4140651226043701 seconds
nid003709: Time to load fused_adam op: 0.40746593475341797 seconds
nid001593: Loading extension module fused_adam...
nid001608: Loading extension module fused_adam...
nid001613: Loading extension module fused_adam...
nid001612: Loading extension module fused_adam...
nid001417: Loading extension module fused_adam...
nid001417: Time to load fused_adam op: 0.2043910026550293 seconds
nid001613: Loading extension module fused_adam...
nid001413: Loading extension module fused_adam...
nid003697: Loading extension module fused_adam...
nid001613: Time to load fused_adam op: 0.10454130172729492 seconds
nid001592: Loading extension module fused_adam...
nid003697: Time to load fused_adam op: 0.422792911529541 seconds
nid003705: Loading extension module fused_adam...
nid001601: Loading extension module fused_adam...
nid001613: Loading extension module fused_adam...
nid001605: Loading extension module fused_adam...
nid001592: Time to load fused_adam op: 0.30805349349975586 seconds
nid003712: Loading extension module fused_adam...
nid001613: Time to load fused_adam op: 0.10360598564147949 seconds
nid001601: Time to load fused_adam op: 0.20475029945373535 seconds
nid003705: Time to load fused_adam op: 0.40645837783813477 seconds
nid001605: Time to load fused_adam op: 0.4150862693786621 seconds
nid003709: Loading extension module fused_adam...
nid003712: Time to load fused_adam op: 0.4121835231781006 seconds
nid003693: Loading extension module fused_adam...
nid003709: Time to load fused_adam op: 0.4053812026977539 seconds
nid003704: Loading extension module fused_adam...
nid003693: Time to load fused_adam op: 0.3058130741119385 seconds
nid003701: Loading extension module fused_adam...
nid003704: Time to load fused_adam op: 0.5068197250366211 seconds
nid003701: Time to load fused_adam op: 0.3104441165924072 seconds
nid003700: Loading extension module fused_adam...
nid001620: Loading extension module fused_adam...
nid001412: Loading extension module fused_adam...
nid001589: Loading extension module fused_adam...
nid003692: Loading extension module fused_adam...
nid001620: Time to load fused_adam op: 0.2156970500946045 seconds
nid001412: Time to load fused_adam op: 0.2071373462677002 seconds
nid001589: Time to load fused_adam op: 0.21122288703918457 seconds
nid003700: Time to load fused_adam op: 0.507009744644165 seconds
nid003708: Loading extension module fused_adam...
nid001412: Loading extension module fused_adam...
nid001596: Loading extension module fused_adam...
nid001412: Time to load fused_adam op: 0.2048356533050537 seconds
nid001609: Loading extension module fused_adam...
nid003708: Time to load fused_adam op: 0.4058046340942383 seconds
nid001596: Time to load fused_adam op: 0.3108186721801758 seconds
nid001609: Time to load fused_adam op: 0.4102902412414551 seconds
nid001620: Loading extension module fused_adam...
nid001620: Time to load fused_adam op: 0.20476818084716797 seconds
nid001601: Loading extension module fused_adam...
nid001601: Time to load fused_adam op: 0.20459699630737305 seconds
nid001617: Loading extension module fused_adam...
nid001592: Loading extension module fused_adam...
nid001596: Loading extension module fused_adam...
nid001604: Loading extension module fused_adam...
nid001616: Loading extension module fused_adam...
nid001592: Time to load fused_adam op: 0.41957783699035645 seconds
nid001604: Time to load fused_adam op: 0.406696081161499 seconds
nid001596: Time to load fused_adam op: 0.3081796169281006 seconds
nid001617: Time to load fused_adam op: 0.41202592849731445 seconds
nid001616: Time to load fused_adam op: 0.4062788486480713 seconds
nid003696: Loading extension module fused_adam...
nid003713: Loading extension module fused_adam...
nid003696: Time to load fused_adam op: 0.2098543643951416 seconds
nid001600: Loading extension module fused_adam...
nid001609: Loading extension module fused_adam...
nid003713: Time to load fused_adam op: 0.40662312507629395 seconds
nid001593: Loading extension module fused_adam...
nid001600: Time to load fused_adam op: 0.2091972827911377 seconds
nid001609: Time to load fused_adam op: 0.4067084789276123 seconds
nid003712: Loading extension module fused_adam...
nid001600: Loading extension module fused_adam...
nid001593: Time to load fused_adam op: 0.41056346893310547 seconds
nid001600: Time to load fused_adam op: 0.20450329780578613 seconds
nid003712: Time to load fused_adam op: 0.4056406021118164 seconds
nid001612: Loading extension module fused_adam...
nid001612: Loading extension module fused_adam...
nid003713: Loading extension module fused_adam...
nid001605: Loading extension module fused_adam...
nid001612: Time to load fused_adam op: 0.5138962268829346 seconds
nid001612: Time to load fused_adam op: 0.5079317092895508 seconds
nid003713: Time to load fused_adam op: 0.40673160552978516 seconds
nid001605: Time to load fused_adam op: 0.40681982040405273 seconds
nid001600: Loading extension module fused_adam...
nid001600: Time to load fused_adam op: 0.20421266555786133 seconds
nid003696: Loading extension module fused_adam...
nid003696: Time to load fused_adam op: 0.2048201560974121 seconds
nid001609: Loading extension module fused_adam...
nid003693: Loading extension module fused_adam...
nid003693: Time to load fused_adam op: 0.4092745780944824 seconds
nid001620: Loading extension module fused_adam...
nid001620: Time to load fused_adam op: 0.20505642890930176 seconds
nid003696: Loading extension module fused_adam...
nid003705: Loading extension module fused_adam...
nid001592: Loading extension module fused_adam...
nid001413: Loading extension module fused_adam...
nid003696: Time to load fused_adam op: 0.20896124839782715 seconds
nid003709: Loading extension module fused_adam...
nid001592: Time to load fused_adam op: 0.40629005432128906 seconds
nid003705: Time to load fused_adam op: 0.5153491497039795 seconds
nid001413: Time to load fused_adam op: 0.5069143772125244 seconds
nid003709: Time to load fused_adam op: 0.5169258117675781 seconds
nid001597: Loading extension module fused_adam...
nid003700: Loading extension module fused_adam...
nid003708: Loading extension module fused_adam...
nid003704: Loading extension module fused_adam...
nid001597: Time to load fused_adam op: 0.4072000980377197 seconds
nid001417: Loading extension module fused_adam...
nid003708: Time to load fused_adam op: 0.5097732543945312 seconds
nid003704: Time to load fused_adam op: 0.610405683517456 seconds
nid001604: Loading extension module fused_adam...
nid001589: Loading extension module fused_adam...
nid001417: Time to load fused_adam op: 0.3054661750793457 seconds
nid003697: Loading extension module fused_adam...
nid001412: Loading extension module fused_adam...
nid001617: Loading extension module fused_adam...
nid001604: Time to load fused_adam op: 0.5107724666595459 seconds
nid001589: Time to load fused_adam op: 0.31327080726623535 seconds
nid003697: Time to load fused_adam op: 0.4066040515899658 seconds
nid001412: Time to load fused_adam op: 0.31011533737182617 seconds
nid001617: Time to load fused_adam op: 0.4055919647216797 seconds
nid003692: Loading extension module fused_adam...
nid003692: Time to load fused_adam op: 0.5063424110412598 seconds
nid003708: Loading extension module fused_adam...
nid003693: Loading extension module fused_adam...
nid003697: Loading extension module fused_adam...
nid003708: Time to load fused_adam op: 0.5063056945800781 seconds
nid001617: Loading extension module fused_adam...
nid003705: Loading extension module fused_adam...
nid003693: Time to load fused_adam op: 0.4058351516723633 seconds
nid001593: Loading extension module fused_adam...
nid003697: Time to load fused_adam op: 0.4055161476135254 seconds
nid001617: Time to load fused_adam op: 0.40529584884643555 seconds
nid003705: Time to load fused_adam op: 0.5068633556365967 seconds
nid001593: Time to load fused_adam op: 0.4059867858886719 seconds
nid001608: Time to load fused_adam op: 0.5002260208129883 seconds
nid001613: Time to load fused_adam op: 0.2026517391204834 seconds
nid003692: Time to load fused_adam op: 0.5887546539306641 seconds
nid001612: Time to load fused_adam op: 0.49994874000549316 seconds
nid001413: Time to load fused_adam op: 0.6007449626922607 seconds
nid001593: Time to load fused_adam op: 0.4004981517791748 seconds
nid001609: Time to load fused_adam op: 0.43792223930358887 seconds
nid003700: Time to load fused_adam op: 0.6291396617889404 seconds
nid003700: [2024-10-10 05:52:16,113] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003701: [2024-10-10 05:52:16,250] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003704: [2024-10-10 05:52:16,302] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003705: [2024-10-10 05:52:16,346] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003708: [2024-10-10 05:52:16,422] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003709: [2024-10-10 05:52:16,464] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003713: [2024-10-10 05:52:16,509] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003712: [2024-10-10 05:52:16,597] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001412: [2024-10-10 05:52:16,690] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states
nid001412: [2024-10-10 05:52:16,691] [INFO] [utils.py:803:see_memory_usage] MA 3.08 GB         Max_MA 3.08 GB         CA 3.09 GB         Max_CA 3 GB 
nid001412: [2024-10-10 05:52:16,691] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 35.09 GB, percent = 14.0%
nid001597: [2024-10-10 05:52:16,755] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001412: [2024-10-10 05:52:16,767] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states
nid001412: [2024-10-10 05:52:16,767] [INFO] [utils.py:803:see_memory_usage] MA 4.32 GB         Max_MA 4.94 GB         CA 4.94 GB         Max_CA 5 GB 
nid001412: [2024-10-10 05:52:16,767] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 35.1 GB, percent = 14.0%
nid001412: [2024-10-10 05:52:16,767] [INFO] [stage_1_and_2.py:517:__init__] optimizer state initialized
nid001413: [2024-10-10 05:52:16,790] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001412: [2024-10-10 05:52:16,815] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer
nid001412: [2024-10-10 05:52:16,816] [INFO] [utils.py:803:see_memory_usage] MA 4.32 GB         Max_MA 4.32 GB         CA 4.94 GB         Max_CA 5 GB 
nid001412: [2024-10-10 05:52:16,816] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 35.1 GB, percent = 14.0%
nid001613: [2024-10-10 05:52:16,818] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001412: [2024-10-10 05:52:16,820] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
nid001412: [2024-10-10 05:52:16,820] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
nid001412: [2024-10-10 05:52:16,820] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x7f9ee4939c40>
nid001412: [2024-10-10 05:52:16,820] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[[0.9, 0.95], [0.9, 0.95]]
nid001412: [2024-10-10 05:52:16,820] [INFO] [config.py:979:print] DeepSpeedEngine configuration:
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   activation_checkpointing_config  {
nid001412:     "partition_activations": false, 
nid001412:     "contiguous_memory_optimization": false, 
nid001412:     "cpu_checkpointing": false, 
nid001412:     "number_checkpoints": null, 
nid001412:     "synchronize_checkpoint_boundary": false, 
nid001412:     "profile": false
nid001412: }
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   amp_enabled .................. False
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   amp_params ................... False
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   autotuning_config ............ {
nid001412:     "enabled": false, 
nid001412:     "start_step": null, 
nid001412:     "end_step": null, 
nid001412:     "metric_path": null, 
nid001412:     "arg_mappings": null, 
nid001412:     "metric": "throughput", 
nid001412:     "model_info": null, 
nid001412:     "results_dir": "autotuning_results", 
nid001412:     "exps_dir": "autotuning_exps", 
nid001412:     "overwrite": true, 
nid001412:     "fast": true, 
nid001412:     "start_profile_step": 3, 
nid001412:     "end_profile_step": 5, 
nid001412:     "tuner_type": "gridsearch", 
nid001412:     "tuner_early_stopping": 5, 
nid001412:     "tuner_num_trials": 50, 
nid001412:     "model_info_path": null, 
nid001412:     "mp_size": 1, 
nid001412:     "max_train_batch_size": null, 
nid001412:     "min_train_batch_size": 1, 
nid001412:     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
nid001412:     "min_train_micro_batch_size_per_gpu": 1, 
nid001412:     "num_tuning_micro_batch_sizes": 3
nid001412: }
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   bfloat16_enabled ............. False
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9edf8607f0>
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   communication_data_type ...... None
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   dataloader_drop_last ......... False
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   disable_allgather ............ False
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   dump_state ................... False
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False
nid001412: [2024-10-10 05:52:16,821] [INFO] [config.py:983:print]   elasticity_enabled ........... False
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   flops_profiler_config ........ {
nid001412:     "enabled": false, 
nid001412:     "recompute_fwd_factor": 0.0, 
nid001412:     "profile_step": 1, 
nid001412:     "module_depth": -1, 
nid001412:     "top_modules": 1, 
nid001412:     "detailed": true, 
nid001412:     "output_file": null
nid001412: }
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   fp16_auto_cast ............... False
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   fp16_enabled ................. True
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   global_rank .................. 0
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   grad_accum_dtype ............. None
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 16
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   gradient_clipping ............ 0.0
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 4096
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   load_universal_checkpoint .... False
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   loss_scale ................... 0
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   memory_breakdown ............. False
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   mics_shard_size .............. -1
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   nebula_config ................ {
nid001412:     "enabled": false, 
nid001412:     "persistent_storage_path": null, 
nid001412:     "persistent_time_interval": 100, 
nid001412:     "num_of_version_in_retention": 2, 
nid001412:     "enable_nebula_load": true, 
nid001412:     "load_path": null
nid001412: }
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   optimizer_name ............... adam
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   optimizer_params ............. {'lr': 9.7e-05, 'betas': [0.9, 0.95], 'eps': 1e-08}
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   pld_enabled .................. False
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   pld_params ................... False
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   prescale_gradients ........... False
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   scheduler_name ............... None
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   scheduler_params ............. None
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   sparse_attention ............. None
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   steps_per_print .............. 1
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   train_batch_size ............. 512
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  4
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   use_node_local_storage ....... False
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   wall_clock_breakdown ......... True
nid001412: [2024-10-10 05:52:16,822] [INFO] [config.py:983:print]   weight_quantization_config ... None
nid001412: [2024-10-10 05:52:16,823] [INFO] [config.py:983:print]   world_size ................... 8
nid001412: [2024-10-10 05:52:16,823] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False
nid001412: [2024-10-10 05:52:16,823] [INFO] [config.py:983:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=1260000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=1260000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
nid001412: [2024-10-10 05:52:16,823] [INFO] [config.py:983:print]   zero_enabled ................. True
nid001412: [2024-10-10 05:52:16,823] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True
nid001412: [2024-10-10 05:52:16,823] [INFO] [config.py:983:print]   zero_optimization_stage ...... 1
nid001412: [2024-10-10 05:52:16,823] [INFO] [config.py:969:print_user_config]   json = {
nid001412:     "train_batch_size": 512, 
nid001412:     "train_micro_batch_size_per_gpu": 4, 
nid001412:     "gradient_accumulation_steps": 16, 
nid001412:     "optimizer": {
nid001412:         "type": "Adam", 
nid001412:         "params": {
nid001412:             "lr": 9.7e-05, 
nid001412:             "betas": [0.9, 0.95], 
nid001412:             "eps": 1e-08
nid001412:         }
nid001412:     }, 
nid001412:     "fp16": {
nid001412:         "fp16": true, 
nid001412:         "enabled": true, 
nid001412:         "loss_scale": 0, 
nid001412:         "loss_scale_window": 1000, 
nid001412:         "initial_scale_power": 12, 
nid001412:         "hysteresis": 2, 
nid001412:         "min_loss_scale": 1
nid001412:     }, 
nid001412:     "zero_optimization": {
nid001412:         "stage": 1, 
nid001412:         "allgather_partitions": true, 
nid001412:         "allgather_bucket_size": 1.260000e+09, 
nid001412:         "overlap_comm": true, 
nid001412:         "reduce_scatter": true, 
nid001412:         "reduce_bucket_size": 1.260000e+09, 
nid001412:         "contiguous_gradients": true
nid001412:     }, 
nid001412:     "steps_per_print": 1, 
nid001412:     "wall_clock_breakdown": true
nid001412: }
nid001412: [2024-10-10 05:52:16,823] [INFO] [engine.py:99:__init__] CONFIG: micro_batches=16 micro_batch_size=4
nid001412: [2024-10-10 05:52:16,823] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001417: [2024-10-10 05:52:16,849] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001416: [2024-10-10 05:52:16,864] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001616: [2024-10-10 05:52:16,928] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001617: [2024-10-10 05:52:16,948] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001596: [2024-10-10 05:52:16,950] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001589: [2024-10-10 05:52:16,959] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001593: [2024-10-10 05:52:16,969] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001600: [2024-10-10 05:52:16,979] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001592: [2024-10-10 05:52:16,984] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001620: [2024-10-10 05:52:17,020] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003693: [2024-10-10 05:52:17,035] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001608: [2024-10-10 05:52:17,036] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001601: [2024-10-10 05:52:17,037] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003697: [2024-10-10 05:52:17,046] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001609: [2024-10-10 05:52:17,053] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001605: [2024-10-10 05:52:17,063] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003692: [2024-10-10 05:52:17,074] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001604: [2024-10-10 05:52:17,074] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003696: [2024-10-10 05:52:17,083] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001612: [2024-10-10 05:52:17,133] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003700: [2024-10-10 05:52:18,107] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003700: [2024-10-10 05:52:18,486] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003708: [2024-10-10 05:52:18,519] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003713: [2024-10-10 05:52:18,520] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003709: [2024-10-10 05:52:18,561] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003700: [2024-10-10 05:52:18,594] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003708: [2024-10-10 05:52:18,611] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003701: [2024-10-10 05:52:18,629] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003704: [2024-10-10 05:52:18,645] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003701: [2024-10-10 05:52:18,657] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003704: [2024-10-10 05:52:18,744] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003712: [2024-10-10 05:52:18,754] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003704: [2024-10-10 05:52:18,788] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001600: [2024-10-10 05:52:18,788] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003709: [2024-10-10 05:52:18,813] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001604: [2024-10-10 05:52:18,849] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001601: [2024-10-10 05:52:18,865] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003708: [2024-10-10 05:52:18,865] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003705: [2024-10-10 05:52:18,873] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001613: [2024-10-10 05:52:18,888] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003701: [2024-10-10 05:52:18,912] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003713: [2024-10-10 05:52:18,919] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003705: [2024-10-10 05:52:18,957] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003709: [2024-10-10 05:52:18,959] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003712: [2024-10-10 05:52:18,977] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003705: [2024-10-10 05:52:18,985] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001601: [2024-10-10 05:52:18,993] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003713: [2024-10-10 05:52:19,020] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001416: [2024-10-10 05:52:19,052] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001416: [2024-10-10 05:52:19,060] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001601: [2024-10-10 05:52:19,067] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001612: [2024-10-10 05:52:19,067] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003712: [2024-10-10 05:52:19,072] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001412: [2024-10-10 05:52:19,074] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001620: [2024-10-10 05:52:19,080] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001604: [2024-10-10 05:52:19,136] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001597: [2024-10-10 05:52:19,137] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001604: [2024-10-10 05:52:19,164] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001416: [2024-10-10 05:52:19,174] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001608: [2024-10-10 05:52:19,196] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001597: [2024-10-10 05:52:19,204] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001609: [2024-10-10 05:52:19,210] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001616: [2024-10-10 05:52:19,212] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001413: [2024-10-10 05:52:19,230] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003697: [2024-10-10 05:52:19,231] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001413: [2024-10-10 05:52:19,240] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001620: [2024-10-10 05:52:19,248] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001612: [2024-10-10 05:52:19,250] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001413: [2024-10-10 05:52:19,255] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001620: [2024-10-10 05:52:19,269] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001597: [2024-10-10 05:52:19,271] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003693: [2024-10-10 05:52:19,272] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001608: [2024-10-10 05:52:19,275] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001412: [2024-10-10 05:52:19,276] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001608: [2024-10-10 05:52:19,281] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001616: [2024-10-10 05:52:19,289] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001592: [2024-10-10 05:52:19,290] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001617: [2024-10-10 05:52:19,303] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001612: [2024-10-10 05:52:19,304] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001609: [2024-10-10 05:52:19,317] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001609: [2024-10-10 05:52:19,341] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001605: [2024-10-10 05:52:19,341] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001412: [2024-10-10 05:52:19,347] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003692: [2024-10-10 05:52:19,351] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001617: [2024-10-10 05:52:19,357] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001592: [2024-10-10 05:52:19,357] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001616: [2024-10-10 05:52:19,360] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003693: [2024-10-10 05:52:19,363] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001589: [2024-10-10 05:52:19,392] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001592: [2024-10-10 05:52:19,394] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001617: [2024-10-10 05:52:19,399] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003693: [2024-10-10 05:52:19,408] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001600: [2024-10-10 05:52:19,419] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003696: [2024-10-10 05:52:19,425] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003692: [2024-10-10 05:52:19,427] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001593: [2024-10-10 05:52:19,428] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001417: [2024-10-10 05:52:19,437] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001600: [2024-10-10 05:52:19,452] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001613: [2024-10-10 05:52:19,467] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001417: [2024-10-10 05:52:19,478] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001417: [2024-10-10 05:52:19,487] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001593: [2024-10-10 05:52:19,494] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003696: [2024-10-10 05:52:19,499] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001593: [2024-10-10 05:52:19,506] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001613: [2024-10-10 05:52:19,508] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001605: [2024-10-10 05:52:19,518] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001605: [2024-10-10 05:52:19,531] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003692: [2024-10-10 05:52:19,538] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003696: [2024-10-10 05:52:19,588] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001589: [2024-10-10 05:52:19,616] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001596: [2024-10-10 05:52:19,675] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003697: [2024-10-10 05:52:19,709] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001596: [2024-10-10 05:52:19,714] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid003697: [2024-10-10 05:52:19,730] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001589: [2024-10-10 05:52:19,742] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001596: [2024-10-10 05:52:19,771] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid001412: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=0 STAGE=0 LAYERS=13 [0, 13) STAGE_PARAMS=1324088832 (1324.089M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid001412: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=2 STAGE=0 LAYERS=13 [0, 13) STAGE_PARAMS=1324088832 (1324.089M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid001412: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=3 STAGE=0 LAYERS=13 [0, 13) STAGE_PARAMS=1324088832 (1324.089M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid001412: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=1 STAGE=0 LAYERS=13 [0, 13) STAGE_PARAMS=1324088832 (1324.089M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid001613: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=66 STAGE=2 LAYERS=12 [25, 37) STAGE_PARAMS=1359525888 (1359.526M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid001613: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=65 STAGE=2 LAYERS=12 [25, 37) STAGE_PARAMS=1359525888 (1359.526M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid001613: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=67 STAGE=2 LAYERS=12 [25, 37) STAGE_PARAMS=1359525888 (1359.526M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid001613: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=64 STAGE=2 LAYERS=12 [25, 37) STAGE_PARAMS=1359525888 (1359.526M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid001597: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=34 STAGE=1 LAYERS=12 [13, 25) STAGE_PARAMS=1359525888 (1359.526M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid001597: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=35 STAGE=1 LAYERS=12 [13, 25) STAGE_PARAMS=1359525888 (1359.526M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid001597: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=32 STAGE=1 LAYERS=12 [13, 25) STAGE_PARAMS=1359525888 (1359.526M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid001597: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=33 STAGE=1 LAYERS=12 [13, 25) STAGE_PARAMS=1359525888 (1359.526M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid003700: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=97 STAGE=3 LAYERS=12 [37, 49) STAGE_PARAMS=1097513472 (1097.513M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid003700: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=99 STAGE=3 LAYERS=12 [37, 49) STAGE_PARAMS=1097513472 (1097.513M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid003700: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=98 STAGE=3 LAYERS=12 [37, 49) STAGE_PARAMS=1097513472 (1097.513M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid003700: [2024-10-10 05:52:20,702] [INFO] [engine.py:158:__init__] RANK=96 STAGE=3 LAYERS=12 [37, 49) STAGE_PARAMS=1097513472 (1097.513M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid003700:  > number of parameters on model parallel rank 0: 1097513472
nid001412:  > number of parameters on model parallel rank 0: 1324088832
nid003700:  > number of parameters on model parallel rank 2: 1097513472
nid003700:  > number of parameters on model parallel rank 1: 1097513472
nid003700:  > number of parameters on model parallel rank 3: 1097513472
nid001613:  > number of parameters on model parallel rank 0: 1359525888
nid001597:  > number of parameters on model parallel rank 0: 1359525888
nid001412:  > number of parameters on model parallel rank 1: 1324088832
nid001412:  > number of parameters on model parallel rank 3: 1324088832
nid001412:  > number of parameters on model parallel rank 2: 1324088832
nid001613:  > number of parameters on model parallel rank 1: 1359525888
nid001597:  > number of parameters on model parallel rank 1: 1359525888
nid001613:  > number of parameters on model parallel rank 3: 1359525888
nid001597:  > number of parameters on model parallel rank 3: 1359525888
nid001597:  > number of parameters on model parallel rank 2: 1359525888
nid001613:  > number of parameters on model parallel rank 2: 1359525888
nid001412:  > total params: 20,562,616,320
nid001412: > building train, validation, and test datasets ...
nid001412:     reading sizes...
nid001412:     reading pointers...
nid001412:     reading document index...
nid001412:     creating numpy buffer of mmap...
nid001412:     creating memory view of numpy buffer...
nid001412:  > dataset split:
nid001412:     train:
nid001412:      document indices in [0, 209551959) total of 209551959 documents
nid001412:     validation:
nid001412:      document indices in [209551959, 210394379) total of 842420 documents
nid001412:     test:
nid001412:      document indices in [210394379, 210604984) total of 210605 documents
nid001412:  > loading doc-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_train_indexmap_4096ns_2048sl_1234s_packedpi_ac_doc_idx.npy
nid001412:  > loading sample-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_train_indexmap_4096ns_2048sl_1234s_packedpi_ac_sample_idx.npy
nid001412:  > loading shuffle-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_train_indexmap_4096ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy
nid001412:     loaded indexed file in 0.022 seconds
nid001412:     total number of samples: 181875918
nid001412:     total number of epochs: 1
nid001412:  > loading doc-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_valid_indexmap_5120ns_2048sl_1234s_packedpi_ac_doc_idx.npy
nid001412:  > loading sample-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_valid_indexmap_5120ns_2048sl_1234s_packedpi_ac_sample_idx.npy
nid001412:  > loading shuffle-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_valid_indexmap_5120ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy
nid001412:     loaded indexed file in 0.018 seconds
nid001412:     total number of samples: 726224
nid001412:     total number of epochs: 1
nid001412:  > loading doc-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_test_indexmap_5120ns_2048sl_1234s_packedpi_ac_doc_idx.npy
nid001412:  > loading sample-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_test_indexmap_5120ns_2048sl_1234s_packedpi_ac_sample_idx.npy
nid001412:  > loading shuffle-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_test_indexmap_5120ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy
nid001412:     loaded indexed file in 0.013 seconds
nid001412:     total number of samples: 179782
nid001412:     total number of epochs: 1
nid001412: setting training data start iteration to 0
nid001412: setting validation data start iteration to 0
nid001412: done with setups ...
nid001412: time (ms) | model and optimizer: 11597.01 | train/valid/test data iterators: 2383.81
nid001412: training ...
nid001412: [2024-10-10 05:52:26,714] [INFO] [checkpointing.py:540:forward] Activation Checkpointing Information
nid001412: [2024-10-10 05:52:26,714] [INFO] [checkpointing.py:541:forward] ----Partition Activations False, CPU CHECKPOINTING False
nid001412: [2024-10-10 05:52:26,714] [INFO] [checkpointing.py:542:forward] ----contiguous Memory Checkpointing False with 44 total layers
nid001412: [2024-10-10 05:52:26,714] [INFO] [checkpointing.py:544:forward] ----Synchronization True
nid001412: [2024-10-10 05:52:26,714] [INFO] [checkpointing.py:545:forward] ----Profiling time in checkpointing False
nid001412: [2024-10-10 05:53:04,806] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1998.36 | optimizer_gradients: 2.57 | optimizer_step: 4.60
nid001412: [2024-10-10 05:53:04,806] [INFO] [logging.py:96:log_dist] [Rank 0] step=1, skipped=0, lr=[9.412555410057191e-05, 9.412555410057191e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid001412: [2024-10-10 05:53:04,807] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 766.33 | fwd_microstep: 5902.88 | bwd_microstep: 7297.39 | bwd_inner_microstep: 7297.22 | bwd_allreduce_microstep: 0.01 | step_microstep: 2234.15
nid001412: [2024-10-10 05:53:04,808] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 5902.84 | bwd: 7297.37 | bwd_inner: 7297.20 | bwd_allreduce: 0.01 | step: 2234.14
nid001412: steps: 1 loss: 10.9632 iter time (s): 39.197 samples/sec: 13.062
nid001412: [2024-10-10 05:53:05,131] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 5720.51 | pipe_recv_grad: 12981.28
nid001412:  samples/sec: 13.061 | iteration        1/       8 | elapsed time per iteration (ms): 39201.3 | learning rate: 9.413E-05 | approx flops per GPU: 35.6TFLOPS | lm_loss: 1.096321E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid001412: after 1 iterations memory (MB) | allocated: 4462.7626953125 | max allocated: 13007.85693359375 | reserved: 16658.0 | max reserved: 16658.0
nid001412: time (ms)
nid003713: STAGE:2024-10-10 05:53:22 699016:699016 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001412: [2024-10-10 05:53:22,573] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1936.34 | optimizer_gradients: 2.59 | optimizer_step: 4.63
nid001412: [2024-10-10 05:53:22,573] [INFO] [logging.py:96:log_dist] [Rank 0] step=2, skipped=0, lr=[8.494099076328631e-05, 8.494099076328631e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid001412: [2024-10-10 05:53:22,575] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 14.88 | fwd_microstep: 2159.05 | bwd_microstep: 6209.04 | bwd_inner_microstep: 6208.88 | bwd_allreduce_microstep: 0.00 | step_microstep: 2233.46
nid001412: [2024-10-10 05:53:22,575] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2159.03 | bwd: 6209.04 | bwd_inner: 6208.87 | bwd_allreduce: 0.00 | step: 2233.48
nid001412: steps: 2 loss: 10.9640 iter time (s): 17.442 samples/sec: 29.355
nid001412: [2024-10-10 05:53:22,577] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 202.41 | pipe_recv_grad: 2601.91
nid001412:  samples/sec: 29.350 | iteration        2/       8 | elapsed time per iteration (ms): 17444.8 | learning rate: 8.494E-05 | approx flops per GPU: 79.9TFLOPS | lm_loss: 1.096395E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid001412: time (ms)
nid001412: STAGE:2024-10-10 05:53:22 560029:560029 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid001597: STAGE:2024-10-10 05:53:22 1888490:1888490 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid003713: [W CPUAllocator.cpp:231] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
nid001597: [W CPUAllocator.cpp:231] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
nid001412: [W CPUAllocator.cpp:231] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
nid001412: [2024-10-10 05:53:39,983] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1960.56 | optimizer_gradients: 2.60 | optimizer_step: 4.66
nid001412: [2024-10-10 05:53:39,983] [INFO] [logging.py:96:log_dist] [Rank 0] step=3, skipped=0, lr=[7.085061787049869e-05, 7.085061787049869e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid001412: [2024-10-10 05:53:39,985] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 24.26 | fwd_microstep: 2268.40 | bwd_microstep: 6187.22 | bwd_inner_microstep: 6187.06 | bwd_allreduce_microstep: 0.00 | step_microstep: 2202.51
nid001412: [2024-10-10 05:53:39,986] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2268.46 | bwd: 6187.22 | bwd_inner: 6187.06 | bwd_allreduce: 0.00 | step: 2202.54
nid001412: steps: 3 loss: 12.4412 iter time (s): 17.402 samples/sec: 29.423
nid001412: [2024-10-10 05:53:39,987] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 195.31 | pipe_recv_grad: 2563.07
nid001412:  samples/sec: 29.407 | iteration        3/       8 | elapsed time per iteration (ms): 17410.9 | learning rate: 7.085E-05 | approx flops per GPU: 80.1TFLOPS | lm_loss: 1.244125E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid001412: time (ms)
nid001412: [2024-10-10 05:53:57,531] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1972.32 | optimizer_gradients: 2.60 | optimizer_step: 4.63
nid001412: [2024-10-10 05:53:57,531] [INFO] [logging.py:96:log_dist] [Rank 0] step=4, skipped=0, lr=[5.404254932138936e-05, 5.404254932138936e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid001412: [2024-10-10 05:53:57,533] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 18.80 | fwd_microstep: 2227.99 | bwd_microstep: 6161.07 | bwd_inner_microstep: 6160.91 | bwd_allreduce_microstep: 0.00 | step_microstep: 2339.31
nid001412: [2024-10-10 05:53:57,534] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2228.00 | bwd: 6161.07 | bwd_inner: 6160.91 | bwd_allreduce: 0.00 | step: 2339.34
nid001412: steps: 4 loss: 14.1307 iter time (s): 17.545 samples/sec: 29.182
nid001412: [2024-10-10 05:53:57,536] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 168.63 | pipe_recv_grad: 2593.08
nid001412:  samples/sec: 29.177 | iteration        4/       8 | elapsed time per iteration (ms): 17548.1 | learning rate: 5.404E-05 | approx flops per GPU: 79.4TFLOPS | lm_loss: 1.413071E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid001412: time (ms)
nid001412: [2024-10-10 05:54:14,966] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1914.49 | optimizer_gradients: 2.61 | optimizer_step: 4.62
nid001412: [2024-10-10 05:54:14,966] [INFO] [logging.py:96:log_dist] [Rank 0] step=5, skipped=0, lr=[3.7126933810426706e-05, 3.7126933810426706e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid001412: [2024-10-10 05:54:14,968] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 19.21 | fwd_microstep: 2281.16 | bwd_microstep: 6158.70 | bwd_inner_microstep: 6158.45 | bwd_allreduce_microstep: 0.00 | step_microstep: 2232.20
nid001412: [2024-10-10 05:54:14,969] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2281.21 | bwd: 6158.72 | bwd_inner: 6158.44 | bwd_allreduce: 0.00 | step: 2232.23
nid001412: steps: 5 loss: 13.2670 iter time (s): 17.432 samples/sec: 29.371
nid001412: [2024-10-10 05:54:14,971] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 166.46 | pipe_recv_grad: 2587.39
nid001412:  samples/sec: 29.366 | iteration        5/       8 | elapsed time per iteration (ms): 17435.1 | learning rate: 3.713E-05 | approx flops per GPU: 80.0TFLOPS | lm_loss: 1.326699E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid001412: time (ms)
nid001412: [2024-10-10 05:54:32,339] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1902.58 | optimizer_gradients: 2.60 | optimizer_step: 4.63
nid001412: [2024-10-10 05:54:32,340] [INFO] [logging.py:96:log_dist] [Rank 0] step=6, skipped=0, lr=[2.2730621151619073e-05, 2.2730621151619073e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid001412: [2024-10-10 05:54:32,341] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 20.86 | fwd_microstep: 2288.08 | bwd_microstep: 6154.12 | bwd_inner_microstep: 6153.96 | bwd_allreduce_microstep: 0.00 | step_microstep: 2071.35
nid001412: [2024-10-10 05:54:32,342] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2288.15 | bwd: 6154.12 | bwd_inner: 6153.96 | bwd_allreduce: 0.00 | step: 2071.38
nid001412: steps: 6 loss: 12.7466 iter time (s): 17.370 samples/sec: 29.476
nid001412: [2024-10-10 05:54:32,344] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 166.97 | pipe_recv_grad: 2577.18
nid001412:  samples/sec: 29.471 | iteration        6/       8 | elapsed time per iteration (ms): 17372.9 | learning rate: 2.273E-05 | approx flops per GPU: 80.2TFLOPS | lm_loss: 1.274656E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid001412: time (ms)
nid001412: [2024-10-10 05:54:49,720] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1947.27 | optimizer_gradients: 2.60 | optimizer_step: 4.63
nid001412: [2024-10-10 05:54:49,720] [INFO] [logging.py:96:log_dist] [Rank 0] step=7, skipped=0, lr=[1.3089235062335024e-05, 1.3089235062335024e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid001412: [2024-10-10 05:54:49,722] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 20.53 | fwd_microstep: 2269.36 | bwd_microstep: 6154.81 | bwd_inner_microstep: 6154.65 | bwd_allreduce_microstep: 0.00 | step_microstep: 2220.96
nid001412: [2024-10-10 05:54:49,723] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2269.38 | bwd: 6154.81 | bwd_inner: 6154.65 | bwd_allreduce: 0.00 | step: 2220.98
nid001412: steps: 7 loss: 12.1639 iter time (s): 17.378 samples/sec: 29.462
nid001412: [2024-10-10 05:54:49,724] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 166.06 | pipe_recv_grad: 2574.55
nid001412:  samples/sec: 29.458 | iteration        7/       8 | elapsed time per iteration (ms): 17380.6 | learning rate: 1.309E-05 | approx flops per GPU: 80.2TFLOPS | lm_loss: 1.216392E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid001412: time (ms)
nid003713: STAGE:2024-10-10 05:54:51 699016:699016 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001412: STAGE:2024-10-10 05:54:51 560029:560029 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid001597: STAGE:2024-10-10 05:54:52 1888490:1888490 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid003713: STAGE:2024-10-10 05:56:19 699016:699016 output_json.cpp:417] Completed Stage: Post Processing
nid001412: STAGE:2024-10-10 05:56:28 560029:560029 output_json.cpp:417] Completed Stage: Post Processing
nid001597: STAGE:2024-10-10 05:56:37 1888490:1888490 output_json.cpp:417] Completed Stage: Post Processing
nid001412: [2024-10-10 05:56:54,365] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1897.89 | optimizer_gradients: 2.58 | optimizer_step: 4.62
nid001412: [2024-10-10 05:56:54,365] [INFO] [logging.py:96:log_dist] [Rank 0] step=8, skipped=0, lr=[9.7e-06, 9.7e-06], mom=[[0.9, 0.95], [0.9, 0.95]]
nid001412: [2024-10-10 05:56:54,367] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 12.47 | fwd_microstep: 2513.60 | bwd_microstep: 6093.14 | bwd_inner_microstep: 6092.98 | bwd_allreduce_microstep: 0.00 | step_microstep: 2038.09
nid001412: [2024-10-10 05:56:54,367] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2513.63 | bwd: 6093.13 | bwd_inner: 6092.97 | bwd_allreduce: 0.00 | step: 2038.11
nid001412: steps: 8 loss: 11.7940 iter time (s): 25.651 samples/sec: 19.960
nid001412: [2024-10-10 05:56:54,368] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 160.51 | pipe_recv_grad: 11002.05
nid001412:  samples/sec: 4.108 | iteration        8/       8 | elapsed time per iteration (ms): 124644.0 | learning rate: 9.700E-06 | approx flops per GPU: 11.2TFLOPS | lm_loss: 1.179398E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid001412: time (ms)
nid001617: Connection to nid001617 closed by remote host.
nid001600: Connection to nid001600 closed by remote host.
nid003704: Connection to nid003704 closed by remote host.
nid001620: Connection to nid001620 closed by remote host.
nid001616: Connection to nid001616 closed by remote host.
nid001613: Connection to nid001613 closed by remote host.
nid001609: Connection to nid001609 closed by remote host.
nid003700: Connection to nid003700 closed by remote host.
nid001605: Connection to nid001605 closed by remote host.
nid001597: Connection to nid001597 closed by remote host.
nid001592: Connection to nid001592 closed by remote host.
nid003696: Connection to nid003696 closed by remote host.
pdsh@nid001412: nid001617: ssh exited with exit code 255
pdsh@nid001412: nid001600: ssh exited with exit code 255
nid001596: Connection to nid001596 closed by remote host.
nid001593: Connection to nid001593 closed by remote host.
pdsh@nid001412: nid003704: ssh exited with exit code 255
nid003697: Connection to nid003697 closed by remote host.
nid001601: Connection to nid001601 closed by remote host.
nid001608: Connection to nid001608 closed by remote host.
nid001589: Connection to nid001589 closed by remote host.
nid003692: Connection to nid003692 closed by remote host.
nid001416: Connection to nid001416 closed by remote host.
pdsh@nid001412: nid001620: ssh exited with exit code 255
pdsh@nid001412: nid001613: ssh exited with exit code 255
nid003705: Connection to nid003705 closed by remote host.
pdsh@nid001412: nid001616: ssh exited with exit code 255
nid001413: Connection to nid001413 closed by remote host.
nid003713: Connection to nid003713 closed by remote host.
nid003701: Connection to nid003701 closed by remote host.
nid003712: Connection to nid003712 closed by remote host.
nid001604: Connection to nid001604 closed by remote host.
pdsh@nid001412: nid003700: ssh exited with exit code 255
nid001612: Connection to nid001612 closed by remote host.
pdsh@nid001412: nid001609: ssh exited with exit code 255
pdsh@nid001412: nid001605: ssh exited with exit code 255
nid001417: Connection to nid001417 closed by remote host.
nid003708: Connection to nid003708 closed by remote host.
pdsh@nid001412: nid001592: ssh exited with exit code 255
pdsh@nid001412: nid001597: ssh exited with exit code 255
pdsh@nid001412: nid001596: ssh exited with exit code 255
pdsh@nid001412: nid001601: ssh exited with exit code 255
pdsh@nid001412: nid003692: ssh exited with exit code 255
pdsh@nid001412: nid001416: ssh exited with exit code 255
pdsh@nid001412: nid003713: ssh exited with exit code 255
pdsh@nid001412: nid003696: ssh exited with exit code 255
nid003693: Connection to nid003693 closed by remote host.
pdsh@nid001412: nid003697: ssh exited with exit code 255
pdsh@nid001412: nid001608: ssh exited with exit code 255
pdsh@nid001412: nid003705: ssh exited with exit code 255
pdsh@nid001412: nid001413: ssh exited with exit code 255
pdsh@nid001412: nid001589: ssh exited with exit code 255
pdsh@nid001412: nid003701: ssh exited with exit code 255
pdsh@nid001412: nid003712: ssh exited with exit code 255
pdsh@nid001412: nid001612: ssh exited with exit code 255
pdsh@nid001412: nid001604: ssh exited with exit code 255
pdsh@nid001412: nid003708: ssh exited with exit code 255
pdsh@nid001412: nid001593: ssh exited with exit code 255
pdsh@nid001412: nid001417: ssh exited with exit code 255
pdsh@nid001412: nid003693: ssh exited with exit code 255
nid003709: Connection to nid003709 closed by remote host.
