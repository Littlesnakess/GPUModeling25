cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
aten::zeros,526427,"[[], [], [], [], []]",aten::fill_,526430,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",1691062,0,8.99
aten::to,526436,"[[], [], [], [], [], []]",aten::copy_,526439,"[[], [], []]",Memcpy HtoD (Pageable -> Device),1691097,49779.333333333336,1.001111111111111
aten::layer_norm,526443,"[[2048, 4, 6144], [], [6144], [6144], [], []]",aten::native_layer_norm,526444,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",1691119,21497.0,189.92888888888888
aten::layer_norm,526450,"[[2048, 4, 6144], [], [6144], [6144], [], []]",aten::native_layer_norm,526451,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",1691141,879.0,190.67777777777778
aten::linear,526460,"[[2048, 4, 6144], [2304, 6144], [2304]]",aten::addmm,526465,"[[2304], [8192, 6144], [6144, 2304], [], []]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_relu_f2f_stages_64x3_tn,1691160,2079.6666666666665,899.9355555555555
aten::to,526487,"[[2048, 1, 1, 24], [], [], [], [], [], [], []]",aten::_to_copy,526488,"[[2048, 1, 1, 24], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),1691178,1558.0,5.02
aten::to,526491,"[[2048, 1, 1, 24], [], [], [], [], [], [], []]",aten::_to_copy,526492,"[[2048, 1, 1, 24], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),1691188,12264.0,5.004444444444444
apply_rotary_pos_emb,526495,"[[2048, 4, 8, 24], [2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]",aten::neg,526504,"[[2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1691196,26560.0,8.998888888888889
apply_rotary_pos_emb,526495,"[[2048, 4, 8, 24], [2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]",aten::cat,526516,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",1691205,11639.333333333334,17.00111111111111
None,None,None,None,None,None,kernel_1,1691218,7348.333333333333,7.834444444444444
apply_rotary_pos_emb,526495,"[[2048, 4, 8, 24], [2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]",aten::neg,526527,"[[2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1691225,11965.666666666666,9.994444444444444
apply_rotary_pos_emb,526495,"[[2048, 4, 8, 24], [2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]",aten::cat,526538,"[[2048, 4, 8, 24], [], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",1691234,9275.666666666666,16.70888888888889
None,None,None,None,None,None,kernel_1,1691247,5468.0,7.932222222222222
aten::cat,526545,"[[], []]",aten::cat,526545,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",1691255,11163.333333333334,55.41
aten::cat,526546,"[[], []]",aten::cat,526546,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",1691264,492.0,55.29555555555555
aten::baddbmm,526556,"[[32, 2048, 2048], [32, 2048, 96], [32, 96, 2048], [], []]",aten::baddbmm,526556,"[[32, 2048, 2048], [32, 2048, 96], [32, 96, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,1691282,1397.6666666666667,335.7633333333333
ScaledUpperTriangMaskedSoftmax,526559,"[[32, 2048, 2048]]",ScaledUpperTriangMaskedSoftmax,526559,"[[32, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",1691291,483.0,344.7711111111111
aten::bmm,526576,"[[32, 2048, 2048], [32, 2048, 96]]",aten::bmm,526576,"[[32, 2048, 2048], [32, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,1691337,498.3333333333333,259.03
aten::contiguous,526580,"[[2048, 4, 8, 96], []]",aten::copy_,526584,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1691348,489.0,31.00777777777778
aten::linear,526586,"[[2048, 4, 768], [6144, 768], []]",aten::mm,526593,"[[8192, 768], [768, 6144]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn,1691362,571.6666666666666,323.1511111111111
aten::add,526598,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,526598,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",1691370,483.3333333333333,223.16333333333333
aten::linear,526603,"[[2048, 4, 6144], [3072, 6144], []]",aten::mm,526610,"[[8192, 6144], [6144, 3072]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8::Params),1691383,544.0,1201.1055555555556
None,None,None,None,None,None,kernel_2,1691396,496.3333333333333,86.3411111111111
aten::linear,526618,"[[2048, 4, 3072], [6144, 3072], []]",aten::mm,526625,"[[8192, 3072], [3072, 6144]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,1691410,2023.0,1287.7677777777778
aten::add,526630,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,526630,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",1691421,506.6666666666667,222.28555555555556
aten::add,526632,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,526632,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1691429,519.0,223.9
_ReduceFromModelParallelRegion,526633,"[[2048, 4, 6144]]",nccl:all_reduce,526636,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",1691447,652.6666666666666,36110.12666666666
aten::add,526640,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,526640,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1691486,688.0,224.3177777777778
autograd::engine::evaluate_function: ExpandBackward0,526650,,aten::sum,526652,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",1691541,1671.3333333333333,95.09666666666666
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,526654,,aten::add_,526656,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1691548,501.0,3.21
autograd::engine::evaluate_function: MmBackward0,526661,,aten::mm,526666,"[[6144, 8192], [8192, 3072]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,1691571,1752.6666666666667,1131.138888888889
autograd::engine::evaluate_function: MmBackward0,526661,,aten::mm,526673,"[[8192, 6144], [6144, 3072]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8::Params),1691591,492.3333333333333,1126.9966666666667
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,526683,,aten::add_,526685,"[[6144, 3072], [6144, 3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1691602,493.6666666666667,76.02777777777777
None,None,None,None,None,None,kernel_3,1691621,674.0,123.69666666666667
autograd::engine::evaluate_function: GeLUFunctionBackward,526686,,aten::sum,526693,"[[2048, 4, 3072], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",1691647,1670.0,62.03888888888889
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,526695,,torch::autograd::AccumulateGrad,526696,[[3072]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1691654,494.0,3.132222222222222
autograd::engine::evaluate_function: MmBackward0,526702,,aten::mm,526707,"[[3072, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,1691677,1762.6666666666667,1132.3822222222223
autograd::engine::evaluate_function: MmBackward0,526702,,aten::mm,526714,"[[8192, 3072], [3072, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,1691695,499.6666666666667,1152.6722222222222
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,526724,,aten::add_,526726,"[[3072, 6144], [3072, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1691706,592.6666666666666,74.47555555555556
autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward,526727,,nccl:all_reduce,526731,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",1691726,872.6666666666666,36228.38555555556
autograd::engine::evaluate_function: ExpandBackward0,526735,,aten::sum,526737,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",1691788,1915.6666666666667,99.63888888888889
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,526739,,aten::add_,526741,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1691795,505.6666666666667,3.216666666666667
autograd::engine::evaluate_function: MmBackward0,526746,,aten::mm,526751,"[[6144, 8192], [8192, 768]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,1691818,1735.3333333333333,283.79555555555555
autograd::engine::evaluate_function: MmBackward0,526746,,aten::mm,526758,"[[8192, 6144], [6144, 768]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,1691840,1697.6666666666667,313.7988888888889
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,526768,,aten::add_,526770,"[[6144, 768], [6144, 768], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1691854,503.0,19.31111111111111
autograd::engine::evaluate_function: BmmBackward0,526785,,aten::bmm,526789,"[[32, 2048, 2048], [32, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,1691880,514.0,230.18333333333334
autograd::engine::evaluate_function: BmmBackward0,526785,,aten::bmm,526792,"[[32, 2048, 96], [32, 96, 2048]]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,1691896,491.0,339.9166666666667
autograd::engine::evaluate_function: ScaledUpperTriangMaskedSoftmaxBackward,526809,,ScaledUpperTriangMaskedSoftmaxBackward,526810,"[[32, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",1691910,503.6666666666667,476.41555555555556
autograd::engine::evaluate_function: BaddbmmBackward0,526823,,aten::bmm,526827,"[[32, 2048, 2048], [32, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,1691930,487.6666666666667,252.43444444444444
autograd::engine::evaluate_function: BaddbmmBackward0,526823,,aten::mul,526829,"[[32, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",1691942,489.0,13.99
autograd::engine::evaluate_function: BaddbmmBackward0,526823,,aten::bmm,526832,"[[32, 96, 2048], [32, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,1691957,414.3333333333333,236.82777777777778
autograd::engine::evaluate_function: BaddbmmBackward0,526823,,aten::mul,526834,"[[32, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",1691969,503.0,13.53111111111111
autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward,529431,,aten::mul,529434,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",1691997,507.6666666666667,13.04888888888889
autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward,529431,,aten::mul,529438,"[[], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",1692009,539.0,12.551111111111112
autograd::engine::evaluate_function: NegBackward0,529439,,aten::neg,529441,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1692023,485.6666666666667,6.018888888888889
autograd::engine::evaluate_function: SliceBackward0,529442,,aten::zero_,529447,"[[2048, 4, 8, 24]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1692040,534.6666666666666,5.001111111111111
autograd::engine::evaluate_function: SliceBackward0,529442,,aten::slice_backward,529444,"[[2048, 4, 8, 12], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1692046,426.3333333333333,14.03
autograd::engine::evaluate_function: SliceBackward0,529442,,aten::add,529452,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",1692060,523.3333333333334,23.97222222222222
autograd::engine::evaluate_function: SliceBackward0,529453,,aten::zeros,529456,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1692078,465.6666666666667,4.998888888888889
autograd::engine::evaluate_function: SliceBackward0,529453,,aten::slice_backward,529455,"[[2048, 4, 8, 12], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1692084,395.6666666666667,14.005555555555556
autograd::engine::evaluate_function: SliceBackward0,529453,,aten::add,529463,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",1692098,468.0,23.973333333333333
autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward,529464,,aten::mul,529467,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",1692113,446.3333333333333,12.023333333333333
autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward,529464,,aten::mul,529471,"[[], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",1692125,527.6666666666666,10.204444444444444
autograd::engine::evaluate_function: NegBackward0,529472,,aten::neg,529474,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1692139,545.0,6.081111111111111
autograd::engine::evaluate_function: SliceBackward0,529475,,aten::zeros,529478,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1692156,544.0,5.002222222222223
autograd::engine::evaluate_function: SliceBackward0,529475,,aten::slice_backward,529477,"[[2048, 4, 8, 12], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1692162,437.3333333333333,7.0
autograd::engine::evaluate_function: SliceBackward0,529475,,aten::add,529485,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",1692176,428.6666666666667,10.012222222222222
autograd::engine::evaluate_function: SliceBackward0,529486,,aten::zeros,529489,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1692194,492.6666666666667,5.001111111111111
autograd::engine::evaluate_function: SliceBackward0,529486,,aten::slice_backward,529488,"[[2048, 4, 8, 12], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1692200,410.0,7.004444444444444
autograd::engine::evaluate_function: SliceBackward0,529486,,aten::add,529496,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",1692214,472.0,10.005555555555556
autograd::engine::evaluate_function: SliceBackward0,529497,,aten::zeros,529500,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1692232,469.6666666666667,11.997777777777777
autograd::engine::evaluate_function: SliceBackward0,529497,,aten::slice_backward,529499,"[[2048, 4, 8, 72], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1692238,368.0,57.818888888888885
autograd::engine::evaluate_function: SliceBackward0,529507,,aten::zeros,529510,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1692256,480.6666666666667,11.992222222222223
autograd::engine::evaluate_function: SliceBackward0,529507,,aten::slice_backward,529509,"[[2048, 4, 8, 24], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1692262,388.0,23.645555555555557
autograd::engine::evaluate_function: SliceBackward0,529507,,aten::add,529517,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1692276,477.3333333333333,23.196666666666665
autograd::engine::evaluate_function: SliceBackward0,529518,,aten::zeros,529521,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1692294,532.0,12.001111111111111
autograd::engine::evaluate_function: SliceBackward0,529518,,aten::slice_backward,529520,"[[2048, 4, 8, 72], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1692300,459.3333333333333,27.984444444444446
autograd::engine::evaluate_function: SliceBackward0,529528,,aten::zeros,529531,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",1692318,441.3333333333333,11.995555555555555
autograd::engine::evaluate_function: SliceBackward0,529528,,aten::slice_backward,529530,"[[2048, 4, 8, 24], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",1692324,364.6666666666667,12.03
autograd::engine::evaluate_function: SliceBackward0,529528,,aten::add,529538,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1692338,523.6666666666666,22.984444444444446
autograd::engine::evaluate_function: SplitBackward0,529539,,aten::cat,529541,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",1692354,458.3333333333333,128.87444444444444
autograd::engine::evaluate_function: AddmmBackward0,529550,,aten::mm,529555,"[[8192, 2304], [2304, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nn,1692375,491.6666666666667,884.2311111111111
autograd::engine::evaluate_function: AddmmBackward0,529550,,aten::mm,529559,"[[2304, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nt,1692394,1694.0,829.0133333333333
autograd::engine::evaluate_function: AddmmBackward0,529550,,aten::sum,529563,"[[8192, 2304], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",1692424,1690.3333333333333,49.632222222222225
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,529565,,aten::add_,529567,"[[2304], [2304], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1692431,498.0,3.19
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,529577,,autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,529577,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1692442,552.3333333333334,53.16888888888889
autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward,529580,,nccl:all_reduce,529584,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",1692462,1022.6666666666666,36248.648888888885
autograd::engine::evaluate_function: NativeLayerNormBackward0,529586,,aten::native_layer_norm_backward,529588,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",1692529,726.6666666666666,425.24555555555554
autograd::engine::evaluate_function: NativeLayerNormBackward0,529586,,aten::native_layer_norm_backward,529588,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",1692531,492.0,219.3411111111111
autograd::engine::evaluate_function: NativeLayerNormBackward0,529586,,aten::add,529592,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1692552,492.6666666666667,213.0588888888889
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,529593,,torch::autograd::AccumulateGrad,529594,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1692560,490.3333333333333,3.4611111111111112
None,None,None,None,None,None,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1692567,509.6666666666667,3.0522222222222224
autograd::engine::evaluate_function: NativeLayerNormBackward0,529599,,aten::native_layer_norm_backward,529601,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",1692609,568.6666666666666,419.3
autograd::engine::evaluate_function: NativeLayerNormBackward0,529599,,aten::native_layer_norm_backward,529601,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",1692611,499.3333333333333,219.65555555555557
autograd::engine::evaluate_function: NativeLayerNormBackward0,529599,,aten::add,529605,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1692634,482.3333333333333,213.0822222222222
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,529610,,autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,529610,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1692644,510.3333333333333,3.517777777777778
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,529613,,autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,529613,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",1692651,489.6666666666667,3.0677777777777777
