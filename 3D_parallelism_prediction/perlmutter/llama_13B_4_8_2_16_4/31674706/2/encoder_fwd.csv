cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
aten::clone,296,"[[5242880], []]",aten::copy_,298,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),340770,0,10.821875
aten::to,301,"[[], [], [], [], [], []]",aten::copy_,304,"[[], [], []]",Memcpy HtoD (Pageable -> Device),340789,24714.666666666668,1.0
aten::norm,308,"[[2048, 4, 5120], [], [], []]",aten::norm,308,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",340801,14712.0,94.2515625
aten::mul,309,"[[2048, 4, 1], []]",aten::mul,309,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",340809,345.6666666666667,3.0125
aten::add,310,"[[2048, 4, 1], [], []]",aten::add,310,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",340817,382.0,3.0
aten::div,311,"[[2048, 4, 5120], [2048, 4, 1]]",aten::div,311,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",340825,584.6666666666666,192.8796875
aten::mul,312,"[[5120], [2048, 4, 5120]]",aten::mul,312,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",340833,320.3333333333333,185.965625
aten::linear,317,"[[2048, 4, 5120], [1920, 5120], []]",aten::mm,324,"[[8192, 5120], [5120, 1920]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_tn,340845,459.6666666666667,629.5734375
aten::to,337,"[[2048, 1, 1, 128], [], [], [], [], [], [], []]",aten::copy_,340,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),340855,1198.3333333333333,21.4453125
aten::to,341,"[[2048, 1, 1, 128], [], [], [], [], [], [], []]",aten::_to_copy,342,"[[2048, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),340865,14458.0,21.4984375
None,None,None,None,None,None,kernel_0,340878,22728.666666666668,12.0015625
None,None,None,None,None,None,kernel_1,340890,3733.0,18.9625
None,None,None,None,None,None,kernel_0,340902,5788.333333333333,17.70625
None,None,None,None,None,None,kernel_1,340914,1616.0,18.4875
aten::baddbmm,395,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",aten::baddbmm,395,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,340931,17979.0,241.8140625
ScaledUpperTriangMaskedSoftmax,398,"[[20, 2048, 2048]]",ScaledUpperTriangMaskedSoftmax,398,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",340940,352.0,220.1640625
aten::bmm,415,"[[20, 2048, 2048], [20, 2048, 128]]",aten::bmm,415,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,340985,995.3333333333334,166.3328125
aten::contiguous,419,"[[2048, 4, 5, 128], []]",aten::copy_,423,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",340996,359.3333333333333,25.0046875
aten::linear,425,"[[2048, 4, 640], [5120, 640], []]",aten::mm,432,"[[8192, 640], [640, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_tn,341010,544.6666666666666,246.3296875
_ReduceFromModelParallelRegion,434,"[[2048, 4, 5120]]",nccl:all_reduce,437,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",341028,622.3333333333334,30957.7421875
aten::add,442,"[[2048, 4, 5120], [2048, 4, 5120], []]",aten::add,442,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",341067,441.3333333333333,189.76875
aten::norm,443,"[[2048, 4, 5120], [], [], []]",aten::norm,443,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",341089,350.0,89.9890625
aten::mul,444,"[[2048, 4, 1], []]",aten::mul,444,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",341101,351.0,3.0015625
aten::add,445,"[[2048, 4, 1], [], []]",aten::add,445,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",341113,379.6666666666667,3.0
aten::div,446,"[[2048, 4, 5120], [2048, 4, 1]]",aten::div,446,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",341125,318.6666666666667,192.93125
aten::mul,447,"[[5120], [2048, 4, 5120]]",aten::mul,447,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",341137,350.0,185.96875
aten::to,450,"[[], [], [], [], [], []]",aten::copy_,453,"[[], [], []]",Memcpy HtoD (Pageable -> Device),341151,399.6666666666667,1.0
aten::linear,460,"[[2048, 4, 5120], [2560, 5120], []]",aten::mm,467,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8::Params),341166,28167.0,765.753125
aten::add,469,"[[2048, 4, 2560], [2560], []]",aten::add,469,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",341174,356.6666666666667,93.55625
aten::gelu,470,"[[2048, 4, 2560], []]",aten::gelu,470,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",341182,353.3333333333333,66.9734375
aten::linear,471,"[[2048, 4, 2560], [5120, 2560], []]",aten::mm,478,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,341197,1402.3333333333333,927.1453125
_ReduceFromModelParallelRegion,480,"[[2048, 4, 5120]]",nccl:all_reduce,483,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",341218,461.6666666666667,31135.4765625
aten::add,490,"[[2048, 4, 5120], [2048, 4, 5120], []]",aten::add,490,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",341257,402.6666666666667,186.640625
aten::add,492,"[[2048, 4, 5120], [2048, 4, 5120], []]",aten::add,492,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",341265,347.3333333333333,187.8734375
