cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::fill_,15616,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",492672,0,9.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::zero_,15619,[[41943040]],"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",492690,2484.6666666666665,63.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,CheckpointFunctionBackward,15612,"[[2048, 4, 5120], []]",Memcpy DtoD (Device -> Device),492696,306.3333333333333,20.866666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,nccl:all_gather,15657,[[5242880]],"ncclKernel_AllGather_RING_LL_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)",492722,4629.0,16223.146666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::copy_,15660,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),492729,57.666666666666664,19.973333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,nccl:all_gather,15657,[[5242880]],Memcpy DtoD (Device -> Device),492733,57.333333333333336,19.52
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,nccl:all_gather,15657,[[5242880]],Memcpy DtoD (Device -> Device),492737,56.0,20.173333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,nccl:all_gather,15657,[[5242880]],Memcpy DtoD (Device -> Device),492741,57.0,19.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,nccl:all_gather,15657,[[5242880]],Memcpy DtoD (Device -> Device),492745,55.333333333333336,19.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,nccl:all_gather,15657,[[5242880]],Memcpy DtoD (Device -> Device),492749,56.0,19.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,nccl:all_gather,15657,[[5242880]],Memcpy DtoD (Device -> Device),492753,57.0,19.746666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,nccl:all_gather,15657,[[5242880]],Memcpy DtoD (Device -> Device),492757,56.666666666666664,19.746666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::copy_,15698,"[[], [], []]",Memcpy HtoD (Pageable -> Device),492825,46.666666666666664,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::norm,15702,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",492839,2336.6666666666665,91.82666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,15703,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",492847,38.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add,15704,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",492855,184.66666666666666,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::div,15705,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",492863,183.0,193.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,15706,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",492871,36.333333333333336,186.10666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mm,15718,"[[8192, 5120], [5120, 1920]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_tn,492883,41.666666666666664,630.5333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::copy_,15734,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),492893,150.66666666666666,21.573333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::_to_copy,15736,"[[2048, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),492903,1690.3333333333333,21.426666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::neg,15748,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",492911,2644.0,14.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::cat,15760,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",492920,1072.0,43.026666666666664
None,None,None,None,None,None,kernel_1,492933,182.66666666666666,20.346666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::neg,15771,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",492940,748.0,17.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::cat,15782,"[[2048, 4, 5, 128], [], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",492949,633.0,42.906666666666666
None,None,None,None,None,None,kernel_1,492962,55.0,20.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::baddbmm,15798,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,492979,2344.3333333333335,240.09333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,ScaledUpperTriangMaskedSoftmax,15801,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",492988,41.666666666666664,219.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::bmm,15818,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,493033,40.333333333333336,169.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::copy_,15826,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",493044,40.333333333333336,25.026666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mm,15835,"[[8192, 640], [640, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_tn,493058,38.666666666666664,247.46666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,nccl:all_reduce,15840,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",493076,53.0,31746.746666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add,15845,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",493115,40.666666666666664,188.05333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::norm,15846,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",493137,41.0,89.94666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,15847,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",493149,40.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add,15848,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",493161,42.0,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::div,15849,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",493173,37.333333333333336,193.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,15850,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",493185,41.333333333333336,186.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::_to_copy,15854,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),493199,51.0,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mm,15870,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8::Params),493214,3362.6666666666665,761.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add,15872,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",493222,40.0,93.85333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::gelu,18945,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",493230,35.0,67.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mm,18953,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,493245,153.0,927.8533333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,nccl:all_reduce,18958,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",493266,58.0,31662.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add,18965,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",493305,53.0,184.94666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add,18967,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",493313,38.0,188.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::sum,18975,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",493364,139.66666666666666,86.38666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add_,18979,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",493371,42.333333333333336,3.1733333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mm,18991,"[[5120, 8192], [8192, 2560]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,493396,144.66666666666666,759.3333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mm,18998,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8::Params),493416,40.666666666666664,763.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add_,19010,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",493427,40.0,51.013333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::gelu_backward,19013,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3>)",493441,46.0,98.97333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::sum,19016,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",493470,134.33333333333334,53.013333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add_,19020,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",493477,39.0,3.066666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mm,19030,"[[2560, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,493497,48.333333333333336,928.0933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mm,19037,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,493512,38.666666666666664,778.4933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add_,19049,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",493523,40.666666666666664,51.89333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,nccl:all_reduce,19054,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",493543,67.33333333333333,31348.02666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19058,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",493588,60.666666666666664,185.13333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19059,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",493600,44.0,188.14666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::sum,19060,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",493627,135.66666666666666,86.02666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add_,19064,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",493640,41.333333333333336,3.3333333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::div,19067,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",493656,42.0,193.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::div,19068,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",493670,41.666666666666664,197.90666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::neg,19069,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",493684,34.0,120.29333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19070,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",493698,44.0,189.52
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::div,19071,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",493712,41.666666666666664,200.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::sum,19072,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",493730,39.333333333333336,90.61333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add,19073,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",493745,40.333333333333336,177.06666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19078,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",493764,38.0,3.3733333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::div,19081,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",493780,42.0,196.97333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::eq,19082,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",493794,36.666666666666664,3.3466666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::masked_fill_,19083,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",493799,43.666666666666664,208.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19086,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",493813,38.0,187.09333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add,19087,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",493828,46.333333333333336,188.17333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mm,19101,"[[5120, 8192], [8192, 640]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nt,493855,45.0,198.85333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mm,19108,"[[8192, 5120], [5120, 640]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,493876,133.66666666666666,209.89333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add_,19120,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",493890,37.333333333333336,15.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::bmm,19139,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,493917,39.333333333333336,146.58666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::bmm,19142,"[[20, 2048, 128], [20, 128, 2048]]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,493935,41.0,243.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,ScaledUpperTriangMaskedSoftmaxBackward,19160,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",493949,39.666666666666664,301.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::bmm,19177,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,493970,40.333333333333336,166.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19179,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",493984,39.333333333333336,11.56
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::bmm,19182,"[[20, 128, 2048], [20, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x6_nt,494001,39.0,185.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19184,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",494015,39.666666666666664,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19208,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",494041,37.0,60.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19212,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",494055,41.333333333333336,61.17333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::neg,19215,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",494071,39.333333333333336,15.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::zero_,19221,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",494090,37.666666666666664,10.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::copy_,19225,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",494096,44.666666666666664,33.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add,19226,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",494112,40.666666666666664,71.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::zeros,19230,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",494132,39.0,11.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::slice_backward,19229,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",494138,29.666666666666668,33.626666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add,19237,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",494154,41.333333333333336,71.05333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19241,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",494171,40.666666666666664,28.066666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19245,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",494185,41.333333333333336,22.973333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::neg,19248,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",494201,39.666666666666664,15.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::zero_,19254,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",494220,42.666666666666664,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::slice_backward,19251,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",494226,42.333333333333336,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add,19259,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",494242,47.0,31.706666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::zeros,19263,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",494262,35.666666666666664,10.333333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::slice_backward,19262,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",494268,41.666666666666664,16.093333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add,19270,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",494284,44.0,30.066666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::cat,19273,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",494302,38.0,114.61333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mm,19287,"[[1920, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,494326,40.333333333333336,621.9466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mm,19294,"[[8192, 1920], [1920, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nn,494344,36.333333333333336,607.7866666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add_,19306,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",494355,41.333333333333336,42.85333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,nccl:all_reduce,19311,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",494375,70.0,31776.81333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19315,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",494422,65.66666666666667,185.09333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19316,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",494436,42.0,188.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::sum,19317,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",494469,140.0,86.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add_,19321,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",494482,40.0,3.2933333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::div,19324,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",494500,42.0,193.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::div,19325,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",494516,41.0,197.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::neg,19326,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",494532,35.333333333333336,120.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19327,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",494548,38.0,189.30666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::div,19328,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",494564,41.666666666666664,206.62666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::sum,19329,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",494584,41.0,90.46666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add,19330,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",494601,38.666666666666664,177.22666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19335,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",494622,41.333333333333336,3.506666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::div,19338,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",494640,39.333333333333336,197.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::eq,19339,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",494656,37.333333333333336,3.5866666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::masked_fill_,19340,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",494661,38.333333333333336,208.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::mul,19343,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",494677,40.0,187.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,15611,,aten::add,19344,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",494694,43.0,188.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::fill_,19354,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",494725,3185.3333333333335,9.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::zeros,19355,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",494740,1520.3333333333333,63.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,CheckpointFunctionBackward,19350,"[[2048, 4, 5120], []]",Memcpy DtoD (Device -> Device),494746,44.333333333333336,21.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,nccl:all_gather,19395,[[5242880]],"ncclKernel_AllGather_RING_LL_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)",494772,2377.0,16717.093333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,nccl:all_gather,19395,[[5242880]],Memcpy DtoD (Device -> Device),494779,71.33333333333333,19.893333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,nccl:all_gather,19395,[[5242880]],Memcpy DtoD (Device -> Device),494783,56.0,19.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,nccl:all_gather,19395,[[5242880]],Memcpy DtoD (Device -> Device),494787,55.0,20.186666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,nccl:all_gather,19395,[[5242880]],Memcpy DtoD (Device -> Device),494791,57.0,20.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,nccl:all_gather,19395,[[5242880]],Memcpy DtoD (Device -> Device),494795,55.333333333333336,19.69333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,nccl:all_gather,19395,[[5242880]],Memcpy DtoD (Device -> Device),494799,54.0,19.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,nccl:all_gather,19395,[[5242880]],Memcpy DtoD (Device -> Device),494803,55.333333333333336,19.666666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,nccl:all_gather,19395,[[5242880]],Memcpy DtoD (Device -> Device),494807,58.0,19.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::copy_,19436,"[[], [], []]",Memcpy HtoD (Pageable -> Device),494875,45.0,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::norm,19440,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",494889,1984.0,91.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19441,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",494897,39.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add,19442,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",494905,44.333333333333336,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::div,19443,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",494913,38.0,193.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19444,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",494921,41.0,186.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mm,19456,"[[8192, 5120], [5120, 1920]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_tn,494933,40.333333333333336,630.5733333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::copy_,19472,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),494943,132.66666666666666,21.506666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::_to_copy,19474,"[[2048, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),494953,1654.0,21.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::neg,19486,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",494961,2286.0,13.986666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::cat,19498,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",494970,914.0,43.053333333333335
None,None,None,None,None,None,kernel_1,494983,114.0,20.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::neg,19509,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",494990,730.3333333333334,17.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::cat,19520,"[[2048, 4, 5, 128], [], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",494999,733.0,42.906666666666666
None,None,None,None,None,None,kernel_1,495012,60.666666666666664,20.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::baddbmm,19536,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,495029,2190.3333333333335,239.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,ScaledUpperTriangMaskedSoftmax,19539,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",495038,41.333333333333336,220.05333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::bmm,19556,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,495083,39.666666666666664,168.94666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::copy_,19564,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",495094,39.0,25.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mm,19573,"[[8192, 640], [640, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_tn,495108,40.333333333333336,247.30666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,nccl:all_reduce,19578,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",495126,52.666666666666664,31609.266666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add,19583,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",495165,42.0,188.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::norm,19584,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",495187,39.666666666666664,90.13333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19585,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",495199,37.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add,19586,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",495211,43.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::div,19587,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",495223,34.666666666666664,193.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19588,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",495235,46.666666666666664,186.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::_to_copy,19592,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),495249,49.333333333333336,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mm,19608,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8::Params),495264,3354.6666666666665,760.8533333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add,19610,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",495272,38.333333333333336,93.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::gelu,19611,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",495280,50.0,67.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mm,19619,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,495295,165.33333333333334,927.7066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,nccl:all_reduce,19624,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",495316,69.33333333333333,31482.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add,19631,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",495355,52.0,184.90666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add,19633,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",495363,39.666666666666664,187.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::sum,19641,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",495414,138.0,86.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add_,19645,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",495421,39.333333333333336,3.1333333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mm,19657,"[[5120, 8192], [8192, 2560]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,495446,146.66666666666666,758.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mm,19664,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8::Params),495466,39.333333333333336,763.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add_,19676,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",495477,39.666666666666664,51.026666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::gelu_backward,19679,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3>)",495491,46.666666666666664,98.93333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::sum,19682,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",495520,134.66666666666666,52.586666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add_,19686,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",495527,40.0,3.4133333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mm,19696,"[[2560, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,495547,41.333333333333336,927.4266666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mm,19703,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,495562,39.0,778.3066666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add_,19715,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",495573,42.666666666666664,51.93333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,nccl:all_reduce,19720,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",495593,68.0,31782.48
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19724,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",495638,60.666666666666664,185.14666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19725,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",495650,45.666666666666664,188.06666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::sum,19726,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",495677,136.33333333333334,86.57333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add_,19730,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",495690,39.333333333333336,3.1866666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::div,19733,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",495706,45.333333333333336,193.38666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::div,19734,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",495720,41.333333333333336,197.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::neg,19735,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",495734,37.333333333333336,120.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19736,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",495748,41.666666666666664,190.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::div,19737,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",495762,37.0,201.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::sum,19738,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",495780,38.666666666666664,90.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add,19739,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",495795,41.0,177.26666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19744,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",495814,38.666666666666664,3.3866666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::div,19747,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",495830,42.666666666666664,196.97333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::eq,19748,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",495844,35.666666666666664,3.3733333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::masked_fill_,19749,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",495849,41.666666666666664,207.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19752,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",495863,39.666666666666664,187.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add,19753,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",495878,43.333333333333336,188.10666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mm,19767,"[[5120, 8192], [8192, 640]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nt,495905,45.666666666666664,198.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mm,19774,"[[8192, 5120], [5120, 640]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,495926,133.0,209.78666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add_,19786,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",495940,39.0,15.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::bmm,19805,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,495967,40.333333333333336,145.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::bmm,19808,"[[20, 2048, 128], [20, 128, 2048]]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,495985,40.333333333333336,241.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,ScaledUpperTriangMaskedSoftmaxBackward,19826,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",495999,39.333333333333336,301.93333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::bmm,19843,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,496020,36.666666666666664,165.94666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19845,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",496034,42.666666666666664,11.533333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::bmm,19848,"[[20, 128, 2048], [20, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x6_nt,496051,37.666666666666664,184.56
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19850,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",496065,41.0,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19874,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",496091,38.666666666666664,61.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19878,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",496105,40.666666666666664,61.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::neg,19881,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",496121,39.333333333333336,15.493333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::fill_,19888,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",496140,40.666666666666664,10.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::copy_,19891,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",496146,43.666666666666664,33.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add,19892,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",496162,38.666666666666664,71.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::zeros,19896,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",496182,39.666666666666664,11.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::slice_backward,19895,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",496188,30.666666666666668,34.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add,19903,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",496204,38.666666666666664,70.97333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19907,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",496221,39.0,28.133333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19911,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",496235,40.666666666666664,23.413333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::neg,19914,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",496251,40.333333333333336,15.386666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::zero_,19920,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",496270,42.666666666666664,10.066666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::slice_backward,19917,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",496276,43.333333333333336,12.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add,19925,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",496292,45.666666666666664,31.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::zeros,19929,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",496312,39.666666666666664,10.293333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::slice_backward,19928,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",496318,42.666666666666664,16.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add,19936,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",496334,45.333333333333336,30.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::cat,19939,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",496352,38.0,114.56
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mm,19953,"[[1920, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,496376,38.0,622.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mm,19960,"[[8192, 1920], [1920, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nn,496394,39.0,607.7066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add_,19972,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",496405,37.666666666666664,42.74666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,nccl:all_reduce,19977,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",496425,72.33333333333333,31492.693333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19981,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",496472,65.66666666666667,185.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19982,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",496486,43.666666666666664,188.10666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::sum,19983,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",496519,140.33333333333334,85.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add_,19987,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",496530,39.333333333333336,3.2133333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::div,19990,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",496546,46.0,193.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::div,19991,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",496560,40.666666666666664,197.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::neg,19992,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",496574,34.0,120.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,19993,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",496588,44.0,189.46666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::div,19994,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",496602,40.333333333333336,206.81333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::sum,19995,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",496620,39.666666666666664,90.42666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add,19996,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",496635,41.0,177.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,20001,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",496654,40.0,3.3866666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::div,20004,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",496670,40.0,197.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::eq,20005,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",496684,37.666666666666664,3.5733333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::masked_fill_,20006,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",496689,38.333333333333336,207.90666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::mul,20009,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",496703,39.666666666666664,187.22666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,19349,,aten::add,20010,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",496718,44.0,188.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::fill_,20020,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",496748,3267.3333333333335,9.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::zeros,20021,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",496763,1517.0,63.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,CheckpointFunctionBackward,20016,"[[2048, 4, 5120], []]",Memcpy DtoD (Device -> Device),496769,43.666666666666664,21.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,nccl:all_gather,20061,[[5242880]],"ncclKernel_AllGather_RING_LL_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)",496795,2139.0,16852.466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::copy_,20064,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),496802,75.33333333333333,19.666666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,nccl:all_gather,20061,[[5242880]],Memcpy DtoD (Device -> Device),496806,55.333333333333336,19.426666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,nccl:all_gather,20061,[[5242880]],Memcpy DtoD (Device -> Device),496810,53.666666666666664,20.106666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,nccl:all_gather,20061,[[5242880]],Memcpy DtoD (Device -> Device),496814,56.333333333333336,19.85333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,nccl:all_gather,20061,[[5242880]],Memcpy DtoD (Device -> Device),496818,52.666666666666664,19.813333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,nccl:all_gather,20061,[[5242880]],Memcpy DtoD (Device -> Device),496822,53.333333333333336,19.826666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,nccl:all_gather,20061,[[5242880]],Memcpy DtoD (Device -> Device),496826,54.0,19.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,nccl:all_gather,20061,[[5242880]],Memcpy DtoD (Device -> Device),496830,57.333333333333336,19.906666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::copy_,20102,"[[], [], []]",Memcpy HtoD (Pageable -> Device),496898,47.0,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::norm,20106,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",496912,2004.3333333333333,91.98666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20107,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",496920,39.0,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add,20108,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",496928,43.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::div,20109,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",496936,41.333333333333336,193.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20110,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",496944,40.666666666666664,186.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mm,20122,"[[8192, 5120], [5120, 1920]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_tn,496956,40.333333333333336,630.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::copy_,20138,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),496966,115.33333333333333,21.866666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::_to_copy,20140,"[[2048, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),496976,1672.6666666666667,21.453333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::neg,20152,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",496984,2300.0,14.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::cat,20164,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",496993,909.0,43.10666666666667
None,None,None,None,None,None,kernel_1,497006,105.33333333333333,20.30666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::neg,20175,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",497013,785.3333333333334,17.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::cat,20186,"[[2048, 4, 5, 128], [], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",497022,713.6666666666666,42.89333333333333
None,None,None,None,None,None,kernel_1,497035,75.33333333333333,20.14666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::baddbmm,20202,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,497052,2257.0,240.46666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,ScaledUpperTriangMaskedSoftmax,20205,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",497061,40.0,220.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::bmm,20222,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,497106,39.666666666666664,167.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::copy_,20230,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",497117,38.666666666666664,25.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mm,20239,"[[8192, 640], [640, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_tn,497131,42.333333333333336,247.53333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,nccl:all_reduce,20244,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",497149,51.0,31373.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add,20249,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",497188,42.333333333333336,188.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::norm,20250,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",497210,41.0,89.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20251,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",497222,40.666666666666664,3.013333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add,20252,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",497234,43.333333333333336,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::div,20253,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",497246,34.333333333333336,193.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20254,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",497258,45.666666666666664,186.02666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::_to_copy,20258,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),497272,51.666666666666664,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mm,20274,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8::Params),497287,3258.6666666666665,761.2666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add,20276,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",497295,37.0,93.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::gelu,20277,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",497303,37.0,66.98666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mm,20285,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,497318,157.66666666666666,927.4666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,nccl:all_reduce,20290,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",497339,56.666666666666664,31576.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add,20297,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",497378,52.0,185.02666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add,20299,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",497386,41.0,187.97333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::sum,20307,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",497437,135.33333333333334,86.21333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add_,20311,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",497444,40.333333333333336,3.2266666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mm,20323,"[[5120, 8192], [8192, 2560]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,497469,144.0,758.9466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mm,20330,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8::Params),497489,40.333333333333336,763.6933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add_,20342,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",497500,39.333333333333336,51.013333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::gelu_backward,20345,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3>)",497514,45.666666666666664,99.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::sum,20348,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",497543,132.66666666666666,52.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,torch::autograd::AccumulateGrad,20351,[[2560]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",497550,38.666666666666664,3.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mm,20362,"[[2560, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,497570,46.666666666666664,927.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mm,20369,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,497585,40.333333333333336,778.5466666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add_,20381,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",497596,38.666666666666664,51.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,nccl:all_reduce,20386,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",497616,69.0,31690.866666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20390,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",497661,59.333333333333336,185.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20391,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",497673,45.666666666666664,187.94666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::sum,20392,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",497700,134.33333333333334,86.22666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add_,20396,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",497713,39.0,3.2666666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::div,20399,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",497729,44.333333333333336,193.50666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::div,20400,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",497743,41.0,197.82666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::neg,20401,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",497757,35.333333333333336,120.17333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20402,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",497771,44.0,189.46666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::div,20403,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",497785,41.333333333333336,201.02666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::sum,20404,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",497803,37.666666666666664,90.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add,20405,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",497818,40.666666666666664,177.38666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20410,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",497837,40.0,3.4266666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::div,20413,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",497853,40.666666666666664,196.94666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::eq,20414,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",497867,34.0,3.2666666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::masked_fill_,20415,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",497872,42.0,207.90666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20418,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",497886,42.666666666666664,187.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add,20419,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",497901,43.666666666666664,187.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mm,20433,"[[5120, 8192], [8192, 640]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nt,497928,44.0,198.94666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mm,20440,"[[8192, 5120], [5120, 640]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,497949,132.66666666666666,209.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add_,20452,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",497963,38.333333333333336,15.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::bmm,20471,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,497990,38.0,145.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::bmm,20474,"[[20, 2048, 128], [20, 128, 2048]]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,498008,41.666666666666664,243.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,ScaledUpperTriangMaskedSoftmaxBackward,20492,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",498022,40.0,302.1066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::bmm,20509,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,498043,41.666666666666664,165.66666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20511,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",498057,40.666666666666664,11.506666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::bmm,20514,"[[20, 128, 2048], [20, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x6_nt,498074,40.333333333333336,184.48
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20516,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",498088,39.0,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20540,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",498114,39.0,61.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20544,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",498128,39.666666666666664,61.21333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::neg,20547,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",498144,41.0,15.586666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::zero_,20553,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",498163,39.0,10.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::copy_,20557,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",498169,45.0,33.333333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add,20558,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",498185,39.0,71.41333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::zeros,20562,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",498205,41.666666666666664,11.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::slice_backward,20561,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",498211,30.333333333333332,33.56
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add,20569,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",498227,39.666666666666664,70.98666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20573,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",498244,40.0,28.066666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20577,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",498258,42.666666666666664,22.986666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::neg,20580,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",498274,33.666666666666664,15.48
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::zeros,20584,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",498293,40.666666666666664,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::slice_backward,20583,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",498299,44.0,12.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add,20591,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",498315,46.333333333333336,31.666666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::zeros,20595,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",498335,36.666666666666664,10.253333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::slice_backward,20594,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",498341,44.333333333333336,16.066666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add,20602,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",498357,44.333333333333336,29.986666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::cat,20605,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",498375,36.0,114.30666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mm,20619,"[[1920, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,498399,43.333333333333336,621.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mm,20626,"[[8192, 1920], [1920, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nn,498417,37.666666666666664,607.8933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add_,20638,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",498428,38.666666666666664,42.693333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,nccl:all_reduce,20643,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",498448,78.0,31656.946666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20647,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",498495,61.0,185.14666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20648,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",498509,45.666666666666664,187.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::sum,20649,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",498542,136.33333333333334,86.13333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add_,20653,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",498555,42.0,3.3333333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::div,20656,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",498573,40.666666666666664,193.61333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::div,20657,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",498589,37.666666666666664,197.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::neg,20658,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",498605,35.666666666666664,120.14666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20659,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",498621,42.0,189.36
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::div,20660,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",498637,44.333333333333336,206.49333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::sum,20661,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",498657,38.0,90.73333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add,20662,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",498674,40.0,177.46666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20667,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",498695,40.666666666666664,3.3466666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::div,20670,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",498713,43.333333333333336,197.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::eq,20671,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",498729,38.0,3.52
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::masked_fill_,20672,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",498734,38.666666666666664,207.97333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::mul,20675,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",498750,42.666666666666664,187.21333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20015,,aten::add,20676,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",498767,42.0,187.97333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::fill_,20686,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",498798,3167.6666666666665,9.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::zeros,20687,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",498813,1469.0,63.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,CheckpointFunctionBackward,20682,"[[2048, 4, 5120], []]",Memcpy DtoD (Device -> Device),498819,52.666666666666664,21.066666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,nccl:all_gather,20727,[[5242880]],"ncclKernel_AllGather_RING_LL_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)",498845,2241.0,16528.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,nccl:all_gather,20727,[[5242880]],Memcpy DtoD (Device -> Device),498852,71.0,19.933333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,nccl:all_gather,20727,[[5242880]],Memcpy DtoD (Device -> Device),498856,55.0,18.986666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,nccl:all_gather,20727,[[5242880]],Memcpy DtoD (Device -> Device),498860,54.666666666666664,20.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,nccl:all_gather,20727,[[5242880]],Memcpy DtoD (Device -> Device),498864,54.333333333333336,19.85333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,nccl:all_gather,20727,[[5242880]],Memcpy DtoD (Device -> Device),498868,58.666666666666664,19.746666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,nccl:all_gather,20727,[[5242880]],Memcpy DtoD (Device -> Device),498872,55.333333333333336,19.786666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,nccl:all_gather,20727,[[5242880]],Memcpy DtoD (Device -> Device),498876,54.333333333333336,19.733333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,nccl:all_gather,20727,[[5242880]],Memcpy DtoD (Device -> Device),498880,56.0,19.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::copy_,20768,"[[], [], []]",Memcpy HtoD (Pageable -> Device),498948,47.333333333333336,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::norm,20772,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",498962,1992.3333333333333,92.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,20773,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",498970,38.333333333333336,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add,20774,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",498978,43.333333333333336,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::div,20775,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",498986,40.666666666666664,193.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,20776,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",498994,40.666666666666664,186.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mm,20788,"[[8192, 5120], [5120, 1920]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_tn,499006,41.333333333333336,630.7066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::copy_,20804,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),499016,130.33333333333334,21.973333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::to,20805,"[[2048, 1, 1, 128], [], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),499026,1683.0,21.893333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::neg,20818,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",499034,2254.3333333333335,14.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::cat,20830,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",499043,981.3333333333334,43.04
None,None,None,None,None,None,kernel_1,499056,116.0,20.30666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::neg,20841,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",499063,753.3333333333334,17.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::cat,20852,"[[2048, 4, 5, 128], [], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",499072,707.6666666666666,42.86666666666667
None,None,None,None,None,None,kernel_1,499085,83.66666666666667,20.253333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::baddbmm,20868,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,499102,2236.6666666666665,240.13333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,ScaledUpperTriangMaskedSoftmax,20871,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",499111,41.666666666666664,219.97333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::bmm,20888,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,499156,40.666666666666664,168.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::copy_,20896,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",499167,37.666666666666664,25.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mm,20905,"[[8192, 640], [640, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_tn,499181,42.0,247.46666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,nccl:all_reduce,20910,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",499199,57.0,31562.253333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add,20915,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",499238,43.0,188.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::norm,20916,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",499260,38.0,90.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,20917,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",499272,37.333333333333336,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add,20918,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",499284,42.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::div,20919,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",499296,36.333333333333336,192.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,20920,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",499308,42.333333333333336,186.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::_to_copy,20924,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),499322,52.0,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mm,20940,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8::Params),499337,3280.3333333333335,761.3733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add,20942,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",499345,41.0,93.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::gelu,20943,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",499353,34.666666666666664,67.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mm,20951,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,499368,158.66666666666666,927.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,nccl:all_reduce,20956,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",499389,55.0,31347.666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add,20963,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",499428,53.333333333333336,184.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add,20965,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",499436,38.666666666666664,187.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::sum,20973,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",499487,135.0,86.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add_,20977,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",499494,38.333333333333336,3.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mm,20989,"[[5120, 8192], [8192, 2560]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,499519,147.0,758.4666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mm,20996,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8::Params),499539,41.333333333333336,763.4266666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add_,21008,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",499550,39.333333333333336,51.013333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::gelu_backward,21011,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3>)",499564,44.333333333333336,99.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::sum,21014,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",499593,133.66666666666666,53.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,torch::autograd::AccumulateGrad,21017,[[2560]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",499600,40.0,3.3333333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mm,21028,"[[2560, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,499620,43.666666666666664,928.1866666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mm,21035,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,499635,39.666666666666664,778.3066666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add_,21047,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",499646,42.333333333333336,51.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,nccl:all_reduce,21052,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",499666,65.0,31593.746666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21056,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",499711,62.666666666666664,185.17333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21057,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",499723,44.333333333333336,187.86666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::sum,21058,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",499750,134.33333333333334,86.22666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add_,21062,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",499763,41.0,3.1866666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::div,21065,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",499779,45.333333333333336,193.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::div,21066,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",499793,43.666666666666664,197.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::neg,21067,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",499807,35.666666666666664,120.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21068,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",499821,44.333333333333336,189.46666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::div,21069,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",499835,43.0,200.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::sum,21070,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",499853,36.0,90.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add,21071,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",499868,40.333333333333336,177.22666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21076,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",499887,40.0,3.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::div,21079,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",499903,41.333333333333336,196.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::eq,21080,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",499917,34.666666666666664,3.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::masked_fill_,21081,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",499922,45.333333333333336,208.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21084,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",499936,37.666666666666664,187.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add,21085,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",499951,46.333333333333336,188.17333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mm,21099,"[[5120, 8192], [8192, 640]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nt,499978,43.666666666666664,198.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mm,21106,"[[8192, 5120], [5120, 640]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,499999,132.0,209.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add_,21118,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",500013,37.666666666666664,15.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::bmm,21137,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,500040,43.0,145.86666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::bmm,21140,"[[20, 2048, 128], [20, 128, 2048]]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,500058,36.666666666666664,243.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,ScaledUpperTriangMaskedSoftmaxBackward,21158,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",500072,40.333333333333336,301.93333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::bmm,21175,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,500093,41.666666666666664,165.58666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21177,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",500107,41.333333333333336,11.533333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::bmm,21180,"[[20, 128, 2048], [20, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x6_nt,500124,39.666666666666664,184.41333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21182,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",500138,40.333333333333336,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21206,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",500164,37.0,60.906666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21210,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",500178,41.666666666666664,61.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::neg,21213,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",500194,39.333333333333336,15.653333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::zero_,21219,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",500213,37.333333333333336,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::copy_,21223,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",500219,44.333333333333336,33.36
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add,21224,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",500235,40.0,70.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::zero_,21230,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",500255,39.0,10.986666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::slice_backward,21227,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",500261,28.333333333333332,33.77333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add,21235,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",500277,40.0,70.58666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21239,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",500294,39.666666666666664,28.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21243,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",500308,40.333333333333336,22.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::neg,21246,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",500324,38.666666666666664,15.48
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::zero_,21252,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",500343,43.333333333333336,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::slice_backward,21249,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",500349,40.0,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add,21257,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",500365,46.666666666666664,31.746666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::zeros,21261,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",500385,36.333333333333336,10.346666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::slice_backward,21260,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",500391,40.333333333333336,16.053333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add,21268,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",500407,46.666666666666664,30.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::cat,21271,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",500425,36.333333333333336,114.48
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mm,21285,"[[1920, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,500449,43.0,622.6133333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mm,21292,"[[8192, 1920], [1920, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nn,500467,37.333333333333336,607.7333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add_,21304,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",500478,37.0,42.82666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,nccl:all_reduce,21309,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",500498,74.66666666666667,31546.226666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21313,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",500545,67.66666666666667,185.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21314,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",500559,45.333333333333336,188.10666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::sum,21315,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",500592,137.33333333333334,86.13333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add_,21319,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",500605,41.333333333333336,3.3333333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::div,21322,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",500623,43.0,193.69333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::div,21323,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",500639,37.333333333333336,197.82666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::neg,21324,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",500655,33.666666666666664,120.29333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21325,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",500671,43.0,189.26666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::div,21326,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",500687,39.333333333333336,207.05333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::sum,21327,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",500707,42.0,90.45333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add,21328,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",500724,39.0,177.33333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21333,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",500745,41.666666666666664,3.3733333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::div,21336,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",500763,42.0,197.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::eq,21337,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",500779,39.333333333333336,3.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::masked_fill_,21338,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",500784,37.333333333333336,207.90666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::mul,21341,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",500800,40.333333333333336,187.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,20681,,aten::add,21342,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",500817,43.333333333333336,188.02666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::fill_,21352,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",500848,3104.3333333333335,9.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::zeros,21353,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",500863,1493.0,63.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,CheckpointFunctionBackward,21348,"[[2048, 4, 5120], []]",Memcpy DtoD (Device -> Device),500869,42.0,20.986666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,nccl:all_gather,21393,[[5242880]],"ncclKernel_AllGather_RING_LL_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)",500895,2155.0,16828.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::copy_,21396,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),500902,70.0,19.626666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,nccl:all_gather,21393,[[5242880]],Memcpy DtoD (Device -> Device),500906,53.333333333333336,19.413333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,nccl:all_gather,21393,[[5242880]],Memcpy DtoD (Device -> Device),500910,55.666666666666664,20.106666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,nccl:all_gather,21393,[[5242880]],Memcpy DtoD (Device -> Device),500914,53.333333333333336,20.053333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,nccl:all_gather,21393,[[5242880]],Memcpy DtoD (Device -> Device),500918,54.666666666666664,19.613333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,nccl:all_gather,21393,[[5242880]],Memcpy DtoD (Device -> Device),500922,56.333333333333336,19.773333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,nccl:all_gather,21393,[[5242880]],Memcpy DtoD (Device -> Device),500926,55.0,19.506666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,nccl:all_gather,21393,[[5242880]],Memcpy DtoD (Device -> Device),500930,58.0,19.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::copy_,21434,"[[], [], []]",Memcpy HtoD (Pageable -> Device),500998,46.666666666666664,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::norm,21438,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",501012,2000.0,91.94666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21439,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",501020,41.0,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add,21440,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",501028,43.0,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::div,21441,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",501036,40.333333333333336,193.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21442,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",501044,41.0,186.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mm,21454,"[[8192, 5120], [5120, 1920]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_tn,501056,41.0,630.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::_to_copy,21468,"[[2048, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),501066,156.0,21.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::_to_copy,21472,"[[2048, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),501076,1943.0,21.64
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::neg,21484,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",501084,2278.3333333333335,14.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::cat,21496,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",501093,938.3333333333334,43.06666666666667
None,None,None,None,None,None,kernel_1,501106,98.0,20.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::neg,21507,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",501113,749.0,17.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::cat,21518,"[[2048, 4, 5, 128], [], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",501122,787.0,42.82666666666667
None,None,None,None,None,None,kernel_1,501135,121.66666666666667,20.133333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::baddbmm,21534,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,501152,2275.0,240.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,ScaledUpperTriangMaskedSoftmax,21537,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",501161,42.0,220.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::bmm,21554,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,501206,38.666666666666664,168.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::copy_,21562,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",501217,38.666666666666664,25.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mm,21571,"[[8192, 640], [640, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_tn,501231,40.666666666666664,247.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,nccl:all_reduce,21576,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",501249,54.333333333333336,31459.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add,21581,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",501288,41.666666666666664,188.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::norm,21582,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",501310,37.333333333333336,89.78666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21583,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",501322,43.0,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add,21584,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",501334,42.0,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::div,21585,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",501346,36.0,193.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21586,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",501358,46.0,186.05333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::_to_copy,21590,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),501372,50.666666666666664,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mm,21606,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8::Params),501387,3374.0,761.3733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add,21608,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",501395,39.333333333333336,93.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::gelu,21609,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",501403,34.0,67.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mm,21617,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,501418,157.33333333333334,927.6266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,nccl:all_reduce,21622,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",501439,58.0,31289.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add,21629,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",501478,50.333333333333336,184.86666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add,21631,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",501486,41.333333333333336,187.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::sum,21639,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",501537,135.66666666666666,86.49333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add_,21643,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",501544,39.666666666666664,3.1866666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mm,21655,"[[5120, 8192], [8192, 2560]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,501569,146.33333333333334,758.8666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mm,21662,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8::Params),501589,39.333333333333336,764.1733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add_,21674,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",501600,42.666666666666664,51.093333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::gelu_backward,21677,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3>)",501614,48.333333333333336,98.77333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::sum,21680,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",501643,135.66666666666666,53.053333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add_,21684,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",501650,41.333333333333336,3.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mm,21694,"[[2560, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,501670,42.0,927.5333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mm,21701,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,501685,42.0,778.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add_,21713,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",501696,39.666666666666664,51.973333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,nccl:all_reduce,21718,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",501716,65.33333333333333,31505.266666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21722,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",501761,60.0,185.17333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21723,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",501773,43.333333333333336,187.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::sum,21724,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",501800,135.66666666666666,86.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add_,21728,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",501813,39.333333333333336,3.466666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::div,21731,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",501829,40.0,193.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::div,21732,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",501843,40.666666666666664,197.77333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::neg,21733,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",501857,37.666666666666664,120.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21734,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",501871,42.666666666666664,189.54666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::div,21735,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",501885,41.666666666666664,201.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::sum,21736,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",501903,38.333333333333336,90.42666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add,21737,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",501918,37.0,177.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21742,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",501937,40.666666666666664,3.453333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::div,21745,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",501953,40.666666666666664,196.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::eq,21746,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",501967,34.0,3.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::masked_fill_,21747,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",501972,44.666666666666664,207.94666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21750,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",501986,42.333333333333336,187.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add,21751,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",502001,43.333333333333336,188.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mm,21765,"[[5120, 8192], [8192, 640]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nt,502028,41.333333333333336,198.97333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mm,21772,"[[8192, 5120], [5120, 640]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,502049,135.33333333333334,209.78666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add_,21784,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",502063,40.0,15.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::bmm,21803,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,502090,38.333333333333336,146.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::bmm,21806,"[[20, 2048, 128], [20, 128, 2048]]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,502108,40.0,243.70666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,ScaledUpperTriangMaskedSoftmaxBackward,21824,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",502122,39.666666666666664,302.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::bmm,21841,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,502143,41.333333333333336,165.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21843,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",502157,38.666666666666664,11.653333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::bmm,21846,"[[20, 128, 2048], [20, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x6_nt,502174,37.666666666666664,184.78666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21848,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",502188,42.0,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21872,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",502214,36.666666666666664,60.986666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21876,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",502228,41.666666666666664,61.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::neg,21879,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",502244,38.333333333333336,15.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::zero_,21885,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",502263,37.0,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::copy_,21889,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",502269,43.333333333333336,33.45333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add,21890,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",502285,39.333333333333336,70.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::zeros,21894,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",502305,41.0,11.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::slice_backward,21893,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",502311,30.333333333333332,33.93333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add,21901,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",502327,37.0,70.73333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21905,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",502344,41.333333333333336,28.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21909,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",502358,39.0,22.85333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::neg,21912,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",502374,37.0,15.466666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::zero_,21918,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",502393,41.333333333333336,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::slice_backward,21915,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",502399,44.666666666666664,12.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add,21923,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",502415,45.666666666666664,31.666666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::zeros,21927,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",502435,38.0,10.64
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::slice_backward,21926,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",502441,36.666666666666664,16.066666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add,21934,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",502457,46.666666666666664,29.973333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::cat,21937,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",502475,38.666666666666664,114.26666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mm,21951,"[[1920, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,502499,40.666666666666664,622.2933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mm,21958,"[[8192, 1920], [1920, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nn,502517,38.0,607.7466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add_,21970,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",502528,41.333333333333336,42.74666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,nccl:all_reduce,21975,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",502548,71.66666666666667,31514.613333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21979,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",502595,66.66666666666667,185.14666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21980,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",502609,45.666666666666664,187.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::sum,21981,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",502642,135.33333333333334,86.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add_,21985,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",502655,42.666666666666664,3.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::div,21988,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",502673,42.666666666666664,193.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::div,21989,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",502689,36.333333333333336,197.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::neg,21990,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",502705,35.0,120.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21991,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",502721,39.0,189.21333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::div,21992,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",502737,45.0,207.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::sum,21993,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",502757,37.666666666666664,90.77333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add,21994,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",502774,38.666666666666664,177.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,21999,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",502795,42.666666666666664,3.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::div,22002,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",502813,40.333333333333336,197.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::eq,22003,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",502829,36.333333333333336,3.5733333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::masked_fill_,22004,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",502834,36.333333333333336,208.14666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::mul,22007,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",502850,41.666666666666664,187.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,21347,,aten::add,22008,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",502867,46.0,188.13333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::fill_,22018,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",502898,3150.0,9.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::zeros,22019,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",502913,1753.0,63.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,CheckpointFunctionBackward,22014,"[[2048, 4, 5120], []]",Memcpy DtoD (Device -> Device),502919,35.666666666666664,21.066666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,nccl:all_gather,22059,[[5242880]],"ncclKernel_AllGather_RING_LL_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)",502945,2172.0,16723.253333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,nccl:all_gather,22059,[[5242880]],Memcpy DtoD (Device -> Device),502952,71.0,19.866666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,nccl:all_gather,22059,[[5242880]],Memcpy DtoD (Device -> Device),502956,54.666666666666664,19.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,nccl:all_gather,22059,[[5242880]],Memcpy DtoD (Device -> Device),502960,54.333333333333336,20.14666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,nccl:all_gather,22059,[[5242880]],Memcpy DtoD (Device -> Device),502964,55.0,19.85333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,nccl:all_gather,22059,[[5242880]],Memcpy DtoD (Device -> Device),502968,56.0,19.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,nccl:all_gather,22059,[[5242880]],Memcpy DtoD (Device -> Device),502972,54.0,19.666666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,nccl:all_gather,22059,[[5242880]],Memcpy DtoD (Device -> Device),502976,56.666666666666664,19.733333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,nccl:all_gather,22059,[[5242880]],Memcpy DtoD (Device -> Device),502980,55.333333333333336,19.786666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::_to_copy,22098,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),503048,50.333333333333336,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::norm,22104,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",503062,1975.0,91.98666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22105,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",503070,39.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add,22106,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",503078,44.0,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::div,22107,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",503086,304.3333333333333,193.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22108,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",503094,40.666666666666664,186.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mm,22120,"[[8192, 5120], [5120, 1920]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_tn,503106,42.0,630.8666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::_to_copy,22134,"[[2048, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),503116,134.33333333333334,21.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::_to_copy,22138,"[[2048, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),503126,1690.6666666666667,21.346666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::neg,22150,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",503134,2421.0,13.986666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::cat,22162,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",503143,941.0,43.013333333333335
None,None,None,None,None,None,kernel_1,503156,118.0,20.226666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::neg,22173,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",503163,786.3333333333334,17.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::cat,22184,"[[2048, 4, 5, 128], [], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",503172,706.3333333333334,42.92
None,None,None,None,None,None,kernel_1,503185,57.0,20.14666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::baddbmm,22200,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,503202,2235.6666666666665,240.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,ScaledUpperTriangMaskedSoftmax,22203,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",503211,39.666666666666664,220.13333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::bmm,22220,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,503256,39.666666666666664,168.86666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::copy_,22228,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",503267,40.0,25.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mm,22237,"[[8192, 640], [640, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_tn,503281,40.666666666666664,247.48
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,nccl:all_reduce,22242,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",503299,55.666666666666664,31218.626666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add,22247,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",503338,43.666666666666664,187.85333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::norm,22248,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",503360,39.333333333333336,90.17333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22249,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",503372,40.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add,22250,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",503384,42.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::div,22251,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",503396,36.666666666666664,193.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22252,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",503408,40.666666666666664,186.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::_to_copy,22256,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),503422,52.333333333333336,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mm,22272,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8::Params),503437,3292.6666666666665,761.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add,22274,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",503445,40.333333333333336,93.78666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::gelu,22275,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",503453,33.666666666666664,67.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mm,22283,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,503468,159.66666666666666,927.9333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,nccl:all_reduce,22288,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",503489,53.666666666666664,31268.053333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add,22295,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",503528,52.666666666666664,184.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add,22297,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",503536,41.0,187.90666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::sum,22305,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",503587,136.0,86.54666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add_,22309,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",503594,40.333333333333336,3.1333333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mm,22321,"[[5120, 8192], [8192, 2560]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,503619,146.66666666666666,758.4666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mm,22328,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8::Params),503639,38.666666666666664,764.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add_,22340,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",503650,39.666666666666664,51.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::gelu_backward,22343,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3>)",503664,46.666666666666664,98.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::sum,22346,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",503693,136.33333333333334,52.74666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,torch::autograd::AccumulateGrad,22349,[[2560]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",503700,39.0,3.3733333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mm,22360,"[[2560, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,503720,44.0,928.3066666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mm,22367,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,503735,40.0,778.2266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add_,22379,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",503746,41.666666666666664,51.986666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,nccl:all_reduce,22384,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",503766,68.0,31623.293333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22388,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",503811,60.333333333333336,184.93333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22389,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",503823,44.0,188.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::sum,22390,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",503850,138.0,86.01333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add_,22394,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",503863,38.666666666666664,3.4133333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::div,22397,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",503879,42.0,193.17333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::div,22398,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",503893,43.333333333333336,197.90666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::neg,22399,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",503907,35.0,120.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22400,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",503921,45.666666666666664,189.52
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::div,22401,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",503935,40.333333333333336,201.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::sum,22402,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",503953,38.666666666666664,90.37333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add,22403,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",503968,38.333333333333336,177.10666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22408,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",503987,39.666666666666664,3.453333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::div,22411,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",504003,42.333333333333336,196.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::eq,22412,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",504017,35.333333333333336,3.3733333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::masked_fill_,22413,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",504022,41.0,208.17333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22416,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",504036,40.333333333333336,187.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add,22417,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",504051,45.0,188.05333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mm,22431,"[[5120, 8192], [8192, 640]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nt,504078,44.0,198.94666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mm,22438,"[[8192, 5120], [5120, 640]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,504099,130.66666666666666,209.57333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add_,22450,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",504113,41.0,15.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::bmm,22469,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,504140,42.333333333333336,144.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::bmm,22472,"[[20, 2048, 128], [20, 128, 2048]]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,504158,41.333333333333336,243.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,ScaledUpperTriangMaskedSoftmaxBackward,22490,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",504172,38.0,302.0933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::bmm,22507,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,504193,41.0,165.81333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22509,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",504207,39.666666666666664,11.626666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::bmm,22512,"[[20, 128, 2048], [20, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x6_nt,504224,37.0,184.42666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22514,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",504238,38.333333333333336,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22538,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",504264,40.333333333333336,61.013333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22542,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",504278,43.666666666666664,61.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::neg,22545,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",504294,40.666666666666664,15.653333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::zero_,22551,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",504313,36.666666666666664,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::copy_,22555,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",504319,45.0,33.38666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add,22556,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",504335,37.666666666666664,71.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::zeros,22560,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",504355,41.0,10.986666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::slice_backward,22559,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",504361,30.333333333333332,34.013333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add,22567,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",504377,39.0,70.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22571,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",504394,40.333333333333336,28.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22575,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",504408,40.666666666666664,22.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::neg,22578,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",504424,40.0,15.306666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::zeros,22582,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",504443,45.0,10.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::slice_backward,22581,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",504449,42.333333333333336,12.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add,22589,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",504465,46.0,31.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::zeros,22593,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",504485,37.333333333333336,10.373333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::slice_backward,22592,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",504491,41.333333333333336,16.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add,22600,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",504507,44.666666666666664,30.066666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::cat,22603,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",504525,39.0,114.13333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mm,22617,"[[1920, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,504549,39.666666666666664,622.6933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mm,22624,"[[8192, 1920], [1920, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nn,504567,41.333333333333336,607.9466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add_,22636,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",504578,36.666666666666664,42.56
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,nccl:all_reduce,22641,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",504598,76.33333333333333,31436.693333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22645,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",504645,66.66666666666667,185.13333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22646,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",504659,43.333333333333336,188.10666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::sum,22647,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",504692,137.0,85.82666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add_,22651,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",504705,40.0,3.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::div,22654,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",504723,44.333333333333336,193.64
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::div,22655,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",504739,37.666666666666664,197.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::neg,22656,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",504755,34.666666666666664,120.13333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22657,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",504771,45.333333333333336,189.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::div,22658,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",504787,40.0,207.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::sum,22659,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",504807,42.333333333333336,90.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add,22660,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",504824,38.666666666666664,177.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22665,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",504845,40.0,3.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::div,22668,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",504863,40.0,197.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::eq,22669,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",504879,39.0,3.56
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::masked_fill_,22670,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",504884,38.0,208.02666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::mul,22673,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",504900,40.666666666666664,187.30666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22013,,aten::add,22674,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",504917,42.0,188.10666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::fill_,22684,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",504948,3094.6666666666665,9.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::zeros,22685,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",504963,1489.6666666666667,63.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,CheckpointFunctionBackward,22680,"[[2048, 4, 5120], []]",Memcpy DtoD (Device -> Device),504969,48.666666666666664,21.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,nccl:all_gather,22725,[[5242880]],"ncclKernel_AllGather_RING_LL_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)",504995,2180.0,16678.066666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::copy_,22728,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),505002,68.0,19.453333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,nccl:all_gather,22725,[[5242880]],Memcpy DtoD (Device -> Device),505006,56.666666666666664,19.293333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,nccl:all_gather,22725,[[5242880]],Memcpy DtoD (Device -> Device),505010,57.333333333333336,20.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,nccl:all_gather,22725,[[5242880]],Memcpy DtoD (Device -> Device),505014,53.666666666666664,20.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,nccl:all_gather,22725,[[5242880]],Memcpy DtoD (Device -> Device),505018,57.666666666666664,19.653333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,nccl:all_gather,22725,[[5242880]],Memcpy DtoD (Device -> Device),505022,56.333333333333336,19.973333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,nccl:all_gather,22725,[[5242880]],Memcpy DtoD (Device -> Device),505026,53.666666666666664,19.586666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,nccl:all_gather,22725,[[5242880]],Memcpy DtoD (Device -> Device),505030,57.666666666666664,19.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::_to_copy,22764,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),505098,47.666666666666664,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::norm,22770,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",505112,2009.6666666666667,92.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,22771,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",505120,41.333333333333336,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add,22772,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",505128,45.0,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::div,22773,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",505136,38.0,193.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,22774,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",505144,41.333333333333336,186.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mm,22786,"[[8192, 5120], [5120, 1920]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_tn,505156,39.0,630.8133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::_to_copy,22800,"[[2048, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),505166,144.33333333333334,21.266666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::to,22803,"[[2048, 1, 1, 128], [], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),505176,1643.6666666666667,21.386666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::neg,22816,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",505184,2267.3333333333335,14.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::cat,22828,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",505193,893.6666666666666,43.0
None,None,None,None,None,None,kernel_1,505206,100.66666666666667,20.293333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::neg,22839,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",505213,771.3333333333334,17.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::cat,22850,"[[2048, 4, 5, 128], [], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",505222,705.3333333333334,42.84
None,None,None,None,None,None,kernel_1,505235,80.66666666666667,20.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::baddbmm,22866,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,505252,2208.3333333333335,240.86666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,ScaledUpperTriangMaskedSoftmax,22869,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",505261,41.0,220.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::bmm,22886,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,505306,35.333333333333336,167.89333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::copy_,22894,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",505317,42.666666666666664,25.026666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mm,22903,"[[8192, 640], [640, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_tn,505331,42.0,247.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,nccl:all_reduce,22908,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",505349,52.0,31597.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add,22913,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",505388,40.666666666666664,188.22666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::norm,22914,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",505410,39.333333333333336,89.66666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,22915,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",505422,43.333333333333336,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add,22916,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",505434,41.333333333333336,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::div,22917,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",505446,36.0,193.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,22918,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",505458,44.666666666666664,186.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::_to_copy,22922,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),505472,51.0,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mm,22938,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8::Params),505487,3296.0,761.52
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add,22940,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",505495,39.666666666666664,93.85333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::gelu,22941,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",505503,35.0,67.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mm,22949,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,505518,176.66666666666666,927.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,nccl:all_reduce,22954,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",505539,65.66666666666667,31279.013333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add,22961,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",505578,55.0,184.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add,22963,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",505586,40.333333333333336,188.45333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::sum,22971,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",505637,136.0,86.14666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add_,22975,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",505644,40.333333333333336,3.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mm,22987,"[[5120, 8192], [8192, 2560]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,505669,145.66666666666666,758.8133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mm,22994,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8::Params),505689,38.0,763.8133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add_,23006,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",505700,41.0,51.10666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::gelu_backward,23009,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3>)",505714,46.0,99.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::sum,23012,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",505743,133.66666666666666,52.93333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add_,23016,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",505750,40.333333333333336,3.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mm,23026,"[[2560, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,505770,44.0,927.1066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mm,23033,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,505785,41.0,777.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add_,23045,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",505796,38.0,51.733333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,nccl:all_reduce,23050,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",505816,68.66666666666667,31655.226666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23054,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",505861,60.666666666666664,185.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23055,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",505873,43.333333333333336,188.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::sum,23056,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",505900,139.0,85.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add_,23060,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",505913,38.666666666666664,3.1866666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::div,23063,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",505929,45.333333333333336,193.65333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::div,23064,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",505943,39.0,197.82666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::neg,23065,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",505957,37.666666666666664,120.22666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23066,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",505971,42.666666666666664,189.54666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::div,23067,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",505985,40.666666666666664,200.89333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::sum,23068,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",506003,39.333333333333336,90.65333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add,23069,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",506018,41.333333333333336,177.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23074,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",506037,41.666666666666664,3.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::div,23077,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",506053,44.0,197.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::eq,23078,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",506067,33.666666666666664,3.3466666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::masked_fill_,23079,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",506072,43.0,208.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23082,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",506086,39.333333333333336,187.10666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add,23083,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",506101,45.0,188.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mm,23097,"[[5120, 8192], [8192, 640]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nt,506128,43.0,198.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mm,23104,"[[8192, 5120], [5120, 640]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,506149,132.33333333333334,209.85333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add_,23116,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",506163,41.0,15.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::bmm,23135,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,506190,40.666666666666664,144.86666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::bmm,23138,"[[20, 2048, 128], [20, 128, 2048]]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,506208,38.666666666666664,243.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,ScaledUpperTriangMaskedSoftmaxBackward,23156,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",506222,41.333333333333336,301.9866666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::bmm,23173,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,506243,39.0,166.61333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23175,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",506257,40.333333333333336,11.493333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::bmm,23178,"[[20, 128, 2048], [20, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x6_nt,506274,39.666666666666664,184.89333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23180,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",506288,40.0,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23204,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",506314,38.666666666666664,61.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23208,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",506328,41.666666666666664,61.266666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::neg,23211,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",506344,37.0,15.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::zero_,23217,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",506363,36.666666666666664,10.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::slice_backward,23214,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",506369,44.333333333333336,33.346666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add,23222,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",506385,39.666666666666664,70.81333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::zeros,23226,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",506405,40.333333333333336,11.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::slice_backward,23225,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",506411,29.666666666666668,33.85333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add,23233,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",506427,37.333333333333336,70.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23237,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",506444,39.333333333333336,28.093333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23241,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",506458,43.0,22.933333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::neg,23244,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",506474,42.333333333333336,15.266666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::zeros,23248,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",506493,42.0,10.026666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::slice_backward,23247,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",506499,44.666666666666664,12.026666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add,23255,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",506515,46.0,31.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::zeros,23259,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",506535,36.0,10.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::slice_backward,23258,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",506541,41.666666666666664,16.173333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add,23266,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",506557,43.333333333333336,30.026666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::cat,23269,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",506575,40.666666666666664,114.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mm,23283,"[[1920, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,506599,39.333333333333336,622.0133333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mm,23290,"[[8192, 1920], [1920, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nn,506617,40.666666666666664,607.9466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add_,23302,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",506628,40.666666666666664,42.53333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,nccl:all_reduce,23307,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",506648,73.66666666666667,31446.36
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23311,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",506695,68.33333333333333,185.17333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23312,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",506709,44.333333333333336,188.09333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::sum,23313,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",506742,135.33333333333334,86.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add_,23317,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",506755,41.0,3.2533333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::div,23320,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",506773,44.0,193.66666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::div,23321,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",506789,36.333333333333336,197.90666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::neg,23322,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",506805,36.333333333333336,120.14666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23323,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",506821,43.666666666666664,189.38666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::div,23324,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",506837,41.333333333333336,206.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::sum,23325,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",506857,39.333333333333336,90.77333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add,23326,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",506874,38.0,177.53333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23331,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",506895,38.666666666666664,3.2666666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::div,23334,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",506913,44.0,197.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::eq,23335,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",506929,39.333333333333336,3.4133333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::masked_fill_,23336,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",506934,40.333333333333336,207.97333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::mul,23339,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",506950,43.0,187.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,22679,,aten::add,23340,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",506967,43.0,188.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::zero_,23349,"[[1, 1, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",506998,3116.0,9.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::zero_,23353,[[41943040]],"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",507013,1499.0,63.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,CheckpointFunctionBackward,23346,"[[2048, 4, 5120], []]",Memcpy DtoD (Device -> Device),507019,38.0,21.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,nccl:all_gather,23391,[[5242880]],"ncclKernel_AllGather_RING_LL_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)",507045,2387.0,16847.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,nccl:all_gather,23391,[[5242880]],Memcpy DtoD (Device -> Device),507052,70.0,19.893333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,nccl:all_gather,23391,[[5242880]],Memcpy DtoD (Device -> Device),507056,53.666666666666664,19.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,nccl:all_gather,23391,[[5242880]],Memcpy DtoD (Device -> Device),507060,56.333333333333336,20.186666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,nccl:all_gather,23391,[[5242880]],Memcpy DtoD (Device -> Device),507064,56.0,19.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,nccl:all_gather,23391,[[5242880]],Memcpy DtoD (Device -> Device),507068,54.333333333333336,19.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,nccl:all_gather,23391,[[5242880]],Memcpy DtoD (Device -> Device),507072,56.666666666666664,19.626666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,nccl:all_gather,23391,[[5242880]],Memcpy DtoD (Device -> Device),507076,55.333333333333336,19.506666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,nccl:all_gather,23391,[[5242880]],Memcpy DtoD (Device -> Device),507080,57.0,19.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::_to_copy,23430,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),507148,47.666666666666664,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::norm,23436,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",507162,1983.6666666666667,92.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23437,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",507170,40.333333333333336,3.013333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add,23438,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",507178,44.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::div,23439,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",507186,38.333333333333336,193.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23440,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",507194,43.0,186.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mm,23452,"[[8192, 5120], [5120, 1920]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_tn,507206,39.0,630.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::copy_,23468,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),507216,137.33333333333334,21.426666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::_to_copy,23470,"[[2048, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),507226,1672.6666666666667,22.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::neg,23482,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",507234,2294.6666666666665,13.973333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::cat,23494,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",507243,919.0,43.06666666666667
None,None,None,None,None,None,kernel_1,507256,114.33333333333333,20.173333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::neg,23505,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",507263,773.3333333333334,17.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::cat,23516,"[[2048, 4, 5, 128], [], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",507272,725.6666666666666,42.88
None,None,None,None,None,None,kernel_1,507285,343.0,20.373333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::baddbmm,23532,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,507302,2246.0,240.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,ScaledUpperTriangMaskedSoftmax,23535,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",507311,40.666666666666664,219.94666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::bmm,23552,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,507356,40.666666666666664,168.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::copy_,23560,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",507367,39.0,25.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mm,23569,"[[8192, 640], [640, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_tn,507381,43.0,247.89333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,nccl:all_reduce,23574,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",507399,52.666666666666664,31279.266666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add,23579,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",507438,41.333333333333336,188.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::norm,23580,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",507460,40.0,90.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23581,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",507472,41.333333333333336,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add,23582,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",507484,40.333333333333336,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::div,23583,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",507496,38.0,193.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23584,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",507508,40.666666666666664,186.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::_to_copy,23588,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),507522,52.333333333333336,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mm,23604,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8::Params),507537,3310.3333333333335,761.4933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add,23606,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",507545,41.0,93.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::gelu,23607,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",507553,35.666666666666664,66.98666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mm,23615,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,507568,175.66666666666666,928.3333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,nccl:all_reduce,23620,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",507589,63.0,31517.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add,23627,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",507628,53.666666666666664,184.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add,23629,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",507636,42.666666666666664,188.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::sum,23637,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",507687,135.33333333333334,86.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add_,23641,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",507694,41.666666666666664,3.2266666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mm,23653,"[[5120, 8192], [8192, 2560]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,507719,145.33333333333334,759.2666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mm,23660,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8::Params),507739,39.0,763.7066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add_,23672,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",507750,40.0,51.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::gelu_backward,23675,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3>)",507764,44.333333333333336,99.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::sum,23678,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",507793,136.33333333333334,53.093333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add_,23682,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",507800,40.0,3.2533333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mm,23692,"[[2560, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,507820,42.666666666666664,928.2533333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mm,23699,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,507835,41.333333333333336,777.8933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add_,23711,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",507846,38.666666666666664,51.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,nccl:all_reduce,23716,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",507866,69.66666666666667,31717.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23720,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",507911,57.666666666666664,185.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23721,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",507923,44.333333333333336,188.09333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::sum,23722,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",507950,138.66666666666666,85.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add_,23726,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",507963,40.666666666666664,3.506666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::div,23729,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",507979,38.0,193.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::div,23730,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",507993,43.333333333333336,197.90666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::neg,23731,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",508007,35.333333333333336,120.17333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23732,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",508021,45.333333333333336,189.37333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::div,23733,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",508035,40.666666666666664,201.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::sum,23734,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",508053,38.333333333333336,90.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add,23735,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",508068,41.666666666666664,177.17333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23740,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",508087,37.333333333333336,3.3466666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::div,23743,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",508103,43.333333333333336,197.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::eq,23744,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",508117,34.0,3.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::masked_fill_,23745,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",508122,42.666666666666664,208.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23748,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",508136,42.666666666666664,187.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add,23749,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",508151,43.333333333333336,188.09333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mm,23763,"[[5120, 8192], [8192, 640]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nt,508178,45.0,198.89333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mm,23770,"[[8192, 5120], [5120, 640]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,508199,131.66666666666666,209.78666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add_,23782,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",508213,39.0,15.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::bmm,23801,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,508240,41.333333333333336,144.97333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::bmm,23804,"[[20, 2048, 128], [20, 128, 2048]]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,508258,40.666666666666664,244.06666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,ScaledUpperTriangMaskedSoftmaxBackward,23822,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",508272,41.666666666666664,302.17333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::bmm,23839,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,508293,42.333333333333336,166.64
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23841,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",508307,40.333333333333336,11.546666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::bmm,23844,"[[20, 128, 2048], [20, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x6_nt,508324,39.666666666666664,185.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23846,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",508338,40.333333333333336,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23870,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",508364,38.0,60.906666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23874,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",508378,39.0,61.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::neg,23877,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",508394,44.333333333333336,15.666666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::zero_,23883,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",508413,36.333333333333336,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::slice_backward,23880,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",508419,45.0,33.50666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add,23888,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",508435,42.333333333333336,71.14666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::zeros,23892,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",508455,36.333333333333336,10.986666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::slice_backward,23891,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",508461,32.666666666666664,34.013333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add,23899,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",508477,40.0,70.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23903,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",508494,39.666666666666664,28.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23907,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",508508,38.666666666666664,22.933333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::neg,23910,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",508524,39.666666666666664,15.373333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::zero_,23916,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",508543,41.666666666666664,10.026666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::slice_backward,23913,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",508549,46.0,12.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add,23921,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",508565,45.666666666666664,31.69333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::zeros,23925,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",508585,36.0,10.466666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::slice_backward,23924,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",508591,38.666666666666664,16.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add,23932,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",508607,44.666666666666664,30.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::cat,23935,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",508625,39.0,114.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mm,23949,"[[1920, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,508649,38.0,622.8133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mm,23956,"[[8192, 1920], [1920, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nn,508667,38.666666666666664,608.0266666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add_,23968,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",508678,38.666666666666664,42.74666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,nccl:all_reduce,23973,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",508698,72.66666666666667,31393.493333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23977,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",508745,64.66666666666667,185.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23978,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",508759,43.0,188.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::sum,23979,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",508792,139.0,85.89333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add_,23983,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",508805,40.0,3.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::div,23986,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",508823,42.666666666666664,193.70666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::div,23987,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",508839,36.333333333333336,197.89333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::neg,23988,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",508855,35.666666666666664,120.29333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23989,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",508871,42.0,189.17333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::div,23990,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",508887,41.666666666666664,206.69333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::sum,23991,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",508907,36.666666666666664,90.53333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add,23992,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",508924,39.666666666666664,177.38666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,23997,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",508945,39.333333333333336,3.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::div,24000,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",508963,41.0,197.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::eq,24001,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",508979,38.666666666666664,3.6133333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::masked_fill_,24002,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",508984,37.0,208.06666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::mul,24005,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",509000,40.0,187.21333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,23345,,aten::add,24006,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",509017,44.0,188.09333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::zero_,24015,"[[1, 1, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",509048,3109.3333333333335,9.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::zeros,24017,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",509063,1530.0,63.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,CheckpointFunctionBackward,24012,"[[2048, 4, 5120], []]",Memcpy DtoD (Device -> Device),509069,38.333333333333336,21.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,nccl:all_gather,24057,[[5242880]],"ncclKernel_AllGather_RING_LL_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)",509095,2123.0,16591.373333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,nccl:all_gather,24057,[[5242880]],Memcpy DtoD (Device -> Device),509102,69.33333333333333,19.56
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,nccl:all_gather,24057,[[5242880]],Memcpy DtoD (Device -> Device),509106,56.0,19.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,nccl:all_gather,24057,[[5242880]],Memcpy DtoD (Device -> Device),509110,53.0,20.14666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,nccl:all_gather,24057,[[5242880]],Memcpy DtoD (Device -> Device),509114,54.0,20.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,nccl:all_gather,24057,[[5242880]],Memcpy DtoD (Device -> Device),509118,55.0,19.786666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,nccl:all_gather,24057,[[5242880]],Memcpy DtoD (Device -> Device),509122,54.666666666666664,19.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,nccl:all_gather,24057,[[5242880]],Memcpy DtoD (Device -> Device),509126,58.0,19.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,nccl:all_gather,24057,[[5242880]],Memcpy DtoD (Device -> Device),509130,57.0,19.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::copy_,24098,"[[], [], []]",Memcpy HtoD (Pageable -> Device),509198,49.666666666666664,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::norm,24102,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",509212,1971.6666666666667,92.10666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24103,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",509220,41.333333333333336,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add,24104,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",509228,43.0,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::div,24105,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",509236,40.666666666666664,193.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24106,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",509244,40.0,186.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mm,24118,"[[8192, 5120], [5120, 1920]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_tn,509256,40.0,630.8266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::copy_,24134,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),509266,99.33333333333333,21.52
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::_to_copy,24136,"[[2048, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),509276,1659.6666666666667,21.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::neg,24148,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",509284,2300.0,14.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::cat,24160,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",509293,879.3333333333334,43.013333333333335
None,None,None,None,None,None,kernel_1,509306,102.33333333333333,20.333333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::neg,24171,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",509313,751.0,17.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::cat,24182,"[[2048, 4, 5, 128], [], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",509322,710.6666666666666,42.89333333333333
None,None,None,None,None,None,kernel_1,509335,61.0,20.30666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::baddbmm,24198,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,509352,2221.0,240.48
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,ScaledUpperTriangMaskedSoftmax,24201,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",509361,41.666666666666664,220.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::bmm,24218,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,509406,245.66666666666666,168.14666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::copy_,24226,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",509417,40.0,25.066666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mm,24235,"[[8192, 640], [640, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_tn,509431,39.0,247.54666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,nccl:all_reduce,24240,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",509449,51.666666666666664,31722.746666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add,24245,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",509488,41.333333333333336,188.14666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::norm,24246,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",509506,40.666666666666664,89.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24247,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",509516,39.666666666666664,3.026666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add,24248,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",509526,44.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::div,24249,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",509536,32.666666666666664,193.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24250,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",509546,48.0,186.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::_to_copy,24254,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),509558,51.666666666666664,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mm,24270,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8::Params),509572,3327.6666666666665,761.4933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add,24272,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",509580,38.333333333333336,93.81333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::gelu,24273,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",509588,35.0,67.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mm,24281,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,509603,157.33333333333334,928.3733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,nccl:all_reduce,24286,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",509624,51.333333333333336,31239.226666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add,24293,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",509663,53.333333333333336,184.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add,24295,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",509671,37.666666666666664,188.33333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::sum,24303,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",509722,139.0,86.05333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add_,24307,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",509729,43.0,3.2266666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mm,24319,"[[5120, 8192], [8192, 2560]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,509754,144.66666666666666,758.8133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mm,24326,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8::Params),509774,38.333333333333336,764.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add_,24338,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",509785,39.666666666666664,51.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::gelu_backward,24341,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3>)",509799,46.333333333333336,98.94666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::sum,24344,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",509828,133.0,53.21333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,torch::autograd::AccumulateGrad,24347,[[2560]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",509835,39.333333333333336,3.0533333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mm,24358,"[[2560, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,509855,46.333333333333336,926.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mm,24365,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,509870,40.333333333333336,778.2266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add_,24377,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",509881,40.0,51.973333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,nccl:all_reduce,24382,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",509901,69.33333333333333,31475.826666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24386,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",509946,56.0,185.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24387,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",509958,43.333333333333336,188.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::sum,24388,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",509985,139.66666666666666,85.86666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add_,24392,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",509998,42.333333333333336,3.2133333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::div,24395,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",510014,44.0,193.42666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::div,24396,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",510028,41.0,197.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::neg,24397,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",510042,35.0,120.22666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24398,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",510056,43.0,189.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::div,24399,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",510070,43.0,200.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::sum,24400,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",510088,36.0,90.73333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add,24401,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",510103,39.0,177.26666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24406,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",510122,41.666666666666664,3.453333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::div,24409,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",510138,40.333333333333336,196.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::eq,24410,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",510152,35.666666666666664,3.3333333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::masked_fill_,24411,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",510157,42.666666666666664,208.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24414,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",510171,39.0,187.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add,24415,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",510186,43.666666666666664,188.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mm,24429,"[[5120, 8192], [8192, 640]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nt,510213,42.333333333333336,198.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mm,24436,"[[8192, 5120], [5120, 640]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,510234,136.66666666666666,209.78666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add_,24448,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",510248,37.666666666666664,15.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::bmm,24467,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,510275,35.0,145.46666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::bmm,24470,"[[20, 2048, 128], [20, 128, 2048]]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,510293,41.0,243.82666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,ScaledUpperTriangMaskedSoftmaxBackward,24488,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",510307,41.333333333333336,302.02666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::bmm,24505,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,510328,39.333333333333336,166.56
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24507,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",510342,38.333333333333336,11.506666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::bmm,24510,"[[20, 128, 2048], [20, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x6_nt,510359,41.333333333333336,184.69333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24512,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",510373,39.666666666666664,12.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24536,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",510399,38.0,61.053333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24540,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",510413,40.333333333333336,61.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::neg,24543,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",510429,41.0,15.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::zero_,24549,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",510448,37.0,10.026666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::slice_backward,24546,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",510454,45.333333333333336,33.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add,24554,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",510470,37.333333333333336,71.13333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::zeros,24558,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",510490,41.666666666666664,11.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::slice_backward,24557,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",510496,30.0,33.946666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add,24565,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",510512,37.666666666666664,70.52
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24569,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",510529,39.333333333333336,28.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24573,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",510543,41.666666666666664,22.85333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::neg,24576,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",510559,39.0,15.373333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::zero_,24582,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",510578,41.333333333333336,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::slice_backward,24579,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",510584,43.0,12.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add,24587,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",510600,47.0,31.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::zero_,24593,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",510620,38.0,10.546666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::slice_backward,24590,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",510626,38.666666666666664,16.093333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add,24598,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",510642,44.666666666666664,30.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::cat,24601,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",510660,38.333333333333336,114.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mm,24615,"[[1920, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,510684,40.333333333333336,621.9466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mm,24622,"[[8192, 1920], [1920, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nn,510702,39.666666666666664,607.8666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add_,24634,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",510713,36.666666666666664,42.78666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,nccl:all_reduce,24639,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",510733,73.0,31420.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24643,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",510780,63.666666666666664,185.14666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24644,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",510794,42.666666666666664,188.06666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::sum,24645,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",510827,138.33333333333334,86.14666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add_,24649,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",510840,39.333333333333336,3.2533333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::div,24652,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",510858,44.666666666666664,193.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::div,24653,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",510874,36.333333333333336,197.86666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::neg,24654,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",510890,35.333333333333336,120.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24655,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",510906,43.333333333333336,189.38666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::div,24656,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",510922,41.0,206.26666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::sum,24657,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",510942,41.333333333333336,90.73333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add,24658,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",510959,37.666666666666664,177.49333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24663,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",510980,40.333333333333336,3.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::div,24666,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",510998,40.333333333333336,197.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::eq,24667,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",511014,41.0,3.52
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::masked_fill_,24668,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",511019,37.666666666666664,208.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::mul,24671,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",511035,40.0,187.13333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24011,,aten::add,24672,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",511052,44.666666666666664,188.05333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::zero_,24681,"[[1, 1, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",511083,3024.0,9.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::zeros,24683,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",511098,1455.6666666666667,63.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,CheckpointFunctionBackward,24678,"[[2048, 4, 5120], []]",Memcpy DtoD (Device -> Device),511104,49.0,21.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,nccl:all_gather,24723,[[5242880]],"ncclKernel_AllGather_RING_LL_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)",511130,2260.3333333333335,16671.893333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,nccl:all_gather,24723,[[5242880]],Memcpy DtoD (Device -> Device),511137,69.0,19.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,nccl:all_gather,24723,[[5242880]],Memcpy DtoD (Device -> Device),511141,57.333333333333336,19.066666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,nccl:all_gather,24723,[[5242880]],Memcpy DtoD (Device -> Device),511145,54.0,20.213333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,nccl:all_gather,24723,[[5242880]],Memcpy DtoD (Device -> Device),511149,53.666666666666664,20.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,nccl:all_gather,24723,[[5242880]],Memcpy DtoD (Device -> Device),511153,54.666666666666664,19.773333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,nccl:all_gather,24723,[[5242880]],Memcpy DtoD (Device -> Device),511157,53.666666666666664,19.69333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,nccl:all_gather,24723,[[5242880]],Memcpy DtoD (Device -> Device),511161,58.0,19.64
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,nccl:all_gather,24723,[[5242880]],Memcpy DtoD (Device -> Device),511165,55.333333333333336,19.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::_to_copy,24762,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),511233,50.666666666666664,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::norm,24768,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",511247,1974.0,92.02666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,24769,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",511255,40.0,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add,24770,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",511263,42.333333333333336,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::div,24771,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",511271,36.0,193.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,24772,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",511279,41.666666666666664,186.02666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mm,24784,"[[8192, 5120], [5120, 1920]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_tn,511291,38.666666666666664,630.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::_to_copy,24798,"[[2048, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),511301,138.33333333333334,21.266666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::_to_copy,24802,"[[2048, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),511311,1628.6666666666667,21.106666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::neg,24814,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",511319,2287.0,14.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::cat,24826,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",511328,992.0,43.06666666666667
None,None,None,None,None,None,kernel_1,511341,113.0,20.36
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::neg,24837,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",511348,788.0,17.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::cat,24848,"[[2048, 4, 5, 128], [], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",511357,725.6666666666666,42.85333333333333
None,None,None,None,None,None,kernel_1,511370,78.33333333333333,20.226666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::baddbmm,24864,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,511387,2225.6666666666665,240.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,ScaledUpperTriangMaskedSoftmax,24867,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",511396,42.666666666666664,219.94666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::bmm,24884,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,511441,42.333333333333336,168.81333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::copy_,24892,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",511452,36.666666666666664,25.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mm,24901,"[[8192, 640], [640, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_tn,511466,42.333333333333336,247.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,nccl:all_reduce,24906,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",511484,50.666666666666664,31232.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add,24911,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",511523,42.333333333333336,188.06666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::norm,24912,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",511545,41.0,90.09333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,24913,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",511557,39.666666666666664,3.013333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add,24914,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",511569,42.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::div,24915,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",511581,36.333333333333336,193.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,24916,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",511593,41.666666666666664,186.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::_to_copy,24920,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),511607,51.666666666666664,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mm,24936,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8::Params),511622,3265.3333333333335,761.4133333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add,24938,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",511630,39.0,93.78666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::gelu,24939,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",511638,37.0,66.97333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mm,24947,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,511653,153.33333333333334,928.56
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,nccl:all_reduce,24952,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",511674,56.333333333333336,31228.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add,24959,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",511713,53.0,184.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add,24961,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",511721,42.0,188.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::sum,24969,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",511772,138.66666666666666,86.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add_,24973,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",511779,39.0,3.2266666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mm,24985,"[[5120, 8192], [8192, 2560]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,511804,144.33333333333334,759.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mm,24992,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8::Params),511824,39.0,764.4666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add_,25004,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",511835,40.666666666666664,51.06666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::gelu_backward,25007,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3>)",511849,46.666666666666664,98.89333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::sum,25010,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",511878,133.33333333333334,52.733333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add_,25014,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",511885,41.333333333333336,3.3333333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mm,25024,"[[2560, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,511905,42.666666666666664,927.7733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mm,25031,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,511920,41.666666666666664,778.5466666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add_,25043,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",511931,39.333333333333336,51.973333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,nccl:all_reduce,25048,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",511951,67.33333333333333,31696.866666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25052,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",511996,59.333333333333336,185.13333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25053,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",512008,44.666666666666664,188.13333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::sum,25054,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",512035,136.33333333333334,85.74666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add_,25058,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",512048,40.666666666666664,3.453333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::div,25061,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",512064,41.0,193.26666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::div,25062,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",512078,42.666666666666664,197.85333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::neg,25063,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",512092,35.333333333333336,120.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25064,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",512106,42.666666666666664,189.41333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::div,25065,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",512120,43.333333333333336,200.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::sum,25066,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",512138,39.0,90.69333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add,25067,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",512153,39.0,177.26666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25072,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",512172,39.666666666666664,3.4266666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::div,25075,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",512188,40.666666666666664,196.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::eq,25076,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",512202,35.0,3.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::masked_fill_,25077,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",512207,42.333333333333336,207.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25080,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",512221,41.333333333333336,187.14666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add,25081,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",512236,44.666666666666664,188.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mm,25095,"[[5120, 8192], [8192, 640]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nt,512263,43.666666666666664,198.94666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mm,25102,"[[8192, 5120], [5120, 640]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,512284,133.33333333333334,209.49333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add_,25114,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",512298,40.666666666666664,15.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::bmm,25133,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,512325,42.333333333333336,145.33333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::bmm,25136,"[[20, 2048, 128], [20, 128, 2048]]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,512343,41.333333333333336,243.94666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,ScaledUpperTriangMaskedSoftmaxBackward,25154,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",512357,38.0,302.14666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::bmm,25171,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,512378,40.666666666666664,166.74666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25173,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",512392,39.0,11.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::bmm,25176,"[[20, 128, 2048], [20, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x6_nt,512409,33.666666666666664,185.06666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25178,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",512423,40.666666666666664,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25202,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",512449,39.0,61.026666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25206,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",512463,41.0,61.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::neg,25209,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",512479,41.0,15.746666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::zero_,25215,"[[2048, 4, 5, 128]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",512498,36.0,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::slice_backward,25212,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",512504,44.0,33.586666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add,25220,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",512520,39.333333333333336,71.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::zeros,25224,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",512540,39.666666666666664,11.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::slice_backward,25223,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",512546,30.0,33.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add,25231,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",512562,37.666666666666664,71.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25235,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",512579,40.333333333333336,28.093333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25239,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",512593,39.333333333333336,22.933333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::neg,25242,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",512609,35.333333333333336,15.386666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::zeros,25246,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",512628,41.666666666666664,10.026666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::slice_backward,25245,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",512634,44.0,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add,25253,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",512650,46.666666666666664,31.733333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::zeros,25257,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",512670,34.0,10.48
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::slice_backward,25256,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",512676,40.666666666666664,16.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add,25264,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",512692,46.333333333333336,30.026666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::cat,25267,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",512710,38.333333333333336,114.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mm,25281,"[[1920, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,512734,37.333333333333336,622.2933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mm,25288,"[[8192, 1920], [1920, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nn,512752,41.666666666666664,608.0133333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add_,25300,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",512763,40.0,42.61333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,nccl:all_reduce,25305,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",512783,74.33333333333333,31482.81333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25309,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",512830,66.66666666666667,185.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25310,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",512844,42.333333333333336,188.09333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::sum,25311,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",512877,138.0,85.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add_,25315,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",512890,39.0,3.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::div,25318,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",512908,44.333333333333336,193.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::div,25319,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",512924,35.0,197.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::neg,25320,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",512940,37.0,120.36
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25321,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",512956,39.666666666666664,189.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::div,25322,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",512972,38.0,206.64
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::sum,25323,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",512992,41.666666666666664,90.50666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add,25324,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",513009,39.0,177.38666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25329,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",513030,39.666666666666664,3.3733333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::div,25332,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",513048,43.0,197.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::eq,25333,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",513064,42.0,3.506666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::masked_fill_,25334,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",513069,39.666666666666664,208.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::mul,25337,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",513085,38.666666666666664,187.22666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,24677,,aten::add,25338,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",513102,43.0,188.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::zero_,25347,"[[1, 1, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",513133,3143.3333333333335,9.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::zeros,25349,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",513148,1492.6666666666667,63.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,CheckpointFunctionBackward,25344,"[[2048, 4, 5120], []]",Memcpy DtoD (Device -> Device),513154,208.66666666666666,21.053333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,nccl:all_gather,25389,[[5242880]],"ncclKernel_AllGather_RING_LL_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)",513180,2207.6666666666665,16672.306666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,nccl:all_gather,25389,[[5242880]],Memcpy DtoD (Device -> Device),513187,69.66666666666667,19.56
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,nccl:all_gather,25389,[[5242880]],Memcpy DtoD (Device -> Device),513191,57.666666666666664,19.253333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,nccl:all_gather,25389,[[5242880]],Memcpy DtoD (Device -> Device),513195,55.666666666666664,20.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,nccl:all_gather,25389,[[5242880]],Memcpy DtoD (Device -> Device),513199,58.0,20.026666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,nccl:all_gather,25389,[[5242880]],Memcpy DtoD (Device -> Device),513203,52.666666666666664,19.613333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,nccl:all_gather,25389,[[5242880]],Memcpy DtoD (Device -> Device),513207,58.0,19.85333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,nccl:all_gather,25389,[[5242880]],Memcpy DtoD (Device -> Device),513211,56.666666666666664,19.613333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,nccl:all_gather,25389,[[5242880]],Memcpy DtoD (Device -> Device),513215,56.666666666666664,19.746666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::_to_copy,25428,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),513283,48.0,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::norm,25434,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",513297,1977.3333333333333,92.10666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25435,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",513305,40.666666666666664,3.013333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add,25436,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",513313,42.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::div,25437,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",513321,44.333333333333336,193.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25438,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",513329,40.333333333333336,186.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mm,25450,"[[8192, 5120], [5120, 1920]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_tn,513341,229.66666666666666,630.8933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::copy_,25466,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),513351,143.66666666666666,21.586666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::_to_copy,25468,"[[2048, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),513361,1658.3333333333333,21.30666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::neg,25480,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",513369,2244.6666666666665,14.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::cat,25492,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",513378,946.6666666666666,43.026666666666664
None,None,None,None,None,None,kernel_1,513391,117.66666666666667,20.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::neg,25503,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",513398,777.6666666666666,17.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::cat,25514,"[[2048, 4, 5, 128], [], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",513407,743.6666666666666,42.88
None,None,None,None,None,None,kernel_1,513420,72.66666666666667,20.36
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::baddbmm,25530,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,513437,2237.0,240.65333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,ScaledUpperTriangMaskedSoftmax,25533,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",513446,40.666666666666664,220.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::bmm,25550,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,513491,40.333333333333336,168.09333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::copy_,25558,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",513502,42.333333333333336,25.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mm,25567,"[[8192, 640], [640, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_tn,513516,40.0,247.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,nccl:all_reduce,25572,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",513534,52.666666666666664,31354.013333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add,25577,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",513573,41.333333333333336,188.34666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::norm,25578,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",513595,39.333333333333336,89.90666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25579,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",513607,38.0,3.013333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add,25580,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",513619,42.666666666666664,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::div,25581,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",513631,35.666666666666664,193.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25582,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",513643,48.333333333333336,186.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::_to_copy,25586,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),513657,49.666666666666664,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mm,25602,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_tn_align8::Params),513672,3268.3333333333335,761.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add,25604,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",513680,37.666666666666664,93.85333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::gelu,25605,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",513688,36.333333333333336,66.98666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mm,25613,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,513703,151.33333333333334,928.1466666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,nccl:all_reduce,25618,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",513724,53.0,31232.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add,25625,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",513763,52.0,184.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add,25627,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",513771,41.0,188.37333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::sum,25635,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",513822,140.33333333333334,86.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add_,25639,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",513829,42.333333333333336,3.1733333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mm,25651,"[[5120, 8192], [8192, 2560]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,513854,145.66666666666666,759.2266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mm,25658,"[[8192, 5120], [5120, 2560]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8::Params),513874,39.666666666666664,763.6266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add_,25670,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",513885,41.333333333333336,51.013333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::gelu_backward,25673,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half, c10::Half)#1}, at::detail::Array<char*, 3>)",513899,43.666666666666664,98.98666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::sum,25676,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",513928,132.66666666666666,52.973333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add_,25680,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",513935,41.666666666666664,3.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mm,25690,"[[2560, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,513955,43.333333333333336,927.8133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mm,25697,"[[8192, 2560], [2560, 5120]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,513970,43.333333333333336,778.4666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add_,25709,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",513981,41.0,51.89333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,nccl:all_reduce,25714,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",514001,67.0,31505.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25718,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",514046,59.333333333333336,185.10666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25719,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",514058,46.0,188.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::sum,25720,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",514085,135.0,86.14666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add_,25724,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",514098,41.0,3.2933333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::div,25727,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",514114,43.666666666666664,193.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::div,25728,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",514128,38.666666666666664,197.78666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::neg,25729,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",514142,36.0,120.22666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25730,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",514156,43.333333333333336,189.66666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::div,25731,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",514170,41.0,200.94666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::sum,25732,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",514188,37.0,90.54666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add,25733,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",514203,41.666666666666664,177.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25738,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",514222,42.333333333333336,3.3866666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::div,25741,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",514238,39.666666666666664,196.97333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::eq,25742,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",514252,36.666666666666664,3.2666666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::masked_fill_,25743,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",514257,44.0,207.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25746,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",514271,41.0,187.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add,25747,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",514286,43.0,188.10666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mm,25761,"[[5120, 8192], [8192, 640]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nt,514313,43.666666666666664,198.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mm,25768,"[[8192, 5120], [5120, 640]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,514334,133.33333333333334,209.82666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add_,25780,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",514348,37.666666666666664,15.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::bmm,25799,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,514375,42.333333333333336,144.70666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::bmm,25802,"[[20, 2048, 128], [20, 128, 2048]]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,514393,38.666666666666664,244.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,ScaledUpperTriangMaskedSoftmaxBackward,25820,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",514407,39.666666666666664,302.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::bmm,25837,"[[20, 2048, 2048], [20, 2048, 128]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,514428,41.666666666666664,166.38666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25839,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",514442,39.333333333333336,11.746666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::bmm,25842,"[[20, 128, 2048], [20, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x6_nt,514459,33.333333333333336,184.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25844,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",514473,40.666666666666664,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25868,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",514499,40.333333333333336,60.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25872,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",514513,40.666666666666664,61.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::neg,25875,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",514529,39.666666666666664,15.773333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::zeros,25879,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",514548,38.0,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::slice_backward,25878,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",514554,44.0,33.653333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add,25886,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",514570,37.333333333333336,71.46666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::zeros,25890,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",514590,39.333333333333336,10.986666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::slice_backward,25889,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",514596,30.666666666666668,33.973333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add,25897,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",514612,40.333333333333336,71.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25901,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",514629,38.333333333333336,28.066666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25905,"[[], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",514643,39.333333333333336,22.946666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::neg,25908,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",514659,38.333333333333336,15.333333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::zeros,25912,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",514678,43.666666666666664,10.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::slice_backward,25911,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",514684,43.0,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add,25919,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",514700,45.0,31.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::zeros,25923,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",514720,38.333333333333336,10.466666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::slice_backward,25922,"[[2048, 4, 5, 64], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",514726,39.666666666666664,16.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add,25930,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",514742,43.666666666666664,30.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::cat,25933,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",514760,38.666666666666664,114.38666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mm,25947,"[[1920, 8192], [8192, 5120]]",sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x128x32_stage3_warpsize4x2x1_tensor16x8x16_kernel,514784,37.666666666666664,622.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mm,25954,"[[8192, 1920], [1920, 5120]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nn,514802,40.666666666666664,607.9466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add_,25966,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",514813,38.666666666666664,42.666666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,nccl:all_reduce,25971,"[[2048, 4, 5120]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",514833,76.66666666666667,31544.586666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25975,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",514880,64.33333333333333,185.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25976,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",514894,43.0,187.85333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::sum,25977,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",514927,139.66666666666666,85.98666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add_,25981,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",514940,37.666666666666664,3.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::div,25984,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",514958,43.333333333333336,193.77333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::div,25985,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",514974,37.666666666666664,197.86666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::neg,25986,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",514990,34.666666666666664,120.26666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25987,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",515006,41.666666666666664,189.38666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::div,25988,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",515022,40.0,206.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::sum,25989,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",515042,39.333333333333336,90.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add,25990,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",515059,39.666666666666664,177.52
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,25995,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",515080,40.333333333333336,3.3866666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::div,25998,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",515098,41.666666666666664,197.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::eq,25999,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, at::detail::Array<char*, 2>)",515114,38.666666666666664,3.533333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::masked_fill_,26000,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#22}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",515119,37.0,208.05333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::mul,26003,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",515135,43.333333333333336,187.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,25343,,aten::add,26004,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",515152,44.333333333333336,188.04
