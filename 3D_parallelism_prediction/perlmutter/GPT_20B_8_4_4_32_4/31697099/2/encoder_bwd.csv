cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
aten::zeros,3192,"[[], [], [], [], []]",aten::fill_,3195,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",137990,0,8.546666666666667
aten::to,3201,"[[], [], [], [], [], []]",aten::copy_,3204,"[[], [], []]",Memcpy HtoD (Pageable -> Device),138024,3363.0,1.0
aten::layer_norm,3208,"[[2048, 4, 6144], [], [6144], [6144], [], []]",aten::native_layer_norm,3209,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",138046,1722.0,166.08
aten::layer_norm,3215,"[[2048, 4, 6144], [], [6144], [6144], [], []]",aten::native_layer_norm,3216,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",138068,41.333333333333336,169.33333333333334
aten::linear,3225,"[[2048, 4, 6144], [4608, 6144], [4608]]",aten::addmm,3230,"[[4608], [8192, 6144], [6144, 4608], [], []]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_relu_f2f_stages_64x3_tn,138087,372.6666666666667,1777.6533333333334
aten::to,3252,"[[2048, 1, 1, 24], [], [], [], [], [], [], []]",aten::copy_,3255,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),138105,126.66666666666667,5.026666666666666
aten::to,3256,"[[2048, 1, 1, 24], [], [], [], [], [], [], []]",aten::copy_,3259,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),138115,959.3333333333334,5.0
apply_rotary_pos_emb,3260,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]",aten::neg,3269,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",138123,2097.6666666666665,14.013333333333334
apply_rotary_pos_emb,3260,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]",aten::cat,3281,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",138132,842.6666666666666,28.48
None,None,None,None,None,None,kernel_1,138145,291.0,12.0
apply_rotary_pos_emb,3260,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]",aten::neg,3292,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",138152,906.3333333333334,15.96
apply_rotary_pos_emb,3260,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]",aten::cat,3303,"[[2048, 4, 16, 24], [], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",138161,659.0,28.106666666666666
None,None,None,None,None,None,kernel_1,138174,205.33333333333334,12.0
aten::cat,3310,"[[], []]",aten::cat,3310,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",138182,815.3333333333334,102.88
aten::cat,3311,"[[], []]",aten::cat,3311,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",138191,40.0,103.72
aten::baddbmm,3321,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",aten::baddbmm,3321,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,138209,40.666666666666664,641.36
ScaledUpperTriangMaskedSoftmax,3324,"[[64, 2048, 2048]]",ScaledUpperTriangMaskedSoftmax,3324,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",138218,42.333333333333336,602.36
aten::bmm,3341,"[[64, 2048, 2048], [64, 2048, 96]]",aten::bmm,3341,"[[64, 2048, 2048], [64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,138264,38.0,404.36
aten::contiguous,3345,"[[2048, 4, 16, 96], []]",aten::copy_,3349,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",138275,44.0,60.93333333333333
aten::linear,3351,"[[2048, 4, 1536], [6144, 1536], []]",aten::mm,3358,"[[8192, 1536], [1536, 6144]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn,138292,157.0,633.9733333333334
aten::add,3363,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,3363,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",138303,40.333333333333336,215.18666666666667
aten::linear,3368,"[[2048, 4, 6144], [6144, 6144], []]",aten::mm,3375,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),138316,44.333333333333336,2289.1066666666666
None,None,None,None,None,None,kernel_2,138329,41.333333333333336,160.26666666666668
aten::linear,3383,"[[2048, 4, 6144], [6144, 6144], []]",aten::mm,3390,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),138341,41.333333333333336,2288.786666666667
aten::add,3395,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,3395,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",138349,42.666666666666664,212.48
aten::add,3397,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,3397,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",138357,42.333333333333336,173.37333333333333
_ReduceFromModelParallelRegion,3398,"[[2048, 4, 6144]]",nccl:all_reduce,3401,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",138375,54.666666666666664,753.6933333333334
aten::add,3405,"[[2048, 4, 6144], [2048, 4, 6144], []]",aten::add,3405,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",138414,60.0,173.54666666666665
autograd::engine::evaluate_function: ExpandBackward0,3415,,aten::sum,3417,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",138469,137.33333333333334,86.17333333333333
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,3419,,aten::add_,3421,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",138476,40.666666666666664,3.1066666666666665
autograd::engine::evaluate_function: UnsafeViewBackward0,3422,,aten::copy_,3428,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",138492,46.0,219.18666666666667
autograd::engine::evaluate_function: MmBackward0,3430,,aten::mm,3435,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,138514,158.0,2253.866666666667
autograd::engine::evaluate_function: MmBackward0,3430,,aten::mm,3442,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),138534,38.666666666666664,2261.0666666666666
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,3452,,aten::add_,3454,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",138545,44.333333333333336,119.04
None,None,None,None,None,None,kernel_3,138564,47.666666666666664,214.2
autograd::engine::evaluate_function: GeLUFunctionBackward,3455,,aten::sum,3462,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",138590,135.66666666666666,83.61333333333333
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,3464,,aten::add_,3466,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",138597,42.0,3.12
autograd::engine::evaluate_function: MmBackward0,3471,,aten::mm,3476,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,138620,156.66666666666666,2244.52
autograd::engine::evaluate_function: MmBackward0,3471,,aten::mm,3483,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),138640,40.333333333333336,2233.24
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,3493,,aten::add_,3495,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",138651,45.0,119.16
autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward,3496,,nccl:all_reduce,3500,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",138671,67.66666666666667,759.3733333333333
autograd::engine::evaluate_function: ExpandBackward0,3504,,aten::sum,3506,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",138733,144.66666666666666,80.30666666666667
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,3508,,aten::add_,3510,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",138740,42.333333333333336,3.066666666666667
autograd::engine::evaluate_function: UnsafeViewBackward0,3511,,aten::copy_,3517,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",138756,51.333333333333336,219.12
autograd::engine::evaluate_function: MmBackward0,3519,,aten::mm,3524,"[[6144, 8192], [8192, 1536]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,138778,143.33333333333334,564.44
autograd::engine::evaluate_function: MmBackward0,3519,,aten::mm,3531,"[[8192, 6144], [6144, 1536]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,138796,41.333333333333336,599.2133333333334
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,3541,,aten::add_,3543,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",138807,39.333333333333336,27.653333333333332
autograd::engine::evaluate_function: BmmBackward0,3558,,aten::bmm,3562,"[[64, 2048, 2048], [64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,138833,36.666666666666664,372.6
autograd::engine::evaluate_function: BmmBackward0,3558,,aten::bmm,3565,"[[64, 2048, 96], [64, 96, 2048]]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,138849,44.666666666666664,652.4933333333333
autograd::engine::evaluate_function: ScaledUpperTriangMaskedSoftmaxBackward,3582,,ScaledUpperTriangMaskedSoftmaxBackward,3583,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",138863,41.666666666666664,852.3866666666667
autograd::engine::evaluate_function: BaddbmmBackward0,4620,,aten::bmm,4624,"[[64, 2048, 2048], [64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,138883,41.0,396.88
autograd::engine::evaluate_function: BaddbmmBackward0,4620,,aten::mul,4626,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",138895,41.666666666666664,26.013333333333332
autograd::engine::evaluate_function: BaddbmmBackward0,4620,,aten::bmm,4629,"[[64, 96, 2048], [64, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,138910,42.0,372.52
autograd::engine::evaluate_function: BaddbmmBackward0,4620,,aten::mul,4631,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",138922,42.666666666666664,28.386666666666667
autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward,4668,,aten::mul,4671,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",138950,41.0,19.573333333333334
autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward,4668,,aten::mul,4675,"[[], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",138962,42.333333333333336,17.733333333333334
autograd::engine::evaluate_function: NegBackward0,4676,,aten::neg,4678,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",138976,39.333333333333336,9.186666666666667
autograd::engine::evaluate_function: SliceBackward0,4679,,aten::fill_,4685,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",138993,41.666666666666664,7.0
autograd::engine::evaluate_function: SliceBackward0,4679,,aten::copy_,4688,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",138999,43.0,22.72
autograd::engine::evaluate_function: SliceBackward0,4679,,aten::add,4689,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",139013,37.666666666666664,41.12
autograd::engine::evaluate_function: SliceBackward0,4690,,aten::fill_,4696,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",139031,41.666666666666664,7.0
autograd::engine::evaluate_function: SliceBackward0,4690,,aten::copy_,4699,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",139037,40.333333333333336,23.493333333333332
autograd::engine::evaluate_function: SliceBackward0,4690,,aten::add,4700,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",139051,39.666666666666664,40.693333333333335
autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward,4701,,aten::mul,4704,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",139066,43.333333333333336,20.573333333333334
autograd::engine::evaluate_function: torch::jit::(anonymous namespace)::DifferentiableGraphBackward,4701,,aten::mul,4708,"[[], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",139078,44.0,18.093333333333334
autograd::engine::evaluate_function: NegBackward0,4709,,aten::neg,4711,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",139092,42.0,11.2
autograd::engine::evaluate_function: SliceBackward0,4712,,aten::fill_,4718,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",139109,42.333333333333336,7.013333333333334
autograd::engine::evaluate_function: SliceBackward0,4712,,aten::copy_,4721,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",139115,45.333333333333336,10.0
autograd::engine::evaluate_function: SliceBackward0,4712,,aten::add,4722,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",139129,37.666666666666664,18.69333333333333
autograd::engine::evaluate_function: SliceBackward0,4723,,aten::fill_,4729,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",139147,37.0,7.0
autograd::engine::evaluate_function: SliceBackward0,4723,,aten::copy_,4732,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",139153,43.0,12.506666666666666
autograd::engine::evaluate_function: SliceBackward0,4723,,aten::add,4733,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",139167,38.0,16.866666666666667
autograd::engine::evaluate_function: SliceBackward0,4734,,aten::fill_,4740,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",139185,40.666666666666664,20.413333333333334
autograd::engine::evaluate_function: SliceBackward0,4734,,aten::copy_,4743,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",139191,42.333333333333336,107.54666666666667
autograd::engine::evaluate_function: SliceBackward0,4744,,aten::fill_,4750,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",139209,42.0,22.493333333333332
autograd::engine::evaluate_function: SliceBackward0,4744,,aten::copy_,4753,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",139215,42.333333333333336,40.13333333333333
autograd::engine::evaluate_function: SliceBackward0,4744,,aten::add,4754,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",139229,41.666666666666664,44.13333333333333
autograd::engine::evaluate_function: SliceBackward0,4755,,aten::fill_,4761,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",139247,42.0,21.0
autograd::engine::evaluate_function: SliceBackward0,4755,,aten::copy_,4764,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",139253,39.333333333333336,55.78666666666667
autograd::engine::evaluate_function: SliceBackward0,4765,,aten::fill_,4771,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",139271,42.333333333333336,22.92
autograd::engine::evaluate_function: SliceBackward0,4765,,aten::copy_,4774,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",139277,39.0,23.293333333333333
autograd::engine::evaluate_function: SliceBackward0,4765,,aten::add,4775,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",139291,42.666666666666664,44.2
autograd::engine::evaluate_function: SplitBackward0,4776,,aten::cat,4778,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",139307,42.666666666666664,249.6
autograd::engine::evaluate_function: AddmmBackward0,4787,,aten::mm,4792,"[[8192, 4608], [4608, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),139330,45.333333333333336,1694.8666666666666
autograd::engine::evaluate_function: AddmmBackward0,4787,,aten::mm,4796,"[[4608, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,139349,137.66666666666666,1648.7733333333333
autograd::engine::evaluate_function: AddmmBackward0,4787,,aten::sum,4800,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",139379,137.33333333333334,62.973333333333336
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,4802,,aten::add_,4804,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",139386,42.333333333333336,3.026666666666667
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,4814,,aten::add_,4816,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",139397,47.666666666666664,86.17333333333333
autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward,4817,,nccl:all_reduce,4821,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",139417,90.33333333333333,754.48
autograd::engine::evaluate_function: NativeLayerNormBackward0,4823,,aten::native_layer_norm_backward,4825,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",139484,64.33333333333333,361.38666666666666
autograd::engine::evaluate_function: NativeLayerNormBackward0,4823,,aten::native_layer_norm_backward,4825,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",139486,40.0,207.61333333333334
autograd::engine::evaluate_function: NativeLayerNormBackward0,4823,,aten::add,4829,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",139507,39.666666666666664,251.05333333333334
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,4830,,aten::add_,4832,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",139515,42.666666666666664,3.2133333333333334
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,4833,,aten::add_,4835,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",139522,44.666666666666664,3.0
autograd::engine::evaluate_function: NativeLayerNormBackward0,4836,,aten::native_layer_norm_backward,4838,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",139564,45.0,356.7733333333333
autograd::engine::evaluate_function: NativeLayerNormBackward0,4836,,aten::native_layer_norm_backward,4838,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",139566,41.333333333333336,202.98666666666668
autograd::engine::evaluate_function: NativeLayerNormBackward0,4836,,aten::add,4842,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",139589,40.0,251.04
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,4843,,aten::copy_,4847,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",139610,39.333333333333336,222.37333333333333
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,4848,,aten::add_,4850,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",139618,42.666666666666664,3.1066666666666665
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,4851,,aten::add_,4853,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",139625,47.666666666666664,3.0
