[2024-10-10 07:25:56,682] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
NeoXArgs.from_ymls() ['/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/configs/GPT_20B_8_4_4.yml', '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/configs/local_setup.yml']
INFO:root:NeoXArgs.calculate_derived() Total number of GPUs determined to be: 128
-------------------- arguments --------------------
  attention_config ................ ['global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global']updated
  batch_size ...................... 4...........................updated
  bias_gelu_fusion ................ True........................updated
  checkpoint_activations .......... True........................updated
  checkpoint_factor ............... 500.........................updated
  config_files .................... {'GPT_20B_8_4_4.yml': '# DISCLAIMER: This is the configuration file for the GPT-NeoX-20B model as it was trained on 96x 40GB A100\n# GPUs. Depending on your system configuration, you may need to change some parameters in order to fit\n# the model in memory.\n\n{\n  # Tokenizer /  checkpoint settings - you will need to change these to the location you have them saved in\n  # "vocab_file": "./20B_checkpoints/20B_tokenizer.json",\n  # "save": "./20B_checkpoints",\n  # "load": "./20B_checkpoints",\n\n  # If finetuning, edit the following to the location of your finetuning dataset:\n  # "data_path": "./data/pile_20B_tokenizer/pile_20B_tokenizer_text_document",\n\n  # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\n  # across the node boundaries )\n  "pipe_parallel_size": 8,\n  "model_parallel_size": 4,\n\n  # model settings\n  "num_layers": 44,\n  "hidden_size": 6144,\n  "num_attention_heads": 64,\n  "seq_length": 2048,\n  "max_position_embeddings": 2048,\n  "norm": "layernorm",\n  "pos_emb": "rotary",\n  "rotary_pct": 0.25,\n  "no_weight_tying": true,\n  "gpt_j_residual": true,\n  "output_layer_parallelism": "column",\n  "scaled_upper_triang_masked_softmax_fusion": true,\n  "bias_gelu_fusion": true,\n  "rope_fusion": false,\n  "layernorm_fusion": false,\n\n  # init methods\n  "init_method": "small_init",\n  "output_layer_init_method": "wang_init",\n\n  # optimizer settings\n  "optimizer": {\n    "type": "Adam",\n    "params": {\n      "lr": 0.97e-4,\n      "betas": [0.9, 0.95],\n      "eps": 1.0e-8,\n      }\n      },\n\n  "min_lr": 0.97e-5,\n\n  # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training\n  "zero_optimization": {\n  "stage": 1,\n  "allgather_partitions": True,\n  "allgather_bucket_size": 1260000000,\n  "overlap_comm": True,\n  "reduce_scatter": True,\n  "reduce_bucket_size": 1260000000,\n  "contiguous_gradients": True,\n  },\n\n  # batch / data settings (assuming 96 GPUs)\n  "train_micro_batch_size_per_gpu": 4,\n  "gradient_accumulation_steps": 16,\n  "data_impl": "mmap",\n  "split": "995,4,1",\n\n  # activation checkpointing\n  "checkpoint_activations": true,\n  "checkpoint_num_layers": 1,\n  "partition_activations": false,\n  "synchronize_each_layer": true,\n\n  # regularization\n  "gradient_clipping": 1.0,\n  "weight_decay": 0.01,\n  "hidden_dropout": 0,\n  "attention_dropout": 0,\n\n  # precision settings\n  "fp16": {\n    "fp16": true,\n    "enabled": true,\n    "loss_scale": 0,\n    "loss_scale_window": 1000,\n    "initial_scale_power": 12,\n    "hysteresis": 2,\n    "min_loss_scale": 1\n    },\n\n  # misc. training settings\n  "train_iters": 1000,\n  "lr_decay_iters": 1000,\n\n  "distributed_backend": "nccl",\n  "lr_decay_style": "cosine",\n  "warmup": 0.01,\n  "checkpoint_factor": 500, # this variable previously called `save-interval`\n  "eval_interval": 1000,\n  "eval_iters": 10,\n\n  # logging\n  "log_interval": 1,\n  "steps_per_print": 1,\n  "wall_clock_breakdown": true,\n\n  ### NEW DATA: ####\n  # "tokenizer_type": "HFTokenizer",\n  # "tensorboard-dir": "./tensorboard",\n  # "log_dir": "./logs",\n\n  # distributed training settings\n  # "launcher": "slurm",\n  # "deepspeed_slurm": true,\n\n  # profiling settings\n  "profile": True,\n  "profile_step_start": 2,\n  "profile_step_stop": 7,\n}', 'local_setup.yml': '# Suggested data paths when using GPT-NeoX locally\n{\n  # "data_path": "/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/data/pile_text_document",\n  # "data_path": "/pscratch/sd/z/zhaozh/data/pile/processed/pile_text_document",\n\n  "data-path": "/pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document",\n\n  # or for weighted datasets:\n  # "train-data-paths": ["data/enwik8/enwik8_text_document", "data/enwik8/enwik8_text_document"],\n  # "test-data-paths": ["data/enwik8/enwik8_text_document", "data/enwik8/enwik8_text_document"],\n  # "valid-data-paths": ["data/enwik8/enwik8_text_document", "data/enwik8/enwik8_text_document"],\n  # "train-data-weights": [1., 2.],\n  # "test-data-weights": [2., 1.],\n  # "valid-data-weights": [0.5, 0.4],\n\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\n  # WARNING: setting this to True will override any user provided weights\n  # "weight_by_num_documents": false,\n  # "weighted_sampler_alpha": 0.3,\n\n  "vocab_file": "/pscratch/sd/z/zhaozh/data/pile/gpt2-vocab.json",\n  "merge_file": "/pscratch/sd/z/zhaozh/data/pile/gpt2-merges.txt",\n\n  "save": "checkpoints-test",\n  "load": "checkpoints-test2",\n  "checkpoint_validation_with_forward_pass": False,\n\n  "tensorboard_dir": "tensorboard",\n  "log_dir": "logs",\n  "use_wandb": True,\n  "wandb_host": "https://api.wandb.ai",\n  "wandb_project": "neox"\n}\n'}updated
  data_impl ....................... mmap........................updated
  data_path ....................... /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_documentupdated
  dynamic_loss_scale .............. True........................updated
  eval_iters ...................... 10..........................updated
  fp16 ............................ {'fp16': True, 'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 12, 'hysteresis': 2, 'min_loss_scale': 1}updated
  global_num_gpus ................. 128.........................updated
  gpt_j_residual .................. True........................updated
  gradient_accumulation_steps ..... 16..........................updated
  hidden_size ..................... 6144........................updated
  init_method ..................... small_init..................updated
  is_pipe_parallel ................ True........................updated
  load ............................ checkpoints-test2...........updated
  log_dir ......................... logs........................updated
  log_interval .................... 1...........................updated
  lr .............................. 9.7e-05.....................updated
  lr_decay_iters .................. 1000........................updated
  lr_decay_style .................. cosine......................updated
  max_position_embeddings ......... 2048........................updated
  merge_file ...................... /pscratch/sd/z/zhaozh/data/pile/gpt2-merges.txtupdated
  min_lr .......................... 9.7e-06.....................updated
  model_parallel_size ............. 4...........................updated
  no_weight_tying ................. True........................updated
  num_attention_heads ............. 64..........................updated
  num_layers ...................... 44..........................updated
  optimizer ....................... {'type': 'Adam', 'params': {'lr': 9.7e-05, 'betas': [0.9, 0.95], 'eps': 1e-08}}updated
  optimizer_type .................. Adam........................updated
  output_layer_init_method ........ wang_init...................updated
  pipe_parallel_size .............. 8...........................updated
  pos_emb ......................... rotary......................updated
  precision ....................... fp16........................updated
  profile ......................... True........................updated
  profile_step_start .............. 2...........................updated
  profile_step_stop ............... 7...........................updated
  rotary_pct ...................... 0.25........................updated
  save ............................ checkpoints-test............updated
  save_iters ...................... [500].......................updated
  scaled_upper_triang_masked_softmax_fusion  True...............updated
  seq_length ...................... 2048........................updated
  sparsity_config ................. {}..........................updated
  split ........................... 995,4,1.....................updated
  steps_per_print ................. 1...........................updated
  synchronize_each_layer .......... True........................updated
  tensorboard_dir ................. tensorboard.................updated
  text_gen_type ................... unconditional...............updated
  train_batch_size ................ 256.........................updated
  train_iters ..................... 1000........................updated
  train_micro_batch_size_per_gpu .. 4...........................updated
  use_wandb ....................... True........................updated
  user_script ..................... /pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/train_profiling.pyupdated
  vocab_file ...................... /pscratch/sd/z/zhaozh/data/pile/gpt2-vocab.jsonupdated
  wall_clock_breakdown ............ True........................updated
  wandb_group ..................... l93r147r_pgfmeqc0...........updated
  weight_decay .................... 0.01........................updated
  zero_allgather_bucket_size ...... 1260000000..................updated
  zero_contiguous_gradients ....... True........................updated
  zero_optimization ............... {'stage': 1, 'allgather_partitions': True, 'allgather_bucket_size': 1260000000, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 1260000000, 'contiguous_gradients': True}updated
  zero_reduce_bucket_size ......... 1260000000..................updated
  zero_reduce_scatter ............. True........................updated
  zero_stage ...................... 1...........................updated
  account ......................... None........................default
  activation ...................... gelu........................default
  activation_checkpointing ........ None........................default
  adlr_autoresume ................. False.......................default
  adlr_autoresume_interval ........ 1000........................default
  allow_chopped ................... True........................default
  amp ............................. None........................default
  apply_query_key_layer_scaling ... False.......................default
  attention_dropout ............... 0...........................default
  attention_softmax_in_fp32 ....... False.......................default
  autotuning ...................... None........................default
  autotuning_run .................. None........................default
  base_shapes_file ................ None........................default
  bf16 ............................ None........................default
  bias_dropout_fusion ............. False.......................default
  char_level_ppl .................. False.......................default
  checkpoint ...................... None........................default
  checkpoint_in_cpu ............... False.......................default
  checkpoint_num_layers ........... 1...........................default
  checkpoint_scale ................ linear......................default
  checkpoint_validation_with_forward_pass  False................default
  clip_grad ....................... 1.0.........................default
  comet_experiment_name ........... None........................default
  comet_others .................... None........................default
  comet_project ................... None........................default
  comet_tags ...................... None........................default
  comet_workspace ................. None........................default
  comment ......................... None........................default
  comms_logger .................... None........................default
  communication_data_type ......... None........................default
  compression_training ............ None........................default
  contiguous_checkpointing ........ False.......................default
  coord_check ..................... False.......................default
  create_moe_param_group .......... True........................default
  csv_monitor ..................... None........................default
  curriculum_learning ............. None........................default
  curriculum_seqlen ............... 0...........................default
  data_efficiency ................. None........................default
  data_types ...................... None........................default
  dataset_impl .................... gpt2........................default
  deepscale ....................... False.......................default
  deepscale_config ................ None........................default
  deepspeed ....................... True........................default
  deepspeed_activation_checkpointing  True......................default
  deepspeed_extra_args ............ None........................default
  deepspeed_mpi ................... False.......................default
  deepspeed_slurm ................. False.......................default
  detect_nvlink_pairs ............. False.......................default
  distributed_backend ............. nccl........................default
  do_test ......................... None........................default
  do_train ........................ None........................default
  do_valid ........................ None........................default
  dpo_beta ........................ 0.1.........................default
  dpo_fp32 ........................ True........................default
  dpo_reference_free .............. False.......................default
  dump_state ...................... False.......................default
  elasticity ...................... None........................default
  enable_expert_tensor_parallelism  False.......................default
  eod_mask_loss ................... False.......................default
  eval_interval ................... 1000........................default
  eval_results_prefix ............. ............................default
  eval_tasks ...................... None........................default
  exclude ......................... None........................default
  exit_interval ................... None........................default
  expansion_factor ................ None........................default
  expert_interval ................. 2...........................default
  extra_save_iters ................ None........................default
  finetune ........................ False.......................default
  flops_profiler .................. None........................default
  force_multi ..................... False.......................default
  fp16_lm_cross_entropy ........... False.......................default
  fp32_allreduce .................. False.......................default
  git_hash ........................ d79c5331....................default
  gmlp_attn_dim ................... 64..........................default
  gpt_j_tied ...................... False.......................default
  gradient_clipping ............... 1.0.........................default
  gradient_noise_scale_cpu_offload  False.......................default
  gradient_noise_scale_n_batches .. 5...........................default
  gradient_predivide_factor ....... 1.0.........................default
  hidden_dropout .................. 0...........................default
  hostfile ........................ None........................default
  hysteresis ...................... 2...........................default
  include ......................... None........................default
  init_method_std ................. 0.02........................default
  intermediate_size ............... None........................default
  iteration ....................... None........................default
  keep_last_n_checkpoints ......... None........................default
  kto_beta ........................ 0.1.........................default
  kto_desirable_weight ............ 1.0.........................default
  kto_fp32 ........................ True........................default
  kto_undesirable_weight .......... 1.0.........................default
  launcher ........................ pdsh........................default
  layernorm_epsilon ............... 1e-05.......................default
  layernorm_fusion ................ False.......................default
  lazy_mpu_init ................... False.......................default
  local_rank ...................... None........................default
  log_grad_norm ................... False.......................default
  log_grad_pct_zeros .............. False.......................default
  log_gradient_noise_scale ........ False.......................default
  log_optimizer_states ............ False.......................default
  log_param_norm .................. False.......................default
  loss_scale ...................... None........................default
  loss_scale_window ............... 1000.0......................default
  make_vocab_size_divisible_by .... 128.........................default
  mamba_causal_conv_fusion ........ False.......................default
  mamba_inner_func_fusion ......... False.......................default
  mamba_selective_fp32_params ..... True........................default
  mamba_selective_scan_fusion ..... False.......................default
  mamba_use_bias_in_conv .......... True........................default
  mamba_use_bias_in_linears ....... False.......................default
  master_addr ..................... None........................default
  master_port ..................... 29500.......................default
  maximum_tokens .................. 64..........................default
  memory_profiling ................ False.......................default
  memory_profiling_path ........... None........................default
  min_scale ....................... 1.0.........................default
  mlp_multiple_of ................. 1...........................default
  mmap_warmup ..................... False.......................default
  moe_eval_capacity_factor ........ 1.0.........................default
  moe_expert_parallel_size ........ 1...........................default
  moe_glu ......................... False.......................default
  moe_jitter_eps .................. None........................default
  moe_lbl_in_fp32 ................. False.......................default
  moe_loss_coeff .................. 0.1.........................default
  moe_min_capacity ................ 4...........................default
  moe_num_experts ................. 1...........................default
  moe_token_dropping .............. False.......................default
  moe_top_k ....................... 1...........................default
  moe_train_capacity_factor ....... 1.0.........................default
  moe_type ........................ megablocks..................default
  moe_use_residual ................ True........................default
  mup_attn_temp ................... 1.0.........................default
  mup_embedding_mult .............. 1.0.........................default
  mup_init_scale .................. 1.0.........................default
  mup_output_temp ................. 1.0.........................default
  mup_rp_embedding_mult ........... 1.0.........................default
  mup_width_scale ................. 2...........................default
  neg_test_data_paths ............. None........................default
  neg_test_label_data_paths ....... None........................default
  neg_train_data_paths ............ None........................default
  neg_train_label_data_paths ...... None........................default
  neg_valid_data_paths ............ None........................default
  neg_valid_label_data_paths ...... None........................default
  no_load_optim ................... False.......................default
  no_load_rng ..................... False.......................default
  no_save_optim ................... False.......................default
  no_save_rng ..................... False.......................default
  no_ssh_check .................... False.......................default
  norm ............................ layernorm...................default
  num_gpus ........................ None........................default
  num_kv_heads .................... None........................default
  num_nodes ....................... -1..........................default
  num_samples ..................... 1...........................default
  num_unique_layers ............... None........................default
  num_workers ..................... 2...........................default
  onnx_safe ....................... False.......................default
  opt_pos_emb_offset .............. 0...........................default
  output_layer_parallelism ........ column......................default
  override_lr_scheduler ........... False.......................default
  pack_impl ....................... packed......................default
  padded_vocab_size ............... None........................default
  param_sharing_style ............. grouped.....................default
  partition_activations ........... False.......................default
  pipe_partition_method ........... type:transformer|mlp........default
  pos_test_data_paths ............. None........................default
  pos_test_label_data_paths ....... None........................default
  pos_train_data_paths ............ None........................default
  pos_train_label_data_paths ...... None........................default
  pos_valid_data_paths ............ None........................default
  pos_valid_label_data_paths ...... None........................default
  precompute_model_name ........... None........................default
  prescale_gradients .............. False.......................default
  profile_backward ................ False.......................default
  prompt_end ...................... 
...........................default
  rank ............................ None........................default
  recompute ....................... False.......................default
  return_logits ................... False.......................default
  rms_norm_epsilon ................ 1e-08.......................default
  rmsnorm_fusion .................. False.......................default
  rope_fusion ..................... False.......................default
  rotary_emb_base ................. 10000.......................default
  rotary_save_freqs_buffer ........ False.......................default
  rpe_max_distance ................ 128.........................default
  rpe_num_buckets ................. 32..........................default
  s3_chunk_size ................... 104857600...................default
  s3_path ......................... None........................default
  sample_input_file ............... None........................default
  sample_output_file .............. samples.txt.................default
  save_base_shapes ................ False.......................default
  scaled_masked_softmax_fusion .... False.......................default
  scalenorm_epsilon ............... 1e-08.......................default
  scheduler ....................... None........................default
  seed ............................ 1234........................default
  sequence_parallel ............... False.......................default
  short_seq_prob .................. 0.1.........................default
  sliding_window_width ............ None........................default
  soft_prompt_tuning .............. None........................default
  sparse_attention ................ None........................default
  sparse_gradients ................ False.......................default
  temperature ..................... 0.0.........................default
  tensorboard ..................... None........................default
  test_data_paths ................. None........................default
  test_data_weights ............... None........................default
  test_label_data_paths ........... None........................default
  test_reward_data_paths .......... None........................default
  tokenizer_type .................. GPT2BPETokenizer............default
  top_k ........................... 0...........................default
  top_p ........................... 0.0.........................default
  train_data_paths ................ None........................default
  train_data_weights .............. None........................default
  train_impl ...................... normal......................default
  train_label_data_paths .......... None........................default
  train_reward_data_paths ......... None........................default
  use_bias_in_attn_linear ......... True........................default
  use_bias_in_mlp ................. True........................default
  use_bias_in_norms ............... True........................default
  use_bnb_optimizer ............... False.......................default
  use_checkpoint_lr_scheduler ..... False.......................default
  use_comet ....................... None........................default
  use_cpu_initialization .......... False.......................default
  use_flashattn_swiglu ............ False.......................default
  use_mup ......................... False.......................default
  use_qk_layernorm ................ False.......................default
  use_shared_fs ................... True........................default
  use_tutel ....................... False.......................default
  valid_data_paths ................ None........................default
  valid_data_weights .............. None........................default
  valid_label_data_paths .......... None........................default
  valid_reward_data_paths ......... None........................default
  wandb ........................... None........................default
  wandb_host ...................... https://api.wandb.ai........default
  wandb_init_all_ranks ............ False.......................default
  wandb_project ................... neox........................default
  wandb_team ...................... None........................default
  warmup .......................... 0.01........................default
  weight_by_num_documents ......... False.......................default
  weighted_sampler_alpha .......... 1.0.........................default
  world_size ...................... None........................default
---------------- end of arguments ----------------
NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 4 
[2024-10-10 07:26:33,499] [INFO] [multinode_runner.py:73:get_cmd] Running on the following workers: nid008276,nid008301,nid008304,nid008333,nid008336,nid008337,nid008384,nid008385,nid008389,nid008392,nid008393,nid008409,nid008412,nid008420,nid008421,nid008453,nid008456,nid008476,nid008492,nid008493,nid008613,nid008616,nid008617,nid008620,nid008636,nid008637,nid008640,nid008641,nid008677,nid008680,nid008681,nid008684
[2024-10-10 07:26:33,499] [INFO] [runner.py:586:main] cmd = pdsh -S -f 1024 -w nid008276,nid008301,nid008304,nid008333,nid008336,nid008337,nid008384,nid008385,nid008389,nid008392,nid008393,nid008409,nid008412,nid008420,nid008421,nid008453,nid008456,nid008476,nid008492,nid008493,nid008613,nid008616,nid008617,nid008620,nid008636,nid008637,nid008640,nid008641,nid008677,nid008680,nid008681,nid008684 export PYTHONPATH=/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/slurms:/opt/nersc/pymon; export NCCL_NET_GDR_LEVEL=PHB; export NCCL_SOCKET_IFNAME=hsn;  cd /pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/slurms; /pscratch/sd/z/zby2022/envs/gpt_neox_20240914/bin/python -u -m deepspeed.launcher.launch --world_info=eyJuaWQwMDgyNzYiOiBbMCwgMSwgMiwgM10sICJuaWQwMDgzMDEiOiBbMCwgMSwgMiwgM10sICJuaWQwMDgzMDQiOiBbMCwgMSwgMiwgM10sICJuaWQwMDgzMzMiOiBbMCwgMSwgMiwgM10sICJuaWQwMDgzMzYiOiBbMCwgMSwgMiwgM10sICJuaWQwMDgzMzciOiBbMCwgMSwgMiwgM10sICJuaWQwMDgzODQiOiBbMCwgMSwgMiwgM10sICJuaWQwMDgzODUiOiBbMCwgMSwgMiwgM10sICJuaWQwMDgzODkiOiBbMCwgMSwgMiwgM10sICJuaWQwMDgzOTIiOiBbMCwgMSwgMiwgM10sICJuaWQwMDgzOTMiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg0MDkiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg0MTIiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg0MjAiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg0MjEiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg0NTMiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg0NTYiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg0NzYiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg0OTIiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg0OTMiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg2MTMiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg2MTYiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg2MTciOiBbMCwgMSwgMiwgM10sICJuaWQwMDg2MjAiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg2MzYiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg2MzciOiBbMCwgMSwgMiwgM10sICJuaWQwMDg2NDAiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg2NDEiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg2NzciOiBbMCwgMSwgMiwgM10sICJuaWQwMDg2ODAiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg2ODEiOiBbMCwgMSwgMiwgM10sICJuaWQwMDg2ODQiOiBbMCwgMSwgMiwgM119 --node_rank=%n --master_addr=nid008276 --master_port=29500 /pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/train_profiling.py --deepspeed_config 'eyJ0cmFpbl9iYXRjaF9zaXplIjogMjU2LCAidHJhaW5fbWljcm9fYmF0Y2hfc2l6ZV9wZXJfZ3B1IjogNCwgImdyYWRpZW50X2FjY3VtdWxhdGlvbl9zdGVwcyI6IDE2LCAib3B0aW1pemVyIjogeyJ0eXBlIjogIkFkYW0iLCAicGFyYW1zIjogeyJsciI6IDkuN2UtMDUsICJiZXRhcyI6IFswLjksIDAuOTVdLCAiZXBzIjogMWUtMDh9fSwgImZwMTYiOiB7ImZwMTYiOiB0cnVlLCAiZW5hYmxlZCI6IHRydWUsICJsb3NzX3NjYWxlIjogMCwgImxvc3Nfc2NhbGVfd2luZG93IjogMTAwMCwgImluaXRpYWxfc2NhbGVfcG93ZXIiOiAxMiwgImh5c3RlcmVzaXMiOiAyLCAibWluX2xvc3Nfc2NhbGUiOiAxfSwgInplcm9fb3B0aW1pemF0aW9uIjogeyJzdGFnZSI6IDEsICJhbGxnYXRoZXJfcGFydGl0aW9ucyI6IHRydWUsICJhbGxnYXRoZXJfYnVja2V0X3NpemUiOiAxMjYwMDAwMDAwLCAib3ZlcmxhcF9jb21tIjogdHJ1ZSwgInJlZHVjZV9zY2F0dGVyIjogdHJ1ZSwgInJlZHVjZV9idWNrZXRfc2l6ZSI6IDEyNjAwMDAwMDAsICJjb250aWd1b3VzX2dyYWRpZW50cyI6IHRydWV9LCAic3RlcHNfcGVyX3ByaW50IjogMSwgIndhbGxfY2xvY2tfYnJlYWtkb3duIjogdHJ1ZX0=' --megatron_config '{"train_batch_size": 256, "train_micro_batch_size_per_gpu": 4, "gradient_accumulation_steps": 16, "optimizer": {"type": "Adam", "params": {"lr": 9.7e-05, "betas": [0.9, 0.95], "eps": 1e-08}}, "fp16": {"fp16": true, "enabled": true, "loss_scale": 0, "loss_scale_window": 1000, "initial_scale_power": 12, "hysteresis": 2, "min_loss_scale": 1}, "zero_optimization": {"stage": 1, "allgather_partitions": true, "allgather_bucket_size": 1260000000, "overlap_comm": true, "reduce_scatter": true, "reduce_bucket_size": 1260000000, "contiguous_gradients": true}, "steps_per_print": 1, "wall_clock_breakdown": true, "precision": "fp16", "num_layers": 44, "hidden_size": 6144, "num_attention_heads": 64, "seq_length": 2048, "max_position_embeddings": 2048, "pos_emb": "rotary", "no_weight_tying": true, "attention_config": ["global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global"], "sparsity_config": {}, "scaled_upper_triang_masked_softmax_fusion": true, "bias_gelu_fusion": true, "rotary_pct": 0.25, "init_method": "small_init", "output_layer_init_method": "wang_init", "gpt_j_residual": true, "lr_decay_style": "cosine", "lr_decay_iters": 1000, "min_lr": 9.7e-06, "optimizer_type": "Adam", "zero_stage": 1, "zero_reduce_scatter": true, "zero_contiguous_gradients": true, "zero_reduce_bucket_size": 1260000000, "zero_allgather_bucket_size": 1260000000, "lr": 9.7e-05, "data_path": "/pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document", "data_impl": "mmap", "save": "checkpoints-test", "config_files": {"GPT_20B_8_4_4.yml": "# DISCLAIMER: This is the configuration file for the GPT-NeoX-20B model as it was trained on 96x 40GB A100\n# GPUs. Depending on your system configuration, you may need to change some parameters in order to fit\n# the model in memory.\n\n{\n  # Tokenizer /  checkpoint settings - you will need to change these to the location you have them saved in\n  # \"vocab_file\": \"./20B_checkpoints/20B_tokenizer.json\",\n  # \"save\": \"./20B_checkpoints\",\n  # \"load\": \"./20B_checkpoints\",\n\n  # If finetuning, edit the following to the location of your finetuning dataset:\n  # \"data_path\": \"./data/pile_20B_tokenizer/pile_20B_tokenizer_text_document\",\n\n  # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\n  # across the node boundaries )\n  \"pipe_parallel_size\": 8,\n  \"model_parallel_size\": 4,\n\n  # model settings\n  \"num_layers\": 44,\n  \"hidden_size\": 6144,\n  \"num_attention_heads\": 64,\n  \"seq_length\": 2048,\n  \"max_position_embeddings\": 2048,\n  \"norm\": \"layernorm\",\n  \"pos_emb\": \"rotary\",\n  \"rotary_pct\": 0.25,\n  \"no_weight_tying\": true,\n  \"gpt_j_residual\": true,\n  \"output_layer_parallelism\": \"column\",\n  \"scaled_upper_triang_masked_softmax_fusion\": true,\n  \"bias_gelu_fusion\": true,\n  \"rope_fusion\": false,\n  \"layernorm_fusion\": false,\n\n  # init methods\n  \"init_method\": \"small_init\",\n  \"output_layer_init_method\": \"wang_init\",\n\n  # optimizer settings\n  \"optimizer\": {\n    \"type\": \"Adam\",\n    \"params\": {\n      \"lr\": 0.97e-4,\n      \"betas\": [0.9, 0.95],\n      \"eps\": 1.0e-8,\n      }\n      },\n\n  \"min_lr\": 0.97e-5,\n\n  # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training\n  \"zero_optimization\": {\n  \"stage\": 1,\n  \"allgather_partitions\": True,\n  \"allgather_bucket_size\": 1260000000,\n  \"overlap_comm\": True,\n  \"reduce_scatter\": True,\n  \"reduce_bucket_size\": 1260000000,\n  \"contiguous_gradients\": True,\n  },\n\n  # batch / data settings (assuming 96 GPUs)\n  \"train_micro_batch_size_per_gpu\": 4,\n  \"gradient_accumulation_steps\": 16,\n  \"data_impl\": \"mmap\",\n  \"split\": \"995,4,1\",\n\n  # activation checkpointing\n  \"checkpoint_activations\": true,\n  \"checkpoint_num_layers\": 1,\n  \"partition_activations\": false,\n  \"synchronize_each_layer\": true,\n\n  # regularization\n  \"gradient_clipping\": 1.0,\n  \"weight_decay\": 0.01,\n  \"hidden_dropout\": 0,\n  \"attention_dropout\": 0,\n\n  # precision settings\n  \"fp16\": {\n    \"fp16\": true,\n    \"enabled\": true,\n    \"loss_scale\": 0,\n    \"loss_scale_window\": 1000,\n    \"initial_scale_power\": 12,\n    \"hysteresis\": 2,\n    \"min_loss_scale\": 1\n    },\n\n  # misc. training settings\n  \"train_iters\": 1000,\n  \"lr_decay_iters\": 1000,\n\n  \"distributed_backend\": \"nccl\",\n  \"lr_decay_style\": \"cosine\",\n  \"warmup\": 0.01,\n  \"checkpoint_factor\": 500, # this variable previously called `save-interval`\n  \"eval_interval\": 1000,\n  \"eval_iters\": 10,\n\n  # logging\n  \"log_interval\": 1,\n  \"steps_per_print\": 1,\n  \"wall_clock_breakdown\": true,\n\n  ### NEW DATA: ####\n  # \"tokenizer_type\": \"HFTokenizer\",\n  # \"tensorboard-dir\": \"./tensorboard\",\n  # \"log_dir\": \"./logs\",\n\n  # distributed training settings\n  # \"launcher\": \"slurm\",\n  # \"deepspeed_slurm\": true,\n\n  # profiling settings\n  \"profile\": True,\n  \"profile_step_start\": 2,\n  \"profile_step_stop\": 7,\n}", "local_setup.yml": "# Suggested data paths when using GPT-NeoX locally\n{\n  # \"data_path\": \"/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/data/pile_text_document\",\n  # \"data_path\": \"/pscratch/sd/z/zhaozh/data/pile/processed/pile_text_document\",\n\n  \"data-path\": \"/pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document\",\n\n  # or for weighted datasets:\n  # \"train-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"test-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"valid-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"train-data-weights\": [1., 2.],\n  # \"test-data-weights\": [2., 1.],\n  # \"valid-data-weights\": [0.5, 0.4],\n\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\n  # WARNING: setting this to True will override any user provided weights\n  # \"weight_by_num_documents\": false,\n  # \"weighted_sampler_alpha\": 0.3,\n\n  \"vocab_file\": \"/pscratch/sd/z/zhaozh/data/pile/gpt2-vocab.json\",\n  \"merge_file\": \"/pscratch/sd/z/zhaozh/data/pile/gpt2-merges.txt\",\n\n  \"save\": \"checkpoints-test\",\n  \"load\": \"checkpoints-test2\",\n  \"checkpoint_validation_with_forward_pass\": False,\n\n  \"tensorboard_dir\": \"tensorboard\",\n  \"log_dir\": \"logs\",\n  \"use_wandb\": True,\n  \"wandb_host\": \"https://api.wandb.ai\",\n  \"wandb_project\": \"neox\"\n}\n"}, "load": "checkpoints-test2", "checkpoint_factor": 500, "batch_size": 4, "train_iters": 1000, "eval_iters": 10, "split": "995,4,1", "vocab_file": "/pscratch/sd/z/zhaozh/data/pile/gpt2-vocab.json", "merge_file": "/pscratch/sd/z/zhaozh/data/pile/gpt2-merges.txt", "weight_decay": 0.01, "checkpoint_activations": true, "synchronize_each_layer": true, "dynamic_loss_scale": true, "pipe_parallel_size": 8, "model_parallel_size": 4, "world_size": 1, "is_pipe_parallel": true, "use_wandb": true, "wandb_group": "l93r147r_pgfmeqc0", "log_dir": "logs", "tensorboard_dir": "tensorboard", "log_interval": 1, "profile": true, "profile_step_start": 2, "profile_step_stop": 7, "text_gen_type": "unconditional", "local_rank": 0, "rank": 0, "user_script": "/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/train_profiling.py", "save_iters": [500], "global_num_gpus": 128}'
nid008421: ***************************************************************************
nid008421:                           NOTICE TO USERS
nid008421: 
nid008421: Lawrence Berkeley National Laboratory operates this computer system under 
nid008421: contract to the U.S. Department of Energy.  This computer system is the 
nid008421: property of the United States Government and is for authorized use only.
nid008421: Users (authorized or unauthorized) have no explicit or implicit 
nid008421: expectation of privacy.
nid008421: 
nid008421: Any or all uses of this system and all files on this system may be
nid008421: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008421: to authorized site, Department of Energy, and law enforcement personnel,
nid008421: as well as authorized officials of other agencies, both domestic and foreign.
nid008421: By using this system, the user consents to such interception, monitoring,
nid008421: recording, copying, auditing, inspection, and disclosure at the discretion
nid008421: of authorized site or Department of Energy personnel.
nid008421: 
nid008421: Unauthorized or improper use of this system may result in administrative
nid008421: disciplinary action and civil and criminal penalties. By continuing to use
nid008421: this system you indicate your awareness of and consent to these terms and
nid008421: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008421: stated in this warning.
nid008421: 
nid008421: *****************************************************************************
nid008421: 
nid008421: Login connection to host x1404c7s1b0n1:
nid008421: 
nid008616: ***************************************************************************
nid008616:                           NOTICE TO USERS
nid008616: 
nid008616: Lawrence Berkeley National Laboratory operates this computer system under 
nid008616: contract to the U.S. Department of Energy.  This computer system is the 
nid008616: property of the United States Government and is for authorized use only.
nid008616: Users (authorized or unauthorized) have no explicit or implicit 
nid008616: expectation of privacy.
nid008616: 
nid008616: Any or all uses of this system and all files on this system may be
nid008616: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008616: to authorized site, Department of Energy, and law enforcement personnel,
nid008616: as well as authorized officials of other agencies, both domestic and foreign.
nid008616: By using this system, the user consents to such interception, monitoring,
nid008616: recording, copying, auditing, inspection, and disclosure at the discretion
nid008616: of authorized site or Department of Energy personnel.
nid008616: 
nid008616: Unauthorized or improper use of this system may result in administrative
nid008616: disciplinary action and civil and criminal penalties. By continuing to use
nid008616: this system you indicate your awareness of and consent to these terms and
nid008616: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008616: stated in this warning.
nid008616: 
nid008616: *****************************************************************************
nid008616: 
nid008616: Login connection to host x1405c5s2b0n0:
nid008616: 
nid008276: ***************************************************************************
nid008276:                           NOTICE TO USERS
nid008276: 
nid008276: Lawrence Berkeley National Laboratory operates this computer system under 
nid008276: contract to the U.S. Department of Energy.  This computer system is the 
nid008276: property of the United States Government and is for authorized use only.
nid008276: Users (authorized or unauthorized) have no explicit or implicit 
nid008276: expectation of privacy.
nid008276: 
nid008276: Any or all uses of this system and all files on this system may be
nid008276: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008276: to authorized site, Department of Energy, and law enforcement personnel,
nid008276: as well as authorized officials of other agencies, both domestic and foreign.
nid008276: By using this system, the user consents to such interception, monitoring,
nid008276: recording, copying, auditing, inspection, and disclosure at the discretion
nid008276: of authorized site or Department of Energy personnel.
nid008276: 
nid008276: Unauthorized or improper use of this system may result in administrative
nid008276: disciplinary action and civil and criminal penalties. By continuing to use
nid008276: this system you indicate your awareness of and consent to these terms and
nid008276: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008276: stated in this warning.
nid008276: 
nid008276: *****************************************************************************
nid008276: 
nid008276: Login connection to host x1404c2s5b0n0:
nid008276: 
nid008384: ***************************************************************************
nid008384:                           NOTICE TO USERS
nid008384: 
nid008384: Lawrence Berkeley National Laboratory operates this computer system under 
nid008384: contract to the U.S. Department of Energy.  This computer system is the 
nid008384: property of the United States Government and is for authorized use only.
nid008384: Users (authorized or unauthorized) have no explicit or implicit 
nid008384: expectation of privacy.
nid008384: 
nid008384: Any or all uses of this system and all files on this system may be
nid008384: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008384: to authorized site, Department of Energy, and law enforcement personnel,
nid008384: as well as authorized officials of other agencies, both domestic and foreign.
nid008384: By using this system, the user consents to such interception, monitoring,
nid008384: recording, copying, auditing, inspection, and disclosure at the discretion
nid008384: of authorized site or Department of Energy personnel.
nid008384: 
nid008384: Unauthorized or improper use of this system may result in administrative
nid008384: disciplinary action and civil and criminal penalties. By continuing to use
nid008384: this system you indicate your awareness of and consent to these terms and
nid008384: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008384: stated in this warning.
nid008384: 
nid008384: *****************************************************************************
nid008384: 
nid008384: Login connection to host x1404c6s0b0n0:
nid008384: 
nid008336: ***************************************************************************
nid008336:                           NOTICE TO USERS
nid008336: 
nid008336: Lawrence Berkeley National Laboratory operates this computer system under 
nid008336: contract to the U.S. Department of Energy.  This computer system is the 
nid008336: property of the United States Government and is for authorized use only.
nid008336: Users (authorized or unauthorized) have no explicit or implicit 
nid008336: expectation of privacy.
nid008336: 
nid008336: Any or all uses of this system and all files on this system may be
nid008336: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008336: to authorized site, Department of Energy, and law enforcement personnel,
nid008336: as well as authorized officials of other agencies, both domestic and foreign.
nid008336: By using this system, the user consents to such interception, monitoring,
nid008336: recording, copying, auditing, inspection, and disclosure at the discretion
nid008336: of authorized site or Department of Energy personnel.
nid008336: 
nid008336: Unauthorized or improper use of this system may result in administrative
nid008336: disciplinary action and civil and criminal penalties. By continuing to use
nid008336: this system you indicate your awareness of and consent to these terms and
nid008336: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008336: stated in this warning.
nid008336: 
nid008336: *****************************************************************************
nid008336: 
nid008336: Login connection to host x1404c4s4b0n0:
nid008336: 
nid008677: ***************************************************************************
nid008677:                           NOTICE TO USERS
nid008677: 
nid008677: Lawrence Berkeley National Laboratory operates this computer system under 
nid008677: contract to the U.S. Department of Energy.  This computer system is the 
nid008677: property of the United States Government and is for authorized use only.
nid008677: Users (authorized or unauthorized) have no explicit or implicit 
nid008677: expectation of privacy.
nid008677: 
nid008677: Any or all uses of this system and all files on this system may be
nid008677: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008677: to authorized site, Department of Energy, and law enforcement personnel,
nid008677: as well as authorized officials of other agencies, both domestic and foreign.
nid008677: By using this system, the user consents to such interception, monitoring,
nid008677: recording, copying, auditing, inspection, and disclosure at the discretion
nid008677: of authorized site or Department of Energy personnel.
nid008677: 
nid008677: Unauthorized or improper use of this system may result in administrative
nid008677: disciplinary action and civil and criminal penalties. By continuing to use
nid008677: this system you indicate your awareness of and consent to these terms and
nid008677: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008677: stated in this warning.
nid008677: 
nid008677: *****************************************************************************
nid008677: 
nid008677: Login connection to host x1405c7s1b0n1:
nid008677: 
nid008337: ***************************************************************************
nid008337:                           NOTICE TO USERS
nid008337: 
nid008337: Lawrence Berkeley National Laboratory operates this computer system under 
nid008337: contract to the U.S. Department of Energy.  This computer system is the 
nid008337: property of the United States Government and is for authorized use only.
nid008337: Users (authorized or unauthorized) have no explicit or implicit 
nid008337: expectation of privacy.
nid008337: 
nid008337: Any or all uses of this system and all files on this system may be
nid008337: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008337: to authorized site, Department of Energy, and law enforcement personnel,
nid008337: as well as authorized officials of other agencies, both domestic and foreign.
nid008337: By using this system, the user consents to such interception, monitoring,
nid008337: recording, copying, auditing, inspection, and disclosure at the discretion
nid008337: of authorized site or Department of Energy personnel.
nid008337: 
nid008337: Unauthorized or improper use of this system may result in administrative
nid008337: disciplinary action and civil and criminal penalties. By continuing to use
nid008337: this system you indicate your awareness of and consent to these terms and
nid008337: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008337: stated in this warning.
nid008337: 
nid008337: *****************************************************************************
nid008337: 
nid008337: Login connection to host x1404c4s4b0n1:
nid008337: 
nid008613: ***************************************************************************
nid008613:                           NOTICE TO USERS
nid008613: 
nid008613: Lawrence Berkeley National Laboratory operates this computer system under 
nid008613: contract to the U.S. Department of Energy.  This computer system is the 
nid008613: property of the United States Government and is for authorized use only.
nid008613: Users (authorized or unauthorized) have no explicit or implicit 
nid008613: expectation of privacy.
nid008613: 
nid008613: Any or all uses of this system and all files on this system may be
nid008613: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008613: to authorized site, Department of Energy, and law enforcement personnel,
nid008613: as well as authorized officials of other agencies, both domestic and foreign.
nid008613: By using this system, the user consents to such interception, monitoring,
nid008613: recording, copying, auditing, inspection, and disclosure at the discretion
nid008613: of authorized site or Department of Energy personnel.
nid008613: 
nid008613: Unauthorized or improper use of this system may result in administrative
nid008613: disciplinary action and civil and criminal penalties. By continuing to use
nid008613: this system you indicate your awareness of and consent to these terms and
nid008613: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008613: stated in this warning.
nid008613: 
nid008613: *****************************************************************************
nid008613: 
nid008613: Login connection to host x1405c5s1b0n1:
nid008613: 
nid008492: ***************************************************************************
nid008492:                           NOTICE TO USERS
nid008492: 
nid008492: Lawrence Berkeley National Laboratory operates this computer system under 
nid008492: contract to the U.S. Department of Energy.  This computer system is the 
nid008492: property of the United States Government and is for authorized use only.
nid008492: Users (authorized or unauthorized) have no explicit or implicit 
nid008492: expectation of privacy.
nid008492: 
nid008492: Any or all uses of this system and all files on this system may be
nid008492: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008492: to authorized site, Department of Energy, and law enforcement personnel,
nid008492: as well as authorized officials of other agencies, both domestic and foreign.
nid008492: By using this system, the user consents to such interception, monitoring,
nid008492: recording, copying, auditing, inspection, and disclosure at the discretion
nid008492: of authorized site or Department of Energy personnel.
nid008492: 
nid008492: Unauthorized or improper use of this system may result in administrative
nid008492: disciplinary action and civil and criminal penalties. By continuing to use
nid008492: this system you indicate your awareness of and consent to these terms and
nid008492: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008492: stated in this warning.
nid008492: 
nid008492: *****************************************************************************
nid008492: 
nid008492: Login connection to host x1405c1s3b0n0:
nid008492: 
nid008385: ***************************************************************************
nid008385:                           NOTICE TO USERS
nid008385: 
nid008385: Lawrence Berkeley National Laboratory operates this computer system under 
nid008385: contract to the U.S. Department of Energy.  This computer system is the 
nid008385: property of the United States Government and is for authorized use only.
nid008385: Users (authorized or unauthorized) have no explicit or implicit 
nid008385: expectation of privacy.
nid008385: 
nid008385: Any or all uses of this system and all files on this system may be
nid008385: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008385: to authorized site, Department of Energy, and law enforcement personnel,
nid008385: as well as authorized officials of other agencies, both domestic and foreign.
nid008385: By using this system, the user consents to such interception, monitoring,
nid008385: recording, copying, auditing, inspection, and disclosure at the discretion
nid008385: of authorized site or Department of Energy personnel.
nid008385: 
nid008385: Unauthorized or improper use of this system may result in administrative
nid008385: disciplinary action and civil and criminal penalties. By continuing to use
nid008385: this system you indicate your awareness of and consent to these terms and
nid008385: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008385: stated in this warning.
nid008385: 
nid008385: *****************************************************************************
nid008385: 
nid008385: Login connection to host x1404c6s0b0n1:
nid008385: 
nid008409: ***************************************************************************
nid008409:                           NOTICE TO USERS
nid008409: 
nid008409: Lawrence Berkeley National Laboratory operates this computer system under 
nid008409: contract to the U.S. Department of Energy.  This computer system is the 
nid008409: property of the United States Government and is for authorized use only.
nid008409: Users (authorized or unauthorized) have no explicit or implicit 
nid008409: expectation of privacy.
nid008409: 
nid008409: Any or all uses of this system and all files on this system may be
nid008409: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008409: to authorized site, Department of Energy, and law enforcement personnel,
nid008409: as well as authorized officials of other agencies, both domestic and foreign.
nid008409: By using this system, the user consents to such interception, monitoring,
nid008409: recording, copying, auditing, inspection, and disclosure at the discretion
nid008409: of authorized site or Department of Energy personnel.
nid008409: 
nid008409: Unauthorized or improper use of this system may result in administrative
nid008409: disciplinary action and civil and criminal penalties. By continuing to use
nid008409: this system you indicate your awareness of and consent to these terms and
nid008409: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008409: stated in this warning.
nid008409: 
nid008409: *****************************************************************************
nid008409: 
nid008409: Login connection to host x1404c6s6b0n1:
nid008409: 
nid008392: ***************************************************************************
nid008392:                           NOTICE TO USERS
nid008392: 
nid008392: Lawrence Berkeley National Laboratory operates this computer system under 
nid008392: contract to the U.S. Department of Energy.  This computer system is the 
nid008392: property of the United States Government and is for authorized use only.
nid008392: Users (authorized or unauthorized) have no explicit or implicit 
nid008392: expectation of privacy.
nid008392: 
nid008392: Any or all uses of this system and all files on this system may be
nid008392: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008392: to authorized site, Department of Energy, and law enforcement personnel,
nid008392: as well as authorized officials of other agencies, both domestic and foreign.
nid008392: By using this system, the user consents to such interception, monitoring,
nid008392: recording, copying, auditing, inspection, and disclosure at the discretion
nid008392: of authorized site or Department of Energy personnel.
nid008392: 
nid008392: Unauthorized or improper use of this system may result in administrative
nid008392: disciplinary action and civil and criminal penalties. By continuing to use
nid008392: this system you indicate your awareness of and consent to these terms and
nid008392: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008392: stated in this warning.
nid008392: 
nid008392: *****************************************************************************
nid008392: 
nid008392: Login connection to host x1404c6s2b0n0:
nid008392: 
nid008617: ***************************************************************************
nid008617:                           NOTICE TO USERS
nid008617: 
nid008617: Lawrence Berkeley National Laboratory operates this computer system under 
nid008617: contract to the U.S. Department of Energy.  This computer system is the 
nid008617: property of the United States Government and is for authorized use only.
nid008617: Users (authorized or unauthorized) have no explicit or implicit 
nid008617: expectation of privacy.
nid008617: 
nid008617: Any or all uses of this system and all files on this system may be
nid008617: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008617: to authorized site, Department of Energy, and law enforcement personnel,
nid008617: as well as authorized officials of other agencies, both domestic and foreign.
nid008617: By using this system, the user consents to such interception, monitoring,
nid008617: recording, copying, auditing, inspection, and disclosure at the discretion
nid008617: of authorized site or Department of Energy personnel.
nid008617: 
nid008617: Unauthorized or improper use of this system may result in administrative
nid008617: disciplinary action and civil and criminal penalties. By continuing to use
nid008617: this system you indicate your awareness of and consent to these terms and
nid008617: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008617: stated in this warning.
nid008617: 
nid008617: *****************************************************************************
nid008617: 
nid008617: Login connection to host x1405c5s2b0n1:
nid008617: 
nid008412: ***************************************************************************
nid008412:                           NOTICE TO USERS
nid008412: 
nid008412: Lawrence Berkeley National Laboratory operates this computer system under 
nid008412: contract to the U.S. Department of Energy.  This computer system is the 
nid008412: property of the United States Government and is for authorized use only.
nid008412: Users (authorized or unauthorized) have no explicit or implicit 
nid008412: expectation of privacy.
nid008412: 
nid008412: Any or all uses of this system and all files on this system may be
nid008412: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008412: to authorized site, Department of Energy, and law enforcement personnel,
nid008412: as well as authorized officials of other agencies, both domestic and foreign.
nid008412: By using this system, the user consents to such interception, monitoring,
nid008412: recording, copying, auditing, inspection, and disclosure at the discretion
nid008412: of authorized site or Department of Energy personnel.
nid008412: 
nid008412: Unauthorized or improper use of this system may result in administrative
nid008412: disciplinary action and civil and criminal penalties. By continuing to use
nid008412: this system you indicate your awareness of and consent to these terms and
nid008412: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008412: stated in this warning.
nid008412: 
nid008412: *****************************************************************************
nid008412: 
nid008412: Login connection to host x1404c6s7b0n0:
nid008412: 
nid008476: ***************************************************************************
nid008476:                           NOTICE TO USERS
nid008476: 
nid008476: Lawrence Berkeley National Laboratory operates this computer system under 
nid008476: contract to the U.S. Department of Energy.  This computer system is the 
nid008476: property of the United States Government and is for authorized use only.
nid008476: Users (authorized or unauthorized) have no explicit or implicit 
nid008476: expectation of privacy.
nid008476: 
nid008476: Any or all uses of this system and all files on this system may be
nid008476: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008476: to authorized site, Department of Energy, and law enforcement personnel,
nid008476: as well as authorized officials of other agencies, both domestic and foreign.
nid008476: By using this system, the user consents to such interception, monitoring,
nid008476: recording, copying, auditing, inspection, and disclosure at the discretion
nid008476: of authorized site or Department of Energy personnel.
nid008476: 
nid008476: Unauthorized or improper use of this system may result in administrative
nid008476: disciplinary action and civil and criminal penalties. By continuing to use
nid008476: this system you indicate your awareness of and consent to these terms and
nid008476: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008476: stated in this warning.
nid008476: 
nid008476: *****************************************************************************
nid008476: 
nid008476: Login connection to host x1405c0s7b0n0:
nid008476: 
nid008620: ***************************************************************************
nid008620:                           NOTICE TO USERS
nid008620: 
nid008620: Lawrence Berkeley National Laboratory operates this computer system under 
nid008620: contract to the U.S. Department of Energy.  This computer system is the 
nid008620: property of the United States Government and is for authorized use only.
nid008620: Users (authorized or unauthorized) have no explicit or implicit 
nid008620: expectation of privacy.
nid008620: 
nid008620: Any or all uses of this system and all files on this system may be
nid008620: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008620: to authorized site, Department of Energy, and law enforcement personnel,
nid008620: as well as authorized officials of other agencies, both domestic and foreign.
nid008620: By using this system, the user consents to such interception, monitoring,
nid008620: recording, copying, auditing, inspection, and disclosure at the discretion
nid008620: of authorized site or Department of Energy personnel.
nid008620: 
nid008620: Unauthorized or improper use of this system may result in administrative
nid008620: disciplinary action and civil and criminal penalties. By continuing to use
nid008620: this system you indicate your awareness of and consent to these terms and
nid008620: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008620: stated in this warning.
nid008620: 
nid008620: *****************************************************************************
nid008620: 
nid008620: Login connection to host x1405c5s3b0n0:
nid008620: 
nid008304: ***************************************************************************
nid008304:                           NOTICE TO USERS
nid008304: 
nid008304: Lawrence Berkeley National Laboratory operates this computer system under 
nid008304: contract to the U.S. Department of Energy.  This computer system is the 
nid008304: property of the United States Government and is for authorized use only.
nid008304: Users (authorized or unauthorized) have no explicit or implicit 
nid008304: expectation of privacy.
nid008304: 
nid008304: Any or all uses of this system and all files on this system may be
nid008304: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008304: to authorized site, Department of Energy, and law enforcement personnel,
nid008304: as well as authorized officials of other agencies, both domestic and foreign.
nid008304: By using this system, the user consents to such interception, monitoring,
nid008304: recording, copying, auditing, inspection, and disclosure at the discretion
nid008304: of authorized site or Department of Energy personnel.
nid008304: 
nid008304: Unauthorized or improper use of this system may result in administrative
nid008304: disciplinary action and civil and criminal penalties. By continuing to use
nid008304: this system you indicate your awareness of and consent to these terms and
nid008304: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008304: stated in this warning.
nid008304: 
nid008304: *****************************************************************************
nid008304: 
nid008304: Login connection to host x1404c3s4b0n0:
nid008304: 
nid008684: ***************************************************************************
nid008684:                           NOTICE TO USERS
nid008684: 
nid008684: Lawrence Berkeley National Laboratory operates this computer system under 
nid008684: contract to the U.S. Department of Energy.  This computer system is the 
nid008684: property of the United States Government and is for authorized use only.
nid008684: Users (authorized or unauthorized) have no explicit or implicit 
nid008684: expectation of privacy.
nid008684: 
nid008684: Any or all uses of this system and all files on this system may be
nid008684: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008684: to authorized site, Department of Energy, and law enforcement personnel,
nid008684: as well as authorized officials of other agencies, both domestic and foreign.
nid008684: By using this system, the user consents to such interception, monitoring,
nid008684: recording, copying, auditing, inspection, and disclosure at the discretion
nid008684: of authorized site or Department of Energy personnel.
nid008684: 
nid008684: Unauthorized or improper use of this system may result in administrative
nid008684: disciplinary action and civil and criminal penalties. By continuing to use
nid008684: this system you indicate your awareness of and consent to these terms and
nid008684: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008684: stated in this warning.
nid008684: 
nid008684: *****************************************************************************
nid008684: 
nid008684: Login connection to host x1405c7s3b0n0:
nid008684: 
nid008301: ***************************************************************************
nid008301:                           NOTICE TO USERS
nid008301: 
nid008301: Lawrence Berkeley National Laboratory operates this computer system under 
nid008301: contract to the U.S. Department of Energy.  This computer system is the 
nid008301: property of the United States Government and is for authorized use only.
nid008301: Users (authorized or unauthorized) have no explicit or implicit 
nid008301: expectation of privacy.
nid008301: 
nid008301: Any or all uses of this system and all files on this system may be
nid008301: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008301: to authorized site, Department of Energy, and law enforcement personnel,
nid008301: as well as authorized officials of other agencies, both domestic and foreign.
nid008301: By using this system, the user consents to such interception, monitoring,
nid008301: recording, copying, auditing, inspection, and disclosure at the discretion
nid008301: of authorized site or Department of Energy personnel.
nid008301: 
nid008301: Unauthorized or improper use of this system may result in administrative
nid008301: disciplinary action and civil and criminal penalties. By continuing to use
nid008301: this system you indicate your awareness of and consent to these terms and
nid008301: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008301: stated in this warning.
nid008301: 
nid008301: *****************************************************************************
nid008301: 
nid008301: Login connection to host x1404c3s3b0n1:
nid008301: 
nid008389: ***************************************************************************
nid008389:                           NOTICE TO USERS
nid008389: 
nid008389: Lawrence Berkeley National Laboratory operates this computer system under 
nid008389: contract to the U.S. Department of Energy.  This computer system is the 
nid008389: property of the United States Government and is for authorized use only.
nid008389: Users (authorized or unauthorized) have no explicit or implicit 
nid008389: expectation of privacy.
nid008389: 
nid008389: Any or all uses of this system and all files on this system may be
nid008389: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008389: to authorized site, Department of Energy, and law enforcement personnel,
nid008389: as well as authorized officials of other agencies, both domestic and foreign.
nid008389: By using this system, the user consents to such interception, monitoring,
nid008389: recording, copying, auditing, inspection, and disclosure at the discretion
nid008389: of authorized site or Department of Energy personnel.
nid008389: 
nid008389: Unauthorized or improper use of this system may result in administrative
nid008389: disciplinary action and civil and criminal penalties. By continuing to use
nid008389: this system you indicate your awareness of and consent to these terms and
nid008389: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008389: stated in this warning.
nid008389: 
nid008389: *****************************************************************************
nid008389: 
nid008389: Login connection to host x1404c6s1b0n1:
nid008389: 
nid008680: ***************************************************************************
nid008680:                           NOTICE TO USERS
nid008680: 
nid008680: Lawrence Berkeley National Laboratory operates this computer system under 
nid008680: contract to the U.S. Department of Energy.  This computer system is the 
nid008680: property of the United States Government and is for authorized use only.
nid008680: Users (authorized or unauthorized) have no explicit or implicit 
nid008680: expectation of privacy.
nid008680: 
nid008680: Any or all uses of this system and all files on this system may be
nid008680: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008680: to authorized site, Department of Energy, and law enforcement personnel,
nid008680: as well as authorized officials of other agencies, both domestic and foreign.
nid008680: By using this system, the user consents to such interception, monitoring,
nid008680: recording, copying, auditing, inspection, and disclosure at the discretion
nid008680: of authorized site or Department of Energy personnel.
nid008680: 
nid008680: Unauthorized or improper use of this system may result in administrative
nid008680: disciplinary action and civil and criminal penalties. By continuing to use
nid008680: this system you indicate your awareness of and consent to these terms and
nid008680: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008680: stated in this warning.
nid008680: 
nid008680: *****************************************************************************
nid008680: 
nid008680: Login connection to host x1405c7s2b0n0:
nid008680: 
nid008636: ***************************************************************************
nid008636:                           NOTICE TO USERS
nid008636: 
nid008636: Lawrence Berkeley National Laboratory operates this computer system under 
nid008636: contract to the U.S. Department of Energy.  This computer system is the 
nid008636: property of the United States Government and is for authorized use only.
nid008636: Users (authorized or unauthorized) have no explicit or implicit 
nid008636: expectation of privacy.
nid008636: 
nid008636: Any or all uses of this system and all files on this system may be
nid008636: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008636: to authorized site, Department of Energy, and law enforcement personnel,
nid008636: as well as authorized officials of other agencies, both domestic and foreign.
nid008636: By using this system, the user consents to such interception, monitoring,
nid008636: recording, copying, auditing, inspection, and disclosure at the discretion
nid008636: of authorized site or Department of Energy personnel.
nid008636: 
nid008636: Unauthorized or improper use of this system may result in administrative
nid008636: disciplinary action and civil and criminal penalties. By continuing to use
nid008636: this system you indicate your awareness of and consent to these terms and
nid008636: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008636: stated in this warning.
nid008636: 
nid008636: *****************************************************************************
nid008636: 
nid008636: Login connection to host x1405c5s7b0n0:
nid008636: 
nid008681: ***************************************************************************
nid008681:                           NOTICE TO USERS
nid008681: 
nid008681: Lawrence Berkeley National Laboratory operates this computer system under 
nid008681: contract to the U.S. Department of Energy.  This computer system is the 
nid008681: property of the United States Government and is for authorized use only.
nid008681: Users (authorized or unauthorized) have no explicit or implicit 
nid008681: expectation of privacy.
nid008681: 
nid008681: Any or all uses of this system and all files on this system may be
nid008681: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008681: to authorized site, Department of Energy, and law enforcement personnel,
nid008681: as well as authorized officials of other agencies, both domestic and foreign.
nid008681: By using this system, the user consents to such interception, monitoring,
nid008681: recording, copying, auditing, inspection, and disclosure at the discretion
nid008681: of authorized site or Department of Energy personnel.
nid008681: 
nid008681: Unauthorized or improper use of this system may result in administrative
nid008681: disciplinary action and civil and criminal penalties. By continuing to use
nid008681: this system you indicate your awareness of and consent to these terms and
nid008681: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008681: stated in this warning.
nid008681: 
nid008681: *****************************************************************************
nid008681: 
nid008681: Login connection to host x1405c7s2b0n1:
nid008681: 
nid008453: ***************************************************************************
nid008453:                           NOTICE TO USERS
nid008453: 
nid008453: Lawrence Berkeley National Laboratory operates this computer system under 
nid008453: contract to the U.S. Department of Energy.  This computer system is the 
nid008453: property of the United States Government and is for authorized use only.
nid008453: Users (authorized or unauthorized) have no explicit or implicit 
nid008453: expectation of privacy.
nid008453: 
nid008453: Any or all uses of this system and all files on this system may be
nid008453: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008453: to authorized site, Department of Energy, and law enforcement personnel,
nid008453: as well as authorized officials of other agencies, both domestic and foreign.
nid008453: By using this system, the user consents to such interception, monitoring,
nid008453: recording, copying, auditing, inspection, and disclosure at the discretion
nid008453: of authorized site or Department of Energy personnel.
nid008453: 
nid008453: Unauthorized or improper use of this system may result in administrative
nid008453: disciplinary action and civil and criminal penalties. By continuing to use
nid008453: this system you indicate your awareness of and consent to these terms and
nid008453: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008453: stated in this warning.
nid008453: 
nid008453: *****************************************************************************
nid008453: 
nid008453: Login connection to host x1405c0s1b0n1:
nid008453: 
nid008333: ***************************************************************************
nid008333:                           NOTICE TO USERS
nid008333: 
nid008333: Lawrence Berkeley National Laboratory operates this computer system under 
nid008333: contract to the U.S. Department of Energy.  This computer system is the 
nid008333: property of the United States Government and is for authorized use only.
nid008333: Users (authorized or unauthorized) have no explicit or implicit 
nid008333: expectation of privacy.
nid008333: 
nid008333: Any or all uses of this system and all files on this system may be
nid008333: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008333: to authorized site, Department of Energy, and law enforcement personnel,
nid008333: as well as authorized officials of other agencies, both domestic and foreign.
nid008333: By using this system, the user consents to such interception, monitoring,
nid008333: recording, copying, auditing, inspection, and disclosure at the discretion
nid008333: of authorized site or Department of Energy personnel.
nid008333: 
nid008333: Unauthorized or improper use of this system may result in administrative
nid008333: disciplinary action and civil and criminal penalties. By continuing to use
nid008333: this system you indicate your awareness of and consent to these terms and
nid008333: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008333: stated in this warning.
nid008333: 
nid008333: *****************************************************************************
nid008333: 
nid008333: Login connection to host x1404c4s3b0n1:
nid008333: 
nid008420: ***************************************************************************
nid008420:                           NOTICE TO USERS
nid008420: 
nid008420: Lawrence Berkeley National Laboratory operates this computer system under 
nid008420: contract to the U.S. Department of Energy.  This computer system is the 
nid008420: property of the United States Government and is for authorized use only.
nid008420: Users (authorized or unauthorized) have no explicit or implicit 
nid008420: expectation of privacy.
nid008420: 
nid008420: Any or all uses of this system and all files on this system may be
nid008420: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008420: to authorized site, Department of Energy, and law enforcement personnel,
nid008420: as well as authorized officials of other agencies, both domestic and foreign.
nid008420: By using this system, the user consents to such interception, monitoring,
nid008420: recording, copying, auditing, inspection, and disclosure at the discretion
nid008420: of authorized site or Department of Energy personnel.
nid008420: 
nid008420: Unauthorized or improper use of this system may result in administrative
nid008420: disciplinary action and civil and criminal penalties. By continuing to use
nid008420: this system you indicate your awareness of and consent to these terms and
nid008420: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008420: stated in this warning.
nid008420: 
nid008420: *****************************************************************************
nid008420: 
nid008420: Login connection to host x1404c7s1b0n0:
nid008420: 
nid008637: ***************************************************************************
nid008637:                           NOTICE TO USERS
nid008637: 
nid008637: Lawrence Berkeley National Laboratory operates this computer system under 
nid008637: contract to the U.S. Department of Energy.  This computer system is the 
nid008637: property of the United States Government and is for authorized use only.
nid008637: Users (authorized or unauthorized) have no explicit or implicit 
nid008637: expectation of privacy.
nid008637: 
nid008637: Any or all uses of this system and all files on this system may be
nid008637: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008637: to authorized site, Department of Energy, and law enforcement personnel,
nid008637: as well as authorized officials of other agencies, both domestic and foreign.
nid008637: By using this system, the user consents to such interception, monitoring,
nid008637: recording, copying, auditing, inspection, and disclosure at the discretion
nid008637: of authorized site or Department of Energy personnel.
nid008637: 
nid008637: Unauthorized or improper use of this system may result in administrative
nid008637: disciplinary action and civil and criminal penalties. By continuing to use
nid008637: this system you indicate your awareness of and consent to these terms and
nid008637: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008637: stated in this warning.
nid008637: 
nid008637: *****************************************************************************
nid008637: 
nid008637: Login connection to host x1405c5s7b0n1:
nid008637: 
nid008640: ***************************************************************************
nid008640:                           NOTICE TO USERS
nid008640: 
nid008640: Lawrence Berkeley National Laboratory operates this computer system under 
nid008640: contract to the U.S. Department of Energy.  This computer system is the 
nid008640: property of the United States Government and is for authorized use only.
nid008640: Users (authorized or unauthorized) have no explicit or implicit 
nid008640: expectation of privacy.
nid008640: 
nid008640: Any or all uses of this system and all files on this system may be
nid008640: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008640: to authorized site, Department of Energy, and law enforcement personnel,
nid008640: as well as authorized officials of other agencies, both domestic and foreign.
nid008640: By using this system, the user consents to such interception, monitoring,
nid008640: recording, copying, auditing, inspection, and disclosure at the discretion
nid008640: of authorized site or Department of Energy personnel.
nid008640: 
nid008640: Unauthorized or improper use of this system may result in administrative
nid008640: disciplinary action and civil and criminal penalties. By continuing to use
nid008640: this system you indicate your awareness of and consent to these terms and
nid008640: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008640: stated in this warning.
nid008640: 
nid008640: *****************************************************************************
nid008640: 
nid008640: Login connection to host x1405c6s0b0n0:
nid008640: 
nid008393: ***************************************************************************
nid008393:                           NOTICE TO USERS
nid008393: 
nid008393: Lawrence Berkeley National Laboratory operates this computer system under 
nid008393: contract to the U.S. Department of Energy.  This computer system is the 
nid008393: property of the United States Government and is for authorized use only.
nid008393: Users (authorized or unauthorized) have no explicit or implicit 
nid008393: expectation of privacy.
nid008393: 
nid008393: Any or all uses of this system and all files on this system may be
nid008393: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008393: to authorized site, Department of Energy, and law enforcement personnel,
nid008393: as well as authorized officials of other agencies, both domestic and foreign.
nid008393: By using this system, the user consents to such interception, monitoring,
nid008393: recording, copying, auditing, inspection, and disclosure at the discretion
nid008393: of authorized site or Department of Energy personnel.
nid008393: 
nid008393: Unauthorized or improper use of this system may result in administrative
nid008393: disciplinary action and civil and criminal penalties. By continuing to use
nid008393: this system you indicate your awareness of and consent to these terms and
nid008393: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008393: stated in this warning.
nid008393: 
nid008393: *****************************************************************************
nid008393: 
nid008393: Login connection to host x1404c6s2b0n1:
nid008393: 
nid008456: ***************************************************************************
nid008456:                           NOTICE TO USERS
nid008456: 
nid008456: Lawrence Berkeley National Laboratory operates this computer system under 
nid008456: contract to the U.S. Department of Energy.  This computer system is the 
nid008456: property of the United States Government and is for authorized use only.
nid008456: Users (authorized or unauthorized) have no explicit or implicit 
nid008456: expectation of privacy.
nid008456: 
nid008456: Any or all uses of this system and all files on this system may be
nid008456: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008456: to authorized site, Department of Energy, and law enforcement personnel,
nid008456: as well as authorized officials of other agencies, both domestic and foreign.
nid008456: By using this system, the user consents to such interception, monitoring,
nid008456: recording, copying, auditing, inspection, and disclosure at the discretion
nid008456: of authorized site or Department of Energy personnel.
nid008456: 
nid008456: Unauthorized or improper use of this system may result in administrative
nid008456: disciplinary action and civil and criminal penalties. By continuing to use
nid008456: this system you indicate your awareness of and consent to these terms and
nid008456: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008456: stated in this warning.
nid008456: 
nid008456: *****************************************************************************
nid008456: 
nid008456: Login connection to host x1405c0s2b0n0:
nid008456: 
nid008641: ***************************************************************************
nid008641:                           NOTICE TO USERS
nid008641: 
nid008641: Lawrence Berkeley National Laboratory operates this computer system under 
nid008641: contract to the U.S. Department of Energy.  This computer system is the 
nid008641: property of the United States Government and is for authorized use only.
nid008641: Users (authorized or unauthorized) have no explicit or implicit 
nid008641: expectation of privacy.
nid008641: 
nid008641: Any or all uses of this system and all files on this system may be
nid008641: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008641: to authorized site, Department of Energy, and law enforcement personnel,
nid008641: as well as authorized officials of other agencies, both domestic and foreign.
nid008641: By using this system, the user consents to such interception, monitoring,
nid008641: recording, copying, auditing, inspection, and disclosure at the discretion
nid008641: of authorized site or Department of Energy personnel.
nid008641: 
nid008641: Unauthorized or improper use of this system may result in administrative
nid008641: disciplinary action and civil and criminal penalties. By continuing to use
nid008641: this system you indicate your awareness of and consent to these terms and
nid008641: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008641: stated in this warning.
nid008641: 
nid008641: *****************************************************************************
nid008641: 
nid008641: Login connection to host x1405c6s0b0n1:
nid008641: 
nid008493: ***************************************************************************
nid008493:                           NOTICE TO USERS
nid008493: 
nid008493: Lawrence Berkeley National Laboratory operates this computer system under 
nid008493: contract to the U.S. Department of Energy.  This computer system is the 
nid008493: property of the United States Government and is for authorized use only.
nid008493: Users (authorized or unauthorized) have no explicit or implicit 
nid008493: expectation of privacy.
nid008493: 
nid008493: Any or all uses of this system and all files on this system may be
nid008493: intercepted, monitored, recorded, copied, audited, inspected, and disclosed
nid008493: to authorized site, Department of Energy, and law enforcement personnel,
nid008493: as well as authorized officials of other agencies, both domestic and foreign.
nid008493: By using this system, the user consents to such interception, monitoring,
nid008493: recording, copying, auditing, inspection, and disclosure at the discretion
nid008493: of authorized site or Department of Energy personnel.
nid008493: 
nid008493: Unauthorized or improper use of this system may result in administrative
nid008493: disciplinary action and civil and criminal penalties. By continuing to use
nid008493: this system you indicate your awareness of and consent to these terms and
nid008493: conditions of use. LOG OFF IMMEDIATELY if you do not agree to the conditions
nid008493: stated in this warning.
nid008493: 
nid008493: *****************************************************************************
nid008493: 
nid008493: Login connection to host x1405c1s3b0n1:
nid008493: 
nid008276: [2024-10-10 07:26:57,916] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008276: [2024-10-10 07:26:59,870] [INFO] [launch.py:138:main] 0 NCCL_NET_GDR_LEVEL=PHB
nid008276: [2024-10-10 07:26:59,870] [INFO] [launch.py:138:main] 0 NCCL_SOCKET_IFNAME=hsn
nid008276: [2024-10-10 07:26:59,870] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008276: [2024-10-10 07:26:59,870] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=0
nid008276: [2024-10-10 07:26:59,870] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008276: [2024-10-10 07:26:59,870] [INFO] [launch.py:163:main] dist_world_size=128
nid008276: [2024-10-10 07:26:59,870] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008637: [2024-10-10 07:27:00,230] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008301: [2024-10-10 07:27:00,667] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008677: [2024-10-10 07:27:01,328] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008409: [2024-10-10 07:27:01,474] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008393: [2024-10-10 07:27:01,481] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008385: [2024-10-10 07:27:01,704] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008276: [2024-10-10 07:27:01,811] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008276: [2024-10-10 07:27:01,815] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008276: [2024-10-10 07:27:01,818] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008276: [2024-10-10 07:27:01,818] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008412: [2024-10-10 07:27:02,113] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008333: [2024-10-10 07:27:02,175] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008493: [2024-10-10 07:27:02,176] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008616: [2024-10-10 07:27:02,234] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008492: [2024-10-10 07:27:02,296] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008421: [2024-10-10 07:27:02,438] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008476: [2024-10-10 07:27:02,465] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008453: [2024-10-10 07:27:02,570] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008641: [2024-10-10 07:27:02,583] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008336: [2024-10-10 07:27:02,587] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008636: [2024-10-10 07:27:02,587] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008456: [2024-10-10 07:27:02,597] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008681: [2024-10-10 07:27:02,602] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008392: [2024-10-10 07:27:02,615] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008304: [2024-10-10 07:27:02,665] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008640: [2024-10-10 07:27:02,683] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008620: [2024-10-10 07:27:02,761] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008420: [2024-10-10 07:27:02,781] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008613: [2024-10-10 07:27:03,008] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008684: [2024-10-10 07:27:03,467] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008680: [2024-10-10 07:27:03,859] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008337: [2024-10-10 07:27:03,999] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008617: [2024-10-10 07:27:04,114] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008637: [2024-10-10 07:27:04,124] [INFO] [launch.py:138:main] 25 NCCL_NET_GDR_LEVEL=PHB
nid008637: [2024-10-10 07:27:04,124] [INFO] [launch.py:138:main] 25 NCCL_SOCKET_IFNAME=hsn
nid008637: [2024-10-10 07:27:04,124] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008637: [2024-10-10 07:27:04,124] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=25
nid008637: [2024-10-10 07:27:04,124] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008637: [2024-10-10 07:27:04,124] [INFO] [launch.py:163:main] dist_world_size=128
nid008637: [2024-10-10 07:27:04,124] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008301: [2024-10-10 07:27:04,607] [INFO] [launch.py:138:main] 1 NCCL_NET_GDR_LEVEL=PHB
nid008301: [2024-10-10 07:27:04,607] [INFO] [launch.py:138:main] 1 NCCL_SOCKET_IFNAME=hsn
nid008301: [2024-10-10 07:27:04,607] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008301: [2024-10-10 07:27:04,607] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=1
nid008301: [2024-10-10 07:27:04,607] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008301: [2024-10-10 07:27:04,607] [INFO] [launch.py:163:main] dist_world_size=128
nid008301: [2024-10-10 07:27:04,607] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008389: [2024-10-10 07:27:04,764] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008384: [2024-10-10 07:27:04,887] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008276: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008276: 
nid008276: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008276: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008276: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008276: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008276: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008276: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008276: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008276: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008276: 
nid008276: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008677: [2024-10-10 07:27:05,139] [INFO] [launch.py:138:main] 28 NCCL_NET_GDR_LEVEL=PHB
nid008677: [2024-10-10 07:27:05,139] [INFO] [launch.py:138:main] 28 NCCL_SOCKET_IFNAME=hsn
nid008677: [2024-10-10 07:27:05,139] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008677: [2024-10-10 07:27:05,139] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=28
nid008677: [2024-10-10 07:27:05,139] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008677: [2024-10-10 07:27:05,139] [INFO] [launch.py:163:main] dist_world_size=128
nid008677: [2024-10-10 07:27:05,139] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008276: STAGE:2024-10-10 07:27:05 673054:673054 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008276: STAGE:2024-10-10 07:27:05 673055:673055 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008276: STAGE:2024-10-10 07:27:05 673056:673056 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008276: STAGE:2024-10-10 07:27:05 673053:673053 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008409: [2024-10-10 07:27:05,350] [INFO] [launch.py:138:main] 11 NCCL_NET_GDR_LEVEL=PHB
nid008409: [2024-10-10 07:27:05,350] [INFO] [launch.py:138:main] 11 NCCL_SOCKET_IFNAME=hsn
nid008409: [2024-10-10 07:27:05,350] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008409: [2024-10-10 07:27:05,350] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=11
nid008409: [2024-10-10 07:27:05,350] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008409: [2024-10-10 07:27:05,350] [INFO] [launch.py:163:main] dist_world_size=128
nid008409: [2024-10-10 07:27:05,350] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008393: [2024-10-10 07:27:05,376] [INFO] [launch.py:138:main] 10 NCCL_NET_GDR_LEVEL=PHB
nid008393: [2024-10-10 07:27:05,376] [INFO] [launch.py:138:main] 10 NCCL_SOCKET_IFNAME=hsn
nid008393: [2024-10-10 07:27:05,376] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008393: [2024-10-10 07:27:05,376] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=10
nid008393: [2024-10-10 07:27:05,376] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008393: [2024-10-10 07:27:05,376] [INFO] [launch.py:163:main] dist_world_size=128
nid008393: [2024-10-10 07:27:05,376] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008385: [2024-10-10 07:27:05,528] [INFO] [launch.py:138:main] 7 NCCL_NET_GDR_LEVEL=PHB
nid008385: [2024-10-10 07:27:05,529] [INFO] [launch.py:138:main] 7 NCCL_SOCKET_IFNAME=hsn
nid008385: [2024-10-10 07:27:05,529] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008385: [2024-10-10 07:27:05,529] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=7
nid008385: [2024-10-10 07:27:05,529] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008385: [2024-10-10 07:27:05,529] [INFO] [launch.py:163:main] dist_world_size=128
nid008385: [2024-10-10 07:27:05,529] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008493: [2024-10-10 07:27:05,959] [INFO] [launch.py:138:main] 19 NCCL_NET_GDR_LEVEL=PHB
nid008493: [2024-10-10 07:27:05,959] [INFO] [launch.py:138:main] 19 NCCL_SOCKET_IFNAME=hsn
nid008493: [2024-10-10 07:27:05,959] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008493: [2024-10-10 07:27:05,959] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=19
nid008493: [2024-10-10 07:27:05,959] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008493: [2024-10-10 07:27:05,959] [INFO] [launch.py:163:main] dist_world_size=128
nid008493: [2024-10-10 07:27:05,959] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008412: [2024-10-10 07:27:05,970] [INFO] [launch.py:138:main] 12 NCCL_NET_GDR_LEVEL=PHB
nid008412: [2024-10-10 07:27:05,970] [INFO] [launch.py:138:main] 12 NCCL_SOCKET_IFNAME=hsn
nid008412: [2024-10-10 07:27:05,970] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008412: [2024-10-10 07:27:05,970] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=12
nid008412: [2024-10-10 07:27:05,970] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008412: [2024-10-10 07:27:05,970] [INFO] [launch.py:163:main] dist_world_size=128
nid008412: [2024-10-10 07:27:05,970] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008333: [2024-10-10 07:27:06,006] [INFO] [launch.py:138:main] 3 NCCL_NET_GDR_LEVEL=PHB
nid008333: [2024-10-10 07:27:06,006] [INFO] [launch.py:138:main] 3 NCCL_SOCKET_IFNAME=hsn
nid008333: [2024-10-10 07:27:06,006] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008333: [2024-10-10 07:27:06,006] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=3
nid008333: [2024-10-10 07:27:06,006] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008333: [2024-10-10 07:27:06,006] [INFO] [launch.py:163:main] dist_world_size=128
nid008333: [2024-10-10 07:27:06,006] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008616: [2024-10-10 07:27:06,011] [INFO] [launch.py:138:main] 21 NCCL_NET_GDR_LEVEL=PHB
nid008616: [2024-10-10 07:27:06,011] [INFO] [launch.py:138:main] 21 NCCL_SOCKET_IFNAME=hsn
nid008616: [2024-10-10 07:27:06,011] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008616: [2024-10-10 07:27:06,011] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=21
nid008616: [2024-10-10 07:27:06,011] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008616: [2024-10-10 07:27:06,011] [INFO] [launch.py:163:main] dist_world_size=128
nid008616: [2024-10-10 07:27:06,011] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008637: [2024-10-10 07:27:06,107] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008637: [2024-10-10 07:27:06,118] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008492: [2024-10-10 07:27:06,128] [INFO] [launch.py:138:main] 18 NCCL_NET_GDR_LEVEL=PHB
nid008492: [2024-10-10 07:27:06,128] [INFO] [launch.py:138:main] 18 NCCL_SOCKET_IFNAME=hsn
nid008492: [2024-10-10 07:27:06,128] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008492: [2024-10-10 07:27:06,128] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=18
nid008492: [2024-10-10 07:27:06,128] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008492: [2024-10-10 07:27:06,128] [INFO] [launch.py:163:main] dist_world_size=128
nid008492: [2024-10-10 07:27:06,128] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008637: [2024-10-10 07:27:06,130] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008637: [2024-10-10 07:27:06,131] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008476: [2024-10-10 07:27:06,234] [INFO] [launch.py:138:main] 17 NCCL_NET_GDR_LEVEL=PHB
nid008476: [2024-10-10 07:27:06,234] [INFO] [launch.py:138:main] 17 NCCL_SOCKET_IFNAME=hsn
nid008476: [2024-10-10 07:27:06,234] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008476: [2024-10-10 07:27:06,234] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=17
nid008476: [2024-10-10 07:27:06,234] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008476: [2024-10-10 07:27:06,234] [INFO] [launch.py:163:main] dist_world_size=128
nid008476: [2024-10-10 07:27:06,234] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008421: [2024-10-10 07:27:06,305] [INFO] [launch.py:138:main] 14 NCCL_NET_GDR_LEVEL=PHB
nid008421: [2024-10-10 07:27:06,305] [INFO] [launch.py:138:main] 14 NCCL_SOCKET_IFNAME=hsn
nid008421: [2024-10-10 07:27:06,305] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008421: [2024-10-10 07:27:06,305] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=14
nid008421: [2024-10-10 07:27:06,305] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008421: [2024-10-10 07:27:06,305] [INFO] [launch.py:163:main] dist_world_size=128
nid008421: [2024-10-10 07:27:06,305] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008304: [2024-10-10 07:27:06,371] [INFO] [launch.py:138:main] 2 NCCL_NET_GDR_LEVEL=PHB
nid008304: [2024-10-10 07:27:06,371] [INFO] [launch.py:138:main] 2 NCCL_SOCKET_IFNAME=hsn
nid008304: [2024-10-10 07:27:06,371] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008304: [2024-10-10 07:27:06,371] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=2
nid008304: [2024-10-10 07:27:06,371] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008304: [2024-10-10 07:27:06,371] [INFO] [launch.py:163:main] dist_world_size=128
nid008304: [2024-10-10 07:27:06,371] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008681: [2024-10-10 07:27:06,375] [INFO] [launch.py:138:main] 30 NCCL_NET_GDR_LEVEL=PHB
nid008681: [2024-10-10 07:27:06,375] [INFO] [launch.py:138:main] 30 NCCL_SOCKET_IFNAME=hsn
nid008681: [2024-10-10 07:27:06,375] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008681: [2024-10-10 07:27:06,375] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=30
nid008681: [2024-10-10 07:27:06,375] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008681: [2024-10-10 07:27:06,375] [INFO] [launch.py:163:main] dist_world_size=128
nid008681: [2024-10-10 07:27:06,375] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008641: [2024-10-10 07:27:06,389] [INFO] [launch.py:138:main] 27 NCCL_NET_GDR_LEVEL=PHB
nid008641: [2024-10-10 07:27:06,389] [INFO] [launch.py:138:main] 27 NCCL_SOCKET_IFNAME=hsn
nid008641: [2024-10-10 07:27:06,389] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008641: [2024-10-10 07:27:06,390] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=27
nid008641: [2024-10-10 07:27:06,390] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008641: [2024-10-10 07:27:06,390] [INFO] [launch.py:163:main] dist_world_size=128
nid008641: [2024-10-10 07:27:06,390] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008276: STAGE:2024-10-10 07:27:06 673056:673056 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:06 673053:673053 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008276: 
nid008276: STAGE:2024-10-10 07:27:06 673055:673055 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008276: STAGE:2024-10-10 07:27:06 673054:673054 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008276: NeoXArgs.configure_distributed_args() using world size: 128 and model-parallel size: 4 
nid008276: > building GPT2BPETokenizer tokenizer ...
nid008453: [2024-10-10 07:27:06,447] [INFO] [launch.py:138:main] 15 NCCL_NET_GDR_LEVEL=PHB
nid008453: [2024-10-10 07:27:06,447] [INFO] [launch.py:138:main] 15 NCCL_SOCKET_IFNAME=hsn
nid008453: [2024-10-10 07:27:06,447] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008453: [2024-10-10 07:27:06,447] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=15
nid008453: [2024-10-10 07:27:06,447] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008453: [2024-10-10 07:27:06,447] [INFO] [launch.py:163:main] dist_world_size=128
nid008453: [2024-10-10 07:27:06,447] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008276:  > padded vocab (size: 50257) with 431 dummy tokens (new size: 50688)
nid008456: [2024-10-10 07:27:06,466] [INFO] [launch.py:138:main] 16 NCCL_NET_GDR_LEVEL=PHB
nid008456: [2024-10-10 07:27:06,466] [INFO] [launch.py:138:main] 16 NCCL_SOCKET_IFNAME=hsn
nid008456: [2024-10-10 07:27:06,466] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008456: [2024-10-10 07:27:06,466] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=16
nid008456: [2024-10-10 07:27:06,466] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008456: [2024-10-10 07:27:06,466] [INFO] [launch.py:163:main] dist_world_size=128
nid008456: [2024-10-10 07:27:06,466] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008336: [2024-10-10 07:27:06,472] [INFO] [launch.py:138:main] 4 NCCL_NET_GDR_LEVEL=PHB
nid008336: [2024-10-10 07:27:06,472] [INFO] [launch.py:138:main] 4 NCCL_SOCKET_IFNAME=hsn
nid008336: [2024-10-10 07:27:06,472] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008336: [2024-10-10 07:27:06,472] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=4
nid008336: [2024-10-10 07:27:06,472] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008336: [2024-10-10 07:27:06,472] [INFO] [launch.py:163:main] dist_world_size=128
nid008336: [2024-10-10 07:27:06,472] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008636: [2024-10-10 07:27:06,490] [INFO] [launch.py:138:main] 24 NCCL_NET_GDR_LEVEL=PHB
nid008636: [2024-10-10 07:27:06,490] [INFO] [launch.py:138:main] 24 NCCL_SOCKET_IFNAME=hsn
nid008636: [2024-10-10 07:27:06,490] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008636: [2024-10-10 07:27:06,490] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=24
nid008636: [2024-10-10 07:27:06,490] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008636: [2024-10-10 07:27:06,490] [INFO] [launch.py:163:main] dist_world_size=128
nid008636: [2024-10-10 07:27:06,490] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008392: [2024-10-10 07:27:06,500] [INFO] [launch.py:138:main] 9 NCCL_NET_GDR_LEVEL=PHB
nid008392: [2024-10-10 07:27:06,500] [INFO] [launch.py:138:main] 9 NCCL_SOCKET_IFNAME=hsn
nid008392: [2024-10-10 07:27:06,501] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008392: [2024-10-10 07:27:06,501] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=9
nid008392: [2024-10-10 07:27:06,501] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008392: [2024-10-10 07:27:06,501] [INFO] [launch.py:163:main] dist_world_size=128
nid008392: [2024-10-10 07:27:06,501] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008620: [2024-10-10 07:27:06,547] [INFO] [launch.py:138:main] 23 NCCL_NET_GDR_LEVEL=PHB
nid008620: [2024-10-10 07:27:06,548] [INFO] [launch.py:138:main] 23 NCCL_SOCKET_IFNAME=hsn
nid008620: [2024-10-10 07:27:06,548] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008620: [2024-10-10 07:27:06,548] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=23
nid008620: [2024-10-10 07:27:06,548] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008620: [2024-10-10 07:27:06,548] [INFO] [launch.py:163:main] dist_world_size=128
nid008620: [2024-10-10 07:27:06,548] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008301: [2024-10-10 07:27:06,639] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008301: [2024-10-10 07:27:06,666] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008301: [2024-10-10 07:27:06,672] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008301: [2024-10-10 07:27:06,673] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008420: [2024-10-10 07:27:06,714] [INFO] [launch.py:138:main] 13 NCCL_NET_GDR_LEVEL=PHB
nid008420: [2024-10-10 07:27:06,714] [INFO] [launch.py:138:main] 13 NCCL_SOCKET_IFNAME=hsn
nid008420: [2024-10-10 07:27:06,714] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008420: [2024-10-10 07:27:06,714] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=13
nid008420: [2024-10-10 07:27:06,714] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008420: [2024-10-10 07:27:06,714] [INFO] [launch.py:163:main] dist_world_size=128
nid008420: [2024-10-10 07:27:06,714] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008276: > setting up tensorboard ...
nid008640: [2024-10-10 07:27:06,742] [INFO] [launch.py:138:main] 26 NCCL_NET_GDR_LEVEL=PHB
nid008640: [2024-10-10 07:27:06,742] [INFO] [launch.py:138:main] 26 NCCL_SOCKET_IFNAME=hsn
nid008640: [2024-10-10 07:27:06,742] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008640: [2024-10-10 07:27:06,742] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=26
nid008640: [2024-10-10 07:27:06,742] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008640: [2024-10-10 07:27:06,742] [INFO] [launch.py:163:main] dist_world_size=128
nid008640: [2024-10-10 07:27:06,742] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008276: [2024-10-10 07:27:06,834] [INFO] [comm.py:637:init_distributed] cdb=None
nid008613: [2024-10-10 07:27:06,936] [INFO] [launch.py:138:main] 20 NCCL_NET_GDR_LEVEL=PHB
nid008613: [2024-10-10 07:27:06,936] [INFO] [launch.py:138:main] 20 NCCL_SOCKET_IFNAME=hsn
nid008613: [2024-10-10 07:27:06,936] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008613: [2024-10-10 07:27:06,936] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=20
nid008613: [2024-10-10 07:27:06,936] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008613: [2024-10-10 07:27:06,936] [INFO] [launch.py:163:main] dist_world_size=128
nid008613: [2024-10-10 07:27:06,936] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008276: [2024-10-10 07:27:06,992] [INFO] [comm.py:637:init_distributed] cdb=None
nid008276: Loading extension module scaled_upper_triang_masked_softmax_cuda...
nid008276: [2024-10-10 07:27:07,112] [INFO] [comm.py:637:init_distributed] cdb=None
nid008276: Loading extension module scaled_masked_softmax_cuda...
nid008677: [2024-10-10 07:27:07,180] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008677: [2024-10-10 07:27:07,184] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008677: [2024-10-10 07:27:07,191] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008677: [2024-10-10 07:27:07,191] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008276: Detected CUDA files, patching ldflags
nid008276: Emitting ninja build file /pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/fused_kernels/build/build.ninja...
nid008276: Building extension module fused_rotary_positional_embedding...
nid008276: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
nid008276: ninja: no work to do.
nid008276: Loading extension module fused_rotary_positional_embedding...
nid008276: > initializing torch distributed ...
nid008276: [2024-10-10 07:27:07,213] [INFO] [comm.py:637:init_distributed] cdb=None
nid008276: [2024-10-10 07:27:07,213] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
nid008684: [2024-10-10 07:27:07,352] [INFO] [launch.py:138:main] 31 NCCL_NET_GDR_LEVEL=PHB
nid008684: [2024-10-10 07:27:07,352] [INFO] [launch.py:138:main] 31 NCCL_SOCKET_IFNAME=hsn
nid008684: [2024-10-10 07:27:07,352] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008684: [2024-10-10 07:27:07,352] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=31
nid008684: [2024-10-10 07:27:07,352] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008684: [2024-10-10 07:27:07,352] [INFO] [launch.py:163:main] dist_world_size=128
nid008684: [2024-10-10 07:27:07,352] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008409: [2024-10-10 07:27:07,391] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008409: [2024-10-10 07:27:07,398] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008409: [2024-10-10 07:27:07,401] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008409: [2024-10-10 07:27:07,401] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008393: [2024-10-10 07:27:07,419] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008393: [2024-10-10 07:27:07,427] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008393: [2024-10-10 07:27:07,432] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008393: [2024-10-10 07:27:07,434] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008385: [2024-10-10 07:27:07,562] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008385: [2024-10-10 07:27:07,582] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008385: [2024-10-10 07:27:07,590] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008385: [2024-10-10 07:27:07,604] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008680: [2024-10-10 07:27:07,768] [INFO] [launch.py:138:main] 29 NCCL_NET_GDR_LEVEL=PHB
nid008680: [2024-10-10 07:27:07,768] [INFO] [launch.py:138:main] 29 NCCL_SOCKET_IFNAME=hsn
nid008680: [2024-10-10 07:27:07,768] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008680: [2024-10-10 07:27:07,768] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=29
nid008680: [2024-10-10 07:27:07,768] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008680: [2024-10-10 07:27:07,768] [INFO] [launch.py:163:main] dist_world_size=128
nid008680: [2024-10-10 07:27:07,768] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008337: [2024-10-10 07:27:07,939] [INFO] [launch.py:138:main] 5 NCCL_NET_GDR_LEVEL=PHB
nid008337: [2024-10-10 07:27:07,939] [INFO] [launch.py:138:main] 5 NCCL_SOCKET_IFNAME=hsn
nid008337: [2024-10-10 07:27:07,939] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008337: [2024-10-10 07:27:07,939] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=5
nid008337: [2024-10-10 07:27:07,939] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008337: [2024-10-10 07:27:07,939] [INFO] [launch.py:163:main] dist_world_size=128
nid008337: [2024-10-10 07:27:07,939] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008493: [2024-10-10 07:27:07,992] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008617: [2024-10-10 07:27:08,010] [INFO] [launch.py:138:main] 22 NCCL_NET_GDR_LEVEL=PHB
nid008617: [2024-10-10 07:27:08,010] [INFO] [launch.py:138:main] 22 NCCL_SOCKET_IFNAME=hsn
nid008617: [2024-10-10 07:27:08,010] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008617: [2024-10-10 07:27:08,010] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=22
nid008617: [2024-10-10 07:27:08,010] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008617: [2024-10-10 07:27:08,010] [INFO] [launch.py:163:main] dist_world_size=128
nid008617: [2024-10-10 07:27:08,010] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008493: [2024-10-10 07:27:08,045] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008493: [2024-10-10 07:27:08,053] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008493: [2024-10-10 07:27:08,053] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008616: [2024-10-10 07:27:08,058] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008412: [2024-10-10 07:27:08,069] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008333: [2024-10-10 07:27:08,070] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008616: [2024-10-10 07:27:08,070] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008616: [2024-10-10 07:27:08,075] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008616: [2024-10-10 07:27:08,077] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008333: [2024-10-10 07:27:08,099] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008333: [2024-10-10 07:27:08,100] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008333: [2024-10-10 07:27:08,102] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008412: [2024-10-10 07:27:08,104] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008412: [2024-10-10 07:27:08,106] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008412: [2024-10-10 07:27:08,109] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008492: [2024-10-10 07:27:08,163] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008492: [2024-10-10 07:27:08,185] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008492: [2024-10-10 07:27:08,190] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008492: [2024-10-10 07:27:08,192] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008476: [2024-10-10 07:27:08,269] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008476: [2024-10-10 07:27:08,297] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008476: [2024-10-10 07:27:08,300] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008476: [2024-10-10 07:27:08,304] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008421: [2024-10-10 07:27:08,326] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008421: [2024-10-10 07:27:08,364] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008421: [2024-10-10 07:27:08,367] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008421: [2024-10-10 07:27:08,371] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008304: [2024-10-10 07:27:08,402] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008304: [2024-10-10 07:27:08,444] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008304: [2024-10-10 07:27:08,447] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008304: [2024-10-10 07:27:08,451] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008681: [2024-10-10 07:27:08,469] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008453: [2024-10-10 07:27:08,473] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008641: [2024-10-10 07:27:08,482] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008641: [2024-10-10 07:27:08,486] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008641: [2024-10-10 07:27:08,492] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008641: [2024-10-10 07:27:08,493] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008681: [2024-10-10 07:27:08,506] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008681: [2024-10-10 07:27:08,510] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008681: [2024-10-10 07:27:08,511] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008456: [2024-10-10 07:27:08,514] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008453: [2024-10-10 07:27:08,518] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008453: [2024-10-10 07:27:08,523] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008453: [2024-10-10 07:27:08,525] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008456: [2024-10-10 07:27:08,544] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008456: [2024-10-10 07:27:08,548] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008456: [2024-10-10 07:27:08,551] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008392: [2024-10-10 07:27:08,556] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008392: [2024-10-10 07:27:08,560] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008336: [2024-10-10 07:27:08,563] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008636: [2024-10-10 07:27:08,565] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008392: [2024-10-10 07:27:08,567] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008392: [2024-10-10 07:27:08,571] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008336: [2024-10-10 07:27:08,577] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008336: [2024-10-10 07:27:08,579] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008336: [2024-10-10 07:27:08,583] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008636: [2024-10-10 07:27:08,588] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008636: [2024-10-10 07:27:08,589] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008620: [2024-10-10 07:27:08,590] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008636: [2024-10-10 07:27:08,593] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008620: [2024-10-10 07:27:08,602] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008620: [2024-10-10 07:27:08,607] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008620: [2024-10-10 07:27:08,609] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008389: [2024-10-10 07:27:08,630] [INFO] [launch.py:138:main] 8 NCCL_NET_GDR_LEVEL=PHB
nid008389: [2024-10-10 07:27:08,630] [INFO] [launch.py:138:main] 8 NCCL_SOCKET_IFNAME=hsn
nid008389: [2024-10-10 07:27:08,630] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008389: [2024-10-10 07:27:08,631] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=8
nid008389: [2024-10-10 07:27:08,631] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008389: [2024-10-10 07:27:08,631] [INFO] [launch.py:163:main] dist_world_size=128
nid008389: [2024-10-10 07:27:08,631] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008420: [2024-10-10 07:27:08,757] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008384: [2024-10-10 07:27:08,762] [INFO] [launch.py:138:main] 6 NCCL_NET_GDR_LEVEL=PHB
nid008384: [2024-10-10 07:27:08,762] [INFO] [launch.py:138:main] 6 NCCL_SOCKET_IFNAME=hsn
nid008384: [2024-10-10 07:27:08,763] [INFO] [launch.py:145:main] WORLD INFO DICT: {'nid008276': [0, 1, 2, 3], 'nid008301': [0, 1, 2, 3], 'nid008304': [0, 1, 2, 3], 'nid008333': [0, 1, 2, 3], 'nid008336': [0, 1, 2, 3], 'nid008337': [0, 1, 2, 3], 'nid008384': [0, 1, 2, 3], 'nid008385': [0, 1, 2, 3], 'nid008389': [0, 1, 2, 3], 'nid008392': [0, 1, 2, 3], 'nid008393': [0, 1, 2, 3], 'nid008409': [0, 1, 2, 3], 'nid008412': [0, 1, 2, 3], 'nid008420': [0, 1, 2, 3], 'nid008421': [0, 1, 2, 3], 'nid008453': [0, 1, 2, 3], 'nid008456': [0, 1, 2, 3], 'nid008476': [0, 1, 2, 3], 'nid008492': [0, 1, 2, 3], 'nid008493': [0, 1, 2, 3], 'nid008613': [0, 1, 2, 3], 'nid008616': [0, 1, 2, 3], 'nid008617': [0, 1, 2, 3], 'nid008620': [0, 1, 2, 3], 'nid008636': [0, 1, 2, 3], 'nid008637': [0, 1, 2, 3], 'nid008640': [0, 1, 2, 3], 'nid008641': [0, 1, 2, 3], 'nid008677': [0, 1, 2, 3], 'nid008680': [0, 1, 2, 3], 'nid008681': [0, 1, 2, 3], 'nid008684': [0, 1, 2, 3]}
nid008384: [2024-10-10 07:27:08,763] [INFO] [launch.py:151:main] nnodes=32, num_local_procs=4, node_rank=6
nid008384: [2024-10-10 07:27:08,763] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'nid008276': [0, 1, 2, 3], 'nid008301': [4, 5, 6, 7], 'nid008304': [8, 9, 10, 11], 'nid008333': [12, 13, 14, 15], 'nid008336': [16, 17, 18, 19], 'nid008337': [20, 21, 22, 23], 'nid008384': [24, 25, 26, 27], 'nid008385': [28, 29, 30, 31], 'nid008389': [32, 33, 34, 35], 'nid008392': [36, 37, 38, 39], 'nid008393': [40, 41, 42, 43], 'nid008409': [44, 45, 46, 47], 'nid008412': [48, 49, 50, 51], 'nid008420': [52, 53, 54, 55], 'nid008421': [56, 57, 58, 59], 'nid008453': [60, 61, 62, 63], 'nid008456': [64, 65, 66, 67], 'nid008476': [68, 69, 70, 71], 'nid008492': [72, 73, 74, 75], 'nid008493': [76, 77, 78, 79], 'nid008613': [80, 81, 82, 83], 'nid008616': [84, 85, 86, 87], 'nid008617': [88, 89, 90, 91], 'nid008620': [92, 93, 94, 95], 'nid008636': [96, 97, 98, 99], 'nid008637': [100, 101, 102, 103], 'nid008640': [104, 105, 106, 107], 'nid008641': [108, 109, 110, 111], 'nid008677': [112, 113, 114, 115], 'nid008680': [116, 117, 118, 119], 'nid008681': [120, 121, 122, 123], 'nid008684': [124, 125, 126, 127]})
nid008384: [2024-10-10 07:27:08,763] [INFO] [launch.py:163:main] dist_world_size=128
nid008384: [2024-10-10 07:27:08,763] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
nid008640: [2024-10-10 07:27:08,784] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008420: [2024-10-10 07:27:08,796] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008640: [2024-10-10 07:27:08,801] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008420: [2024-10-10 07:27:08,803] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008640: [2024-10-10 07:27:08,805] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008420: [2024-10-10 07:27:08,807] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008640: [2024-10-10 07:27:08,808] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008613: [2024-10-10 07:27:08,948] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008613: [2024-10-10 07:27:08,986] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008613: [2024-10-10 07:27:08,992] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008613: [2024-10-10 07:27:08,993] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008684: [2024-10-10 07:27:09,388] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008684: [2024-10-10 07:27:09,414] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008684: [2024-10-10 07:27:09,420] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008684: [2024-10-10 07:27:09,433] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008680: [2024-10-10 07:27:09,795] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008680: [2024-10-10 07:27:09,821] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008680: [2024-10-10 07:27:09,827] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008680: [2024-10-10 07:27:09,828] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008337: [2024-10-10 07:27:09,947] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008637: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008637: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008637: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008637: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008337: [2024-10-10 07:27:09,951] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008637: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008637: 
nid008637: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008637: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008637: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008637: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008637: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008637: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008337: [2024-10-10 07:27:09,953] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008337: [2024-10-10 07:27:09,957] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008617: [2024-10-10 07:27:10,044] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008617: [2024-10-10 07:27:10,065] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008617: [2024-10-10 07:27:10,070] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008617: [2024-10-10 07:27:10,072] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008637: STAGE:2024-10-10 07:27:10 85848:85848 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008637: STAGE:2024-10-10 07:27:10 85846:85846 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008637: STAGE:2024-10-10 07:27:10 85849:85849 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008637: STAGE:2024-10-10 07:27:10 85847:85847 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008389: [2024-10-10 07:27:10,642] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008301: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008301: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008301: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008301: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008301: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008301: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008301: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008301: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008301: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008301: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008301: 
nid008301: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008389: [2024-10-10 07:27:10,705] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008389: [2024-10-10 07:27:10,726] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008389: [2024-10-10 07:27:10,730] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008301: STAGE:2024-10-10 07:27:10 1858798:1858798 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008301: STAGE:2024-10-10 07:27:10 1858796:1858796 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008301: STAGE:2024-10-10 07:27:10 1858795:1858795 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008301: STAGE:2024-10-10 07:27:10 1858797:1858797 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008384: [2024-10-10 07:27:10,869] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008384: [2024-10-10 07:27:10,887] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008384: [2024-10-10 07:27:10,891] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008384: [2024-10-10 07:27:10,891] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nid008677: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008677: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008677: 
nid008677: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008677: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008677: 
nid008677: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008677: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008677: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008677: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008677: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008677: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008677: STAGE:2024-10-10 07:27:11 1817346:1817346 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008677: STAGE:2024-10-10 07:27:11 1817345:1817345 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008677: STAGE:2024-10-10 07:27:11 1817344:1817344 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008677: STAGE:2024-10-10 07:27:11 1817347:1817347 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008409: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008409: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008409: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008409: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008409: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008409: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008409: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008409: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008409: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008409: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008409: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008409: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008637: STAGE:2024-10-10 07:27:11 85846:85846 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:11 85849:85849 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008637: 
nid008637: STAGE:2024-10-10 07:27:11 85848:85848 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:11 85847:85847 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008637: 
nid008393: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008393: 
nid008393: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008393: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008393: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008393: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008393: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008393: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008393: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008393: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008393: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008393: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008409: STAGE:2024-10-10 07:27:11 2095578:2095578 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:11 2095579:2095579 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008409: 
nid008409: STAGE:2024-10-10 07:27:11 2095576:2095576 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008409: STAGE:2024-10-10 07:27:11 2095577:2095577 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008385: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008385: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008385: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008385: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008385: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008385: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008385: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008385: 
nid008385: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008385: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008385: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008385: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008393: STAGE:2024-10-10 07:27:11 408892:408892 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008393: STAGE:2024-10-10 07:27:11 408894:408894 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008393: STAGE:2024-10-10 07:27:11 408895:408895 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008393: STAGE:2024-10-10 07:27:11 408893:408893 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008637: [2024-10-10 07:27:11,492] [INFO] [comm.py:637:init_distributed] cdb=None
nid008385: STAGE:2024-10-10 07:27:11 951676:951676 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:11 951675:951675 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:11 951677:951677 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008385: 
nid008385: 
nid008385: STAGE:2024-10-10 07:27:11 951678:951678 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008637: [2024-10-10 07:27:11,701] [INFO] [comm.py:637:init_distributed] cdb=None
nid008333: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008333: 
nid008333: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008333: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008333: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008333: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008333: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008333: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008333: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008333: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008333: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008333: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008637: [2024-10-10 07:27:11,839] [INFO] [comm.py:637:init_distributed] cdb=None
nid008493: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008493: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008493: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008493: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008493: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008493: 
nid008493: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008493: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008493: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008493: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008493: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008493: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008637: [2024-10-10 07:27:11,878] [INFO] [comm.py:637:init_distributed] cdb=None
nid008301: STAGE:2024-10-10 07:27:11 1858798:1858798 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008301: STAGE:2024-10-10 07:27:11 1858797:1858797 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008301: STAGE:2024-10-10 07:27:11 1858795:1858795 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008301: STAGE:2024-10-10 07:27:11 1858796:1858796 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008492: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008492: 
nid008492: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008492: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008492: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008492: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008492: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008492: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008492: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008492: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008492: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008492: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008412: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008412: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008412: 
nid008412: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008412: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008412: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008412: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008412: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008412: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008412: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008412: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008412: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008476: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008476: 
nid008476: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008476: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008476: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008476: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008476: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008476: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008476: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008476: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008476: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008476: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008493: STAGE:2024-10-10 07:27:12 1048558:1048558 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 1048559:1048559 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008493: 
nid008493: STAGE:2024-10-10 07:27:12 1048560:1048560 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008493: STAGE:2024-10-10 07:27:12 1048561:1048561 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008333: STAGE:2024-10-10 07:27:12 1501784:1501784 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 1501783:1501783 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008333: STAGE:2024-10-10 07:27:12 1501786:1501786 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008333: 
nid008616: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008616: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008616: 
nid008616: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008616: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008616: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008616: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008616: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008616: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008616: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008616: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008616: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008333: STAGE:2024-10-10 07:27:12 1501785:1501785 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008492: STAGE:2024-10-10 07:27:12 2172976:2172976 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008492: STAGE:2024-10-10 07:27:12 2172977:2172977 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008492: STAGE:2024-10-10 07:27:12 2172975:2172975 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008492: STAGE:2024-10-10 07:27:12 2172974:2172974 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008677: STAGE:2024-10-10 07:27:12 1817346:1817346 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:12 1817347:1817347 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008677: 
nid008677: STAGE:2024-10-10 07:27:12 1817345:1817345 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008677: STAGE:2024-10-10 07:27:12 1817344:1817344 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008412: STAGE:2024-10-10 07:27:12 1665340:1665340 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 1665338:1665338 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008412: 
nid008412: STAGE:2024-10-10 07:27:12 1665339:1665339 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008412: STAGE:2024-10-10 07:27:12 1665341:1665341 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008476: STAGE:2024-10-10 07:27:12 1465816:1465816 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008476: STAGE:2024-10-10 07:27:12 1465818:1465818 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008476: STAGE:2024-10-10 07:27:12 1465815:1465815 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008476: STAGE:2024-10-10 07:27:12 1465817:1465817 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008304: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008304: 
nid008304: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008304: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008304: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008304: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008304: 
nid008304: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008304: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008304: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008304: 
nid008304: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008421: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008421: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008421: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008421: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008421: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008421: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008421: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008421: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008421: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008421: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008421: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008421: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008616: STAGE:2024-10-10 07:27:12 1232273:1232273 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 1232274:1232274 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008616: 
nid008616: STAGE:2024-10-10 07:27:12 1232272:1232272 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008616: STAGE:2024-10-10 07:27:12 1232271:1232271 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008681: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008681: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008681: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008681: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008641: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008641: 
nid008641: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008641: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008681: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008681: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008681: 
nid008681: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008681: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008681: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008681: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008681: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008641: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008641: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008641: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008641: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008641: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008641: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008641: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008641: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008453: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008453: 
nid008453: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008453: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008453: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008453: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008453: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008453: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008453: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008453: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008453: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008453: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008304: STAGE:2024-10-10 07:27:12 1377566:1377566 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 1377569:1377569 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008304: 
nid008304: STAGE:2024-10-10 07:27:12 1377568:1377568 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008304: STAGE:2024-10-10 07:27:12 1377567:1377567 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008421: STAGE:2024-10-10 07:27:12 2115306:2115306 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 2115308:2115308 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008421: 
nid008421: STAGE:2024-10-10 07:27:12 2115309:2115309 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008421: STAGE:2024-10-10 07:27:12 2115307:2115307 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008301: [2024-10-10 07:27:12,305] [INFO] [comm.py:637:init_distributed] cdb=None
nid008336: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008336: 
nid008336: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008336: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008336: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008336: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008336: 
nid008336: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008336: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008336: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008336: 
nid008336: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008409: STAGE:2024-10-10 07:27:12 2095579:2095579 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008409: STAGE:2024-10-10 07:27:12 2095578:2095578 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:12 2095577:2095577 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008409: 
nid008409: STAGE:2024-10-10 07:27:12 2095576:2095576 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008392: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008392: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008392: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008392: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008392: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008392: 
nid008392: 
nid008392: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008392: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transferFor s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008392: 
nid008392: 
nid008392: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008456: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008456: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008456: 
nid008456: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008456: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008456: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008456: 
nid008456: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008456: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008456: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008456: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008456: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008681: STAGE:2024-10-10 07:27:12 112072:112072 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 112071:112071 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008681: 
nid008681: STAGE:2024-10-10 07:27:12 112070:112070 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008681: STAGE:2024-10-10 07:27:12 112069:112069 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008453: STAGE:2024-10-10 07:27:12 441994:441994 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 441992:441992 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 441993:441993 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008453: 
nid008453: STAGE:2024-10-10 07:27:12 441995:441995 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008453: 
nid008641: STAGE:2024-10-10 07:27:12 60003:60003 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 60001:60001 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008641: 
nid008641: STAGE:2024-10-10 07:27:12 60004:60004 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008641: STAGE:2024-10-10 07:27:12 60002:60002 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008301: [2024-10-10 07:27:12,407] [INFO] [comm.py:637:init_distributed] cdb=None
nid008636: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008636: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008636: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008636: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008636: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008636: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008636: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008636: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008636: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008636: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008636: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008636: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008620: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008620: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008620: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008620: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008620: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008620: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008620: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008620: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008620: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008620: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008620: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008620: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008336: STAGE:2024-10-10 07:27:12 1201578:1201578 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008336: STAGE:2024-10-10 07:27:12 1201579:1201579 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008336: STAGE:2024-10-10 07:27:12 1201577:1201577 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008336: STAGE:2024-10-10 07:27:12 1201576:1201576 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008385: STAGE:2024-10-10 07:27:12 951676:951676 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008385: STAGE:2024-10-10 07:27:12 951675:951675 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008385: STAGE:2024-10-10 07:27:12 951677:951677 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:12 951678:951678 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008385: 
nid008456: STAGE:2024-10-10 07:27:12 906022:906022 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 906020:906020 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008456: 
nid008456: STAGE:2024-10-10 07:27:12 906021:906021 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008393: STAGE:2024-10-10 07:27:12 408892:408892 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008393: STAGE:2024-10-10 07:27:12 408894:408894 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008393: STAGE:2024-10-10 07:27:12 408895:408895 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008393: STAGE:2024-10-10 07:27:12 408893:408893 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008456: STAGE:2024-10-10 07:27:12 906023:906023 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008636: STAGE:2024-10-10 07:27:12 2052407:2052407 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008636: STAGE:2024-10-10 07:27:12 2052405:2052405 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008636: STAGE:2024-10-10 07:27:12 2052406:2052406 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008636: STAGE:2024-10-10 07:27:12 2052408:2052408 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008620: STAGE:2024-10-10 07:27:12 603026:603026 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 603028:603028 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008620: 
nid008620: STAGE:2024-10-10 07:27:12 603027:603027 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008620: STAGE:2024-10-10 07:27:12 603025:603025 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008392: STAGE:2024-10-10 07:27:12 544980:544980 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 544979:544979 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008392: 
nid008392: STAGE:2024-10-10 07:27:12 544982:544982 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008392: STAGE:2024-10-10 07:27:12 544981:544981 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008420: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008420: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008420: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008420: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008420: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008420: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008420: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008420: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008420: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008420: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008420: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008420: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008640: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008640: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008640: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008640: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008640: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008640: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008640: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008640: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008640: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008640: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008640: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008640: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008409: [2024-10-10 07:27:12,659] [INFO] [comm.py:637:init_distributed] cdb=None
nid008613: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008613: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008613: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008613: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008613: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008613: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008613: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008613: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008613: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008613: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008613: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008613: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008640: STAGE:2024-10-10 07:27:12 7597:7597 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 7596:7596 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 7599:7599 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008640: 
nid008640: 
nid008640: STAGE:2024-10-10 07:27:12 7598:7598 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008420: STAGE:2024-10-10 07:27:12 1190036:1190036 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 1190037:1190037 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 1190039:1190039 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008420: 
nid008420: 
nid008420: STAGE:2024-10-10 07:27:12 1190038:1190038 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008613: STAGE:2024-10-10 07:27:12 1337980:1337980 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:12 1337979:1337979 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008613: 
nid008613: STAGE:2024-10-10 07:27:12 1337978:1337978 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008613: STAGE:2024-10-10 07:27:12 1337977:1337977 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008493: STAGE:2024-10-10 07:27:12 1048561:1048561 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:12 1048559:1048559 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008493: STAGE:2024-10-10 07:27:12 1048558:1048558 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:12 1048560:1048560 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008493: 
nid008493: 
nid008385: [2024-10-10 07:27:12,927] [INFO] [comm.py:637:init_distributed] cdb=None
nid008476: STAGE:2024-10-10 07:27:13 1465816:1465816 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 1465817:1465817 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 1465815:1465815 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008476: STAGE:2024-10-10 07:27:13 1465818:1465818 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008476: 
nid008476: 
nid008333: STAGE:2024-10-10 07:27:13 1501785:1501785 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 1501783:1501783 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 1501784:1501784 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008333: 
nid008333: 
nid008333: STAGE:2024-10-10 07:27:13 1501786:1501786 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008492: STAGE:2024-10-10 07:27:13 2172975:2172975 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 2172976:2172976 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008492: 
nid008492: STAGE:2024-10-10 07:27:13 2172974:2172974 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 2172977:2172977 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008492: 
nid008409: [2024-10-10 07:27:13,075] [INFO] [comm.py:637:init_distributed] cdb=None
nid008304: STAGE:2024-10-10 07:27:13 1377566:1377566 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 1377569:1377569 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008304: 
nid008304: STAGE:2024-10-10 07:27:13 1377567:1377567 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008304: STAGE:2024-10-10 07:27:13 1377568:1377568 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008412: STAGE:2024-10-10 07:27:13 1665340:1665340 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 1665338:1665338 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008412: STAGE:2024-10-10 07:27:13 1665341:1665341 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008412: STAGE:2024-10-10 07:27:13 1665339:1665339 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008412: 
nid008385: [2024-10-10 07:27:13,149] [INFO] [comm.py:637:init_distributed] cdb=None
nid008616: STAGE:2024-10-10 07:27:13 1232274:1232274 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 1232273:1232273 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008616: 
nid008616: STAGE:2024-10-10 07:27:13 1232272:1232272 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008616: STAGE:2024-10-10 07:27:13 1232271:1232271 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008684: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008684: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008684: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008684: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008684: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008684: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008421: STAGE:2024-10-10 07:27:13 2115309:2115309 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008421: STAGE:2024-10-10 07:27:13 2115306:2115306 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008421: STAGE:2024-10-10 07:27:13 2115307:2115307 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008421: STAGE:2024-10-10 07:27:13 2115308:2115308 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008409: [2024-10-10 07:27:13,306] [INFO] [comm.py:637:init_distributed] cdb=None
nid008684: STAGE:2024-10-10 07:27:13 2178171:2178171 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008684: STAGE:2024-10-10 07:27:13 2178173:2178173 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008453: STAGE:2024-10-10 07:27:13 441993:441993 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 441995:441995 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008453: STAGE:2024-10-10 07:27:13 441992:441992 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008453: STAGE:2024-10-10 07:27:13 441994:441994 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008453: 
nid008336: STAGE:2024-10-10 07:27:13 1201577:1201577 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 1201579:1201579 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008336: STAGE:2024-10-10 07:27:13 1201576:1201576 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008336: STAGE:2024-10-10 07:27:13 1201578:1201578 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008336: 
nid008681: STAGE:2024-10-10 07:27:13 112069:112069 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008681: STAGE:2024-10-10 07:27:13 112071:112071 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 112070:112070 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008681: 
nid008681: STAGE:2024-10-10 07:27:13 112072:112072 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008684: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008684: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008684: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008641: STAGE:2024-10-10 07:27:13 60003:60003 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 60004:60004 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 60001:60001 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008641: STAGE:2024-10-10 07:27:13 60002:60002 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008641: 
nid008641: 
nid008684: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008684: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008684: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008456: STAGE:2024-10-10 07:27:13 906021:906021 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008456: STAGE:2024-10-10 07:27:13 906020:906020 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 906022:906022 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008456: 
nid008456: STAGE:2024-10-10 07:27:13 906023:906023 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008392: STAGE:2024-10-10 07:27:13 544982:544982 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 544981:544981 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008392: 
nid008392: STAGE:2024-10-10 07:27:13 544979:544979 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 544980:544980 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008392: 
nid008636: STAGE:2024-10-10 07:27:13 2052405:2052405 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 2052408:2052408 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008636: 
nid008636: STAGE:2024-10-10 07:27:13 2052406:2052406 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 2052407:2052407 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008636: 
nid008620: STAGE:2024-10-10 07:27:13 603025:603025 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008620: STAGE:2024-10-10 07:27:13 603028:603028 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 603027:603027 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 603026:603026 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008620: 
nid008620: 
nid008684: STAGE:2024-10-10 07:27:13 2178170:2178170 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008684: STAGE:2024-10-10 07:27:13 2178172:2178172 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008420: STAGE:2024-10-10 07:27:13 1190036:1190036 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 1190038:1190038 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008420: STAGE:2024-10-10 07:27:13 1190039:1190039 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008420: 
nid008420: STAGE:2024-10-10 07:27:13 1190037:1190037 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008337: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008337: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008337: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008337: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008337: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008337: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008337: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008337: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008337: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008640: STAGE:2024-10-10 07:27:13 7599:7599 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008640: STAGE:2024-10-10 07:27:13 7598:7598 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008640: STAGE:2024-10-10 07:27:13 7596:7596 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 7597:7597 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008640: 
nid008617: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008617: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008617: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008680: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008680: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008680: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mambaUnable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008680: 
nid008617: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008617: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008680: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008680: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008680: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008617: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008680: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008680: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008680: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008617: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008617: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008680: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008617: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008680: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008617: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008617: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008617: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008337: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008337: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008337: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008337: STAGE:2024-10-10 07:27:13 811122:811122 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008613: STAGE:2024-10-10 07:27:13 1337979:1337979 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008613: STAGE:2024-10-10 07:27:13 1337978:1337978 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 1337977:1337977 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:13 1337980:1337980 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008613: 
nid008613: 
nid008337: STAGE:2024-10-10 07:27:13 811120:811120 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008337: STAGE:2024-10-10 07:27:13 811119:811119 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008493: [2024-10-10 07:27:13,860] [INFO] [comm.py:637:init_distributed] cdb=None
nid008680: STAGE:2024-10-10 07:27:13 1182067:1182067 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008680: STAGE:2024-10-10 07:27:13 1182064:1182064 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008680: STAGE:2024-10-10 07:27:13 1182065:1182065 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008680: STAGE:2024-10-10 07:27:13 1182066:1182066 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008301: [2024-10-10 07:27:13,950] [INFO] [comm.py:637:init_distributed] cdb=None
nid008301: [2024-10-10 07:27:13,950] [INFO] [comm.py:637:init_distributed] cdb=None
nid008617: STAGE:2024-10-10 07:27:13 536588:536588 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:13 536589:536589 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008617: STAGE:2024-10-10 07:27:13 536591:536591 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008617: 
nid008617: STAGE:2024-10-10 07:27:13 536590:536590 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008337: STAGE:2024-10-10 07:27:14 811121:811121 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008392: [2024-10-10 07:27:14,034] [INFO] [comm.py:637:init_distributed] cdb=None
nid008493: [2024-10-10 07:27:14,109] [INFO] [comm.py:637:init_distributed] cdb=None
nid008684: STAGE:2024-10-10 07:27:14 2178171:2178171 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:14 2178173:2178173 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008684: 
nid008304: [2024-10-10 07:27:14,281] [INFO] [comm.py:637:init_distributed] cdb=None
nid008385: [2024-10-10 07:27:14,291] [INFO] [comm.py:637:init_distributed] cdb=None
nid008389: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008389: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008389: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008389: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008389: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008389: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008389: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008389: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008389: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008389: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008389: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008389: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008684: STAGE:2024-10-10 07:27:14 2178172:2178172 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008684: STAGE:2024-10-10 07:27:14 2178170:2178170 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008336: [2024-10-10 07:27:14,461] [INFO] [comm.py:637:init_distributed] cdb=None
nid008389: STAGE:2024-10-10 07:27:14 447739:447739 ActivityProfilerController.cpp:294] Completed Stage: Warm UpSTAGE:2024-10-10 07:27:14 447738:447738 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008389: 
nid008389: STAGE:2024-10-10 07:27:14 447740:447740 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008389: STAGE:2024-10-10 07:27:14 447737:447737 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008453: [2024-10-10 07:27:14,553] [INFO] [comm.py:637:init_distributed] cdb=None
nid008384: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008384: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008384: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008384: Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
nid008384: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008384: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008384: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008384: For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
nid008384: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008384: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008384: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008384: For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
nid008384: STAGE:2024-10-10 07:27:14 175783:175783 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008384: STAGE:2024-10-10 07:27:14 175785:175785 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008384: STAGE:2024-10-10 07:27:14 175786:175786 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008384: STAGE:2024-10-10 07:27:14 175784:175784 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008492: [2024-10-10 07:27:14,698] [INFO] [comm.py:637:init_distributed] cdb=None
nid008385: [2024-10-10 07:27:14,795] [INFO] [comm.py:637:init_distributed] cdb=None
nid008616: [2024-10-10 07:27:14,798] [INFO] [comm.py:637:init_distributed] cdb=None
nid008337: STAGE:2024-10-10 07:27:14 811121:811121 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008337: STAGE:2024-10-10 07:27:14 811119:811119 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:14 811122:811122 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008337: 
nid008337: STAGE:2024-10-10 07:27:14 811120:811120 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008616: [2024-10-10 07:27:14,814] [INFO] [comm.py:637:init_distributed] cdb=None
nid008616: [2024-10-10 07:27:14,814] [INFO] [comm.py:637:init_distributed] cdb=None
nid008616: [2024-10-10 07:27:14,814] [INFO] [comm.py:637:init_distributed] cdb=None
nid008677: [2024-10-10 07:27:14,820] [INFO] [comm.py:637:init_distributed] cdb=None
nid008677: [2024-10-10 07:27:14,820] [INFO] [comm.py:637:init_distributed] cdb=None
nid008677: [2024-10-10 07:27:14,820] [INFO] [comm.py:637:init_distributed] cdb=None
nid008677: [2024-10-10 07:27:14,820] [INFO] [comm.py:637:init_distributed] cdb=None
nid008421: [2024-10-10 07:27:14,910] [INFO] [comm.py:637:init_distributed] cdb=None
nid008617: STAGE:2024-10-10 07:27:14 536591:536591 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:14 536588:536588 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008617: 
nid008617: STAGE:2024-10-10 07:27:14 536590:536590 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008617: STAGE:2024-10-10 07:27:14 536589:536589 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008421: [2024-10-10 07:27:14,921] [INFO] [comm.py:637:init_distributed] cdb=None
nid008421: [2024-10-10 07:27:14,921] [INFO] [comm.py:637:init_distributed] cdb=None
nid008421: [2024-10-10 07:27:14,922] [INFO] [comm.py:637:init_distributed] cdb=None
nid008684: [2024-10-10 07:27:14,926] [INFO] [comm.py:637:init_distributed] cdb=None
nid008684: [2024-10-10 07:27:14,926] [INFO] [comm.py:637:init_distributed] cdb=None
nid008680: STAGE:2024-10-10 07:27:14 1182067:1182067 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:14 1182065:1182065 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008680: 
nid008680: STAGE:2024-10-10 07:27:14 1182066:1182066 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008680: STAGE:2024-10-10 07:27:14 1182064:1182064 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008304: [2024-10-10 07:27:14,992] [INFO] [comm.py:637:init_distributed] cdb=None
nid008336: [2024-10-10 07:27:15,067] [INFO] [comm.py:637:init_distributed] cdb=None
nid008640: [2024-10-10 07:27:15,077] [INFO] [comm.py:637:init_distributed] cdb=None
nid008640: [2024-10-10 07:27:15,077] [INFO] [comm.py:637:init_distributed] cdb=None
nid008640: [2024-10-10 07:27:15,077] [INFO] [comm.py:637:init_distributed] cdb=None
nid008640: [2024-10-10 07:27:15,077] [INFO] [comm.py:637:init_distributed] cdb=None
nid008392: [2024-10-10 07:27:15,151] [INFO] [comm.py:637:init_distributed] cdb=None
nid008492: [2024-10-10 07:27:15,220] [INFO] [comm.py:637:init_distributed] cdb=None
nid008304: [2024-10-10 07:27:15,228] [INFO] [comm.py:637:init_distributed] cdb=None
nid008304: [2024-10-10 07:27:15,228] [INFO] [comm.py:637:init_distributed] cdb=None
nid008456: [2024-10-10 07:27:15,232] [INFO] [comm.py:637:init_distributed] cdb=None
nid008456: [2024-10-10 07:27:15,232] [INFO] [comm.py:637:init_distributed] cdb=None
nid008456: [2024-10-10 07:27:15,232] [INFO] [comm.py:637:init_distributed] cdb=None
nid008456: [2024-10-10 07:27:15,232] [INFO] [comm.py:637:init_distributed] cdb=None
nid008393: [2024-10-10 07:27:15,232] [INFO] [comm.py:637:init_distributed] cdb=None
nid008393: [2024-10-10 07:27:15,232] [INFO] [comm.py:637:init_distributed] cdb=None
nid008393: [2024-10-10 07:27:15,232] [INFO] [comm.py:637:init_distributed] cdb=None
nid008393: [2024-10-10 07:27:15,232] [INFO] [comm.py:637:init_distributed] cdb=None
nid008681: [2024-10-10 07:27:15,322] [INFO] [comm.py:637:init_distributed] cdb=None
nid008681: [2024-10-10 07:27:15,332] [INFO] [comm.py:637:init_distributed] cdb=None
nid008681: [2024-10-10 07:27:15,332] [INFO] [comm.py:637:init_distributed] cdb=None
nid008681: [2024-10-10 07:27:15,332] [INFO] [comm.py:637:init_distributed] cdb=None
nid008389: STAGE:2024-10-10 07:27:15 447738:447738 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:15 447737:447737 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:15 447740:447740 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008389: 
nid008389: 
nid008389: STAGE:2024-10-10 07:27:15 447739:447739 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008336: [2024-10-10 07:27:15,500] [INFO] [comm.py:637:init_distributed] cdb=None
nid008336: [2024-10-10 07:27:15,501] [INFO] [comm.py:637:init_distributed] cdb=None
nid008420: [2024-10-10 07:27:15,501] [INFO] [comm.py:637:init_distributed] cdb=None
nid008337: [2024-10-10 07:27:15,690] [INFO] [comm.py:637:init_distributed] cdb=None
nid008384: STAGE:2024-10-10 07:27:15 175786:175786 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008384: STAGE:2024-10-10 07:27:15 175783:175783 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008384: STAGE:2024-10-10 07:27:15 175784:175784 ActivityProfilerController.cpp:300] Completed Stage: CollectionSTAGE:2024-10-10 07:27:15 175785:175785 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008384: 
nid008389: [2024-10-10 07:27:15,865] [INFO] [comm.py:637:init_distributed] cdb=None
nid008492: [2024-10-10 07:27:15,869] [INFO] [comm.py:637:init_distributed] cdb=None
nid008492: [2024-10-10 07:27:15,870] [INFO] [comm.py:637:init_distributed] cdb=None
nid008613: [2024-10-10 07:27:16,001] [INFO] [comm.py:637:init_distributed] cdb=None
nid008389: [2024-10-10 07:27:16,081] [INFO] [comm.py:637:init_distributed] cdb=None
nid008392: [2024-10-10 07:27:16,084] [INFO] [comm.py:637:init_distributed] cdb=None
nid008392: [2024-10-10 07:27:16,084] [INFO] [comm.py:637:init_distributed] cdb=None
nid008389: [2024-10-10 07:27:16,101] [INFO] [comm.py:637:init_distributed] cdb=None
nid008389: [2024-10-10 07:27:16,101] [INFO] [comm.py:637:init_distributed] cdb=None
nid008384: [2024-10-10 07:27:16,279] [INFO] [comm.py:637:init_distributed] cdb=None
nid008384: [2024-10-10 07:27:16,388] [INFO] [comm.py:637:init_distributed] cdb=None
nid008384: [2024-10-10 07:27:16,419] [INFO] [comm.py:637:init_distributed] cdb=None
nid008384: [2024-10-10 07:27:16,419] [INFO] [comm.py:637:init_distributed] cdb=None
nid008337: [2024-10-10 07:27:16,424] [INFO] [comm.py:637:init_distributed] cdb=None
nid008337: [2024-10-10 07:27:16,424] [INFO] [comm.py:637:init_distributed] cdb=None
nid008337: [2024-10-10 07:27:16,424] [INFO] [comm.py:637:init_distributed] cdb=None
nid008617: [2024-10-10 07:27:16,606] [INFO] [comm.py:637:init_distributed] cdb=None
nid008617: [2024-10-10 07:27:16,706] [INFO] [comm.py:637:init_distributed] cdb=None
nid008617: [2024-10-10 07:27:16,740] [INFO] [comm.py:637:init_distributed] cdb=None
nid008617: [2024-10-10 07:27:16,740] [INFO] [comm.py:637:init_distributed] cdb=None
nid008684: [2024-10-10 07:27:16,745] [INFO] [comm.py:637:init_distributed] cdb=None
nid008684: [2024-10-10 07:27:16,746] [INFO] [comm.py:637:init_distributed] cdb=None
nid008641: [2024-10-10 07:27:16,748] [INFO] [comm.py:637:init_distributed] cdb=None
nid008641: [2024-10-10 07:27:16,877] [INFO] [comm.py:637:init_distributed] cdb=None
nid008613: [2024-10-10 07:27:16,878] [INFO] [comm.py:637:init_distributed] cdb=None
nid008613: [2024-10-10 07:27:16,879] [INFO] [comm.py:637:init_distributed] cdb=None
nid008613: [2024-10-10 07:27:16,879] [INFO] [comm.py:637:init_distributed] cdb=None
nid008641: [2024-10-10 07:27:16,949] [INFO] [comm.py:637:init_distributed] cdb=None
nid008641: [2024-10-10 07:27:16,949] [INFO] [comm.py:637:init_distributed] cdb=None
nid008420: [2024-10-10 07:27:16,950] [INFO] [comm.py:637:init_distributed] cdb=None
nid008420: [2024-10-10 07:27:16,950] [INFO] [comm.py:637:init_distributed] cdb=None
nid008420: [2024-10-10 07:27:17,028] [INFO] [comm.py:637:init_distributed] cdb=None
nid008636: [2024-10-10 07:27:17,144] [INFO] [comm.py:637:init_distributed] cdb=None
nid008636: [2024-10-10 07:27:17,155] [INFO] [comm.py:637:init_distributed] cdb=None
nid008636: [2024-10-10 07:27:17,155] [INFO] [comm.py:637:init_distributed] cdb=None
nid008636: [2024-10-10 07:27:17,158] [INFO] [comm.py:637:init_distributed] cdb=None
nid008493: [2024-10-10 07:27:17,160] [INFO] [comm.py:637:init_distributed] cdb=None
nid008493: [2024-10-10 07:27:17,160] [INFO] [comm.py:637:init_distributed] cdb=None
nid008409: [2024-10-10 07:27:17,160] [INFO] [comm.py:637:init_distributed] cdb=None
nid008680: [2024-10-10 07:27:17,324] [INFO] [comm.py:637:init_distributed] cdb=None
nid008680: [2024-10-10 07:27:17,433] [INFO] [comm.py:637:init_distributed] cdb=None
nid008680: [2024-10-10 07:27:17,464] [INFO] [comm.py:637:init_distributed] cdb=None
nid008680: [2024-10-10 07:27:17,539] [INFO] [comm.py:637:init_distributed] cdb=None
nid008333: [2024-10-10 07:27:17,571] [INFO] [comm.py:637:init_distributed] cdb=None
nid008333: [2024-10-10 07:27:17,571] [INFO] [comm.py:637:init_distributed] cdb=None
nid008333: [2024-10-10 07:27:17,571] [INFO] [comm.py:637:init_distributed] cdb=None
nid008333: [2024-10-10 07:27:17,571] [INFO] [comm.py:637:init_distributed] cdb=None
nid008476: [2024-10-10 07:27:17,657] [INFO] [comm.py:637:init_distributed] cdb=None
nid008476: [2024-10-10 07:27:17,669] [INFO] [comm.py:637:init_distributed] cdb=None
nid008476: [2024-10-10 07:27:17,669] [INFO] [comm.py:637:init_distributed] cdb=None
nid008476: [2024-10-10 07:27:17,672] [INFO] [comm.py:637:init_distributed] cdb=None
nid008453: [2024-10-10 07:27:17,746] [INFO] [comm.py:637:init_distributed] cdb=None
nid008453: [2024-10-10 07:27:17,775] [INFO] [comm.py:637:init_distributed] cdb=None
nid008453: [2024-10-10 07:27:17,776] [INFO] [comm.py:637:init_distributed] cdb=None
nid008412: [2024-10-10 07:27:17,778] [INFO] [comm.py:637:init_distributed] cdb=None
nid008412: [2024-10-10 07:27:17,778] [INFO] [comm.py:637:init_distributed] cdb=None
nid008412: [2024-10-10 07:27:17,778] [INFO] [comm.py:637:init_distributed] cdb=None
nid008412: [2024-10-10 07:27:17,778] [INFO] [comm.py:637:init_distributed] cdb=None
nid008620: [2024-10-10 07:27:17,868] [INFO] [comm.py:637:init_distributed] cdb=None
nid008620: [2024-10-10 07:27:17,882] [INFO] [comm.py:637:init_distributed] cdb=None
nid008620: [2024-10-10 07:27:17,882] [INFO] [comm.py:637:init_distributed] cdb=None
nid008620: [2024-10-10 07:27:17,882] [INFO] [comm.py:637:init_distributed] cdb=None
nid008276: > initializing model parallel with size 4
nid008276: MPU DP: [0, 4, 8, 12]
nid008276: MPU DP: [1, 5, 9, 13]
nid008276: MPU DP: [2, 6, 10, 14]
nid008276: MPU DP: [3, 7, 11, 15]
nid008276: MPU DP: [16, 20, 24, 28]
nid008276: MPU DP: [17, 21, 25, 29]
nid008276: MPU DP: [18, 22, 26, 30]
nid008276: MPU DP: [19, 23, 27, 31]
nid008276: MPU DP: [32, 36, 40, 44]
nid008276: MPU DP: [33, 37, 41, 45]
nid008276: MPU DP: [34, 38, 42, 46]
nid008276: MPU DP: [35, 39, 43, 47]
nid008276: MPU DP: [48, 52, 56, 60]
nid008276: MPU DP: [49, 53, 57, 61]
nid008276: MPU DP: [50, 54, 58, 62]
nid008276: MPU DP: [51, 55, 59, 63]
nid008276: MPU DP: [64, 68, 72, 76]
nid008276: MPU DP: [65, 69, 73, 77]
nid008276: MPU DP: [66, 70, 74, 78]
nid008276: MPU DP: [67, 71, 75, 79]
nid008276: MPU DP: [80, 84, 88, 92]
nid008276: MPU DP: [81, 85, 89, 93]
nid008276: MPU DP: [82, 86, 90, 94]
nid008276: MPU DP: [83, 87, 91, 95]
nid008276: MPU DP: [96, 100, 104, 108]
nid008276: MPU DP: [97, 101, 105, 109]
nid008276: MPU DP: [98, 102, 106, 110]
nid008276: MPU DP: [99, 103, 107, 111]
nid008276: MPU DP: [112, 116, 120, 124]
nid008276: MPU DP: [113, 117, 121, 125]
nid008276: MPU DP: [114, 118, 122, 126]
nid008276: MPU DP: [115, 119, 123, 127]
nid008276: MPU PP: [0, 16, 32, 48, 64, 80, 96, 112]
nid008276: MPU PP: [1, 17, 33, 49, 65, 81, 97, 113]
nid008276: MPU PP: [2, 18, 34, 50, 66, 82, 98, 114]
nid008276: MPU PP: [3, 19, 35, 51, 67, 83, 99, 115]
nid008276: MPU PP: [4, 20, 36, 52, 68, 84, 100, 116]
nid008276: MPU PP: [5, 21, 37, 53, 69, 85, 101, 117]
nid008276: MPU PP: [6, 22, 38, 54, 70, 86, 102, 118]
nid008276: MPU PP: [7, 23, 39, 55, 71, 87, 103, 119]
nid008276: MPU PP: [8, 24, 40, 56, 72, 88, 104, 120]
nid008276: MPU PP: [9, 25, 41, 57, 73, 89, 105, 121]
nid008276: MPU PP: [10, 26, 42, 58, 74, 90, 106, 122]
nid008276: MPU PP: [11, 27, 43, 59, 75, 91, 107, 123]
nid008276: MPU PP: [12, 28, 44, 60, 76, 92, 108, 124]
nid008276: MPU PP: [13, 29, 45, 61, 77, 93, 109, 125]
nid008276: MPU PP: [14, 30, 46, 62, 78, 94, 110, 126]
nid008276: MPU PP: [15, 31, 47, 63, 79, 95, 111, 127]
nid008276: MPU IO: [0, 4, 8, 12, 112, 116, 120, 124]
nid008276: MPU MP: [0, 1, 2, 3]
nid008276: MPU MP: [4, 5, 6, 7]
nid008276: MPU MP: [8, 9, 10, 11]
nid008276: MPU MP: [12, 13, 14, 15]
nid008276: MPU MP: [16, 17, 18, 19]
nid008276: MPU MP: [20, 21, 22, 23]
nid008276: MPU MP: [24, 25, 26, 27]
nid008276: MPU MP: [28, 29, 30, 31]
nid008276: MPU MP: [32, 33, 34, 35]
nid008276: MPU MP: [36, 37, 38, 39]
nid008276: MPU MP: [40, 41, 42, 43]
nid008276: MPU MP: [44, 45, 46, 47]
nid008276: MPU MP: [48, 49, 50, 51]
nid008276: MPU MP: [52, 53, 54, 55]
nid008276: MPU MP: [56, 57, 58, 59]
nid008276: MPU MP: [60, 61, 62, 63]
nid008276: MPU MP: [64, 65, 66, 67]
nid008276: MPU MP: [68, 69, 70, 71]
nid008276: MPU MP: [72, 73, 74, 75]
nid008276: MPU MP: [76, 77, 78, 79]
nid008276: MPU MP: [80, 81, 82, 83]
nid008276: MPU MP: [84, 85, 86, 87]
nid008276: MPU MP: [88, 89, 90, 91]
nid008276: MPU MP: [92, 93, 94, 95]
nid008276: MPU MP: [96, 97, 98, 99]
nid008276: MPU MP: [100, 101, 102, 103]
nid008276: MPU MP: [104, 105, 106, 107]
nid008276: MPU MP: [108, 109, 110, 111]
nid008276: MPU MP: [112, 113, 114, 115]
nid008276: MPU MP: [116, 117, 118, 119]
nid008276: MPU MP: [120, 121, 122, 123]
nid008276: MPU MP: [124, 125, 126, 127]
nid008276: > setting random seeds to 1234 ...
nid008616: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008389: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008412: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008393: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008616: make: Nothing to be done for 'default'.
nid008616: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008409: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008385: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008389: make: Nothing to be done for 'default'.
nid008389: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008276: [2024-10-10 07:27:23,479] [INFO] [checkpointing.py:227:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
nid008637: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008412: make: Nothing to be done for 'default'.
nid008412: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008393: make: Nothing to be done for 'default'.
nid008393: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008617: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008409: make: Nothing to be done for 'default'.
nid008409: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008385: make: Nothing to be done for 'default'.
nid008385: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008276: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008420: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008637: make: Nothing to be done for 'default'.
nid008637: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008392: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008617: make: Nothing to be done for 'default'.
nid008617: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008276: make: Nothing to be done for 'default'.
nid008276: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008420: make: Nothing to be done for 'default'.
nid008420: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008677: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008453: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008392: make: Nothing to be done for 'default'.
nid008392: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008620: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008681: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008301: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008684: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008677: make: Nothing to be done for 'default'.
nid008677: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008493: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008641: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008613: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008453: make: Nothing to be done for 'default'.
nid008453: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008620: make: Nothing to be done for 'default'.
nid008620: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008681: make: Nothing to be done for 'default'.
nid008681: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008301: make: Nothing to be done for 'default'.
nid008301: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008336: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008684: make: Nothing to be done for 'default'.
nid008684: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008636: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008680: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008276: building GPT2 model ...
nid008276: SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
nid008421: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008492: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008493: make: Nothing to be done for 'default'.
nid008493: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008384: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008641: make: Nothing to be done for 'default'.
nid008641: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008613: make: Nothing to be done for 'default'.
nid008613: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008476: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008304: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008337: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008336: make: Nothing to be done for 'default'.
nid008336: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008636: make: Nothing to be done for 'default'.
nid008636: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008680: make: Nothing to be done for 'default'.
nid008680: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008492: make: Nothing to be done for 'default'.
nid008492: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008421: make: Nothing to be done for 'default'.
nid008421: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008384: make: Nothing to be done for 'default'.
nid008384: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008456: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008476: make: Nothing to be done for 'default'.
nid008476: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008333: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008304: make: Nothing to be done for 'default'.
nid008304: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008337: make: Nothing to be done for 'default'.
nid008337: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008640: make: Entering directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008456: make: Nothing to be done for 'default'.
nid008456: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008333: make: Nothing to be done for 'default'.
nid008333: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008640: make: Nothing to be done for 'default'.
nid008640: make: Leaving directory '/pscratch/sd/z/zby2022/gpt-neox_20240914/gpt-neox/megatron/data'
nid008276: Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=0, model=1): 1, ProcessCoord(pipe=0, data=0, model=2): 2, ProcessCoord(pipe=0, data=0, model=3): 3, ProcessCoord(pipe=0, data=1, model=0): 4, ProcessCoord(pipe=0, data=1, model=1): 5, ProcessCoord(pipe=0, data=1, model=2): 6, ProcessCoord(pipe=0, data=1, model=3): 7, ProcessCoord(pipe=0, data=2, model=0): 8, ProcessCoord(pipe=0, data=2, model=1): 9, ProcessCoord(pipe=0, data=2, model=2): 10, ProcessCoord(pipe=0, data=2, model=3): 11, ProcessCoord(pipe=0, data=3, model=0): 12, ProcessCoord(pipe=0, data=3, model=1): 13, ProcessCoord(pipe=0, data=3, model=2): 14, ProcessCoord(pipe=0, data=3, model=3): 15, ProcessCoord(pipe=1, data=0, model=0): 16, ProcessCoord(pipe=1, data=0, model=1): 17, ProcessCoord(pipe=1, data=0, model=2): 18, ProcessCoord(pipe=1, data=0, model=3): 19, ProcessCoord(pipe=1, data=1, model=0): 20, ProcessCoord(pipe=1, data=1, model=1): 21, ProcessCoord(pipe=1, data=1, model=2): 22, ProcessCoord(pipe=1, data=1, model=3): 23, ProcessCoord(pipe=1, data=2, model=0): 24, ProcessCoord(pipe=1, data=2, model=1): 25, ProcessCoord(pipe=1, data=2, model=2): 26, ProcessCoord(pipe=1, data=2, model=3): 27, ProcessCoord(pipe=1, data=3, model=0): 28, ProcessCoord(pipe=1, data=3, model=1): 29, ProcessCoord(pipe=1, data=3, model=2): 30, ProcessCoord(pipe=1, data=3, model=3): 31, ProcessCoord(pipe=2, data=0, model=0): 32, ProcessCoord(pipe=2, data=0, model=1): 33, ProcessCoord(pipe=2, data=0, model=2): 34, ProcessCoord(pipe=2, data=0, model=3): 35, ProcessCoord(pipe=2, data=1, model=0): 36, ProcessCoord(pipe=2, data=1, model=1): 37, ProcessCoord(pipe=2, data=1, model=2): 38, ProcessCoord(pipe=2, data=1, model=3): 39, ProcessCoord(pipe=2, data=2, model=0): 40, ProcessCoord(pipe=2, data=2, model=1): 41, ProcessCoord(pipe=2, data=2, model=2): 42, ProcessCoord(pipe=2, data=2, model=3): 43, ProcessCoord(pipe=2, data=3, model=0): 44, ProcessCoord(pipe=2, data=3, model=1): 45, ProcessCoord(pipe=2, data=3, model=2): 46, ProcessCoord(pipe=2, data=3, model=3): 47, ProcessCoord(pipe=3, data=0, model=0): 48, ProcessCoord(pipe=3, data=0, model=1): 49, ProcessCoord(pipe=3, data=0, model=2): 50, ProcessCoord(pipe=3, data=0, model=3): 51, ProcessCoord(pipe=3, data=1, model=0): 52, ProcessCoord(pipe=3, data=1, model=1): 53, ProcessCoord(pipe=3, data=1, model=2): 54, ProcessCoord(pipe=3, data=1, model=3): 55, ProcessCoord(pipe=3, data=2, model=0): 56, ProcessCoord(pipe=3, data=2, model=1): 57, ProcessCoord(pipe=3, data=2, model=2): 58, ProcessCoord(pipe=3, data=2, model=3): 59, ProcessCoord(pipe=3, data=3, model=0): 60, ProcessCoord(pipe=3, data=3, model=1): 61, ProcessCoord(pipe=3, data=3, model=2): 62, ProcessCoord(pipe=3, data=3, model=3): 63, ProcessCoord(pipe=4, data=0, model=0): 64, ProcessCoord(pipe=4, data=0, model=1): 65, ProcessCoord(pipe=4, data=0, model=2): 66, ProcessCoord(pipe=4, data=0, model=3): 67, ProcessCoord(pipe=4, data=1, model=0): 68, ProcessCoord(pipe=4, data=1, model=1): 69, ProcessCoord(pipe=4, data=1, model=2): 70, ProcessCoord(pipe=4, data=1, model=3): 71, ProcessCoord(pipe=4, data=2, model=0): 72, ProcessCoord(pipe=4, data=2, model=1): 73, ProcessCoord(pipe=4, data=2, model=2): 74, ProcessCoord(pipe=4, data=2, model=3): 75, ProcessCoord(pipe=4, data=3, model=0): 76, ProcessCoord(pipe=4, data=3, model=1): 77, ProcessCoord(pipe=4, data=3, model=2): 78, ProcessCoord(pipe=4, data=3, model=3): 79, ProcessCoord(pipe=5, data=0, model=0): 80, ProcessCoord(pipe=5, data=0, model=1): 81, ProcessCoord(pipe=5, data=0, model=2): 82, ProcessCoord(pipe=5, data=0, model=3): 83, ProcessCoord(pipe=5, data=1, model=0): 84, ProcessCoord(pipe=5, data=1, model=1): 85, ProcessCoord(pipe=5, data=1, model=2): 86, ProcessCoord(pipe=5, data=1, model=3): 87, ProcessCoord(pipe=5, data=2, model=0): 88, ProcessCoord(pipe=5, data=2, model=1): 89, ProcessCoord(pipe=5, data=2, model=2): 90, ProcessCoord(pipe=5, data=2, model=3): 91, ProcessCoord(pipe=5, data=3, model=0): 92, ProcessCoord(pipe=5, data=3, model=1): 93, ProcessCoord(pipe=5, data=3, model=2): 94, ProcessCoord(pipe=5, data=3, model=3): 95, ProcessCoord(pipe=6, data=0, model=0): 96, ProcessCoord(pipe=6, data=0, model=1): 97, ProcessCoord(pipe=6, data=0, model=2): 98, ProcessCoord(pipe=6, data=0, model=3): 99, ProcessCoord(pipe=6, data=1, model=0): 100, ProcessCoord(pipe=6, data=1, model=1): 101, ProcessCoord(pipe=6, data=1, model=2): 102, ProcessCoord(pipe=6, data=1, model=3): 103, ProcessCoord(pipe=6, data=2, model=0): 104, ProcessCoord(pipe=6, data=2, model=1): 105, ProcessCoord(pipe=6, data=2, model=2): 106, ProcessCoord(pipe=6, data=2, model=3): 107, ProcessCoord(pipe=6, data=3, model=0): 108, ProcessCoord(pipe=6, data=3, model=1): 109, ProcessCoord(pipe=6, data=3, model=2): 110, ProcessCoord(pipe=6, data=3, model=3): 111, ProcessCoord(pipe=7, data=0, model=0): 112, ProcessCoord(pipe=7, data=0, model=1): 113, ProcessCoord(pipe=7, data=0, model=2): 114, ProcessCoord(pipe=7, data=0, model=3): 115, ProcessCoord(pipe=7, data=1, model=0): 116, ProcessCoord(pipe=7, data=1, model=1): 117, ProcessCoord(pipe=7, data=1, model=2): 118, ProcessCoord(pipe=7, data=1, model=3): 119, ProcessCoord(pipe=7, data=2, model=0): 120, ProcessCoord(pipe=7, data=2, model=1): 121, ProcessCoord(pipe=7, data=2, model=2): 122, ProcessCoord(pipe=7, data=2, model=3): 123, ProcessCoord(pipe=7, data=3, model=0): 124, ProcessCoord(pipe=7, data=3, model=1): 125, ProcessCoord(pipe=7, data=3, model=2): 126, ProcessCoord(pipe=7, data=3, model=3): 127}
nid008276: [2024-10-10 07:27:25,072] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer|mlp
nid008276: stage=0 layers=7
nid008276:      0: EmbeddingPipe
nid008276:      1: _pre_transformer_block
nid008276:      2: ParallelTransformerLayerPipe
nid008276:      3: ParallelTransformerLayerPipe
nid008276:      4: ParallelTransformerLayerPipe
nid008276:      5: ParallelTransformerLayerPipe
nid008276:      6: ParallelTransformerLayerPipe
nid008276: stage=1 layers=6
nid008276:      7: ParallelTransformerLayerPipe
nid008276:      8: ParallelTransformerLayerPipe
nid008276:      9: ParallelTransformerLayerPipe
nid008276:     10: ParallelTransformerLayerPipe
nid008276:     11: ParallelTransformerLayerPipe
nid008276:     12: ParallelTransformerLayerPipe
nid008276: stage=2 layers=6
nid008276:     13: ParallelTransformerLayerPipe
nid008276:     14: ParallelTransformerLayerPipe
nid008276:     15: ParallelTransformerLayerPipe
nid008276:     16: ParallelTransformerLayerPipe
nid008276:     17: ParallelTransformerLayerPipe
nid008276:     18: ParallelTransformerLayerPipe
nid008276: stage=3 layers=6
nid008276:     19: ParallelTransformerLayerPipe
nid008276:     20: ParallelTransformerLayerPipe
nid008276:     21: ParallelTransformerLayerPipe
nid008276:     22: ParallelTransformerLayerPipe
nid008276:     23: ParallelTransformerLayerPipe
nid008276:     24: ParallelTransformerLayerPipe
nid008276: stage=4 layers=6
nid008276:     25: ParallelTransformerLayerPipe
nid008276:     26: ParallelTransformerLayerPipe
nid008276:     27: ParallelTransformerLayerPipe
nid008276:     28: ParallelTransformerLayerPipe
nid008276:     29: ParallelTransformerLayerPipe
nid008276:     30: ParallelTransformerLayerPipe
nid008276: stage=5 layers=6
nid008276:     31: ParallelTransformerLayerPipe
nid008276:     32: ParallelTransformerLayerPipe
nid008276:     33: ParallelTransformerLayerPipe
nid008276:     34: ParallelTransformerLayerPipe
nid008276:     35: ParallelTransformerLayerPipe
nid008276:     36: ParallelTransformerLayerPipe
nid008276: stage=6 layers=6
nid008276:     37: ParallelTransformerLayerPipe
nid008276:     38: ParallelTransformerLayerPipe
nid008276:     39: ParallelTransformerLayerPipe
nid008276:     40: ParallelTransformerLayerPipe
nid008276:     41: ParallelTransformerLayerPipe
nid008276:     42: ParallelTransformerLayerPipe
nid008276: stage=7 layers=6
nid008276:     43: ParallelTransformerLayerPipe
nid008276:     44: ParallelTransformerLayerPipe
nid008276:     45: ParallelTransformerLayerPipe
nid008276:     46: _post_transformer_block
nid008276:     47: NormPipe
nid008276:     48: ParallelLinearPipe
nid008276:   loss: partial
nid008684: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008677: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008681: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008680: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008636: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008620: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008640: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008337: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008677: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008684: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008616: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008681: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008389: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008636: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008620: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008384: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008640: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008476: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008337: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008616: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008412: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008389: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008301: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008384: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008276: Configuring Optimizer type: Adam with params: {'lr': 9.7e-05, 'betas': [0.9, 0.95], 'eps': 1e-08}
nid008333: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008492: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008276: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008493: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008476: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008336: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008637: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008453: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008641: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008393: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008456: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008412: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008420: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008304: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008301: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008333: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008492: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008276: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008336: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008637: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008641: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008393: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008453: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008421: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008409: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008420: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008456: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008304: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008385: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008617: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008421: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008409: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008392: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008385: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008617: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008392: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008613: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008613: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008493: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008680: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008677: Detected CUDA files, patching ldflags
nid008677: Emitting ninja build file /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117/fused_adam/build.ninja...
nid008677: Building extension module fused_adam...
nid008677: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
nid008677: ninja: no work to do.
nid008677: Loading extension module fused_adam...
nid008677: Time to load fused_adam op: 0.2913649082183838 seconds
nid008640: Loading extension module fused_adam...
nid008636: Loading extension module fused_adam...
nid008620: Loading extension module fused_adam...
nid008684: Loading extension module fused_adam...
nid008681: Loading extension module fused_adam...
nid008337: Loading extension module fused_adam...
nid008616: Loading extension module fused_adam...
nid008389: Loading extension module fused_adam...
nid008384: Loading extension module fused_adam...
nid008640: Time to load fused_adam op: 0.3164653778076172 seconds
nid008476: Loading extension module fused_adam...
nid008684: Time to load fused_adam op: 0.3254070281982422 seconds
nid008620: Time to load fused_adam op: 0.31832432746887207 seconds
nid008681: Time to load fused_adam op: 0.3198256492614746 seconds
nid008636: Time to load fused_adam op: 0.31929636001586914 seconds
nid008412: Loading extension module fused_adam...
nid008337: Time to load fused_adam op: 0.3195350170135498 seconds
nid008616: Time to load fused_adam op: 0.32066988945007324 seconds
nid008301: Loading extension module fused_adam...
nid008389: Time to load fused_adam op: 0.31788015365600586 seconds
nid008333: Loading extension module fused_adam...
nid008492: Loading extension module fused_adam...
nid008276: Loading extension module fused_adam...
nid008384: Time to load fused_adam op: 0.31750917434692383 seconds
nid008336: Loading extension module fused_adam...
nid008637: Loading extension module fused_adam...
nid008641: Loading extension module fused_adam...
nid008412: Time to load fused_adam op: 0.31534266471862793 seconds
nid008393: Loading extension module fused_adam...
nid008453: Loading extension module fused_adam...
nid008476: Time to load fused_adam op: 0.31957435607910156 seconds
nid008420: Loading extension module fused_adam...
nid008456: Loading extension module fused_adam...
nid008304: Loading extension module fused_adam...
nid008301: Time to load fused_adam op: 0.31540966033935547 seconds
nid008492: Time to load fused_adam op: 0.3154616355895996 seconds
nid008333: Time to load fused_adam op: 0.3166768550872803 seconds
nid008276: Time to load fused_adam op: 0.31653857231140137 seconds
nid008276: > learning rate decay style: cosine
nid008276: DeepSpeed is enabled.
nid008276: [2024-10-10 07:27:25,538] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4+02e2ebf, git-hash=02e2ebf, git-branch=HEAD
nid008336: Time to load fused_adam op: 0.3171675205230713 seconds
nid008421: Loading extension module fused_adam...
nid008637: Time to load fused_adam op: 0.31992554664611816 seconds
nid008453: Time to load fused_adam op: 0.3201885223388672 seconds
nid008409: Loading extension module fused_adam...
nid008393: Time to load fused_adam op: 0.3200852870941162 seconds
nid008641: Time to load fused_adam op: 0.32071518898010254 seconds
nid008456: Time to load fused_adam op: 0.3186964988708496 seconds
nid008304: Time to load fused_adam op: 0.3181328773498535 seconds
nid008493: Loading extension module fused_adam...
nid008680: Loading extension module fused_adam...
nid008420: Time to load fused_adam op: 0.32175660133361816 seconds
nid008385: Loading extension module fused_adam...
nid008617: Loading extension module fused_adam...
nid008409: Time to load fused_adam op: 0.31574535369873047 seconds
nid008421: Time to load fused_adam op: 0.3173494338989258 seconds
nid008392: Loading extension module fused_adam...
nid008493: Time to load fused_adam op: 0.3323812484741211 seconds
nid008680: Time to load fused_adam op: 0.3513946533203125 seconds
nid008385: Time to load fused_adam op: 0.3161132335662842 seconds
nid008617: Time to load fused_adam op: 0.3154420852661133 seconds
nid008392: Time to load fused_adam op: 0.3146054744720459 seconds
nid008613: Loading extension module fused_adam...
nid008613: Time to load fused_adam op: 0.3145105838775635 seconds
nid008276: [2024-10-10 07:27:25,821] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
nid008276: [2024-10-10 07:27:25,821] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
nid008276: [2024-10-10 07:27:25,821] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
nid008276: [2024-10-10 07:27:25,822] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
nid008276: [2024-10-10 07:27:25,822] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
nid008276: [2024-10-10 07:27:25,822] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer
nid008276: [2024-10-10 07:27:25,822] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 1260000000
nid008276: [2024-10-10 07:27:25,822] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 1260000000
nid008276: [2024-10-10 07:27:25,822] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
nid008276: [2024-10-10 07:27:25,822] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
nid008684: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008684: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008684: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008640: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008684: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008640: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008493: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008493: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008684: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008421: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008684: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008620: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008421: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008620: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008333: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008681: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008616: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008333: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008681: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008616: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008492: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008680: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008333: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008493: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008333: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008680: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008616: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008492: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008641: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008421: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008493: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008680: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008616: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008681: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008421: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008680: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008641: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008681: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008336: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008304: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008681: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008336: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008681: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008420: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008304: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008304: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008304: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008420: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008636: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008409: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008301: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008620: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008636: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008677: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008337: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008409: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008333: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008301: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008640: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008620: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008301: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008333: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008620: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008640: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008476: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008677: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008641: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008620: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008301: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008337: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008641: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008421: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008409: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008476: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008392: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008336: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008389: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008421: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008409: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008337: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008640: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008392: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008336: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008616: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008304: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008640: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008337: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008493: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008677: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008616: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008384: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008304: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008493: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008336: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008677: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008389: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008636: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008336: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008301: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008384: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008337: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008492: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008476: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008301: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008636: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008337: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008276: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008476: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008492: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008492: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008492: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008276: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008641: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008677: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008389: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008476: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008409: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008677: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008641: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008276: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008276: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008476: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008389: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008409: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008677: [2024-10-10 07:27:26,780] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008389: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008420: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008680: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008389: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008384: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008420: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008680: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008384: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008420: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008384: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008420: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008392: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008384: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008392: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008637: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008637: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008276: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008636: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008637: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008276: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008637: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008636: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008456: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008392: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008392: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008453: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008456: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008453: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008637: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008637: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008453: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008453: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008456: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008453: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008385: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008456: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008680: [2024-10-10 07:27:26,839] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008453: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008456: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008456: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008385: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008385: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008385: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008613: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008385: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008684: [2024-10-10 07:27:26,860] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008613: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008385: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008613: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008681: [2024-10-10 07:27:26,869] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008613: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008613: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008613: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008412: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008617: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008412: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008412: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008412: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008617: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008412: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008412: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008617: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008617: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008617: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008617: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008684: Detected CUDA files, patching ldflags
nid008684: Emitting ninja build file /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117/fused_adam/build.ninja...
nid008393: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008684: Building extension module fused_adam...
nid008684: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
nid008393: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008393: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008393: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008393: WARNING: APEX not installed - defaulting to deepspeed's fused adam
nid008393: Using /global/u1/z/zby2022/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
nid008684: ninja: no work to do.
nid008385: Loading extension module fused_adam...
nid008385: Loading extension module fused_adam...
nid008684: Loading extension module fused_adam...
nid008336: Loading extension module fused_adam...
nid008385: Time to load fused_adam op: 0.20540833473205566 seconds
nid008385: Time to load fused_adam op: 0.21122527122497559 seconds
nid008392: Loading extension module fused_adam...
nid008684: Time to load fused_adam op: 0.4196605682373047 seconds
nid008640: Loading extension module fused_adam...
nid008336: Time to load fused_adam op: 0.3067014217376709 seconds
nid008337: Loading extension module fused_adam...
nid008392: Time to load fused_adam op: 0.3087902069091797 seconds
nid008616: Loading extension module fused_adam...
nid008640: Time to load fused_adam op: 0.3056614398956299 seconds
nid008304: Loading extension module fused_adam...
nid008337: Time to load fused_adam op: 0.3056983947753906 seconds
nid008616: Time to load fused_adam op: 0.3052346706390381 seconds
nid008493: Loading extension module fused_adam...
nid008304: Time to load fused_adam op: 0.3059830665588379 seconds
nid008493: Time to load fused_adam op: 0.3059513568878174 seconds
nid008677: Loading extension module fused_adam...
nid008385: Loading extension module fused_adam...
nid008613: Loading extension module fused_adam...
nid008385: Time to load fused_adam op: 0.2043302059173584 seconds
nid008389: Loading extension module fused_adam...
nid008677: Time to load fused_adam op: 0.3064901828765869 seconds
nid008336: Loading extension module fused_adam...
nid008613: Time to load fused_adam op: 0.2080678939819336 seconds
nid008336: Time to load fused_adam op: 0.30564355850219727 seconds
nid008389: Time to load fused_adam op: 0.3141043186187744 seconds
nid008684: Loading extension module fused_adam...
nid008301: Loading extension module fused_adam...
nid008384: Loading extension module fused_adam...
nid008684: Time to load fused_adam op: 0.40627598762512207 seconds
nid008337: Loading extension module fused_adam...
nid008636: Loading extension module fused_adam...
nid008301: Time to load fused_adam op: 0.3055129051208496 seconds
nid008384: Time to load fused_adam op: 0.31153392791748047 seconds
nid008337: Time to load fused_adam op: 0.30507826805114746 seconds
nid008640: Loading extension module fused_adam...
nid008492: Loading extension module fused_adam...
nid008476: Loading extension module fused_adam...
nid008636: Time to load fused_adam op: 0.3062877655029297 seconds
nid008640: Time to load fused_adam op: 0.40859055519104004 seconds
nid008613: Loading extension module fused_adam...
nid008492: Time to load fused_adam op: 0.30608439445495605 seconds
nid008476: Time to load fused_adam op: 0.30631446838378906 seconds
nid008613: Time to load fused_adam op: 0.20497941970825195 seconds
nid008492: Loading extension module fused_adam...
nid008393: Loading extension module fused_adam...
nid008492: Time to load fused_adam op: 0.3047628402709961 seconds
nid008613: Loading extension module fused_adam...
nid008393: Time to load fused_adam op: 0.1153256893157959 seconds
nid008393: Loading extension module fused_adam...
nid008613: Time to load fused_adam op: 0.20412611961364746 seconds
nid008393: Time to load fused_adam op: 0.10395097732543945 seconds
nid008641: Loading extension module fused_adam...
nid008677: Loading extension module fused_adam...
nid008476: Loading extension module fused_adam...
nid008409: Loading extension module fused_adam...
nid008389: Loading extension module fused_adam...
nid008677: Time to load fused_adam op: 0.3052957057952881 seconds
nid008476: Time to load fused_adam op: 0.30507779121398926 seconds
nid008276: Loading extension module fused_adam...
nid008493: Loading extension module fused_adam...
nid008641: Time to load fused_adam op: 0.30593180656433105 seconds
nid008393: Loading extension module fused_adam...
nid008684: Loading extension module fused_adam...
nid008389: Time to load fused_adam op: 0.30547571182250977 seconds
nid008409: Time to load fused_adam op: 0.3056199550628662 seconds
nid008276: Loading extension module fused_adam...
nid008393: Time to load fused_adam op: 0.10383033752441406 seconds
nid008493: Time to load fused_adam op: 0.4090285301208496 seconds
nid008684: Time to load fused_adam op: 0.4058187007904053 seconds
nid008389: Loading extension module fused_adam...
nid008276: Time to load fused_adam op: 0.31200504302978516 seconds
nid008276: Time to load fused_adam op: 0.3178575038909912 seconds
nid008389: Time to load fused_adam op: 0.30504751205444336 seconds
nid008420: Loading extension module fused_adam...
nid008680: Loading extension module fused_adam...
nid008421: Loading extension module fused_adam...
nid008420: Time to load fused_adam op: 0.3059957027435303 seconds
nid008384: Loading extension module fused_adam...
nid008384: Time to load fused_adam op: 0.30496883392333984 seconds
nid008680: Time to load fused_adam op: 0.30578112602233887 seconds
nid008421: Time to load fused_adam op: 0.40914416313171387 seconds
nid008620: Loading extension module fused_adam...
nid008420: Loading extension module fused_adam...
nid008420: Time to load fused_adam op: 0.30496644973754883 seconds
nid008384: Loading extension module fused_adam...
nid008620: Time to load fused_adam op: 0.4118831157684326 seconds
nid008384: Time to load fused_adam op: 0.30473780632019043 seconds
nid008333: Loading extension module fused_adam...
nid008392: Loading extension module fused_adam...
nid008333: Time to load fused_adam op: 0.4089536666870117 seconds
nid008392: Time to load fused_adam op: 0.3055427074432373 seconds
nid008616: Loading extension module fused_adam...
nid008681: Loading extension module fused_adam...
nid008616: Time to load fused_adam op: 0.4085566997528076 seconds
nid008681: Time to load fused_adam op: 0.4097907543182373 seconds
nid008637: Loading extension module fused_adam...
nid008637: Loading extension module fused_adam...
nid008276: Loading extension module fused_adam...
nid008333: Loading extension module fused_adam...
nid008636: Loading extension module fused_adam...
nid008412: Loading extension module fused_adam...
nid008493: Loading extension module fused_adam...
nid008492: Loading extension module fused_adam...
nid008637: Time to load fused_adam op: 0.30591750144958496 seconds
nid008333: Time to load fused_adam op: 0.40630006790161133 seconds
nid008637: Time to load fused_adam op: 0.30861759185791016 seconds
nid008680: Loading extension module fused_adam...
nid008636: Time to load fused_adam op: 0.30489635467529297 seconds
nid008492: Time to load fused_adam op: 0.4081270694732666 seconds
nid008493: Time to load fused_adam op: 0.40583348274230957 seconds
nid008276: Time to load fused_adam op: 0.30772829055786133 seconds
nid008680: Time to load fused_adam op: 0.4093196392059326 seconds
nid008616: Loading extension module fused_adam...
nid008412: Loading extension module fused_adam...
nid008617: Loading extension module fused_adam...
nid008616: Time to load fused_adam op: 0.40619826316833496 seconds
nid008617: Time to load fused_adam op: 0.20844197273254395 seconds
nid008680: Loading extension module fused_adam...
nid008412: Time to load fused_adam op: 0.20745325088500977 secondsTime to load fused_adam op: 0.21622800827026367 seconds
nid008412: 
nid008392: Loading extension module fused_adam...
nid008421: Loading extension module fused_adam...
nid008680: Time to load fused_adam op: 0.4060795307159424 seconds
nid008392: Time to load fused_adam op: 0.305161714553833 seconds
nid008641: Loading extension module fused_adam...
nid008681: Loading extension module fused_adam...
nid008421: Time to load fused_adam op: 0.40830278396606445 seconds
nid008412: Loading extension module fused_adam...
nid008641: Time to load fused_adam op: 0.40827012062072754 seconds
nid008681: Time to load fused_adam op: 0.4067518711090088 seconds
nid008456: Loading extension module fused_adam...
nid008412: Time to load fused_adam op: 0.20906591415405273 seconds
nid008453: Loading extension module fused_adam...
nid008336: Loading extension module fused_adam...
nid008617: Loading extension module fused_adam...
nid008456: Time to load fused_adam op: 0.312267541885376 seconds
nid008453: Time to load fused_adam op: 0.3088088035583496 seconds
nid008637: Loading extension module fused_adam...
nid008336: Time to load fused_adam op: 0.40872907638549805 seconds
nid008617: Time to load fused_adam op: 0.2078075408935547 seconds
nid008681: Loading extension module fused_adam...
nid008637: Time to load fused_adam op: 0.305328369140625 seconds
nid008681: Time to load fused_adam op: 0.406388521194458 seconds
nid008304: Time to load fused_adam op: 0.408627986907959 seconds
nid008617: Loading extension module fused_adam...
nid008304: Loading extension module fused_adam...
nid008304: Loading extension module fused_adam...
nid008304: Time to load fused_adam op: 0.4054899215698242 seconds
nid008420: Loading extension module fused_adam...
nid008453: Loading extension module fused_adam...
nid008617: Time to load fused_adam op: 0.2103714942932129 seconds
nid008453: Time to load fused_adam op: 0.3052685260772705 seconds
nid008420: Time to load fused_adam op: 0.4080829620361328 seconds
nid008636: Loading extension module fused_adam...
nid008409: Loading extension module fused_adam...
nid008636: Time to load fused_adam op: 0.4091482162475586 seconds
nid008620: Loading extension module fused_adam...
nid008301: Loading extension module fused_adam...
nid008409: Time to load fused_adam op: 0.40874314308166504 seconds
nid008620: Time to load fused_adam op: 0.4067051410675049 seconds
nid008333: Loading extension module fused_adam...
nid008453: Loading extension module fused_adam...
nid008301: Time to load fused_adam op: 0.40944600105285645 seconds
nid008456: Loading extension module fused_adam...
nid008453: Time to load fused_adam op: 0.304929256439209 seconds
nid008333: Time to load fused_adam op: 0.40633654594421387 seconds
nid008640: Loading extension module fused_adam...
nid008620: Loading extension module fused_adam...
nid008301: Loading extension module fused_adam...
nid008640: Time to load fused_adam op: 0.40677809715270996 seconds
nid008677: Loading extension module fused_adam...
nid008620: Time to load fused_adam op: 0.40553879737854004 seconds
nid008456: Time to load fused_adam op: 0.3097717761993408 seconds
nid008301: Time to load fused_adam op: 0.40622854232788086 seconds
nid008677: Time to load fused_adam op: 0.4096994400024414 seconds
nid008456: Loading extension module fused_adam...
nid008641: Loading extension module fused_adam...
nid008337: Loading extension module fused_adam...
nid008337: Time to load fused_adam op: 0.409987211227417 seconds
nid008476: Loading extension module fused_adam...
nid008641: Time to load fused_adam op: 0.40697216987609863 seconds
nid008421: Loading extension module fused_adam...
nid008476: Time to load fused_adam op: 0.4095933437347412 seconds
nid008409: Loading extension module fused_adam...
nid008456: Time to load fused_adam op: 0.3090388774871826 seconds
nid008421: Time to load fused_adam op: 0.40607643127441406 seconds
nid008409: Time to load fused_adam op: 0.40645360946655273 seconds
nid008276: [2024-10-10 07:27:27,306] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states
nid008276: [2024-10-10 07:27:27,308] [INFO] [utils.py:803:see_memory_usage] MA 1.8 GB         Max_MA 1.8 GB         CA 1.8 GB         Max_CA 2 GB 
nid008412: [2024-10-10 07:27:27,308] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008276: [2024-10-10 07:27:27,308] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 32.11 GB, percent = 12.8%
nid008456: [2024-10-10 07:27:27,309] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008420: [2024-10-10 07:27:27,342] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008493: [2024-10-10 07:27:27,363] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008476: [2024-10-10 07:27:27,365] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008636: [2024-10-10 07:27:27,366] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008301: [2024-10-10 07:27:27,380] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008492: [2024-10-10 07:27:27,384] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008304: [2024-10-10 07:27:27,390] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008453: [2024-10-10 07:27:27,392] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008276: [2024-10-10 07:27:27,392] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states
nid008276: [2024-10-10 07:27:27,393] [INFO] [utils.py:803:see_memory_usage] MA 3.0 GB         Max_MA 3.6 GB         CA 3.61 GB         Max_CA 4 GB 
nid008276: [2024-10-10 07:27:27,393] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 32.22 GB, percent = 12.8%
nid008276: [2024-10-10 07:27:27,393] [INFO] [stage_1_and_2.py:517:__init__] optimizer state initialized
nid008333: [2024-10-10 07:27:27,416] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008421: [2024-10-10 07:27:27,443] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008389: [2024-10-10 07:27:27,453] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008276: [2024-10-10 07:27:27,454] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer
nid008276: [2024-10-10 07:27:27,455] [INFO] [utils.py:803:see_memory_usage] MA 3.0 GB         Max_MA 3.0 GB         CA 3.61 GB         Max_CA 4 GB 
nid008276: [2024-10-10 07:27:27,455] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 32.26 GB, percent = 12.8%
nid008637: [2024-10-10 07:27:27,457] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008613: [2024-10-10 07:27:27,458] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008276: [2024-10-10 07:27:27,458] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
nid008276: [2024-10-10 07:27:27,459] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
nid008276: [2024-10-10 07:27:27,459] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x7ff00f16eee0>
nid008276: [2024-10-10 07:27:27,459] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:27:27,459] [INFO] [config.py:979:print] DeepSpeedEngine configuration:
nid008276: [2024-10-10 07:27:27,459] [INFO] [config.py:983:print]   activation_checkpointing_config  {
nid008276:     "partition_activations": false, 
nid008276:     "contiguous_memory_optimization": false, 
nid008276:     "cpu_checkpointing": false, 
nid008276:     "number_checkpoints": null, 
nid008276:     "synchronize_checkpoint_boundary": false, 
nid008276:     "profile": false
nid008276: }
nid008276: [2024-10-10 07:27:27,459] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
nid008276: [2024-10-10 07:27:27,459] [INFO] [config.py:983:print]   amp_enabled .................. False
nid008276: [2024-10-10 07:27:27,459] [INFO] [config.py:983:print]   amp_params ................... False
nid008276: [2024-10-10 07:27:27,459] [INFO] [config.py:983:print]   autotuning_config ............ {
nid008276:     "enabled": false, 
nid008276:     "start_step": null, 
nid008276:     "end_step": null, 
nid008276:     "metric_path": null, 
nid008276:     "arg_mappings": null, 
nid008276:     "metric": "throughput", 
nid008276:     "model_info": null, 
nid008276:     "results_dir": "autotuning_results", 
nid008276:     "exps_dir": "autotuning_exps", 
nid008276:     "overwrite": true, 
nid008276:     "fast": true, 
nid008276:     "start_profile_step": 3, 
nid008276:     "end_profile_step": 5, 
nid008276:     "tuner_type": "gridsearch", 
nid008276:     "tuner_early_stopping": 5, 
nid008276:     "tuner_num_trials": 50, 
nid008276:     "model_info_path": null, 
nid008276:     "mp_size": 1, 
nid008276:     "max_train_batch_size": null, 
nid008276:     "min_train_batch_size": 1, 
nid008276:     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
nid008276:     "min_train_micro_batch_size_per_gpu": 1, 
nid008276:     "num_tuning_micro_batch_sizes": 3
nid008276: }
nid008276: [2024-10-10 07:27:27,459] [INFO] [config.py:983:print]   bfloat16_enabled ............. False
nid008276: [2024-10-10 07:27:27,459] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False
nid008276: [2024-10-10 07:27:27,459] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True
nid008276: [2024-10-10 07:27:27,459] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False
nid008276: [2024-10-10 07:27:27,459] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7ff00f123310>
nid008276: [2024-10-10 07:27:27,459] [INFO] [config.py:983:print]   communication_data_type ...... None
nid008276: [2024-10-10 07:27:27,459] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   dataloader_drop_last ......... False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   disable_allgather ............ False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   dump_state ................... False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   elasticity_enabled ........... False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   flops_profiler_config ........ {
nid008276:     "enabled": false, 
nid008276:     "recompute_fwd_factor": 0.0, 
nid008276:     "profile_step": 1, 
nid008276:     "module_depth": -1, 
nid008276:     "top_modules": 1, 
nid008276:     "detailed": true, 
nid008276:     "output_file": null
nid008276: }
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   fp16_auto_cast ............... False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   fp16_enabled ................. True
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   global_rank .................. 0
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   grad_accum_dtype ............. None
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 16
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   gradient_clipping ............ 0.0
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 4096
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   load_universal_checkpoint .... False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   loss_scale ................... 0
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   memory_breakdown ............. False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   mics_shard_size .............. -1
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   nebula_config ................ {
nid008276:     "enabled": false, 
nid008276:     "persistent_storage_path": null, 
nid008276:     "persistent_time_interval": 100, 
nid008276:     "num_of_version_in_retention": 2, 
nid008276:     "enable_nebula_load": true, 
nid008276:     "load_path": null
nid008276: }
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   optimizer_name ............... adam
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   optimizer_params ............. {'lr': 9.7e-05, 'betas': [0.9, 0.95], 'eps': 1e-08}
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   pld_enabled .................. False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   pld_params ................... False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   prescale_gradients ........... False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   scheduler_name ............... None
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   scheduler_params ............. None
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   sparse_attention ............. None
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   steps_per_print .............. 1
nid008276: [2024-10-10 07:27:27,460] [INFO] [config.py:983:print]   train_batch_size ............. 256
nid008276: [2024-10-10 07:27:27,461] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  4
nid008276: [2024-10-10 07:27:27,461] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False
nid008276: [2024-10-10 07:27:27,461] [INFO] [config.py:983:print]   use_node_local_storage ....... False
nid008276: [2024-10-10 07:27:27,461] [INFO] [config.py:983:print]   wall_clock_breakdown ......... True
nid008276: [2024-10-10 07:27:27,461] [INFO] [config.py:983:print]   weight_quantization_config ... None
nid008276: [2024-10-10 07:27:27,461] [INFO] [config.py:983:print]   world_size ................... 4
nid008276: [2024-10-10 07:27:27,461] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False
nid008276: [2024-10-10 07:27:27,461] [INFO] [config.py:983:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=1260000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=1260000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
nid008276: [2024-10-10 07:27:27,461] [INFO] [config.py:983:print]   zero_enabled ................. True
nid008276: [2024-10-10 07:27:27,461] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True
nid008276: [2024-10-10 07:27:27,461] [INFO] [config.py:983:print]   zero_optimization_stage ...... 1
nid008276: [2024-10-10 07:27:27,461] [INFO] [config.py:969:print_user_config]   json = {
nid008276:     "train_batch_size": 256, 
nid008276:     "train_micro_batch_size_per_gpu": 4, 
nid008276:     "gradient_accumulation_steps": 16, 
nid008276:     "optimizer": {
nid008276:         "type": "Adam", 
nid008276:         "params": {
nid008276:             "lr": 9.7e-05, 
nid008276:             "betas": [0.9, 0.95], 
nid008276:             "eps": 1e-08
nid008276:         }
nid008276:     }, 
nid008276:     "fp16": {
nid008276:         "fp16": true, 
nid008276:         "enabled": true, 
nid008276:         "loss_scale": 0, 
nid008276:         "loss_scale_window": 1000, 
nid008276:         "initial_scale_power": 12, 
nid008276:         "hysteresis": 2, 
nid008276:         "min_loss_scale": 1
nid008276:     }, 
nid008276:     "zero_optimization": {
nid008276:         "stage": 1, 
nid008276:         "allgather_partitions": true, 
nid008276:         "allgather_bucket_size": 1.260000e+09, 
nid008276:         "overlap_comm": true, 
nid008276:         "reduce_scatter": true, 
nid008276:         "reduce_bucket_size": 1.260000e+09, 
nid008276:         "contiguous_gradients": true
nid008276:     }, 
nid008276:     "steps_per_print": 1, 
nid008276:     "wall_clock_breakdown": true
nid008276: }
nid008276: [2024-10-10 07:27:27,461] [INFO] [engine.py:99:__init__] CONFIG: micro_batches=16 micro_batch_size=4
nid008276: [2024-10-10 07:27:27,461] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008640: [2024-10-10 07:27:27,490] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008617: [2024-10-10 07:27:27,496] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008392: [2024-10-10 07:27:27,508] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008620: [2024-10-10 07:27:27,512] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008616: [2024-10-10 07:27:27,512] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008641: [2024-10-10 07:27:27,520] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008409: [2024-10-10 07:27:27,542] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008393: [2024-10-10 07:27:27,551] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008336: [2024-10-10 07:27:27,570] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008337: [2024-10-10 07:27:27,649] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008385: [2024-10-10 07:27:27,658] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008384: [2024-10-10 07:27:27,697] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008677: [2024-10-10 07:27:28,355] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008677: [2024-10-10 07:27:28,373] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008677: [2024-10-10 07:27:28,490] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008681: [2024-10-10 07:27:28,504] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008681: [2024-10-10 07:27:28,527] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008684: [2024-10-10 07:27:28,537] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008684: [2024-10-10 07:27:28,557] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008680: [2024-10-10 07:27:28,563] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008684: [2024-10-10 07:27:28,592] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008680: [2024-10-10 07:27:28,597] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008681: [2024-10-10 07:27:28,606] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008680: [2024-10-10 07:27:28,623] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008613: [2024-10-10 07:27:28,856] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008456: [2024-10-10 07:27:28,912] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008276: [2024-10-10 07:27:28,914] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008476: [2024-10-10 07:27:28,985] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008301: [2024-10-10 07:27:29,048] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008337: [2024-10-10 07:27:29,058] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008276: [2024-10-10 07:27:29,082] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008304: [2024-10-10 07:27:29,091] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008616: [2024-10-10 07:27:29,093] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008336: [2024-10-10 07:27:29,094] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008276: [2024-10-10 07:27:29,102] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008412: [2024-10-10 07:27:29,108] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008337: [2024-10-10 07:27:29,109] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008493: [2024-10-10 07:27:29,137] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008385: [2024-10-10 07:27:29,143] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008412: [2024-10-10 07:27:29,145] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008301: [2024-10-10 07:27:29,149] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008456: [2024-10-10 07:27:29,149] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008336: [2024-10-10 07:27:29,150] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008492: [2024-10-10 07:27:29,158] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008333: [2024-10-10 07:27:29,162] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008333: [2024-10-10 07:27:29,178] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008385: [2024-10-10 07:27:29,179] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008613: [2024-10-10 07:27:29,182] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008420: [2024-10-10 07:27:29,193] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008333: [2024-10-10 07:27:29,199] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008613: [2024-10-10 07:27:29,202] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008301: [2024-10-10 07:27:29,203] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008393: [2024-10-10 07:27:29,215] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008412: [2024-10-10 07:27:29,217] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008636: [2024-10-10 07:27:29,217] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008304: [2024-10-10 07:27:29,218] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008389: [2024-10-10 07:27:29,218] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008389: [2024-10-10 07:27:29,219] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008637: [2024-10-10 07:27:29,221] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008456: [2024-10-10 07:27:29,230] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008476: [2024-10-10 07:27:29,232] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008409: [2024-10-10 07:27:29,232] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008392: [2024-10-10 07:27:29,238] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008420: [2024-10-10 07:27:29,240] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008389: [2024-10-10 07:27:29,243] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008617: [2024-10-10 07:27:29,260] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008637: [2024-10-10 07:27:29,268] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008641: [2024-10-10 07:27:29,270] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008492: [2024-10-10 07:27:29,271] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008392: [2024-10-10 07:27:29,277] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008617: [2024-10-10 07:27:29,277] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008304: [2024-10-10 07:27:29,287] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008453: [2024-10-10 07:27:29,294] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008637: [2024-10-10 07:27:29,297] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008616: [2024-10-10 07:27:29,300] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008620: [2024-10-10 07:27:29,307] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008617: [2024-10-10 07:27:29,319] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008636: [2024-10-10 07:27:29,326] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008453: [2024-10-10 07:27:29,328] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008476: [2024-10-10 07:27:29,329] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008384: [2024-10-10 07:27:29,333] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008640: [2024-10-10 07:27:29,338] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008636: [2024-10-10 07:27:29,340] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008616: [2024-10-10 07:27:29,341] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008453: [2024-10-10 07:27:29,344] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008337: [2024-10-10 07:27:29,349] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008641: [2024-10-10 07:27:29,359] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008640: [2024-10-10 07:27:29,360] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008384: [2024-10-10 07:27:29,368] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008641: [2024-10-10 07:27:29,372] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008336: [2024-10-10 07:27:29,375] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008640: [2024-10-10 07:27:29,376] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008385: [2024-10-10 07:27:29,380] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008409: [2024-10-10 07:27:29,396] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008420: [2024-10-10 07:27:29,407] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008620: [2024-10-10 07:27:29,407] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008492: [2024-10-10 07:27:29,414] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008393: [2024-10-10 07:27:29,430] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008392: [2024-10-10 07:27:29,451] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008493: [2024-10-10 07:27:29,454] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008620: [2024-10-10 07:27:29,468] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008393: [2024-10-10 07:27:29,482] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008409: [2024-10-10 07:27:29,488] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008493: [2024-10-10 07:27:29,491] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008421: [2024-10-10 07:27:29,539] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008421: [2024-10-10 07:27:29,546] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008421: [2024-10-10 07:27:29,559] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008384: [2024-10-10 07:27:29,588] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
nid008276: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=2 STAGE=0 LAYERS=7 [0, 7) STAGE_PARAMS=644325888 (644.326M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008276: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=3 STAGE=0 LAYERS=7 [0, 7) STAGE_PARAMS=644325888 (644.326M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008276: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=1 STAGE=0 LAYERS=7 [0, 7) STAGE_PARAMS=644325888 (644.326M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008276: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=0 STAGE=0 LAYERS=7 [0, 7) STAGE_PARAMS=644325888 (644.326M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008456: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=65 STAGE=4 LAYERS=6 [25, 31) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008456: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=66 STAGE=4 LAYERS=6 [25, 31) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008456: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=64 STAGE=4 LAYERS=6 [25, 31) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008456: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=67 STAGE=4 LAYERS=6 [25, 31) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008636: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=97 STAGE=6 LAYERS=6 [37, 43) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008636: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=98 STAGE=6 LAYERS=6 [37, 43) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008636: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=96 STAGE=6 LAYERS=6 [37, 43) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008636: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=99 STAGE=6 LAYERS=6 [37, 43) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008389: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=33 STAGE=2 LAYERS=6 [13, 19) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008389: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=35 STAGE=2 LAYERS=6 [13, 19) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008389: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=34 STAGE=2 LAYERS=6 [13, 19) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008389: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=32 STAGE=2 LAYERS=6 [13, 19) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008677: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=114 STAGE=7 LAYERS=6 [43, 49) STAGE_PARAMS=417750528 (417.751M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008336: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=18 STAGE=1 LAYERS=6 [7, 13) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008677: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=113 STAGE=7 LAYERS=6 [43, 49) STAGE_PARAMS=417750528 (417.751M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008336: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=19 STAGE=1 LAYERS=6 [7, 13) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008677: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=112 STAGE=7 LAYERS=6 [43, 49) STAGE_PARAMS=417750528 (417.751M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008336: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=16 STAGE=1 LAYERS=6 [7, 13) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008677: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=115 STAGE=7 LAYERS=6 [43, 49) STAGE_PARAMS=417750528 (417.751M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008613: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=82 STAGE=5 LAYERS=6 [31, 37) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008613: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=83 STAGE=5 LAYERS=6 [31, 37) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008412: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=51 STAGE=3 LAYERS=6 [19, 25) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008336: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=17 STAGE=1 LAYERS=6 [7, 13) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008613: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=80 STAGE=5 LAYERS=6 [31, 37) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008613: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=81 STAGE=5 LAYERS=6 [31, 37) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008412: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=49 STAGE=3 LAYERS=6 [19, 25) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008412: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=50 STAGE=3 LAYERS=6 [19, 25) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008412: [2024-10-10 07:27:30,597] [INFO] [engine.py:158:__init__] RANK=48 STAGE=3 LAYERS=6 [19, 25) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
nid008276:  > number of parameters on model parallel rank 0: 644325888
nid008677:  > number of parameters on model parallel rank 0: 417750528
nid008276:  > number of parameters on model parallel rank 2: 644325888
nid008276:  > number of parameters on model parallel rank 1: 644325888
nid008276:  > number of parameters on model parallel rank 3: 644325888
nid008613:  > number of parameters on model parallel rank 0: 679762944
nid008636:  > number of parameters on model parallel rank 0: 679762944
nid008456:  > number of parameters on model parallel rank 0: 679762944
nid008412:  > number of parameters on model parallel rank 0: 679762944
nid008389:  > number of parameters on model parallel rank 0: 679762944
nid008336:  > number of parameters on model parallel rank 0: 679762944
nid008677:  > number of parameters on model parallel rank 1: 417750528
nid008677:  > number of parameters on model parallel rank 2: 417750528
nid008677:  > number of parameters on model parallel rank 3: 417750528
nid008456:  > number of parameters on model parallel rank 2: 679762944
nid008412:  > number of parameters on model parallel rank 2: 679762944
nid008389:  > number of parameters on model parallel rank 2: 679762944
nid008336:  > number of parameters on model parallel rank 2: 679762944
nid008389:  > number of parameters on model parallel rank 1: 679762944
nid008336:  > number of parameters on model parallel rank 1: 679762944
nid008412:  > number of parameters on model parallel rank 3: 679762944
nid008389:  > number of parameters on model parallel rank 3: 679762944
nid008336:  > number of parameters on model parallel rank 3: 679762944
nid008456:  > number of parameters on model parallel rank 3: 679762944
nid008456:  > number of parameters on model parallel rank 1: 679762944
nid008412:  > number of parameters on model parallel rank 1: 679762944
nid008613:  > number of parameters on model parallel rank 3: 679762944
nid008613:  > number of parameters on model parallel rank 1: 679762944
nid008636:  > number of parameters on model parallel rank 3: 679762944
nid008636:  > number of parameters on model parallel rank 1: 679762944
nid008613:  > number of parameters on model parallel rank 2: 679762944
nid008636:  > number of parameters on model parallel rank 2: 679762944
nid008276:  > total params: 20,562,616,320
nid008276: > building train, validation, and test datasets ...
nid008276:     reading sizes...
nid008276:     reading pointers...
nid008276:     reading document index...
nid008276:     creating numpy buffer of mmap...
nid008276:     creating memory view of numpy buffer...
nid008276:  > dataset split:
nid008276:     train:
nid008276:      document indices in [0, 209551959) total of 209551959 documents
nid008276:     validation:
nid008276:      document indices in [209551959, 210394379) total of 842420 documents
nid008276:     test:
nid008276:      document indices in [210394379, 210604984) total of 210605 documents
nid008276:  > WARNING: could not find index map files, building the indices on rank 0 ...
nid008276:  > elapsed time to build and save doc-idx mapping (seconds): 12.615655
nid008276:     using:
nid008276:      number of documents:       209551959
nid008276:      number of epochs:          1
nid008276:      sequence length:           2048
nid008276:      total number of samples:   181875917
nid008276:  > elapsed time to build and save sample-idx mapping (seconds): 4.575462
nid008276:  > elapsed time to build and save shuffle-idx mapping (seconds): 9.777129
nid008276:  > loading doc-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_train_indexmap_256000ns_2048sl_1234s_packedpi_ac_doc_idx.npy
nid008276:  > loading sample-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_train_indexmap_256000ns_2048sl_1234s_packedpi_ac_sample_idx.npy
nid008276:  > loading shuffle-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_train_indexmap_256000ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy
nid008276:     loaded indexed file in 0.012 seconds
nid008276:     total number of samples: 181875918
nid008276:     total number of epochs: 1
nid008276:  > loading doc-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_valid_indexmap_5120ns_2048sl_1234s_packedpi_ac_doc_idx.npy
nid008276:  > loading sample-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_valid_indexmap_5120ns_2048sl_1234s_packedpi_ac_sample_idx.npy
nid008276:  > loading shuffle-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_valid_indexmap_5120ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy
nid008276:     loaded indexed file in 0.019 seconds
nid008276:     total number of samples: 726224
nid008276:     total number of epochs: 1
nid008276:  > WARNING: could not find index map files, building the indices on rank 0 ...
nid008276:  > elapsed time to build and save doc-idx mapping (seconds): 0.007892
nid008276:     using:
nid008276:      number of documents:       210605
nid008276:      number of epochs:          1
nid008276:      sequence length:           2048
nid008276:      total number of samples:   179781
nid008276:  > elapsed time to build and save sample-idx mapping (seconds): 0.004992
nid008276:  > elapsed time to build and save shuffle-idx mapping (seconds): 0.006166
nid008276:  > loading doc-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_test_indexmap_2560ns_2048sl_1234s_packedpi_ac_doc_idx.npy
nid008276:  > loading sample-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_test_indexmap_2560ns_2048sl_1234s_packedpi_ac_sample_idx.npy
nid008276:  > loading shuffle-idx mapping from /pscratch/sd/z/zby2022/models/gpt-neox/data/pile_text_document_test_indexmap_2560ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy
nid008276:     loaded indexed file in 0.002 seconds
nid008276:     total number of samples: 179782
nid008276:     total number of epochs: 1
nid008276: setting training data start iteration to 0
nid008276: setting validation data start iteration to 0
nid008276: done with setups ...
nid008276: time (ms) | model and optimizer: 9341.75 | train/valid/test data iterators: 30218.80
nid008276: training ...
nid008276: [2024-10-10 07:28:04,109] [INFO] [checkpointing.py:540:forward] Activation Checkpointing Information
nid008276: [2024-10-10 07:28:04,109] [INFO] [checkpointing.py:541:forward] ----Partition Activations False, CPU CHECKPOINTING False
nid008276: [2024-10-10 07:28:04,109] [INFO] [checkpointing.py:542:forward] ----contiguous Memory Checkpointing False with 44 total layers
nid008276: [2024-10-10 07:28:04,109] [INFO] [checkpointing.py:544:forward] ----Synchronization True
nid008276: [2024-10-10 07:28:04,109] [INFO] [checkpointing.py:545:forward] ----Profiling time in checkpointing False
nid008276: [2024-10-10 07:28:52,748] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 821.20 | optimizer_gradients: 2.21 | optimizer_step: 3.82
nid008276: [2024-10-10 07:28:52,748] [INFO] [logging.py:96:log_dist] [Rank 0] step=1, skipped=0, lr=[9.7e-06, 9.7e-06], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:28:52,749] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 685.42 | fwd_microstep: 8868.79 | bwd_microstep: 3655.92 | bwd_inner_microstep: 3655.77 | bwd_allreduce_microstep: 0.01 | step_microstep: 842.47
nid008276: [2024-10-10 07:28:52,750] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 8868.77 | bwd: 3655.91 | bwd_inner: 3655.76 | bwd_allreduce: 0.01 | step: 842.47
nid008276: steps: 1 loss: 11.1198 iter time (s): 49.781 samples/sec: 5.143
nid008276: [2024-10-10 07:28:53,192] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 10648.51 | pipe_recv_grad: 22973.78
nid008276:  samples/sec: 5.142 | iteration        1/    1000 | elapsed time per iteration (ms): 49785.0 | learning rate: 9.700E-06 | approx flops per GPU: 14.0TFLOPS | lm_loss: 1.111983E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: after 1 iterations memory (MB) | allocated: 3129.39306640625 | max allocated: 10106.7255859375 | reserved: 12302.0 | max reserved: 12302.0
nid008276: time (ms)
nid008684: STAGE:2024-10-10 07:29:02 2178173:2178173 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008276: [2024-10-10 07:29:02,490] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 813.56 | optimizer_gradients: 2.22 | optimizer_step: 3.86
nid008276: [2024-10-10 07:29:02,490] [INFO] [logging.py:96:log_dist] [Rank 0] step=2, skipped=0, lr=[1.94e-05, 1.94e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:29:02,492] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 15.93 | fwd_microstep: 1007.86 | bwd_microstep: 2732.27 | bwd_inner_microstep: 2732.12 | bwd_allreduce_microstep: 0.00 | step_microstep: 827.66
nid008276: [2024-10-10 07:29:02,492] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1007.82 | bwd: 2732.27 | bwd_inner: 2732.12 | bwd_allreduce: 0.00 | step: 827.68
nid008276: steps: 2 loss: 11.1311 iter time (s): 9.298 samples/sec: 27.533
nid008276: [2024-10-10 07:29:02,493] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 152.97 | pipe_recv_grad: 2881.67
nid008276:  samples/sec: 27.525 | iteration        2/    1000 | elapsed time per iteration (ms): 9300.7 | learning rate: 1.940E-05 | approx flops per GPU: 74.9TFLOPS | lm_loss: 1.113111E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: STAGE:2024-10-10 07:29:02 673053:673053 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008336: STAGE:2024-10-10 07:29:02 1201576:1201576 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008684: [W CPUAllocator.cpp:231] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
nid008336: [W CPUAllocator.cpp:231] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
nid008276: [W CPUAllocator.cpp:231] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
nid008276: [2024-10-10 07:29:11,802] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 828.92 | optimizer_gradients: 2.25 | optimizer_step: 3.85
nid008276: [2024-10-10 07:29:11,802] [INFO] [logging.py:96:log_dist] [Rank 0] step=3, skipped=0, lr=[2.9100000000000003e-05, 2.9100000000000003e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:29:11,804] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 25.74 | fwd_microstep: 981.99 | bwd_microstep: 2746.56 | bwd_inner_microstep: 2746.41 | bwd_allreduce_microstep: 0.00 | step_microstep: 844.87
nid008276: [2024-10-10 07:29:11,805] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 982.04 | bwd: 2746.56 | bwd_inner: 2746.41 | bwd_allreduce: 0.00 | step: 844.90
nid008276: steps: 3 loss: 15.6249 iter time (s): 9.305 samples/sec: 27.512
nid008276: [2024-10-10 07:29:11,806] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 150.04 | pipe_recv_grad: 2890.03
nid008276:  samples/sec: 27.487 | iteration        3/    1000 | elapsed time per iteration (ms): 9313.3 | learning rate: 2.910E-05 | approx flops per GPU: 74.8TFLOPS | lm_loss: 1.562490E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: [2024-10-10 07:29:21,105] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 822.55 | optimizer_gradients: 2.25 | optimizer_step: 3.89
nid008276: [2024-10-10 07:29:21,105] [INFO] [logging.py:96:log_dist] [Rank 0] step=4, skipped=0, lr=[3.88e-05, 3.88e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:29:21,106] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.06 | fwd_microstep: 965.90 | bwd_microstep: 2734.49 | bwd_inner_microstep: 2734.34 | bwd_allreduce_microstep: 0.00 | step_microstep: 875.46
nid008276: [2024-10-10 07:29:21,108] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 965.94 | bwd: 2734.49 | bwd_inner: 2734.34 | bwd_allreduce: 0.00 | step: 875.50
nid008276: steps: 4 loss: 12.3956 iter time (s): 9.300 samples/sec: 27.527
nid008276: [2024-10-10 07:29:21,109] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 155.64 | pipe_recv_grad: 2886.84
nid008276:  samples/sec: 27.520 | iteration        4/    1000 | elapsed time per iteration (ms): 9302.4 | learning rate: 3.880E-05 | approx flops per GPU: 74.9TFLOPS | lm_loss: 1.239564E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: [2024-10-10 07:29:30,362] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 820.46 | optimizer_gradients: 2.25 | optimizer_step: 3.86
nid008276: [2024-10-10 07:29:30,363] [INFO] [logging.py:96:log_dist] [Rank 0] step=5, skipped=0, lr=[4.85e-05, 4.85e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:29:30,364] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 19.19 | fwd_microstep: 962.06 | bwd_microstep: 2733.77 | bwd_inner_microstep: 2733.62 | bwd_allreduce_microstep: 0.00 | step_microstep: 843.48
nid008276: [2024-10-10 07:29:30,365] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 962.06 | bwd: 2733.77 | bwd_inner: 2733.62 | bwd_allreduce: 0.00 | step: 843.53
nid008276: steps: 5 loss: 15.1567 iter time (s): 9.255 samples/sec: 27.660
nid008276: [2024-10-10 07:29:30,367] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 162.16 | pipe_recv_grad: 2879.51
nid008276:  samples/sec: 27.652 | iteration        5/    1000 | elapsed time per iteration (ms): 9257.8 | learning rate: 4.850E-05 | approx flops per GPU: 75.3TFLOPS | lm_loss: 1.515674E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: [2024-10-10 07:29:39,603] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 811.98 | optimizer_gradients: 2.24 | optimizer_step: 3.86
nid008276: [2024-10-10 07:29:39,603] [INFO] [logging.py:96:log_dist] [Rank 0] step=6, skipped=0, lr=[5.8200000000000005e-05, 5.8200000000000005e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:29:39,605] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 20.57 | fwd_microstep: 973.50 | bwd_microstep: 2727.13 | bwd_inner_microstep: 2726.98 | bwd_allreduce_microstep: 0.00 | step_microstep: 836.50
nid008276: [2024-10-10 07:29:39,606] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 973.52 | bwd: 2727.13 | bwd_inner: 2726.98 | bwd_allreduce: 0.00 | step: 836.53
nid008276: steps: 6 loss: 12.6545 iter time (s): 9.238 samples/sec: 27.712
nid008276: [2024-10-10 07:29:39,607] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 161.33 | pipe_recv_grad: 2874.33
nid008276:  samples/sec: 27.705 | iteration        6/    1000 | elapsed time per iteration (ms): 9240.3 | learning rate: 5.820E-05 | approx flops per GPU: 75.4TFLOPS | lm_loss: 1.265454E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: [2024-10-10 07:29:48,847] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 803.32 | optimizer_gradients: 2.24 | optimizer_step: 3.85
nid008276: [2024-10-10 07:29:48,847] [INFO] [logging.py:96:log_dist] [Rank 0] step=7, skipped=0, lr=[6.79e-05, 6.79e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:29:48,849] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 19.65 | fwd_microstep: 969.45 | bwd_microstep: 2722.83 | bwd_inner_microstep: 2722.68 | bwd_allreduce_microstep: 0.00 | step_microstep: 846.24
nid008276: [2024-10-10 07:29:48,850] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 969.51 | bwd: 2722.83 | bwd_inner: 2722.68 | bwd_allreduce: 0.00 | step: 846.26
nid008276: steps: 7 loss: 11.2380 iter time (s): 9.242 samples/sec: 27.700
nid008276: [2024-10-10 07:29:48,851] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 160.91 | pipe_recv_grad: 2886.36
nid008276:  samples/sec: 27.693 | iteration        7/    1000 | elapsed time per iteration (ms): 9244.1 | learning rate: 6.790E-05 | approx flops per GPU: 75.4TFLOPS | lm_loss: 1.123795E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008684: STAGE:2024-10-10 07:29:49 2178173:2178173 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008276: STAGE:2024-10-10 07:29:49 673053:673053 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008336: STAGE:2024-10-10 07:29:50 1201576:1201576 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008684: STAGE:2024-10-10 07:30:23 2178173:2178173 output_json.cpp:417] Completed Stage: Post Processing
nid008276: STAGE:2024-10-10 07:30:38 673053:673053 output_json.cpp:417] Completed Stage: Post Processing
nid008336: STAGE:2024-10-10 07:30:45 1201576:1201576 output_json.cpp:417] Completed Stage: Post Processing
nid008276: [2024-10-10 07:30:55,218] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 821.51 | optimizer_gradients: 2.21 | optimizer_step: 3.81
nid008276: [2024-10-10 07:30:55,218] [INFO] [logging.py:96:log_dist] [Rank 0] step=8, skipped=0, lr=[7.76e-05, 7.76e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:30:55,219] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 13.51 | fwd_microstep: 8286.30 | bwd_microstep: 2747.69 | bwd_inner_microstep: 2747.54 | bwd_allreduce_microstep: 0.00 | step_microstep: 899.12
nid008276: [2024-10-10 07:30:55,220] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 8286.30 | bwd: 2747.69 | bwd_inner: 2747.54 | bwd_allreduce: 0.00 | step: 899.13
nid008276: steps: 8 loss: 11.4583 iter time (s): 16.884 samples/sec: 15.162
nid008276: [2024-10-10 07:30:55,221] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 361.88 | pipe_recv_grad: 2890.32
nid008276:  samples/sec: 3.857 | iteration        8/    1000 | elapsed time per iteration (ms): 66369.7 | learning rate: 7.760E-05 | approx flops per GPU: 10.5TFLOPS | lm_loss: 1.145835E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: [2024-10-10 07:31:04,543] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 814.34 | optimizer_gradients: 2.20 | optimizer_step: 3.83
nid008276: [2024-10-10 07:31:04,543] [INFO] [logging.py:96:log_dist] [Rank 0] step=9, skipped=0, lr=[8.73e-05, 8.73e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:31:04,544] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 12.64 | fwd_microstep: 977.23 | bwd_microstep: 2752.18 | bwd_inner_microstep: 2752.03 | bwd_allreduce_microstep: 0.00 | step_microstep: 879.75
nid008276: [2024-10-10 07:31:04,545] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 977.27 | bwd: 2752.18 | bwd_inner: 2752.03 | bwd_allreduce: 0.00 | step: 879.77
nid008276: steps: 9 loss: 11.2638 iter time (s): 9.323 samples/sec: 27.458
nid008276: [2024-10-10 07:31:04,546] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 167.85 | pipe_recv_grad: 2847.22
nid008276:  samples/sec: 27.453 | iteration        9/    1000 | elapsed time per iteration (ms): 9325.1 | learning rate: 8.730E-05 | approx flops per GPU: 74.7TFLOPS | lm_loss: 1.126381E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008684: STAGE:2024-10-10 07:31:15 2178173:2178173 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008276: [2024-10-10 07:31:15,995] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 834.87 | optimizer_gradients: 2.23 | optimizer_step: 3.85
nid008276: [2024-10-10 07:31:15,996] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[9.7e-05, 9.7e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:31:15,997] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 17.79 | fwd_microstep: 1328.82 | bwd_microstep: 2697.11 | bwd_inner_microstep: 2696.96 | bwd_allreduce_microstep: 0.00 | step_microstep: 855.22
nid008276: [2024-10-10 07:31:15,998] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1328.85 | bwd: 2697.11 | bwd_inner: 2696.96 | bwd_allreduce: 0.00 | step: 855.23
nid008276: steps: 10 loss: 10.8211 iter time (s): 9.583 samples/sec: 26.714
nid008276: [2024-10-10 07:31:15,999] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 151.45 | pipe_recv_grad: 2872.86
nid008276:  samples/sec: 22.352 | iteration       10/    1000 | elapsed time per iteration (ms): 11453.1 | learning rate: 9.700E-05 | approx flops per GPU: 60.9TFLOPS | lm_loss: 1.082107E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: STAGE:2024-10-10 07:31:16 673053:673053 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008336: STAGE:2024-10-10 07:31:16 1201576:1201576 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008276: [2024-10-10 07:31:25,239] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 822.23 | optimizer_gradients: 2.24 | optimizer_step: 3.86
nid008276: [2024-10-10 07:31:25,239] [INFO] [logging.py:96:log_dist] [Rank 0] step=11, skipped=0, lr=[9.699978022249231e-05, 9.699978022249231e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:31:25,241] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 19.06 | fwd_microstep: 960.80 | bwd_microstep: 2704.10 | bwd_inner_microstep: 2703.95 | bwd_allreduce_microstep: 0.00 | step_microstep: 837.17
nid008276: [2024-10-10 07:31:25,242] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 960.81 | bwd: 2704.10 | bwd_inner: 2703.95 | bwd_allreduce: 0.00 | step: 837.19
nid008276: steps: 11 loss: 10.8186 iter time (s): 9.242 samples/sec: 27.701
nid008276: [2024-10-10 07:31:25,243] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 160.19 | pipe_recv_grad: 2895.55
nid008276:  samples/sec: 27.693 | iteration       11/    1000 | elapsed time per iteration (ms): 9244.3 | learning rate: 9.700E-05 | approx flops per GPU: 75.4TFLOPS | lm_loss: 1.081862E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: [2024-10-10 07:31:34,437] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 804.15 | optimizer_gradients: 2.24 | optimizer_step: 3.87
nid008276: [2024-10-10 07:31:34,437] [INFO] [logging.py:96:log_dist] [Rank 0] step=12, skipped=0, lr=[9.699912089218237e-05, 9.699912089218237e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:31:34,439] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 19.39 | fwd_microstep: 960.39 | bwd_microstep: 2703.78 | bwd_inner_microstep: 2703.62 | bwd_allreduce_microstep: 0.00 | step_microstep: 819.14
nid008276: [2024-10-10 07:31:34,440] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 960.44 | bwd: 2703.78 | bwd_inner: 2703.62 | bwd_allreduce: 0.00 | step: 819.16
nid008276: steps: 12 loss: 10.2503 iter time (s): 9.195 samples/sec: 27.841
nid008276: [2024-10-10 07:31:34,441] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 163.63 | pipe_recv_grad: 2883.58
nid008276:  samples/sec: 27.834 | iteration       12/    1000 | elapsed time per iteration (ms): 9197.4 | learning rate: 9.700E-05 | approx flops per GPU: 75.8TFLOPS | lm_loss: 1.025027E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: [2024-10-10 07:31:43,637] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 801.60 | optimizer_gradients: 2.24 | optimizer_step: 3.87
nid008276: [2024-10-10 07:31:43,638] [INFO] [logging.py:96:log_dist] [Rank 0] step=13, skipped=0, lr=[9.699802201570964e-05, 9.699802201570964e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:31:43,639] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 19.76 | fwd_microstep: 968.92 | bwd_microstep: 2702.25 | bwd_inner_microstep: 2702.10 | bwd_allreduce_microstep: 0.00 | step_microstep: 831.48
nid008276: [2024-10-10 07:31:43,640] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 968.98 | bwd: 2702.25 | bwd_inner: 2702.10 | bwd_allreduce: 0.00 | step: 831.50
nid008276: steps: 13 loss: 9.7699 iter time (s): 9.198 samples/sec: 27.832
nid008276: [2024-10-10 07:31:43,641] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 159.29 | pipe_recv_grad: 2898.09
nid008276:  samples/sec: 27.824 | iteration       13/    1000 | elapsed time per iteration (ms): 9200.6 | learning rate: 9.700E-05 | approx flops per GPU: 75.8TFLOPS | lm_loss: 9.769890E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: [2024-10-10 07:31:52,868] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 807.26 | optimizer_gradients: 2.24 | optimizer_step: 3.86
nid008276: [2024-10-10 07:31:52,868] [INFO] [logging.py:96:log_dist] [Rank 0] step=14, skipped=0, lr=[9.699648360413981e-05, 9.699648360413981e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:31:52,870] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 20.63 | fwd_microstep: 967.92 | bwd_microstep: 2703.03 | bwd_inner_microstep: 2702.88 | bwd_allreduce_microstep: 0.00 | step_microstep: 843.51
nid008276: [2024-10-10 07:31:52,871] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 967.93 | bwd: 2703.03 | bwd_inner: 2702.88 | bwd_allreduce: 0.00 | step: 843.53
nid008276: steps: 14 loss: 9.6549 iter time (s): 9.228 samples/sec: 27.742
nid008276: [2024-10-10 07:31:52,872] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 152.87 | pipe_recv_grad: 2902.52
nid008276:  samples/sec: 27.734 | iteration       14/    1000 | elapsed time per iteration (ms): 9230.5 | learning rate: 9.700E-05 | approx flops per GPU: 75.5TFLOPS | lm_loss: 9.654885E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: [2024-10-10 07:32:02,172] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 807.89 | optimizer_gradients: 2.25 | optimizer_step: 3.84
nid008276: [2024-10-10 07:32:02,172] [INFO] [logging.py:96:log_dist] [Rank 0] step=15, skipped=0, lr=[9.699450567296466e-05, 9.699450567296466e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:32:02,174] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 19.38 | fwd_microstep: 990.73 | bwd_microstep: 2703.36 | bwd_inner_microstep: 2703.21 | bwd_allreduce_microstep: 0.00 | step_microstep: 860.72
nid008276: [2024-10-10 07:32:02,175] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 990.77 | bwd: 2703.36 | bwd_inner: 2703.21 | bwd_allreduce: 0.00 | step: 860.74
nid008276: steps: 15 loss: 9.2121 iter time (s): 9.302 samples/sec: 27.522
nid008276: [2024-10-10 07:32:02,176] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 161.85 | pipe_recv_grad: 2883.21
nid008276:  samples/sec: 27.515 | iteration       15/    1000 | elapsed time per iteration (ms): 9304.0 | learning rate: 9.699E-05 | approx flops per GPU: 74.9TFLOPS | lm_loss: 9.212142E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008684: STAGE:2024-10-10 07:32:02 2178173:2178173 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008276: STAGE:2024-10-10 07:32:02 673053:673053 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008336: STAGE:2024-10-10 07:32:03 1201576:1201576 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008684: STAGE:2024-10-10 07:32:37 2178173:2178173 output_json.cpp:417] Completed Stage: Post Processing
nid008276: STAGE:2024-10-10 07:32:54 673053:673053 output_json.cpp:417] Completed Stage: Post Processing
nid008336: STAGE:2024-10-10 07:33:03 1201576:1201576 output_json.cpp:417] Completed Stage: Post Processing
nid008276: [2024-10-10 07:33:13,051] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 844.81 | optimizer_gradients: 2.21 | optimizer_step: 3.82
nid008276: [2024-10-10 07:33:13,051] [INFO] [logging.py:96:log_dist] [Rank 0] step=16, skipped=0, lr=[9.699208824210191e-05, 9.699208824210191e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:33:13,052] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 13.22 | fwd_microstep: 10647.53 | bwd_microstep: 2730.31 | bwd_inner_microstep: 2730.16 | bwd_allreduce_microstep: 0.00 | step_microstep: 863.06
nid008276: [2024-10-10 07:33:13,053] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 10647.54 | bwd: 2730.31 | bwd_inner: 2730.16 | bwd_allreduce: 0.00 | step: 863.07
nid008276: steps: 16 loss: 8.8715 iter time (s): 18.951 samples/sec: 13.509
nid008276: [2024-10-10 07:33:13,054] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 144.29 | pipe_recv_grad: 2912.54
nid008276:  samples/sec: 3.612 | iteration       16/    1000 | elapsed time per iteration (ms): 70877.8 | learning rate: 9.699E-05 | approx flops per GPU: 9.8TFLOPS | lm_loss: 8.871521E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: [2024-10-10 07:33:22,289] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 812.93 | optimizer_gradients: 2.20 | optimizer_step: 3.82
nid008276: [2024-10-10 07:33:22,290] [INFO] [logging.py:96:log_dist] [Rank 0] step=17, skipped=0, lr=[9.698923133589508e-05, 9.698923133589508e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:33:22,291] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 12.52 | fwd_microstep: 946.34 | bwd_microstep: 2679.82 | bwd_inner_microstep: 2679.67 | bwd_allreduce_microstep: 0.00 | step_microstep: 828.25
nid008276: [2024-10-10 07:33:22,291] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 946.39 | bwd: 2679.82 | bwd_inner: 2679.67 | bwd_allreduce: 0.00 | step: 828.26
nid008276: steps: 17 loss: 8.5617 iter time (s): 9.237 samples/sec: 27.715
nid008276: [2024-10-10 07:33:22,292] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 165.53 | pipe_recv_grad: 2899.23
nid008276:  samples/sec: 27.710 | iteration       17/    1000 | elapsed time per iteration (ms): 9238.6 | learning rate: 9.699E-05 | approx flops per GPU: 75.4TFLOPS | lm_loss: 8.561739E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008684: STAGE:2024-10-10 07:33:33 2178173:2178173 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008276: [2024-10-10 07:33:33,827] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 797.25 | optimizer_gradients: 2.22 | optimizer_step: 3.86
nid008276: [2024-10-10 07:33:33,827] [INFO] [logging.py:96:log_dist] [Rank 0] step=18, skipped=0, lr=[9.698593498311318e-05, 9.698593498311318e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:33:33,829] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 25.96 | fwd_microstep: 1502.74 | bwd_microstep: 2687.00 | bwd_inner_microstep: 2686.84 | bwd_allreduce_microstep: 0.00 | step_microstep: 852.99
nid008276: [2024-10-10 07:33:33,829] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1502.76 | bwd: 2687.00 | bwd_inner: 2686.84 | bwd_allreduce: 0.00 | step: 853.00
nid008276: steps: 18 loss: 8.3040 iter time (s): 9.612 samples/sec: 26.633
nid008276: [2024-10-10 07:33:33,831] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 272.28 | pipe_recv_grad: 2666.97
nid008276:  samples/sec: 22.187 | iteration       18/    1000 | elapsed time per iteration (ms): 11538.4 | learning rate: 9.699E-05 | approx flops per GPU: 60.4TFLOPS | lm_loss: 8.303969E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: STAGE:2024-10-10 07:33:33 673053:673053 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008336: STAGE:2024-10-10 07:33:33 1201576:1201576 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
nid008276: [2024-10-10 07:33:43,297] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 842.87 | optimizer_gradients: 2.25 | optimizer_step: 3.85
nid008276: [2024-10-10 07:33:43,298] [INFO] [logging.py:96:log_dist] [Rank 0] step=19, skipped=0, lr=[9.698219921695046e-05, 9.698219921695046e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:33:43,299] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 20.93 | fwd_microstep: 979.91 | bwd_microstep: 2699.63 | bwd_inner_microstep: 2699.48 | bwd_allreduce_microstep: 0.00 | step_microstep: 954.30
nid008276: [2024-10-10 07:33:43,300] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 979.95 | bwd: 2699.63 | bwd_inner: 2699.48 | bwd_allreduce: 0.00 | step: 954.32
nid008276: steps: 19 loss: 8.0287 iter time (s): 9.468 samples/sec: 27.038
nid008276: [2024-10-10 07:33:43,302] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 163.19 | pipe_recv_grad: 2876.24
nid008276:  samples/sec: 27.030 | iteration       19/    1000 | elapsed time per iteration (ms): 9470.9 | learning rate: 9.698E-05 | approx flops per GPU: 73.6TFLOPS | lm_loss: 8.028683E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: [2024-10-10 07:33:52,582] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 796.34 | optimizer_gradients: 2.24 | optimizer_step: 3.86
nid008276: [2024-10-10 07:33:52,582] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[9.697802407502604e-05, 9.697802407502604e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:33:52,584] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.46 | fwd_microstep: 960.40 | bwd_microstep: 2701.46 | bwd_inner_microstep: 2701.31 | bwd_allreduce_microstep: 0.00 | step_microstep: 918.07
nid008276: [2024-10-10 07:33:52,585] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 960.38 | bwd: 2701.46 | bwd_inner: 2701.31 | bwd_allreduce: 0.00 | step: 918.09
nid008276: steps: 20 loss: 8.1695 iter time (s): 9.282 samples/sec: 27.580
nid008276: [2024-10-10 07:33:52,586] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 163.83 | pipe_recv_grad: 2883.23
nid008276:  samples/sec: 27.573 | iteration       20/    1000 | elapsed time per iteration (ms): 9284.5 | learning rate: 9.698E-05 | approx flops per GPU: 75.1TFLOPS | lm_loss: 8.169478E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: [2024-10-10 07:34:01,808] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 801.13 | optimizer_gradients: 2.24 | optimizer_step: 3.85
nid008276: [2024-10-10 07:34:01,809] [INFO] [logging.py:96:log_dist] [Rank 0] step=21, skipped=0, lr=[9.697340959938354e-05, 9.697340959938354e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:34:01,810] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.42 | fwd_microstep: 1005.47 | bwd_microstep: 2765.03 | bwd_inner_microstep: 2764.88 | bwd_allreduce_microstep: 0.00 | step_microstep: 820.04
nid008276: [2024-10-10 07:34:01,811] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1005.49 | bwd: 2765.03 | bwd_inner: 2764.88 | bwd_allreduce: 0.00 | step: 820.06
nid008276: steps: 21 loss: 8.0996 iter time (s): 9.224 samples/sec: 27.753
nid008276: [2024-10-10 07:34:01,813] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 155.98 | pipe_recv_grad: 2823.13
nid008276:  samples/sec: 27.746 | iteration       21/    1000 | elapsed time per iteration (ms): 9226.7 | learning rate: 9.697E-05 | approx flops per GPU: 75.5TFLOPS | lm_loss: 8.099625E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: [2024-10-10 07:34:14,414] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 816.39 | optimizer_gradients: 2.25 | optimizer_step: 3.85
nid008276: [2024-10-10 07:34:14,414] [INFO] [logging.py:96:log_dist] [Rank 0] step=22, skipped=0, lr=[9.696835583649068e-05, 9.696835583649068e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:34:14,418] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 76.40 | fwd_microstep: 961.50 | bwd_microstep: 6097.75 | bwd_inner_microstep: 6043.93 | bwd_allreduce_microstep: 0.00 | step_microstep: 831.61
nid008276: [2024-10-10 07:34:14,420] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 961.40 | bwd: 6106.86 | bwd_inner: 6071.76 | bwd_allreduce: 0.00 | step: 831.63
nid008276: steps: 22 loss: 8.0291 iter time (s): 12.606 samples/sec: 20.308
nid008276: [2024-10-10 07:34:14,422] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 152.61 | pipe_recv_grad: 2803.57
nid008276:  samples/sec: 20.302 | iteration       22/    1000 | elapsed time per iteration (ms): 12609.6 | learning rate: 9.697E-05 | approx flops per GPU: 55.3TFLOPS | lm_loss: 8.029089E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008276: [2024-10-10 07:34:23,761] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 871.32 | optimizer_gradients: 2.28 | optimizer_step: 3.87
nid008276: [2024-10-10 07:34:23,761] [INFO] [logging.py:96:log_dist] [Rank 0] step=23, skipped=0, lr=[9.696286283723879e-05, 9.696286283723879e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
nid008276: [2024-10-10 07:34:23,763] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 23.15 | fwd_microstep: 974.00 | bwd_microstep: 2702.94 | bwd_inner_microstep: 2702.79 | bwd_allreduce_microstep: 0.00 | step_microstep: 888.67
nid008276: [2024-10-10 07:34:23,764] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 974.04 | bwd: 2702.94 | bwd_inner: 2702.79 | bwd_allreduce: 0.00 | step: 888.71
nid008276: steps: 23 loss: 7.8091 iter time (s): 9.341 samples/sec: 27.406
nid008276: [2024-10-10 07:34:23,766] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 163.08 | pipe_recv_grad: 2897.10
nid008276:  samples/sec: 27.398 | iteration       23/    1000 | elapsed time per iteration (ms): 9343.6 | learning rate: 9.696E-05 | approx flops per GPU: 74.6TFLOPS | lm_loss: 7.809129E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
nid008276: time (ms)
nid008684: STAGE:2024-10-10 07:34:24 2178173:2178173 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008276: STAGE:2024-10-10 07:34:24 673053:673053 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008336: STAGE:2024-10-10 07:34:24 1201576:1201576 ActivityProfilerController.cpp:300] Completed Stage: Collection
nid008684: STAGE:2024-10-10 07:35:01 2178173:2178173 output_json.cpp:417] Completed Stage: Post Processing
nid008276: STAGE:2024-10-10 07:35:11 673053:673053 output_json.cpp:417] Completed Stage: Post Processing
nid008336: STAGE:2024-10-10 07:35:27 1201576:1201576 output_json.cpp:417] Completed Stage: Post Processing
nid008616: Connection to nid008616 closed by remote host.
nid008453: Connection to nid008453 closed by remote host.
nid008637: Connection to nid008637 closed by remote host.
nid008492: Connection to nid008492 closed by remote host.
nid008409: Connection to nid008409 closed by remote host.
nid008620: Connection to nid008620 closed by remote host.
nid008641: Connection to nid008641 closed by remote host.
nid008640: Connection to nid008640 closed by remote host.
nid008636: Connection to nid008636 closed by remote host.
nid008420: Connection to nid008420 closed by remote host.
nid008392: Connection to nid008392 closed by remote host.
nid008389: Connection to nid008389 closed by remote host.
nid008476: Connection to nid008476 closed by remote host.
pdsh@nid008276: nid008616: ssh exited with exit code 255
nid008336: Connection to nid008336 closed by remote host.
nid008421: Connection to nid008421 closed by remote host.
nid008681: Connection to nid008681 closed by remote host.
nid008684: Connection to nid008684 closed by remote host.
nid008301: Connection to nid008301 closed by remote host.
nid008385: Connection to nid008385 closed by remote host.
nid008412: Connection to nid008412 closed by remote host.
nid008493: Connection to nid008493 closed by remote host.
nid008337: Connection to nid008337 closed by remote host.
pdsh@nid008276: nid008453: ssh exited with exit code 255
nid008677: Connection to nid008677 closed by remote host.
nid008617: Connection to nid008617 closed by remote host.
pdsh@nid008276: nid008492: ssh exited with exit code 255
pdsh@nid008276: nid008637: ssh exited with exit code 255
nid008680: Connection to nid008680 closed by remote host.
pdsh@nid008276: nid008620: ssh exited with exit code 255
nid008384: Connection to nid008384 closed by remote host.
nid008304: Connection to nid008304 closed by remote host.
pdsh@nid008276: nid008409: ssh exited with exit code 255
nid008456: Connection to nid008456 closed by remote host.
nid008393: Connection to nid008393 closed by remote host.
pdsh@nid008276: nid008392: ssh exited with exit code 255
pdsh@nid008276: nid008420: ssh exited with exit code 255
pdsh@nid008276: nid008640: ssh exited with exit code 255
pdsh@nid008276: nid008389: ssh exited with exit code 255
nid008333: Connection to nid008333 closed by remote host.
pdsh@nid008276: nid008636: ssh exited with exit code 255
pdsh@nid008276: nid008476: ssh exited with exit code 255
pdsh@nid008276: nid008681: ssh exited with exit code 255
pdsh@nid008276: nid008301: ssh exited with exit code 255
pdsh@nid008276: nid008421: ssh exited with exit code 255
pdsh@nid008276: nid008337: ssh exited with exit code 255
pdsh@nid008276: nid008336: ssh exited with exit code 255
pdsh@nid008276: nid008684: ssh exited with exit code 255
nid008613: Connection to nid008613 closed by remote host.
pdsh@nid008276: nid008493: ssh exited with exit code 255
pdsh@nid008276: nid008677: ssh exited with exit code 255
pdsh@nid008276: nid008617: ssh exited with exit code 255
pdsh@nid008276: nid008641: ssh exited with exit code 255
pdsh@nid008276: nid008385: ssh exited with exit code 255
pdsh@nid008276: nid008384: ssh exited with exit code 255
pdsh@nid008276: nid008680: ssh exited with exit code 255
pdsh@nid008276: nid008412: ssh exited with exit code 255
pdsh@nid008276: nid008304: ssh exited with exit code 255
pdsh@nid008276: nid008393: ssh exited with exit code 255
pdsh@nid008276: nid008456: ssh exited with exit code 255
pdsh@nid008276: nid008333: ssh exited with exit code 255
pdsh@nid008276: nid008613: ssh exited with exit code 255
