cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::zero_,279905,"[[1, 1, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",915443,0,9.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::copy_,279915,"[[], [], []]",Memcpy HtoD (Pageable -> Device),915478,5995.666666666667,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::native_layer_norm,279920,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",915500,2182.3333333333335,169.98666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::native_layer_norm,279927,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",915522,39.0,169.36
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::addmm,279941,"[[4608], [8192, 6144], [6144, 4608], [], []]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_relu_f2f_stages_64x3_tn,915541,435.3333333333333,1780.1866666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::copy_,279966,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),915559,133.0,5.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::copy_,279970,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),915569,1020.6666666666666,5.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::neg,279980,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",915577,2281.3333333333335,14.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,<forward op>,279991,"[[2048, 1, 1, 24], [], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",915586,816.0,28.373333333333335
None,None,None,None,None,None,kernel_1,915599,328.6666666666667,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::neg,280003,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",915606,905.6666666666666,15.986666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,apply_rotary_pos_emb,279971,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",915615,555.3333333333334,28.053333333333335
None,None,None,None,None,None,kernel_1,915628,170.0,11.986666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::cat,280021,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",915636,841.0,102.86666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,CheckpointFunctionBackward,279902,"[[2048, 4, 6144], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",915645,38.0,103.62666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::baddbmm,280032,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,915663,41.666666666666664,649.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,ScaledUpperTriangMaskedSoftmax,280035,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",915672,38.0,603.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::bmm,280052,"[[64, 2048, 2048], [64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,915718,38.333333333333336,403.0133333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::clone,280057,"[[2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",915729,41.333333333333336,60.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::mm,281605,"[[8192, 1536], [1536, 6144]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn,915746,154.66666666666666,643.2533333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::add,281610,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",915757,39.0,215.22666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::mm,281622,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),915770,41.0,2318.6666666666665
None,None,None,None,None,None,kernel_2,915783,42.333333333333336,160.26666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::mm,281637,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),915795,39.666666666666664,2318.866666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,CheckpointFunctionBackward,279902,"[[2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",915803,37.0,212.86666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,CheckpointFunctionBackward,279902,"[[2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",915811,40.0,173.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,nccl:all_reduce,281648,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",915829,50.0,753.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::add,281652,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",915868,50.333333333333336,174.61333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::sum,281664,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",915923,136.66666666666666,86.21333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,torch::autograd::AccumulateGrad,281667,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",915930,39.0,3.1333333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::mm,281678,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,915953,150.66666666666666,2280.826666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,MmBackward0,281674,"[[8192, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),915973,39.0,2294.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,torch::autograd::AccumulateGrad,281696,"[[6144, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",915984,40.666666666666664,119.24
None,None,None,None,None,None,kernel_3,916003,43.0,214.61333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::sum,281705,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",916029,136.0,83.13333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,torch::autograd::AccumulateGrad,281708,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",916036,40.333333333333336,3.1066666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::mm,281719,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,916059,151.66666666666666,2252.4533333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,MmBackward0,281715,"[[8192, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),916079,37.333333333333336,2261.213333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,torch::autograd::AccumulateGrad,281737,"[[6144, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",916090,43.0,119.37333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,nccl:all_reduce,281743,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",916110,73.0,719.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::sum,281749,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",916172,168.33333333333334,80.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,torch::autograd::AccumulateGrad,281752,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",916179,43.333333333333336,3.1466666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::mm,281763,"[[6144, 8192], [8192, 1536]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,916202,143.0,573.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: MmBackward0,281758,,ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,916220,38.0,605.52
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,torch::autograd::AccumulateGrad,281781,"[[6144, 1536]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",916231,39.0,27.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,BmmBackward0,281798,"[[64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,916257,36.0,371.82666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: BmmBackward0,281797,,ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,916273,37.0,654.0933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,ScaledUpperTriangMaskedSoftmaxBackward,281822,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",916287,37.0,853.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,BaddbmmBackward0,281836,"[[64, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,916307,41.666666666666664,396.4533333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,BaddbmmBackward0,281836,"[[64, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",916319,38.333333333333336,26.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,BaddbmmBackward0,281836,"[[64, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,916334,42.333333333333336,372.46666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,BaddbmmBackward0,281836,"[[64, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",916346,36.666666666666664,28.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,<backward op>,281885,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",916374,37.333333333333336,19.293333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,torch::jit::(anonymous namespace)::DifferentiableGraphBackward,281884,"[[2048, 4, 16, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",916386,43.333333333333336,18.413333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: NegBackward0,281891,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",916400,38.666666666666664,9.253333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::slice_backward,281896,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",916417,41.0,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::copy_,281903,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",916423,38.666666666666664,22.813333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: SliceBackward0,281894,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",916437,33.333333333333336,41.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::slice_backward,281907,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",916455,37.333333333333336,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,SliceBackward0,281906,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",916461,39.666666666666664,23.706666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: SliceBackward0,281905,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",916475,37.333333333333336,40.973333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,<backward op>,281918,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",916490,40.333333333333336,20.333333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,torch::jit::(anonymous namespace)::DifferentiableGraphBackward,281917,"[[2048, 4, 16, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",916502,41.333333333333336,18.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,NegBackward0,281925,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",916516,38.0,11.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::slice_backward,281929,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",916533,42.333333333333336,7.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,SliceBackward0,281928,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",916539,42.333333333333336,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: SliceBackward0,281927,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",916553,34.666666666666664,18.586666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::zero_,281943,"[[2048, 4, 16, 24]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",916571,34.666666666666664,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::slice_backward,281940,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",916577,39.333333333333336,12.306666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: SliceBackward0,281938,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",916591,38.666666666666664,16.56
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::slice_backward,281951,"[[2048, 4, 16, 72], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",916609,39.333333333333336,20.053333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::slice_backward,281951,"[[2048, 4, 16, 72], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",916615,48.0,108.57333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::slice_backward,281961,"[[2048, 4, 16, 24], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",916633,36.666666666666664,22.64
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: SliceBackward0,281959,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",916639,37.666666666666664,40.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: SliceBackward0,281959,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",916653,39.666666666666664,44.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::slice_backward,281972,"[[2048, 4, 16, 72], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",916671,39.666666666666664,21.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,SliceBackward0,281971,"[[2048, 4, 16, 72]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",916677,36.666666666666664,55.986666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::slice_backward,281982,"[[2048, 4, 16, 24], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",916695,39.666666666666664,22.826666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,SliceBackward0,281981,"[[2048, 4, 16, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",916701,38.0,23.346666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: SliceBackward0,281980,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",916715,40.0,44.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: SplitBackward0,281991,,"void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",916731,38.666666666666664,249.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,AddmmBackward0,282003,"[[8192, 4608]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),916754,42.0,1694.2533333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::mm,282011,"[[4608, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,916773,140.66666666666666,1646.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::sum,282015,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",916803,138.66666666666666,62.74666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,torch::autograd::AccumulateGrad,282018,[[4608]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",916810,37.666666666666664,3.1466666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,torch::autograd::AccumulateGrad,282030,"[[4608, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",916821,44.333333333333336,86.05333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,nccl:all_reduce,282036,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",916841,93.66666666666667,755.2666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::native_layer_norm_backward,282040,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",916908,68.0,362.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: NativeLayerNormBackward0,282038,,"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",916910,38.0,203.42666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: NativeLayerNormBackward0,282038,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",916931,40.0,164.69333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,torch::autograd::AccumulateGrad,282046,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",916939,39.0,3.3466666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,torch::autograd::AccumulateGrad,282049,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",916946,41.333333333333336,3.013333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,aten::native_layer_norm_backward,282053,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",916988,42.0,372.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: NativeLayerNormBackward0,282051,,"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",916990,39.666666666666664,202.17333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: NativeLayerNormBackward0,282051,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",917013,37.0,165.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,282062,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",917023,40.333333333333336,3.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,279901,,torch::autograd::AccumulateGrad,282066,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",917030,44.333333333333336,3.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,CheckpointFunctionBackward,282069,"[[2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",917053,2505.3333333333335,8.52
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::copy_,282082,"[[], [], []]",Memcpy HtoD (Pageable -> Device),917085,3617.6666666666665,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::native_layer_norm,282087,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",917107,1693.6666666666667,168.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::native_layer_norm,282094,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",917129,38.666666666666664,169.46666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::addmm,282108,"[[4608], [8192, 6144], [6144, 4608], [], []]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_relu_f2f_stages_64x3_tn,917148,153.33333333333334,1782.3733333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::copy_,282133,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),917166,119.33333333333333,5.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::copy_,282137,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),917176,973.0,5.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::neg,282147,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",917184,2083.3333333333335,14.053333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,<forward op>,282158,"[[2048, 1, 1, 24], [], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",917193,773.0,28.373333333333335
None,None,None,None,None,None,kernel_1,917206,270.6666666666667,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::neg,282170,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",917213,873.0,15.986666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,apply_rotary_pos_emb,282138,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",917222,635.3333333333334,28.08
None,None,None,None,None,None,kernel_1,917235,204.33333333333334,11.973333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,CheckpointFunctionBackward,282069,"[[2048, 4, 6144], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",917243,805.0,102.85333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::cat,282189,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",917252,38.0,103.73333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::baddbmm,282199,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,917270,37.0,649.48
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,ScaledUpperTriangMaskedSoftmax,282202,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",917279,39.0,604.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::bmm,282219,"[[64, 2048, 2048], [64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,917325,43.666666666666664,402.64
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::clone,282224,"[[2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",917336,41.333333333333336,60.986666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::mm,282236,"[[8192, 1536], [1536, 6144]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn,917353,151.66666666666666,644.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,CheckpointFunctionBackward,282069,"[[2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",917364,39.0,215.33333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::mm,282253,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),917377,41.333333333333336,2322.8533333333335
None,None,None,None,None,None,kernel_2,917390,39.0,160.14666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::matmul,282265,"[[2048, 4, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),917402,38.0,2322.2266666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,CheckpointFunctionBackward,282069,"[[2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",917410,40.333333333333336,212.90666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,CheckpointFunctionBackward,282069,"[[2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",917418,35.0,173.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,nccl:all_reduce,282279,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",917436,50.666666666666664,753.7733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::add,282283,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",917475,51.0,174.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::sum,282295,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",917530,136.0,85.89333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,torch::autograd::AccumulateGrad,282298,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",917537,39.0,3.013333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::mm,282309,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,917560,151.66666666666666,2284.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: MmBackward0,282304,,void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),917580,38.666666666666664,2297.213333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,torch::autograd::AccumulateGrad,282327,"[[6144, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",917591,40.0,119.28
None,None,None,None,None,None,kernel_3,917610,43.666666666666664,214.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::sum,282336,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",917636,138.66666666666666,83.77333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,torch::autograd::AccumulateGrad,282339,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",917643,39.333333333333336,3.0533333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::mm,282350,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,917666,150.33333333333334,2253.6133333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,MmBackward0,282346,"[[8192, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),917686,40.0,2263.36
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,torch::autograd::AccumulateGrad,282368,"[[6144, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",917697,41.333333333333336,119.26666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,nccl:all_reduce,282374,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",917717,69.66666666666667,719.4133333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::sum,282380,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",917779,157.33333333333334,80.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,torch::autograd::AccumulateGrad,282383,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",917786,44.0,3.1066666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::mm,282394,"[[6144, 8192], [8192, 1536]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,917809,144.0,573.3733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: MmBackward0,282389,,ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,917827,38.0,605.8666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::add_,282413,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",917838,38.333333333333336,27.533333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,BmmBackward0,282429,"[[64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,917864,38.0,371.7866666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: BmmBackward0,282428,,ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,917880,40.333333333333336,654.2133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,ScaledUpperTriangMaskedSoftmaxBackward,282453,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",917894,37.0,852.8666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,BaddbmmBackward0,282467,"[[64, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,917914,37.666666666666664,396.64
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,BaddbmmBackward0,282467,"[[64, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",917926,39.666666666666664,26.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,BaddbmmBackward0,282467,"[[64, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,917941,41.333333333333336,372.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,BaddbmmBackward0,282467,"[[64, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",917953,37.666666666666664,27.906666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,<backward op>,282516,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",917981,35.666666666666664,19.226666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,<backward op>,282516,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",917993,43.333333333333336,18.093333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: NegBackward0,282522,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",918007,43.0,9.226666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::zeros,282528,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",918024,41.333333333333336,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,SliceBackward0,282526,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",918030,40.666666666666664,22.813333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: SliceBackward0,282525,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",918044,36.0,41.42666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::slice_backward,282538,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",918062,37.0,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::slice_backward,282538,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",918068,38.333333333333336,23.69333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: SliceBackward0,282536,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",918082,37.333333333333336,41.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,<backward op>,282549,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",918097,41.0,20.266666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,torch::jit::(anonymous namespace)::DifferentiableGraphBackward,282548,"[[2048, 4, 16, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",918109,40.0,18.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: NegBackward0,282555,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",918123,37.333333333333336,11.226666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::slice_backward,282560,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",918140,43.333333333333336,7.026666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::slice_backward,282560,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",918146,39.666666666666664,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: SliceBackward0,282558,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",918160,34.333333333333336,18.333333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::slice_backward,282571,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",918178,36.0,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: SliceBackward0,282569,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",918184,39.666666666666664,12.173333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: SliceBackward0,282569,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",918198,34.0,16.813333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::slice_backward,282582,"[[2048, 4, 16, 72], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",918216,38.0,20.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,SliceBackward0,282581,"[[2048, 4, 16, 72]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",918222,47.0,108.61333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::slice_backward,282592,"[[2048, 4, 16, 24], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",918240,38.333333333333336,22.613333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: SliceBackward0,282590,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",918246,38.333333333333336,40.36
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: SliceBackward0,282590,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",918260,39.0,44.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::slice_backward,282603,"[[2048, 4, 16, 72], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",918278,42.666666666666664,21.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::slice_backward,282603,"[[2048, 4, 16, 72], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",918284,35.333333333333336,55.77333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::zeros,282614,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",918302,38.0,22.933333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: SliceBackward0,282611,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",918308,39.0,23.293333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: SliceBackward0,282611,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",918322,41.333333333333336,44.346666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,SplitBackward0,282623,"[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",918338,40.666666666666664,249.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,AddmmBackward0,282634,"[[8192, 4608]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),918361,41.333333333333336,1694.6933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::mm,282642,"[[4608, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,918380,141.66666666666666,1646.0533333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::sum,282646,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",918410,138.0,62.85333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,torch::autograd::AccumulateGrad,282649,[[4608]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",918417,37.0,3.1466666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,torch::autograd::AccumulateGrad,282661,"[[4608, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",918428,43.666666666666664,86.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,nccl:all_reduce,282667,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",918448,91.33333333333333,755.2133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::native_layer_norm_backward,282671,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",918515,53.333333333333336,362.37333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: NativeLayerNormBackward0,282669,,"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",918517,40.0,203.26666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: NativeLayerNormBackward0,282669,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",918538,39.666666666666664,164.61333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,282676,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",918546,36.333333333333336,3.3733333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,282679,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",918553,40.0,3.013333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,aten::native_layer_norm_backward,282684,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",918595,45.0,372.7733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: NativeLayerNormBackward0,282682,,"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",918597,37.666666666666664,201.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,autograd::engine::evaluate_function: NativeLayerNormBackward0,282682,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",918620,38.333333333333336,165.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,torch::autograd::AccumulateGrad,282694,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",918630,37.666666666666664,3.2666666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,282068,,torch::autograd::AccumulateGrad,282697,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",918637,41.666666666666664,3.0533333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,CheckpointFunctionBackward,282700,"[[2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",918660,2477.3333333333335,8.506666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::copy_,282713,"[[], [], []]",Memcpy HtoD (Pageable -> Device),918692,3541.6666666666665,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::native_layer_norm,282718,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",918714,1684.0,168.34666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::native_layer_norm,282725,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",918736,40.0,169.21333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::addmm,282739,"[[4608], [8192, 6144], [6144, 4608], [], []]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_relu_f2f_stages_64x3_tn,918755,163.0,1783.36
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::copy_,282764,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),918773,120.0,5.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::copy_,282768,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),918783,959.0,5.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::neg,282778,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",918791,2081.3333333333335,14.133333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,<forward op>,282789,"[[2048, 1, 1, 24], [], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",918800,861.0,28.32
None,None,None,None,None,None,kernel_1,918813,283.3333333333333,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,apply_rotary_pos_emb,282769,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",918820,900.6666666666666,16.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,apply_rotary_pos_emb,282769,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",918829,607.0,28.0
None,None,None,None,None,None,kernel_1,918842,203.0,11.946666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::cat,282819,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",918850,814.6666666666666,102.85333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,CheckpointFunctionBackward,282700,"[[2048, 4, 6144], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",918859,37.0,103.57333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::baddbmm,282830,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,918877,39.666666666666664,649.2933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,ScaledUpperTriangMaskedSoftmax,282833,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",918886,39.666666666666664,603.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::bmm,282850,"[[64, 2048, 2048], [64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,918932,36.666666666666664,402.36
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::clone,282855,"[[2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",918943,41.0,60.986666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::mm,282867,"[[8192, 1536], [1536, 6144]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn,918960,154.0,644.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::add,282872,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",918971,35.333333333333336,215.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::matmul,282881,"[[2048, 4, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),918984,42.0,2323.693333333333
None,None,None,None,None,None,kernel_2,918997,40.0,160.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::mm,282899,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),919009,37.333333333333336,2323.2266666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,CheckpointFunctionBackward,282700,"[[2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",919017,39.333333333333336,212.85333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,CheckpointFunctionBackward,282700,"[[2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",919025,37.666666666666664,173.38666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,nccl:all_reduce,282910,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",919043,54.0,754.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::add,282914,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",919082,53.0,174.13333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::sum,282926,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",919137,136.0,85.97333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,torch::autograd::AccumulateGrad,282929,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",919144,39.0,3.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::mm,282940,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,919167,150.33333333333334,2285.173333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: MmBackward0,282935,,void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),919187,40.333333333333336,2298.6666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,torch::autograd::AccumulateGrad,282958,"[[6144, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",919198,39.0,119.24
None,None,None,None,None,None,kernel_3,919217,47.666666666666664,214.13333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::sum,282967,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",919243,138.0,83.36
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,torch::autograd::AccumulateGrad,282970,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",919250,37.333333333333336,3.1066666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::mm,282981,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,919273,150.66666666666666,2254.5866666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,MmBackward0,282977,"[[8192, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),919293,38.333333333333336,2264.8533333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,torch::autograd::AccumulateGrad,282999,"[[6144, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",919304,47.333333333333336,119.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,nccl:all_reduce,283005,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",919324,66.0,721.0933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::sum,283011,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",919386,162.0,80.89333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,torch::autograd::AccumulateGrad,283014,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",919393,44.0,3.1066666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::mm,283025,"[[6144, 8192], [8192, 1536]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,919416,143.33333333333334,573.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: MmBackward0,283020,,ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,919434,39.666666666666664,606.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,torch::autograd::AccumulateGrad,283043,"[[6144, 1536]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",919445,37.666666666666664,27.69333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,BmmBackward0,283060,"[[64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,919471,34.333333333333336,372.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: BmmBackward0,283059,,ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,919487,40.0,654.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,ScaledUpperTriangMaskedSoftmaxBackward,283084,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",919501,40.0,853.2133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,BaddbmmBackward0,283098,"[[64, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,919521,37.0,396.7866666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::mul,283102,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",919533,39.0,26.053333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,BaddbmmBackward0,283098,"[[64, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,919548,41.333333333333336,372.53333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,BaddbmmBackward0,283098,"[[64, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",919560,39.0,28.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,<backward op>,283147,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",919588,39.666666666666664,19.226666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::mul,283152,"[[], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",919600,41.333333333333336,18.186666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: NegBackward0,283153,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",919614,39.666666666666664,9.213333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::zeros,283159,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",919631,43.0,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::slice_backward,283158,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",919637,40.666666666666664,22.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: SliceBackward0,283156,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",919651,34.333333333333336,41.52
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::zero_,283172,"[[2048, 4, 16, 24]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",919669,37.333333333333336,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::slice_backward,283169,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",919675,39.333333333333336,23.773333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: SliceBackward0,283167,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",919689,33.666666666666664,41.053333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,<backward op>,283180,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",919704,42.0,20.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,torch::jit::(anonymous namespace)::DifferentiableGraphBackward,283179,"[[2048, 4, 16, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",919716,42.0,18.053333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: NegBackward0,283186,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",919730,36.333333333333336,11.253333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::slice_backward,283191,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",919747,43.666666666666664,7.026666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,SliceBackward0,283190,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",919753,40.0,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: SliceBackward0,283189,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",919767,37.333333333333336,18.226666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::slice_backward,283202,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",919785,31.666666666666668,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::slice_backward,283202,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",919791,42.333333333333336,12.186666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: SliceBackward0,283200,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",919805,33.333333333333336,16.85333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::slice_backward,283213,"[[2048, 4, 16, 72], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",919823,34.0,20.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: SliceBackward0,283211,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",919829,46.666666666666664,108.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::slice_backward,283223,"[[2048, 4, 16, 24], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",919847,40.333333333333336,22.493333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: SliceBackward0,283221,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",919853,40.333333333333336,40.306666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: SliceBackward0,283221,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",919867,36.666666666666664,44.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::zero_,283237,"[[2048, 4, 16, 96]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",919885,40.0,21.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: SliceBackward0,283232,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",919891,39.333333333333336,55.666666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::zeros,283245,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",919909,38.666666666666664,23.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: SliceBackward0,283242,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",919915,38.333333333333336,23.333333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: SliceBackward0,283242,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",919929,38.333333333333336,44.45333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: SplitBackward0,283253,,"void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",919945,40.333333333333336,249.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,AddmmBackward0,283265,"[[8192, 4608]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),919968,43.333333333333336,1695.0933333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::mm,283273,"[[4608, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,919987,141.33333333333334,1646.4266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::sum,283277,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",920017,138.33333333333334,62.81333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,torch::autograd::AccumulateGrad,283280,[[4608]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920024,38.666666666666664,3.1466666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,torch::autograd::AccumulateGrad,283292,"[[4608, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920035,45.666666666666664,86.14666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,nccl:all_reduce,283298,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",920055,80.66666666666667,755.5066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::native_layer_norm_backward,283302,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",920122,61.0,362.3333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: NativeLayerNormBackward0,283300,,"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",920124,36.666666666666664,204.05333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: NativeLayerNormBackward0,283300,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920141,38.666666666666664,164.65333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,torch::autograd::AccumulateGrad,283308,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920149,37.333333333333336,3.4133333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,torch::autograd::AccumulateGrad,283311,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920156,40.0,3.026666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,aten::native_layer_norm_backward,283315,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",920192,46.333333333333336,372.6533333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: NativeLayerNormBackward0,283313,,"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",920194,38.0,201.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,autograd::engine::evaluate_function: NativeLayerNormBackward0,283313,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920215,38.333333333333336,165.78666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,torch::autograd::AccumulateGrad,283325,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920225,39.0,3.3466666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,282699,,torch::autograd::AccumulateGrad,283328,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920232,40.666666666666664,3.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::zero_,283334,"[[1, 1, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",920254,2416.6666666666665,8.56
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::copy_,283344,"[[], [], []]",Memcpy HtoD (Pageable -> Device),920286,3538.0,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::native_layer_norm,283349,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",920308,1680.6666666666667,168.41333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::native_layer_norm,283356,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",920330,39.0,169.45333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::addmm,283370,"[[4608], [8192, 6144], [6144, 4608], [], []]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_relu_f2f_stages_64x3_tn,920349,151.0,1784.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::copy_,283395,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),920367,112.0,5.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::copy_,283399,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),920377,953.3333333333334,5.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::neg,283409,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",920385,2075.3333333333335,14.066666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,<forward op>,283420,"[[2048, 1, 1, 24], [], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",920394,794.6666666666666,28.426666666666666
None,None,None,None,None,None,kernel_1,920407,272.0,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::neg,283432,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",920414,886.3333333333334,16.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,apply_rotary_pos_emb,283400,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",920423,622.0,28.026666666666667
None,None,None,None,None,None,kernel_1,920436,189.66666666666666,11.973333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::cat,283450,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",920444,803.6666666666666,102.90666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,CheckpointFunctionBackward,283331,"[[2048, 4, 6144], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",920453,38.666666666666664,103.64
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::baddbmm,283461,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,920471,39.666666666666664,649.4933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,ScaledUpperTriangMaskedSoftmax,283464,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",920480,39.333333333333336,604.0133333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::bmm,283481,"[[64, 2048, 2048], [64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,920526,39.666666666666664,402.81333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::clone,283486,"[[2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",920537,37.0,61.013333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::mm,283498,"[[8192, 1536], [1536, 6144]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn,920554,154.0,645.7066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::add,283503,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",920565,35.333333333333336,215.26666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::mm,283515,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),920578,45.666666666666664,2324.826666666667
None,None,None,None,None,None,kernel_2,920591,40.333333333333336,160.26666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::mm,283530,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),920603,40.333333333333336,2324.9066666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,CheckpointFunctionBackward,283331,"[[2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",920611,37.0,212.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,CheckpointFunctionBackward,283331,"[[2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920619,38.0,173.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,nccl:all_reduce,283541,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",920637,51.333333333333336,753.8133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::add,283545,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920676,52.333333333333336,174.57333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::sum,283557,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",920731,138.0,86.09333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,torch::autograd::AccumulateGrad,283560,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920738,37.666666666666664,3.066666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::mm,283571,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,920761,150.33333333333334,2286.266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,MmBackward0,283567,"[[8192, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),920781,38.0,2299.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,torch::autograd::AccumulateGrad,283589,"[[6144, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920792,41.0,119.28
None,None,None,None,None,None,kernel_3,920811,43.0,213.81333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::sum,283598,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",920837,134.33333333333334,83.50666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,torch::autograd::AccumulateGrad,283601,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920844,40.666666666666664,3.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::mm,283612,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,920867,148.0,2255.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,MmBackward0,283608,"[[8192, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),920887,37.666666666666664,2265.306666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,torch::autograd::AccumulateGrad,283630,"[[6144, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920898,44.666666666666664,119.10666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,nccl:all_reduce,283636,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",920918,65.66666666666667,719.5333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::sum,283642,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",920980,162.0,80.53333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,torch::autograd::AccumulateGrad,283645,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",920987,41.666666666666664,3.1066666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::mm,283656,"[[6144, 8192], [8192, 1536]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,921010,144.33333333333334,574.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: MmBackward0,283651,,ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,921028,39.0,606.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::add_,283675,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",921039,38.333333333333336,27.613333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,BmmBackward0,283691,"[[64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,921065,37.333333333333336,371.93333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: BmmBackward0,283690,,ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,921081,37.666666666666664,658.3066666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,ScaledUpperTriangMaskedSoftmaxBackward,283715,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",921095,38.666666666666664,854.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,BaddbmmBackward0,283729,"[[64, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,921115,38.333333333333336,396.56
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::mul,283733,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",921127,37.0,26.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,BaddbmmBackward0,283729,"[[64, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,921142,41.333333333333336,372.61333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,BaddbmmBackward0,283729,"[[64, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",921154,39.666666666666664,28.213333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,<backward op>,283778,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",921182,36.666666666666664,19.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,<backward op>,283778,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",921194,41.0,18.186666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: NegBackward0,283784,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",921208,41.666666666666664,9.293333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::slice_backward,283789,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",921225,42.0,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::slice_backward,283789,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",921231,38.666666666666664,22.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: SliceBackward0,283787,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",921245,38.0,41.53333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::zeros,283801,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",921263,37.333333333333336,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,SliceBackward0,283799,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",921269,39.666666666666664,23.746666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: SliceBackward0,283798,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",921283,37.333333333333336,41.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,<backward op>,283811,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",921298,37.0,20.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,<backward op>,283811,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",921310,40.333333333333336,18.026666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: NegBackward0,283817,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",921324,37.666666666666664,11.213333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::slice_backward,283822,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",921341,43.0,7.053333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,SliceBackward0,283821,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",921347,41.666666666666664,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: SliceBackward0,283820,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",921361,34.333333333333336,18.386666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::slice_backward,283833,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",921379,36.0,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,SliceBackward0,283832,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",921385,37.0,12.293333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: SliceBackward0,283831,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",921399,39.0,16.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::slice_backward,283844,"[[2048, 4, 16, 72], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",921417,36.0,20.093333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: SliceBackward0,283842,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",921423,48.0,108.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::slice_backward,283854,"[[2048, 4, 16, 24], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",921441,40.333333333333336,22.466666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: SliceBackward0,283852,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",921447,39.0,40.38666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: SliceBackward0,283852,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",921461,37.666666666666664,44.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::slice_backward,283865,"[[2048, 4, 16, 72], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",921479,39.0,21.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::slice_backward,283865,"[[2048, 4, 16, 72], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",921485,38.333333333333336,55.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::zero_,283878,"[[2048, 4, 16, 96]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",921503,40.333333333333336,22.906666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: SliceBackward0,283873,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",921509,36.666666666666664,23.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: SliceBackward0,283873,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",921523,39.0,44.373333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: SplitBackward0,283884,,"void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",921539,40.333333333333336,249.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,AddmmBackward0,283896,"[[8192, 4608]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),921562,44.0,1695.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::mm,283904,"[[4608, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,921581,140.66666666666666,1647.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::sum,283908,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",921611,138.0,62.85333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,torch::autograd::AccumulateGrad,283911,[[4608]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",921618,39.333333333333336,3.1066666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,torch::autograd::AccumulateGrad,283923,"[[4608, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",921629,44.0,86.06666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,nccl:all_reduce,283929,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",921649,80.66666666666667,754.9333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::native_layer_norm_backward,283933,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",921716,59.0,362.46666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: NativeLayerNormBackward0,283931,,"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",921718,37.666666666666664,203.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: NativeLayerNormBackward0,283931,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",921739,40.0,164.49333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,torch::autograd::AccumulateGrad,283939,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",921747,39.333333333333336,3.2933333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,283941,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",921754,41.333333333333336,3.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,aten::native_layer_norm_backward,283946,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",921796,46.333333333333336,372.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: NativeLayerNormBackward0,283944,,"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",921798,36.333333333333336,201.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: NativeLayerNormBackward0,283944,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",921821,41.0,165.92
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,283955,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",921831,37.0,3.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,283330,,torch::autograd::AccumulateGrad,283959,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",921838,43.333333333333336,3.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::zero_,283965,"[[1, 1, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",921861,2417.3333333333335,8.413333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::copy_,283975,"[[], [], []]",Memcpy HtoD (Pageable -> Device),921893,3520.3333333333335,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::native_layer_norm,283980,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",921915,1642.0,168.48
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::layer_norm,283986,"[[2048, 4, 6144], [], [6144], [6144], [], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",921937,36.666666666666664,169.41333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::addmm,284001,"[[4608], [8192, 6144], [6144, 4608], [], []]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_relu_f2f_stages_64x3_tn,921956,149.66666666666666,1785.5733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::copy_,284026,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),921974,139.0,5.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::copy_,284030,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),921984,975.0,5.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::neg,284040,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",921992,2019.6666666666667,14.053333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,<forward op>,284051,"[[2048, 1, 1, 24], [], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",922001,745.0,28.333333333333332
None,None,None,None,None,None,kernel_1,922014,258.6666666666667,11.986666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::neg,284063,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",922021,868.3333333333334,16.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,apply_rotary_pos_emb,284031,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",922030,601.6666666666666,28.066666666666666
None,None,None,None,None,None,kernel_1,922043,167.66666666666666,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::cat,284081,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",922051,765.3333333333334,102.85333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,CheckpointFunctionBackward,283962,"[[2048, 4, 6144], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",922060,38.666666666666664,103.65333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::baddbmm,284092,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,922078,37.666666666666664,649.5466666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,ScaledUpperTriangMaskedSoftmax,284095,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",922087,40.666666666666664,604.1866666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,CheckpointFunctionBackward,283962,"[[2048, 4, 6144], []]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,922133,37.333333333333336,402.41333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::clone,284117,"[[2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",922144,35.666666666666664,60.986666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::mm,284129,"[[8192, 1536], [1536, 6144]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn,922161,155.33333333333334,646.36
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,CheckpointFunctionBackward,283962,"[[2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",922172,38.666666666666664,215.22666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::matmul,284143,"[[2048, 4, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),922185,48.666666666666664,2325.52
None,None,None,None,None,None,kernel_2,922198,43.0,160.22666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::mm,284161,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),922210,36.333333333333336,2325.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,CheckpointFunctionBackward,283962,"[[2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",922218,39.666666666666664,213.01333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,CheckpointFunctionBackward,283962,"[[2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",922226,34.666666666666664,173.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,nccl:all_reduce,284172,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",922244,54.0,754.5066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,CheckpointFunctionBackward,283962,"[[2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",922283,50.333333333333336,174.6
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::sum,284188,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",922338,137.66666666666666,85.70666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,torch::autograd::AccumulateGrad,284191,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",922345,36.333333333333336,3.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::mm,284202,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,922368,151.0,2286.5866666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: MmBackward0,284197,,void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),922388,38.0,2300.52
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,torch::autograd::AccumulateGrad,284220,"[[6144, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",922399,40.666666666666664,119.25333333333333
None,None,None,None,None,None,kernel_3,922418,46.0,213.88
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::sum,284229,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",922444,133.66666666666666,83.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,torch::autograd::AccumulateGrad,284232,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",922451,39.666666666666664,3.0933333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::mm,284243,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,922474,152.66666666666666,2255.8533333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: MmBackward0,284238,,void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),922494,38.333333333333336,2265.5333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,torch::autograd::AccumulateGrad,284261,"[[6144, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",922505,44.666666666666664,119.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,nccl:all_reduce,284267,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",922525,76.0,719.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::sum,284273,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",922587,157.33333333333334,80.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,torch::autograd::AccumulateGrad,284276,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",922594,45.0,3.1866666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::mm,284287,"[[6144, 8192], [8192, 1536]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,922617,141.66666666666666,574.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,MmBackward0,284283,"[[8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,922635,39.0,606.5466666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,torch::autograd::AccumulateGrad,284305,"[[6144, 1536]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",922646,41.0,27.56
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::bmm,284325,"[[64, 2048, 2048], [64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,922672,37.0,372.46666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: BmmBackward0,284321,,ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,922688,36.0,657.9466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,ScaledUpperTriangMaskedSoftmaxBackward,284346,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",922702,40.0,854.2266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,BaddbmmBackward0,284360,"[[64, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,922722,38.666666666666664,396.97333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,BaddbmmBackward0,284360,"[[64, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",922734,38.666666666666664,26.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,BaddbmmBackward0,284360,"[[64, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,922749,41.0,371.9066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,BaddbmmBackward0,284360,"[[64, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",922761,38.666666666666664,28.266666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,<backward op>,284409,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",922789,37.666666666666664,19.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,torch::jit::(anonymous namespace)::DifferentiableGraphBackward,284408,"[[2048, 4, 16, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",922801,43.0,18.346666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: NegBackward0,284415,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",922815,37.666666666666664,9.4
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::slice_backward,284420,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",922832,40.0,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,SliceBackward0,284419,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",922838,40.0,22.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: SliceBackward0,284418,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",922852,33.666666666666664,41.57333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::slice_backward,284431,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",922870,38.666666666666664,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,SliceBackward0,284430,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",922876,40.333333333333336,23.866666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: SliceBackward0,284429,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",922890,35.666666666666664,41.13333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,<backward op>,284442,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",922905,38.666666666666664,20.30666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,torch::jit::(anonymous namespace)::DifferentiableGraphBackward,284441,"[[2048, 4, 16, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",922917,42.333333333333336,18.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: NegBackward0,284448,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",922931,39.333333333333336,11.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::zeros,284454,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",922948,39.0,7.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: SliceBackward0,284451,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",922954,41.0,10.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: SliceBackward0,284451,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",922968,35.0,18.266666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::slice_backward,284464,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",922986,36.333333333333336,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,SliceBackward0,284463,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",922992,40.0,12.133333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: SliceBackward0,284462,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",923006,36.333333333333336,16.813333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::slice_backward,284475,"[[2048, 4, 16, 72], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",923024,38.0,20.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: SliceBackward0,284473,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",923030,45.666666666666664,108.41333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::slice_backward,284485,"[[2048, 4, 16, 24], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",923048,37.666666666666664,22.506666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: SliceBackward0,284483,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",923054,40.666666666666664,40.346666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: SliceBackward0,284483,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",923068,36.333333333333336,44.17333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::slice_backward,284496,"[[2048, 4, 16, 72], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",923086,42.666666666666664,21.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: SliceBackward0,284494,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",923092,36.333333333333336,55.84
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::slice_backward,284506,"[[2048, 4, 16, 24], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",923110,41.0,23.12
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::slice_backward,284506,"[[2048, 4, 16, 24], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",923116,36.0,23.333333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: SliceBackward0,284504,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",923130,40.0,44.373333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: SplitBackward0,284515,,"void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",923146,39.666666666666664,249.38666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,AddmmBackward0,284527,"[[8192, 4608]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),923169,40.333333333333336,1696.8666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::mm,284535,"[[4608, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,923188,143.0,1648.0266666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: AddmmBackward0,284526,,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",923218,137.33333333333334,62.89333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,284541,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",923225,38.333333333333336,3.1333333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,torch::autograd::AccumulateGrad,284554,"[[4608, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",923236,44.333333333333336,86.26666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,nccl:all_reduce,284560,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",923256,90.33333333333333,755.1333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::native_layer_norm_backward,284564,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",923323,58.333333333333336,362.17333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: NativeLayerNormBackward0,284562,,"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",923325,38.333333333333336,203.78666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: NativeLayerNormBackward0,284562,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",923346,39.0,164.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,torch::autograd::AccumulateGrad,284570,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",923354,36.333333333333336,3.3466666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,284572,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",923361,41.333333333333336,3.013333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,aten::native_layer_norm_backward,284577,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",923403,44.0,372.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: NativeLayerNormBackward0,284575,,"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",923405,37.333333333333336,201.73333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: NativeLayerNormBackward0,284575,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",923428,38.333333333333336,166.05333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,284586,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",923438,39.333333333333336,3.28
autograd::engine::evaluate_function: CheckpointFunctionBackward,283961,,torch::autograd::AccumulateGrad,284590,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",923445,42.666666666666664,3.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,CheckpointFunctionBackward,284593,"[[2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<bool>, at::detail::Array<char*, 1>)",923468,2370.0,8.613333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::copy_,284606,"[[], [], []]",Memcpy HtoD (Pageable -> Device),923500,3465.6666666666665,1.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::native_layer_norm,284611,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",923522,1620.3333333333333,168.65333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::native_layer_norm,284618,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",923544,36.0,169.53333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::addmm,284632,"[[4608], [8192, 6144], [6144, 4608], [], []]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_relu_f2f_stages_64x3_tn,923563,151.0,1787.3733333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::copy_,284657,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),923581,113.66666666666667,5.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::copy_,284661,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),923591,960.3333333333334,5.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,apply_rotary_pos_emb,284662,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",923599,2012.0,14.053333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,<forward op>,284682,"[[2048, 1, 1, 24], [], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",923608,765.0,28.32
None,None,None,None,None,None,kernel_1,923621,247.0,12.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,apply_rotary_pos_emb,284662,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",923628,846.0,16.013333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,apply_rotary_pos_emb,284662,"[[2048, 4, 16, 24], [2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 1, 1, 24], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",923637,576.3333333333334,28.04
None,None,None,None,None,None,kernel_1,923650,181.66666666666666,11.986666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::cat,284712,"[[], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",923658,767.6666666666666,103.02666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,CheckpointFunctionBackward,284593,"[[2048, 4, 6144], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",923667,36.333333333333336,103.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::baddbmm,284723,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,923685,38.0,650.2266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,ScaledUpperTriangMaskedSoftmax,284726,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",923694,37.666666666666664,604.2666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::bmm,284743,"[[64, 2048, 2048], [64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,923740,44.666666666666664,402.25333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::clone,284748,"[[2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",923751,37.666666666666664,61.013333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::mm,284760,"[[8192, 1536], [1536, 6144]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn,923768,155.33333333333334,645.9866666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,CheckpointFunctionBackward,284593,"[[2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",923779,39.333333333333336,215.41333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::matmul,284774,"[[2048, 4, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),923792,39.666666666666664,2326.4666666666667
None,None,None,None,None,None,kernel_2,923805,41.666666666666664,160.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::mm,284792,"[[8192, 6144], [6144, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_64x3_tn_align8::Params),923817,38.0,2326.4266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::add,284797,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",923825,39.333333333333336,213.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,CheckpointFunctionBackward,284593,"[[2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",923833,37.666666666666664,173.26666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,nccl:all_reduce,284803,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",923851,52.333333333333336,754.7466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::add,284807,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",923890,52.666666666666664,174.65333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::sum,284819,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",923945,137.33333333333334,86.05333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,torch::autograd::AccumulateGrad,284822,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",923952,39.666666666666664,3.0933333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::mm,284833,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,923975,151.33333333333334,2287.7066666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: MmBackward0,284828,,void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),923995,36.333333333333336,2301.4666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,torch::autograd::AccumulateGrad,284851,"[[6144, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",924006,42.0,119.29333333333334
None,None,None,None,None,None,kernel_3,924025,42.0,213.68
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::sum,284860,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",924051,136.66666666666666,83.29333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,torch::autograd::AccumulateGrad,284863,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",924058,40.0,3.0533333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::mm,284874,"[[6144, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,924081,153.0,2257.64
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,MmBackward0,284870,"[[8192, 6144]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),924101,37.333333333333336,2267.2933333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,torch::autograd::AccumulateGrad,284892,"[[6144, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",924112,44.0,119.2
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,nccl:all_reduce,284898,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",924132,65.33333333333333,720.7866666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::sum,284904,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",924194,161.33333333333334,80.72
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,torch::autograd::AccumulateGrad,284907,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",924201,42.0,3.0933333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::mm,284918,"[[6144, 8192], [8192, 1536]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,924224,143.33333333333334,574.5333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: MmBackward0,284913,,ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,924242,40.333333333333336,606.9066666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,torch::autograd::AccumulateGrad,284936,"[[6144, 1536]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",924253,38.0,27.546666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,BmmBackward0,284953,"[[64, 2048, 96]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nt,924279,39.333333333333336,372.7866666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: BmmBackward0,284952,,ampere_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_tn,924295,34.666666666666664,658.8133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,ScaledUpperTriangMaskedSoftmaxBackward,284977,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",924309,38.0,854.6933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,BaddbmmBackward0,284991,"[[64, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_nn,924329,41.666666666666664,396.6933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,BaddbmmBackward0,284991,"[[64, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",924341,38.0,26.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,BaddbmmBackward0,284991,"[[64, 2048, 2048]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,924356,43.333333333333336,371.96
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,BaddbmmBackward0,284991,"[[64, 2048, 2048]]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",924368,39.0,28.213333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,<backward op>,285040,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",924396,38.333333333333336,19.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,torch::jit::(anonymous namespace)::DifferentiableGraphBackward,285039,"[[2048, 4, 16, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",924408,42.333333333333336,18.346666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: NegBackward0,285046,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",924422,37.0,9.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::zeros,285052,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",924439,40.666666666666664,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::slice_backward,285051,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",924445,39.666666666666664,22.8
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: SliceBackward0,285049,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",924459,36.333333333333336,41.666666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::slice_backward,285062,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",924477,37.666666666666664,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: SliceBackward0,285060,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",924483,40.333333333333336,23.69333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: SliceBackward0,285060,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",924497,36.0,41.04
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,<backward op>,285073,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [], [2048, 1, 1, 24], [], [], [], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",924512,36.666666666666664,20.373333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,torch::jit::(anonymous namespace)::DifferentiableGraphBackward,285072,"[[2048, 4, 16, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",924524,43.0,18.053333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: NegBackward0,285079,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#16}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",924538,39.666666666666664,11.32
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::zero_,285087,"[[2048, 4, 16, 24]]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",924555,41.0,7.013333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::slice_backward,285084,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",924561,41.0,9.986666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: SliceBackward0,285082,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",924575,34.333333333333336,18.44
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::slice_backward,285095,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",924593,41.0,7.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::slice_backward,285095,"[[2048, 4, 16, 12], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",924599,35.666666666666664,12.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: SliceBackward0,285093,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",924613,37.0,16.85333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::zeros,285107,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",924631,34.666666666666664,20.266666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: SliceBackward0,285104,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",924637,44.666666666666664,108.62666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::zeros,285117,"[[], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",924655,38.666666666666664,22.626666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: SliceBackward0,285114,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",924661,38.333333333333336,40.38666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: SliceBackward0,285114,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",924675,40.333333333333336,44.24
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::slice_backward,285127,"[[2048, 4, 16, 72], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",924693,38.333333333333336,21.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::slice_backward,285127,"[[2048, 4, 16, 72], [], [], [], [], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",924699,38.333333333333336,56.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::slice_backward,285137,"[[2048, 4, 16, 24], [], [], [], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",924717,36.0,23.173333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: SliceBackward0,285135,,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#20}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",924723,40.333333333333336,23.413333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: SliceBackward0,285135,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",924737,38.0,44.36
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: SplitBackward0,285146,,"void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 64, 64>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",924753,39.666666666666664,249.61333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,AddmmBackward0,285158,"[[8192, 4608]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x256_32x3_nn_align8::Params),924776,41.666666666666664,1698.5733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::mm,285166,"[[4608, 8192], [8192, 6144]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_nt,924795,141.33333333333334,1649.5866666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::sum,285170,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",924825,135.66666666666666,62.93333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,torch::autograd::AccumulateGrad,285173,[[4608]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",924832,40.0,3.1066666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,torch::autograd::AccumulateGrad,285185,"[[4608, 6144]]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",924843,43.333333333333336,86.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,nccl:all_reduce,285191,"[[2048, 4, 6144]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",924863,82.33333333333333,754.3866666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::native_layer_norm_backward,285195,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",924930,68.66666666666667,362.16
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: NativeLayerNormBackward0,285193,,"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",924932,38.0,203.76
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: NativeLayerNormBackward0,285193,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",924953,36.333333333333336,164.50666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,torch::autograd::AccumulateGrad,285201,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",924961,38.666666666666664,3.3333333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,torch::autograd::AccumulateGrad,285204,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",924968,40.0,3.0533333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,aten::native_layer_norm_backward,285208,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",925010,43.333333333333336,371.6933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: NativeLayerNormBackward0,285206,,"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",925012,41.0,202.18666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,autograd::engine::evaluate_function: NativeLayerNormBackward0,285206,,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",925035,37.0,166.0
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,torch::autograd::AccumulateGrad,285218,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",925045,38.666666666666664,3.1333333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,284592,,torch::autograd::AccumulateGrad,285221,[[6144]],"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",925052,44.666666666666664,3.026666666666667
