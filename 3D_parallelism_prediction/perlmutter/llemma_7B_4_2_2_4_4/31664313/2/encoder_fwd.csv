cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
aten::clone,41974,"[[33554432], []]",aten::copy_,41976,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),253645,0,101.54398148148148
aten::to,41979,"[[], [], [], [], [], []]",aten::copy_,41982,"[[], [], []]",Memcpy HtoD (Pageable -> Device),253664,2250.6666666666665,1.0
aten::norm,41986,"[[4096, 4, 4096], [], [], []]",aten::norm,41986,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",253676,9509.0,118.86111111111111
aten::mul,41987,"[[4096, 4, 1], []]",aten::mul,41987,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",253684,238.0,3.2824074074074074
None,None,None,None,None,None,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",253692,257.3333333333333,3.0
None,None,None,None,None,None,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",253700,229.66666666666666,308.162037037037
aten::mul,41990,"[[4096], [4096, 4, 4096]]",aten::mul,41990,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",253708,230.33333333333334,294.1203703703704
aten::linear,41995,"[[4096, 4, 4096], [6144, 4096], []]",aten::mm,42002,"[[16384, 4096], [4096, 6144]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,253723,947.3333333333334,3201.8425925925926
aten::to,42015,"[[4096, 1, 1, 128], [], [], [], [], [], [], []]",aten::copy_,42018,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),253736,733.0,43.539351851851855
aten::to,42019,"[[4096, 1, 1, 128], [], [], [], [], [], [], []]",aten::copy_,42022,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),253746,13089.666666666666,40.449074074074076
None,None,None,None,None,None,kernel_0,253759,14582.333333333334,98.13657407407408
None,None,None,None,None,None,kernel_1,253771,256.3333333333333,158.40972222222223
None,None,None,None,None,None,kernel_0,253783,235.0,100.2199074074074
None,None,None,None,None,None,kernel_1,253795,238.33333333333334,158.06712962962962
FlashAttnFunc,42076,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128]]",FlashAttnFunc,42076,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128]]","void flash_fwd_kernel<Flash_fwd_kernel_traits<128, 128, 64, 4, false, false, cutlass::half_t, Flash_kernel_traits<128, 128, 64, 4, cutlass::half_t> >, false, true, false, false, true, true, false>(Flash_fwd_params)",253817,512.3333333333334,1382.601851851852
aten::linear,42086,"[[4096, 4, 2048], [4096, 2048], []]",aten::mm,42093,"[[16384, 2048], [2048, 4096]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params),253833,931.6666666666666,1131.4560185185185
_ReduceFromModelParallelRegion,42095,"[[4096, 4, 4096]]",nccl:all_reduce,42098,"[[4096, 4, 4096]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",253854,327.0,1954.3032407407406
aten::add,42103,"[[4096, 4, 4096], [4096, 4, 4096], []]",aten::add,42103,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",253893,247.66666666666666,300.46064814814815
aten::norm,42104,"[[4096, 4, 4096], [], [], []]",aten::norm,42104,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",253915,238.0,118.51620370370371
aten::mul,42105,"[[4096, 4, 1], []]",aten::mul,42105,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",253927,241.0,3.275462962962963
aten::add,42106,"[[4096, 4, 1], [], []]",aten::add,42106,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",253939,264.6666666666667,3.0
None,None,None,None,None,None,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",253951,219.66666666666666,308.287037037037
aten::mul,42108,"[[4096], [4096, 4, 4096]]",aten::mul,42108,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",253963,272.6666666666667,294.13425925925924
aten::to,42111,"[[], [], [], [], [], []]",aten::copy_,42114,"[[], [], []]",Memcpy HtoD (Pageable -> Device),253977,276.3333333333333,1.0023148148148149
aten::linear,42121,"[[4096, 4, 4096], [8192, 4096], []]",aten::mm,42128,"[[16384, 4096], [4096, 8192]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,253994,18828.0,4246.032407407408
aten::add,42130,"[[4096, 4, 8192], [8192], []]",aten::add,42130,"[[4096, 4, 8192], [8192], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",254005,235.33333333333334,581.3356481481482
None,None,None,None,None,None,"void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",254013,236.0,406.849537037037
aten::linear,42132,"[[4096, 4, 8192], [4096, 8192], []]",aten::mm,42139,"[[16384, 8192], [8192, 4096]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_tn,254025,234.66666666666666,3753.363425925926
_ReduceFromModelParallelRegion,42141,"[[4096, 4, 4096]]",nccl:all_reduce,42144,"[[4096, 4, 4096]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",254043,318.0,1989.226851851852
aten::add,42151,"[[4096, 4, 4096], [4096, 4, 4096], []]",aten::add,42151,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",254082,293.3333333333333,294.7916666666667
None,None,None,None,None,None,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",254090,233.0,297.8912037037037
