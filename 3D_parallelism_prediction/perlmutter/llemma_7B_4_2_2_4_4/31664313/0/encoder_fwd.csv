cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
aten::clone,188057,"[[33554432], []]",aten::clone,188057,"[[33554432], []]",Memcpy DtoD (Device -> Device),730891,0,101.37847222222223
aten::to,188062,"[[], [], [], [], [], []]",aten::_to_copy,188063,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),730910,2486.0,1.0
aten::norm,188069,"[[4096, 4, 4096], [], [], []]",aten::norm,188069,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",730922,12238.666666666666,119.08854166666667
None,None,None,None,None,None,"void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",730930,326.3333333333333,3.5711805555555554
None,None,None,None,None,None,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",730938,311.3333333333333,3.0
None,None,None,None,None,None,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",730946,605.6666666666666,313.6076388888889
None,None,None,None,None,None,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",730954,325.0,298.8385416666667
aten::linear,188078,"[[4096, 4, 4096], [6144, 4096], []]",aten::mm,188085,"[[16384, 4096], [4096, 6144]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,730969,1332.0,3267.8680555555557
aten::to,188098,"[[4096, 1, 1, 128], [], [], [], [], [], [], []]",aten::_to_copy,188099,"[[4096, 1, 1, 128], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),730982,966.0,41.35590277777778
None,None,None,None,None,None,Memcpy HtoD (Pageable -> Device),730992,18889.333333333332,41.079861111111114
None,None,None,None,None,None,kernel_0,731005,18328.0,98.40277777777777
None,None,None,None,None,None,kernel_1,731017,317.0,158.41666666666666
None,None,None,None,None,None,kernel_0,731029,353.6666666666667,100.39930555555556
None,None,None,None,None,None,kernel_1,731041,319.3333333333333,158.15451388888889
FlashAttnFunc,188159,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128]]",FlashAttnFunc,188159,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128]]","void flash_fwd_kernel<Flash_fwd_kernel_traits<128, 128, 64, 4, false, false, cutlass::half_t, Flash_kernel_traits<128, 128, 64, 4, cutlass::half_t> >, false, true, false, false, true, true, false>(Flash_fwd_params)",731063,338.6666666666667,1409.907986111111
aten::linear,188169,"[[4096, 4, 2048], [4096, 2048], []]",aten::mm,188176,"[[16384, 2048], [2048, 4096]]",void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params),731079,1249.0,1142.3385416666667
_ReduceFromModelParallelRegion,188178,"[[4096, 4, 4096]]",nccl:all_reduce,188181,"[[4096, 4, 4096]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",731100,421.6666666666667,1964.3350694444443
aten::add,188186,"[[4096, 4, 4096], [4096, 4, 4096], []]",aten::add,188186,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",731139,328.3333333333333,300.36805555555554
aten::norm,188187,"[[4096, 4, 4096], [], [], []]",aten::norm,188187,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float>, unsigned int, c10::Half, 4>)",731161,323.3333333333333,118.67361111111111
aten::mul,188188,"[[4096, 4, 1], []]",aten::mul,188188,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",731173,323.3333333333333,3.560763888888889
None,None,None,None,None,None,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",731185,312.3333333333333,3.0
None,None,None,None,None,None,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",731197,305.6666666666667,313.8142361111111
None,None,None,None,None,None,"void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",731209,350.3333333333333,298.8732638888889
aten::to,188194,"[[], [], [], [], [], []]",aten::_to_copy,188195,"[[], [], [], [], [], [], []]",Memcpy HtoD (Pageable -> Device),731223,395.6666666666667,1.0
aten::linear,188204,"[[4096, 4, 4096], [8192, 4096], []]",aten::mm,188211,"[[16384, 4096], [4096, 8192]]",ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn,731240,24632.666666666668,4333.453125
aten::add,188213,"[[4096, 4, 8192], [8192], []]",aten::add,188213,"[[4096, 4, 8192], [8192], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",731251,323.0,590.9479166666666
None,None,None,None,None,None,"void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#6}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>)",731259,317.3333333333333,409.33680555555554
aten::linear,188215,"[[4096, 4, 8192], [4096, 8192], []]",aten::mm,188222,"[[16384, 8192], [8192, 4096]]",ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_64x3_tn,731271,324.3333333333333,3826.8524305555557
_ReduceFromModelParallelRegion,188224,"[[4096, 4, 4096]]",nccl:all_reduce,188227,"[[4096, 4, 4096]]","ncclKernel_AllReduce_RING_LL_Sum_half(ncclDevComm*, unsigned long, ncclWork*)",731289,415.6666666666667,1992.9652777777778
aten::add,188234,"[[4096, 4, 4096], [4096, 4, 4096], []]",aten::add,188234,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",731328,409.6666666666667,299.3072916666667
None,None,None,None,None,None,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)",731336,312.6666666666667,297.6041666666667
