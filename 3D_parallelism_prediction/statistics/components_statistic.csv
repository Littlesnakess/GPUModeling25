componet,GPT_20B_4_4_8_P,GPT_20B_4_4_8_V,GPT_20B_4_8_4_P,GPT_20B_4_8_4_V,GPT_20B_8_4_4_P,GPT_20B_8_4_4_V,llama_13B_4_8_2_P,llama_13B_4_8_2_V,llemma_7B_4_2_2_P,llemma_7B_4_2_2_V
encoder_fwd,-13.6,-11.47,1.47,-14.17,-12.89,-14.37,-1.84,-10.43,-2.52,-2.24
encoder_bwd,-11.93,-8.05,5.49,-9.69,-7.74,-8.63,-10.34,-11.78,-1.55,-13.33
stage_fwd_max,-13.41,-8.96,6.43,-11.99,-9.5,-9.0,0.53,-9.06,-1.86,0.32
stage_bwd_max,-12.49,-8.55,4.89,-10.37,-8.33,-10.39,-11.11,-12.52,-1.66,-13.73
dp_allreduce(1st stage),-1.9,-49.69,-21.51,-8.43,-2.06,-6.36,5.06,-14.96,-31.21,-12.02
dp_allgather(max_update),-0.02,-52.47,-1.89,-4.94,6.42,-7.66,-1.35,18.68,37.86,9.68
max_update,1.93,-46.33,2.06,-19.58,7.99,-24.12,7.92,25.68,-16.29,9.0
mp_allreduce,-4.85,2.33,10.67,1.22,-1.59,2.53,1.98,1.99,4.42,1.12
pp_p2p,3.81,-32.07,4.73,-34.14,7.53,-33.06,20.91,-36.26,1.61,-3.82
Overall,-8.82,-9.15,3.94,-15.16,-5.87,-8.41,-4.95,-9.02,1.3,-5.18
