[2025-01-31 15:21:06,290] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
NeoXArgs.from_ymls() ['/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/configs/targets/vista/llama_13B_4_8_2.yml', '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/configs/targets/vista/local_setup.yml']
INFO:root:NeoXArgs.calculate_derived() Total number of GPUs determined to be: 64
-------------------- arguments --------------------
  attention_config ................ ['global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global']updated
  batch_size ...................... 4...........................updated
  checkpoint_activations .......... True........................updated
  checkpoint_factor ............... 10000.......................updated
  config_files .................... {'llama_13B_4_8_2.yml': '{\n  "pipe_parallel_size": 4,\n  "model_parallel_size": 8,\n  "make_vocab_size_divisible_by": 128,\n\n  # model settings\n  "num_layers": 40,\n  "hidden_size": 5120,\n  "num_attention_heads": 40,\n  "seq_length": 2048,\n  "max_position_embeddings": 2048,\n  "pos_emb": "rotary",\n  "rotary_pct": 1,\n  "no_weight_tying": true,\n  "gpt_j_residual": false,\n  "output_layer_parallelism": "column",\n  "norm": "rmsnorm",\n  "rms_norm_epsilon": 1.0e-6,\n\n  "scaled_upper_triang_masked_softmax_fusion": true,\n  "bias_gelu_fusion": false,\n  "use_bias_in_norms": false,\n  "use_bias_in_attn_linear": false,\n  # "activation": "swiglu",\n  "mlp_multiple_of": 256,\n\n\n\n  # training setting\n  # finetuning option\n  # "finetune": true,\n\n  # init methods\n  "init_method": "small_init",\n  "output_layer_init_method": "wang_init",\n\n  # optimizer settings\n  "optimizer": {\n    "type": "Adam",\n    "params": {\n     "lr": 0.0002,\n     "betas": [0.9, 0.95],\n     "eps":  1.0e-8,\n    }\n  },\n  "min_lr": 0.00002,\n  "override_lr_scheduler": true,\n\n  # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training\n   "zero_optimization": {\n   "stage": 1,\n   "allgather_partitions": True,\n   "allgather_bucket_size": 500000000,\n   "overlap_comm": True,\n   "reduce_scatter": True,\n   "reduce_bucket_size": 500000000,\n   "contiguous_gradients": True,\n  },\n\n  # batch / data settings\n  "train_micro_batch_size_per_gpu": 4,\n  "gradient_accumulation_steps": 16,\n  "data_impl": "mmap",\n\n  # activation checkpointing\n  "checkpoint_activations": true,\n  "checkpoint_num_layers": 1,\n  "partition_activations": true,\n  "synchronize_each_layer": true,\n\n  # regularization\n  "gradient_clipping": 1.0,\n  "weight_decay": 0.1,\n  "hidden_dropout": 0,\n  "attention_dropout": 0,\n\n  # precision settings\n  "fp16": {\n    "fp16": true,\n    "enabled": true,\n    "loss_scale": 0,\n    "loss_scale_window": 1000,\n    "hysteresis": 2,\n    "min_loss_scale": 1\n  },\n\n  # misc. training settings\n  "train_iters": 8,\n  "lr_decay_iters": 8,\n  "distributed_backend": "nccl",\n  "lr_decay_style": "cosine",\n  "warmup": 0.01,\n  "checkpoint_factor": 10000,\n  "eval_interval": 1000,\n  "eval_iters": 100,\n\n  # logging\n  "log_interval": 1,\n  "steps_per_print": 1,\n  "keep_last_n_checkpoints": 4,\n  "wall_clock_breakdown": true,\n  "mlp_multiple_of": 256,\n\n  # profiling settings\n  "profile": True,\n  "profile_step_start": 2,\n  "profile_step_stop": 7,\n\n  # distributed training settings\n  "launcher": "slurm",\n  "deepspeed_slurm": true,\n\n}\n', 'local_setup.yml': '# Suggested data paths when using GPT-NeoX locally\n{\n  "data_path": "/work/08775/byz2022/vista/data/gpt-neox/data/test_text_document",\n\n  # or for weighted datasets:\n  # "train-data-paths": ["data/enwik8/enwik8_text_document", "data/enwik8/enwik8_text_document"],\n  # "test-data-paths": ["data/enwik8/enwik8_text_document", "data/enwik8/enwik8_text_document"],\n  # "valid-data-paths": ["data/enwik8/enwik8_text_document", "data/enwik8/enwik8_text_document"],\n  # "train-data-weights": [1., 2.],\n  # "test-data-weights": [2., 1.],\n  # "valid-data-weights": [0.5, 0.4],\n\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\n  # WARNING: setting this to True will override any user provided weights\n  # "weight_by_num_documents": false,\n  # "weighted_sampler_alpha": 0.3,\n\n  "vocab_file": "/work/08775/byz2022/vista/data/gpt-neox/data/gpt2-vocab.json",\n  "merge_file": "/work/08775/byz2022/vista/data/gpt-neox/data/gpt2-merges.txt",\n\n  "save": "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test",\n  "load": "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2",\n  "checkpoint_validation_with_forward_pass": False,\n\n  # "tensorboard_dir": "tensorboard",\n  # "log_dir": "logs",\n  "use_wandb": False,\n  "wandb_host": "https://api.wandb.ai",\n  "wandb_project": "neox"\n}'}updated
  data_impl ....................... mmap........................updated
  data_path ....................... /work/08775/byz2022/vista/data/gpt-neox/data/test_text_documentupdated
  deepspeed_slurm ................. True........................updated
  dynamic_loss_scale .............. True........................updated
  fp16 ............................ {'fp16': True, 'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'hysteresis': 2, 'min_loss_scale': 1}updated
  global_num_gpus ................. 64..........................updated
  gradient_accumulation_steps ..... 16..........................updated
  hidden_size ..................... 5120........................updated
  init_method ..................... small_init..................updated
  is_pipe_parallel ................ True........................updated
  keep_last_n_checkpoints ......... 4...........................updated
  launcher ........................ slurm.......................updated
  load ............................ /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2updated
  log_interval .................... 1...........................updated
  lr .............................. 0.0002......................updated
  lr_decay_iters .................. 8...........................updated
  lr_decay_style .................. cosine......................updated
  max_position_embeddings ......... 2048........................updated
  merge_file ...................... /work/08775/byz2022/vista/data/gpt-neox/data/gpt2-merges.txtupdated
  min_lr .......................... 2e-05.......................updated
  mlp_multiple_of ................. 256.........................updated
  model_parallel_size ............. 8...........................updated
  no_weight_tying ................. True........................updated
  norm ............................ rmsnorm.....................updated
  num_attention_heads ............. 40..........................updated
  num_layers ...................... 40..........................updated
  optimizer ....................... {'type': 'Adam', 'params': {'lr': 0.0002, 'betas': [0.9, 0.95], 'eps': 1e-08}}updated
  optimizer_type .................. Adam........................updated
  output_layer_init_method ........ wang_init...................updated
  override_lr_scheduler ........... True........................updated
  partition_activations ........... True........................updated
  pipe_parallel_size .............. 4...........................updated
  pos_emb ......................... rotary......................updated
  precision ....................... fp16........................updated
  profile ......................... True........................updated
  profile_step_start .............. 2...........................updated
  profile_step_stop ............... 7...........................updated
  rms_norm_epsilon ................ 1e-06.......................updated
  save ............................ /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_testupdated
  scaled_upper_triang_masked_softmax_fusion  True...............updated
  seq_length ...................... 2048........................updated
  sparsity_config ................. {}..........................updated
  steps_per_print ................. 1...........................updated
  synchronize_each_layer .......... True........................updated
  text_gen_type ................... unconditional...............updated
  train_batch_size ................ 128.........................updated
  train_iters ..................... 8...........................updated
  train_micro_batch_size_per_gpu .. 4...........................updated
  use_bias_in_attn_linear ......... False.......................updated
  use_bias_in_norms ............... False.......................updated
  use_wandb ....................... False.......................updated
  user_script ..................... /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.pyupdated
  vocab_file ...................... /work/08775/byz2022/vista/data/gpt-neox/data/gpt2-vocab.jsonupdated
  wall_clock_breakdown ............ True........................updated
  zero_allgather_bucket_size ...... 500000000...................updated
  zero_contiguous_gradients ....... True........................updated
  zero_optimization ............... {'stage': 1, 'allgather_partitions': True, 'allgather_bucket_size': 500000000, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000, 'contiguous_gradients': True}updated
  zero_reduce_bucket_size ......... 500000000...................updated
  zero_reduce_scatter ............. True........................updated
  zero_stage ...................... 1...........................updated
  account ......................... None........................default
  activation ...................... gelu........................default
  activation_checkpointing ........ None........................default
  adlr_autoresume ................. False.......................default
  adlr_autoresume_interval ........ 1000........................default
  allow_chopped ................... True........................default
  amp ............................. None........................default
  apply_query_key_layer_scaling ... False.......................default
  attention_dropout ............... 0...........................default
  attention_softmax_in_fp32 ....... False.......................default
  autotuning ...................... None........................default
  autotuning_run .................. None........................default
  base_shapes_file ................ None........................default
  bf16 ............................ None........................default
  bias_dropout_fusion ............. False.......................default
  bias_gelu_fusion ................ False.......................default
  char_level_ppl .................. False.......................default
  checkpoint ...................... None........................default
  checkpoint_in_cpu ............... False.......................default
  checkpoint_num_layers ........... 1...........................default
  checkpoint_scale ................ linear......................default
  checkpoint_validation_with_forward_pass  False................default
  clip_grad ....................... 1.0.........................default
  comet_experiment ................ None........................default
  comet_experiment_name ........... None........................default
  comet_others .................... None........................default
  comet_project ................... None........................default
  comet_tags ...................... None........................default
  comet_workspace ................. None........................default
  comment ......................... None........................default
  comms_logger .................... None........................default
  communication_data_type ......... None........................default
  compression_training ............ None........................default
  contiguous_checkpointing ........ False.......................default
  coord_check ..................... False.......................default
  create_moe_param_group .......... True........................default
  csv_monitor ..................... None........................default
  curriculum_learning ............. None........................default
  curriculum_seqlen ............... 0...........................default
  data_efficiency ................. None........................default
  data_types ...................... None........................default
  dataset_impl .................... gpt2........................default
  deepscale ....................... False.......................default
  deepscale_config ................ None........................default
  deepspeed ....................... True........................default
  deepspeed_activation_checkpointing  True......................default
  deepspeed_extra_args ............ None........................default
  deepspeed_mpi ................... False.......................default
  detect_nvlink_pairs ............. False.......................default
  dim_att ......................... None........................default
  distributed_backend ............. nccl........................default
  do_test ......................... None........................default
  do_train ........................ None........................default
  do_valid ........................ None........................default
  dpo_beta ........................ 0.1.........................default
  dpo_fp32 ........................ True........................default
  dpo_reference_free .............. False.......................default
  dump_state ...................... False.......................default
  elasticity ...................... None........................default
  enable_expert_tensor_parallelism  False.......................default
  eod_mask_loss ................... False.......................default
  eval_interval ................... 1000........................default
  eval_iters ...................... 100.........................default
  eval_results_prefix ............. ............................default
  eval_tasks ...................... None........................default
  exclude ......................... None........................default
  exit_interval ................... None........................default
  expansion_factor ................ None........................default
  expert_interval ................. 2...........................default
  extra_save_iters ................ None........................default
  ffn_dim ......................... None........................default
  finetune ........................ False.......................default
  flops_profiler .................. None........................default
  force_multi ..................... False.......................default
  fp16_lm_cross_entropy ........... False.......................default
  fp32_allreduce .................. False.......................default
  git_hash ........................ f5325805....................default
  gmlp_attn_dim ................... 64..........................default
  gpt_j_residual .................. False.......................default
  gpt_j_tied ...................... False.......................default
  gradient_clipping ............... 1.0.........................default
  gradient_noise_scale_cpu_offload  False.......................default
  gradient_noise_scale_n_batches .. 5...........................default
  gradient_predivide_factor ....... 1.0.........................default
  head_size ....................... None........................default
  hidden_dropout .................. 0...........................default
  hostfile ........................ None........................default
  hysteresis ...................... 2...........................default
  include ......................... None........................default
  init_method_std ................. 0.02........................default
  intermediate_size ............... None........................default
  iteration ....................... None........................default
  kto_beta ........................ 0.1.........................default
  kto_desirable_weight ............ 1.0.........................default
  kto_fp32 ........................ True........................default
  kto_undesirable_weight .......... 1.0.........................default
  layernorm_epsilon ............... 1e-05.......................default
  layernorm_fusion ................ False.......................default
  lazy_mpu_init ................... False.......................default
  local_rank ...................... None........................default
  log_dir ......................... None........................default
  log_grad_norm ................... False.......................default
  log_grad_pct_zeros .............. False.......................default
  log_gradient_noise_scale ........ False.......................default
  log_optimizer_states ............ False.......................default
  log_param_norm .................. False.......................default
  loss_scale ...................... None........................default
  loss_scale_window ............... 1000.0......................default
  lr_decay_fraction ............... None........................default
  make_vocab_size_divisible_by .... 128.........................default
  mamba_causal_conv_fusion ........ False.......................default
  mamba_inner_func_fusion ......... False.......................default
  mamba_selective_fp32_params ..... True........................default
  mamba_selective_scan_fusion ..... False.......................default
  mamba_use_bias_in_conv .......... True........................default
  mamba_use_bias_in_linears ....... False.......................default
  master_addr ..................... None........................default
  master_port ..................... 29500.......................default
  maximum_tokens .................. 64..........................default
  memory_profiling ................ False.......................default
  memory_profiling_path ........... None........................default
  min_scale ....................... 1.0.........................default
  mmap_warmup ..................... False.......................default
  moe_eval_capacity_factor ........ 1.0.........................default
  moe_expert_parallel_size ........ 1...........................default
  moe_glu ......................... False.......................default
  moe_jitter_eps .................. None........................default
  moe_lbl_in_fp32 ................. False.......................default
  moe_loss_coeff .................. 0.1.........................default
  moe_min_capacity ................ 4...........................default
  moe_num_experts ................. 1...........................default
  moe_token_dropping .............. False.......................default
  moe_top_k ....................... 1...........................default
  moe_train_capacity_factor ....... 1.0.........................default
  moe_type ........................ megablocks..................default
  moe_use_residual ................ True........................default
  mup_attn_temp ................... 1.0.........................default
  mup_embedding_mult .............. 1.0.........................default
  mup_init_scale .................. 1.0.........................default
  mup_output_temp ................. 1.0.........................default
  mup_rp_embedding_mult ........... 1.0.........................default
  mup_width_scale ................. 2...........................default
  neg_test_data_paths ............. None........................default
  neg_test_label_data_paths ....... None........................default
  neg_train_data_paths ............ None........................default
  neg_train_label_data_paths ...... None........................default
  neg_valid_data_paths ............ None........................default
  neg_valid_label_data_paths ...... None........................default
  no_load_optim ................... False.......................default
  no_load_rng ..................... False.......................default
  no_save_optim ................... False.......................default
  no_save_rng ..................... False.......................default
  no_ssh_check .................... False.......................default
  num_gpus ........................ None........................default
  num_kv_heads .................... None........................default
  num_nodes ....................... -1..........................default
  num_samples ..................... 1...........................default
  num_unique_layers ............... None........................default
  num_workers ..................... 2...........................default
  onnx_safe ....................... False.......................default
  opt_pos_emb_offset .............. 0...........................default
  output_layer_parallelism ........ column......................default
  pack_impl ....................... packed......................default
  padded_vocab_size ............... None........................default
  param_sharing_style ............. grouped.....................default
  pipe_partition_method ........... type:transformer|mlp........default
  pos_test_data_paths ............. None........................default
  pos_test_label_data_paths ....... None........................default
  pos_train_data_paths ............ None........................default
  pos_train_label_data_paths ...... None........................default
  pos_valid_data_paths ............ None........................default
  pos_valid_label_data_paths ...... None........................default
  precompute_model_name ........... None........................default
  prescale_gradients .............. False.......................default
  profile_backward ................ False.......................default
  prompt_end ...................... 
...........................default
  rank ............................ None........................default
  recompute ....................... False.......................default
  return_logits ................... False.......................default
  rmsnorm_fusion .................. False.......................default
  rope_fusion ..................... False.......................default
  rotary_emb_base ................. 10000.......................default
  rotary_pct ...................... 1...........................default
  rotary_save_freqs_buffer ........ False.......................default
  rpe_max_distance ................ 128.........................default
  rpe_num_buckets ................. 32..........................default
  s3_chunk_size ................... 104857600...................default
  s3_path ......................... None........................default
  sample_input_file ............... None........................default
  sample_output_file .............. samples.txt.................default
  save_base_shapes ................ False.......................default
  scaled_masked_softmax_fusion .... False.......................default
  scalenorm_epsilon ............... 1e-08.......................default
  scheduler ....................... None........................default
  seed ............................ 1234........................default
  sequence_parallel ............... False.......................default
  short_seq_prob .................. 0.1.........................default
  sliding_window_width ............ None........................default
  soft_prompt_tuning .............. None........................default
  sparse_attention ................ None........................default
  sparse_gradients ................ False.......................default
  split ........................... 969, 30, 1..................default
  temperature ..................... 0.0.........................default
  tensorboard ..................... None........................default
  tensorboard_dir ................. None........................default
  test_data_paths ................. None........................default
  test_data_weights ............... None........................default
  test_label_data_paths ........... None........................default
  test_reward_data_paths .......... None........................default
  tokenizer_type .................. GPT2BPETokenizer............default
  top_k ........................... 0...........................default
  top_p ........................... 0.0.........................default
  train_data_paths ................ None........................default
  train_data_weights .............. None........................default
  train_epochs .................... None........................default
  train_impl ...................... normal......................default
  train_label_data_paths .......... None........................default
  train_reward_data_paths ......... None........................default
  use_bias_in_mlp ................. True........................default
  use_bnb_optimizer ............... False.......................default
  use_checkpoint_lr_scheduler ..... False.......................default
  use_comet ....................... None........................default
  use_cpu_initialization .......... False.......................default
  use_flashattn_swiglu ............ False.......................default
  use_mup ......................... False.......................default
  use_qk_layernorm ................ False.......................default
  use_shared_fs ................... True........................default
  use_tutel ....................... False.......................default
  valid_data_paths ................ None........................default
  valid_data_weights .............. None........................default
  valid_label_data_paths .......... None........................default
  valid_reward_data_paths ......... None........................default
  wandb ........................... None........................default
  wandb_group ..................... None........................default
  wandb_host ...................... https://api.wandb.ai........default
  wandb_init_all_ranks ............ False.......................default
  wandb_project ................... neox........................default
  wandb_team ...................... None........................default
  warmup .......................... 0.01........................default
  weight_by_num_documents ......... False.......................default
  weight_decay .................... 0.1.........................default
  weighted_sampler_alpha .......... 1.0.........................default
  world_size ...................... None........................default
  z_loss .......................... 0.0.........................default
---------------- end of arguments ----------------
NeoXArgs.configure_distributed_args() using world size: 64 and model-parallel size: 8 
[2025-01-31 15:21:33,326] [INFO] [runner.py:586:main] cmd = srun -n 64 --export=ALL,PYTHONPATH=/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/slurms /work/08775/byz2022/vista/pythonenvs/gptneox/bin/python -u /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py --deepspeed_config eyJ0cmFpbl9iYXRjaF9zaXplIjogMTI4LCAidHJhaW5fbWljcm9fYmF0Y2hfc2l6ZV9wZXJfZ3B1IjogNCwgImdyYWRpZW50X2FjY3VtdWxhdGlvbl9zdGVwcyI6IDE2LCAib3B0aW1pemVyIjogeyJ0eXBlIjogIkFkYW0iLCAicGFyYW1zIjogeyJsciI6IDAuMDAwMiwgImJldGFzIjogWzAuOSwgMC45NV0sICJlcHMiOiAxZS0wOH19LCAiZnAxNiI6IHsiZnAxNiI6IHRydWUsICJlbmFibGVkIjogdHJ1ZSwgImxvc3Nfc2NhbGUiOiAwLCAibG9zc19zY2FsZV93aW5kb3ciOiAxMDAwLCAiaHlzdGVyZXNpcyI6IDIsICJtaW5fbG9zc19zY2FsZSI6IDF9LCAiemVyb19vcHRpbWl6YXRpb24iOiB7InN0YWdlIjogMSwgImFsbGdhdGhlcl9wYXJ0aXRpb25zIjogdHJ1ZSwgImFsbGdhdGhlcl9idWNrZXRfc2l6ZSI6IDUwMDAwMDAwMCwgIm92ZXJsYXBfY29tbSI6IHRydWUsICJyZWR1Y2Vfc2NhdHRlciI6IHRydWUsICJyZWR1Y2VfYnVja2V0X3NpemUiOiA1MDAwMDAwMDAsICJjb250aWd1b3VzX2dyYWRpZW50cyI6IHRydWV9LCAic3RlcHNfcGVyX3ByaW50IjogMSwgIndhbGxfY2xvY2tfYnJlYWtkb3duIjogdHJ1ZX0= --megatron_config {"launcher": "slurm", "train_batch_size": 128, "train_micro_batch_size_per_gpu": 4, "gradient_accumulation_steps": 16, "optimizer": {"type": "Adam", "params": {"lr": 0.0002, "betas": [0.9, 0.95], "eps": 1e-08}}, "fp16": {"fp16": true, "enabled": true, "loss_scale": 0, "loss_scale_window": 1000, "hysteresis": 2, "min_loss_scale": 1}, "zero_optimization": {"stage": 1, "allgather_partitions": true, "allgather_bucket_size": 500000000, "overlap_comm": true, "reduce_scatter": true, "reduce_bucket_size": 500000000, "contiguous_gradients": true}, "steps_per_print": 1, "wall_clock_breakdown": true, "precision": "fp16", "num_layers": 40, "hidden_size": 5120, "mlp_multiple_of": 256, "num_attention_heads": 40, "seq_length": 2048, "max_position_embeddings": 2048, "norm": "rmsnorm", "rms_norm_epsilon": 1e-06, "pos_emb": "rotary", "no_weight_tying": true, "attention_config": ["global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global"], "sparsity_config": {}, "scaled_upper_triang_masked_softmax_fusion": true, "init_method": "small_init", "output_layer_init_method": "wang_init", "use_bias_in_norms": false, "use_bias_in_attn_linear": false, "lr_decay_style": "cosine", "lr_decay_iters": 8, "min_lr": 2e-05, "override_lr_scheduler": true, "optimizer_type": "Adam", "zero_stage": 1, "zero_reduce_scatter": true, "zero_contiguous_gradients": true, "zero_reduce_bucket_size": 500000000, "zero_allgather_bucket_size": 500000000, "lr": 0.0002, "data_path": "/work/08775/byz2022/vista/data/gpt-neox/data/test_text_document", "data_impl": "mmap", "save": "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test", "config_files": {"llama_13B_4_8_2.yml": "{\n  \"pipe_parallel_size\": 4,\n  \"model_parallel_size\": 8,\n  \"make_vocab_size_divisible_by\": 128,\n\n  # model settings\n  \"num_layers\": 40,\n  \"hidden_size\": 5120,\n  \"num_attention_heads\": 40,\n  \"seq_length\": 2048,\n  \"max_position_embeddings\": 2048,\n  \"pos_emb\": \"rotary\",\n  \"rotary_pct\": 1,\n  \"no_weight_tying\": true,\n  \"gpt_j_residual\": false,\n  \"output_layer_parallelism\": \"column\",\n  \"norm\": \"rmsnorm\",\n  \"rms_norm_epsilon\": 1.0e-6,\n\n  \"scaled_upper_triang_masked_softmax_fusion\": true,\n  \"bias_gelu_fusion\": false,\n  \"use_bias_in_norms\": false,\n  \"use_bias_in_attn_linear\": false,\n  # \"activation\": \"swiglu\",\n  \"mlp_multiple_of\": 256,\n\n\n\n  # training setting\n  # finetuning option\n  # \"finetune\": true,\n\n  # init methods\n  \"init_method\": \"small_init\",\n  \"output_layer_init_method\": \"wang_init\",\n\n  # optimizer settings\n  \"optimizer\": {\n    \"type\": \"Adam\",\n    \"params\": {\n     \"lr\": 0.0002,\n     \"betas\": [0.9, 0.95],\n     \"eps\":  1.0e-8,\n    }\n  },\n  \"min_lr\": 0.00002,\n  \"override_lr_scheduler\": true,\n\n  # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training\n   \"zero_optimization\": {\n   \"stage\": 1,\n   \"allgather_partitions\": True,\n   \"allgather_bucket_size\": 500000000,\n   \"overlap_comm\": True,\n   \"reduce_scatter\": True,\n   \"reduce_bucket_size\": 500000000,\n   \"contiguous_gradients\": True,\n  },\n\n  # batch / data settings\n  \"train_micro_batch_size_per_gpu\": 4,\n  \"gradient_accumulation_steps\": 16,\n  \"data_impl\": \"mmap\",\n\n  # activation checkpointing\n  \"checkpoint_activations\": true,\n  \"checkpoint_num_layers\": 1,\n  \"partition_activations\": true,\n  \"synchronize_each_layer\": true,\n\n  # regularization\n  \"gradient_clipping\": 1.0,\n  \"weight_decay\": 0.1,\n  \"hidden_dropout\": 0,\n  \"attention_dropout\": 0,\n\n  # precision settings\n  \"fp16\": {\n    \"fp16\": true,\n    \"enabled\": true,\n    \"loss_scale\": 0,\n    \"loss_scale_window\": 1000,\n    \"hysteresis\": 2,\n    \"min_loss_scale\": 1\n  },\n\n  # misc. training settings\n  \"train_iters\": 8,\n  \"lr_decay_iters\": 8,\n  \"distributed_backend\": \"nccl\",\n  \"lr_decay_style\": \"cosine\",\n  \"warmup\": 0.01,\n  \"checkpoint_factor\": 10000,\n  \"eval_interval\": 1000,\n  \"eval_iters\": 100,\n\n  # logging\n  \"log_interval\": 1,\n  \"steps_per_print\": 1,\n  \"keep_last_n_checkpoints\": 4,\n  \"wall_clock_breakdown\": true,\n  \"mlp_multiple_of\": 256,\n\n  # profiling settings\n  \"profile\": True,\n  \"profile_step_start\": 2,\n  \"profile_step_stop\": 7,\n\n  # distributed training settings\n  \"launcher\": \"slurm\",\n  \"deepspeed_slurm\": true,\n\n}\n", "local_setup.yml": "# Suggested data paths when using GPT-NeoX locally\n{\n  \"data_path\": \"/work/08775/byz2022/vista/data/gpt-neox/data/test_text_document\",\n\n  # or for weighted datasets:\n  # \"train-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"test-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"valid-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"train-data-weights\": [1., 2.],\n  # \"test-data-weights\": [2., 1.],\n  # \"valid-data-weights\": [0.5, 0.4],\n\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\n  # WARNING: setting this to True will override any user provided weights\n  # \"weight_by_num_documents\": false,\n  # \"weighted_sampler_alpha\": 0.3,\n\n  \"vocab_file\": \"/work/08775/byz2022/vista/data/gpt-neox/data/gpt2-vocab.json\",\n  \"merge_file\": \"/work/08775/byz2022/vista/data/gpt-neox/data/gpt2-merges.txt\",\n\n  \"save\": \"/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test\",\n  \"load\": \"/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2\",\n  \"checkpoint_validation_with_forward_pass\": False,\n\n  # \"tensorboard_dir\": \"tensorboard\",\n  # \"log_dir\": \"logs\",\n  \"use_wandb\": False,\n  \"wandb_host\": \"https://api.wandb.ai\",\n  \"wandb_project\": \"neox\"\n}"}, "load": "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2", "checkpoint_factor": 10000, "batch_size": 4, "train_iters": 8, "keep_last_n_checkpoints": 4, "vocab_file": "/work/08775/byz2022/vista/data/gpt-neox/data/gpt2-vocab.json", "merge_file": "/work/08775/byz2022/vista/data/gpt-neox/data/gpt2-merges.txt", "checkpoint_activations": true, "synchronize_each_layer": true, "partition_activations": true, "dynamic_loss_scale": true, "pipe_parallel_size": 4, "model_parallel_size": 8, "world_size": 64, "is_pipe_parallel": true, "use_wandb": false, "log_interval": 1, "profile": true, "profile_step_start": 2, "profile_step_stop": 7, "text_gen_type": "unconditional", "local_rank": 0, "rank": 0, "deepspeed_slurm": true, "user_script": "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", "global_num_gpus": 64}
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
[2025-01-31 15:21:36,136] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
[2025-01-31 15:21:40,432] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:40,467] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:40,491] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:40,507] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:40,522] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:40,532] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:40,588] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:40,597] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:40,612] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:40,620] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:40,889] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:40,957] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
NeoXArgs.configure_distributed_args() using world size: 64 and model-parallel size: 8 
> building GPT2BPETokenizer tokenizer ...
[2025-01-31 15:21:41,118] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,226] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 > padded vocab (size: 50257) with 943 dummy tokens (new size: 51200)
Detected CUDA files, patching ldflags
Emitting ninja build file /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/fused_kernels/build/build.ninja...
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module scaled_upper_triang_masked_softmax_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[2025-01-31 15:21:41,420] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,426] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,436] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,438] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,445] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,452] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,457] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,462] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,464] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,465] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,466] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,468] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,472] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,476] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,491] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,536] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,550] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-01-31 15:21:41,754] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,778] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,787] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:41,840] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-01-31 15:21:41,898] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-01-31 15:21:41,939] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-01-31 15:21:41,979] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,043] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,069] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,098] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,113] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-01-31 15:21:42,128] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,130] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,132] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,152] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,154] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,162] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,165] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-01-31 15:21:42,167] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,168] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,169] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-01-31 15:21:42,180] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,186] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,188] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,192] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-01-31 15:21:42,193] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,194] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,194] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,194] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,196] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-31 15:21:42,197] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-01-31 15:21:42,201] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
ninja: no work to do.
Loading extension module scaled_upper_triang_masked_softmax_cuda...
Detected CUDA files, patching ldflags
Emitting ninja build file /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/fused_kernels/build/build.ninja...
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module scaled_masked_softmax_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module scaled_masked_softmax_cuda...
Detected CUDA files, patching ldflags
Emitting ninja build file /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/fused_kernels/build/build.ninja...
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_rotary_positional_embedding...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_rotary_positional_embedding...
> initializing torch distributed ...
[2025-01-31 15:21:48,769] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:21:48,769] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
[2025-01-31 15:21:51,942] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
[2025-01-31 15:21:53,601] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
[2025-01-31 15:21:55,233] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
[2025-01-31 15:21:56,621] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  counts = torch.cuda.LongTensor([1])
[2025-01-31 15:21:57,881] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
[2025-01-31 15:21:59,547] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
[2025-01-31 15:22:01,192] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:02,657] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:02,658] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:02,658] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:02,658] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:02,660] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:04,296] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:04,303] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:04,304] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:05,814] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:05,842] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:05,842] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:05,843] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:07,417] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:07,450] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:08,799] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
[2025-01-31 15:22:08,815] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:08,815] [INFO] [comm.py:637:init_distributed] cdb=None
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
[2025-01-31 15:22:08,816] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:10,264] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:10,274] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:10,275] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
[2025-01-31 15:22:11,614] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:11,624] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:12,970] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:12,984] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:12,984] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:12,985] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  counts = torch.cuda.LongTensor([1])
[2025-01-31 15:22:14,382] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:14,391] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:15,854] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:15,864] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:15,864] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:15,865] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:15,866] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:15,866] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:15,867] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:15,867] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:17,248] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
[2025-01-31 15:22:17,269] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:17,269] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:17,270] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:17,270] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:17,270] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:17,272] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:17,272] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:17,273] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  counts = torch.cuda.LongTensor([1])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:17,300] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:18,564] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:18,608] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:18,608] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:19,960] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:20,014] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:20,014] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:20,014] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-31 15:22:20,016] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-01-31 15:22:20,041] [INFO] [comm.py:637:init_distributed] cdb=None
> initializing model parallel with size 8
MPU DP: [0, 8]
MPU DP: [1, 9]
MPU DP: [2, 10]
MPU DP: [3, 11]
MPU DP: [4, 12]
MPU DP: [5, 13]
MPU DP: [6, 14]
MPU DP: [7, 15]
MPU DP: [16, 24]
MPU DP: [17, 25]
MPU DP: [18, 26]
MPU DP: [19, 27]
MPU DP: [20, 28]
MPU DP: [21, 29]
MPU DP: [22, 30]
MPU DP: [23, 31]
MPU DP: [32, 40]
MPU DP: [33, 41]
MPU DP: [34, 42]
MPU DP: [35, 43]
MPU DP: [36, 44]
MPU DP: [37, 45]
MPU DP: [38, 46]
MPU DP: [39, 47]
MPU DP: [48, 56]
MPU DP: [49, 57]
MPU DP: [50, 58]
MPU DP: [51, 59]
MPU DP: [52, 60]
MPU DP: [53, 61]
MPU DP: [54, 62]
MPU DP: [55, 63]
MPU PP: [0, 16, 32, 48]
MPU PP: [1, 17, 33, 49]
MPU PP: [2, 18, 34, 50]
MPU PP: [3, 19, 35, 51]
MPU PP: [4, 20, 36, 52]
MPU PP: [5, 21, 37, 53]
MPU PP: [6, 22, 38, 54]
MPU PP: [7, 23, 39, 55]
MPU PP: [8, 24, 40, 56]
MPU PP: [9, 25, 41, 57]
MPU PP: [10, 26, 42, 58]
MPU PP: [11, 27, 43, 59]
MPU PP: [12, 28, 44, 60]
MPU PP: [13, 29, 45, 61]
MPU PP: [14, 30, 46, 62]
MPU PP: [15, 31, 47, 63]
MPU IO: [0, 8, 48, 56]
MPU MP: [0, 1, 2, 3, 4, 5, 6, 7]
MPU MP: [8, 9, 10, 11, 12, 13, 14, 15]
MPU MP: [16, 17, 18, 19, 20, 21, 22, 23]
MPU MP: [24, 25, 26, 27, 28, 29, 30, 31]
MPU MP: [32, 33, 34, 35, 36, 37, 38, 39]
MPU MP: [40, 41, 42, 43, 44, 45, 46, 47]
MPU MP: [48, 49, 50, 51, 52, 53, 54, 55]
MPU MP: [56, 57, 58, 59, 60, 61, 62, 63]
> setting random seeds to 1234 ...
[2025-01-31 15:22:20,054] [INFO] [checkpointing.py:227:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
> building train, validation, and test datasets ...
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
    reading sizes...
    reading pointers...
    reading document index...
    creating numpy buffer of mmap...
    creating memory view of numpy buffer...
 > dataset split:
    train:
     document indices in [0, 207923) total of 207923 documents
    validation:
     document indices in [207923, 214360) total of 6437 documents
    test:
     document indices in [214360, 214575) total of 215 documents
 > WARNING: could not find index map files, building the indices on rank 0 ...
 > elapsed time to build and save doc-idx mapping (seconds): 0.048731
    using:
     number of documents:       207923
     number of epochs:          1
     sequence length:           2048
     total number of samples:   177173
 > elapsed time to build and save sample-idx mapping (seconds): 0.032177
 > elapsed time to build and save shuffle-idx mapping (seconds): 0.003807
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  counts = torch.cuda.LongTensor([1])
 > loading doc-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_train_indexmap_1024ns_2048sl_1234s_packedpi_ac_doc_idx.npy
 > loading sample-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_train_indexmap_1024ns_2048sl_1234s_packedpi_ac_sample_idx.npy
 > loading shuffle-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_train_indexmap_1024ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy
    loaded indexed file in 0.002 seconds
    total number of samples: 177174
    total number of epochs: 1
 > WARNING: could not find index map files, building the indices on rank 0 ...
 > elapsed time to build and save doc-idx mapping (seconds): 0.001957
    using:
     number of documents:       6437
     number of epochs:          3
     sequence length:           2048
     total number of samples:   14963
 > elapsed time to build and save sample-idx mapping (seconds): 0.001534
 > elapsed time to build and save shuffle-idx mapping (seconds): 0.001548
 > loading doc-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_valid_indexmap_12800ns_2048sl_1234s_packedpi_ac_doc_idx.npy
 > loading sample-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_valid_indexmap_12800ns_2048sl_1234s_packedpi_ac_sample_idx.npy
 > loading shuffle-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_valid_indexmap_12800ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy
    loaded indexed file in 0.001 seconds
    total number of samples: 14964
    total number of epochs: 3
 > WARNING: could not find index map files, building the indices on rank 0 ...
 > elapsed time to build and save doc-idx mapping (seconds): 0.001806
    using:
     number of documents:       215
     number of epochs:          114
     sequence length:           2048
     total number of samples:   12839
 > elapsed time to build and save sample-idx mapping (seconds): 0.001500
 > elapsed time to build and save shuffle-idx mapping (seconds): 0.001360
 > loading doc-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_test_indexmap_12800ns_2048sl_1234s_packedpi_ac_doc_idx.npy
 > loading sample-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_test_indexmap_12800ns_2048sl_1234s_packedpi_ac_sample_idx.npy
 > loading shuffle-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_test_indexmap_12800ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy
    loaded indexed file in 0.001 seconds
    total number of samples: 12840
    total number of epochs: 114
building GPT2 model ...
SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=0, model=1): 1, ProcessCoord(pipe=0, data=0, model=2): 2, ProcessCoord(pipe=0, data=0, model=3): 3, ProcessCoord(pipe=0, data=0, model=4): 4, ProcessCoord(pipe=0, data=0, model=5): 5, ProcessCoord(pipe=0, data=0, model=6): 6, ProcessCoord(pipe=0, data=0, model=7): 7, ProcessCoord(pipe=0, data=1, model=0): 8, ProcessCoord(pipe=0, data=1, model=1): 9, ProcessCoord(pipe=0, data=1, model=2): 10, ProcessCoord(pipe=0, data=1, model=3): 11, ProcessCoord(pipe=0, data=1, model=4): 12, ProcessCoord(pipe=0, data=1, model=5): 13, ProcessCoord(pipe=0, data=1, model=6): 14, ProcessCoord(pipe=0, data=1, model=7): 15, ProcessCoord(pipe=1, data=0, model=0): 16, ProcessCoord(pipe=1, data=0, model=1): 17, ProcessCoord(pipe=1, data=0, model=2): 18, ProcessCoord(pipe=1, data=0, model=3): 19, ProcessCoord(pipe=1, data=0, model=4): 20, ProcessCoord(pipe=1, data=0, model=5): 21, ProcessCoord(pipe=1, data=0, model=6): 22, ProcessCoord(pipe=1, data=0, model=7): 23, ProcessCoord(pipe=1, data=1, model=0): 24, ProcessCoord(pipe=1, data=1, model=1): 25, ProcessCoord(pipe=1, data=1, model=2): 26, ProcessCoord(pipe=1, data=1, model=3): 27, ProcessCoord(pipe=1, data=1, model=4): 28, ProcessCoord(pipe=1, data=1, model=5): 29, ProcessCoord(pipe=1, data=1, model=6): 30, ProcessCoord(pipe=1, data=1, model=7): 31, ProcessCoord(pipe=2, data=0, model=0): 32, ProcessCoord(pipe=2, data=0, model=1): 33, ProcessCoord(pipe=2, data=0, model=2): 34, ProcessCoord(pipe=2, data=0, model=3): 35, ProcessCoord(pipe=2, data=0, model=4): 36, ProcessCoord(pipe=2, data=0, model=5): 37, ProcessCoord(pipe=2, data=0, model=6): 38, ProcessCoord(pipe=2, data=0, model=7): 39, ProcessCoord(pipe=2, data=1, model=0): 40, ProcessCoord(pipe=2, data=1, model=1): 41, ProcessCoord(pipe=2, data=1, model=2): 42, ProcessCoord(pipe=2, data=1, model=3): 43, ProcessCoord(pipe=2, data=1, model=4): 44, ProcessCoord(pipe=2, data=1, model=5): 45, ProcessCoord(pipe=2, data=1, model=6): 46, ProcessCoord(pipe=2, data=1, model=7): 47, ProcessCoord(pipe=3, data=0, model=0): 48, ProcessCoord(pipe=3, data=0, model=1): 49, ProcessCoord(pipe=3, data=0, model=2): 50, ProcessCoord(pipe=3, data=0, model=3): 51, ProcessCoord(pipe=3, data=0, model=4): 52, ProcessCoord(pipe=3, data=0, model=5): 53, ProcessCoord(pipe=3, data=0, model=6): 54, ProcessCoord(pipe=3, data=0, model=7): 55, ProcessCoord(pipe=3, data=1, model=0): 56, ProcessCoord(pipe=3, data=1, model=1): 57, ProcessCoord(pipe=3, data=1, model=2): 58, ProcessCoord(pipe=3, data=1, model=3): 59, ProcessCoord(pipe=3, data=1, model=4): 60, ProcessCoord(pipe=3, data=1, model=5): 61, ProcessCoord(pipe=3, data=1, model=6): 62, ProcessCoord(pipe=3, data=1, model=7): 63}
[2025-01-31 15:22:21,298] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer|mlp
stage=0 layers=12
     0: EmbeddingPipe
     1: _pre_transformer_block
     2: ParallelTransformerLayerPipe
     3: ParallelTransformerLayerPipe
     4: ParallelTransformerLayerPipe
     5: ParallelTransformerLayerPipe
     6: ParallelTransformerLayerPipe
     7: ParallelTransformerLayerPipe
     8: ParallelTransformerLayerPipe
     9: ParallelTransformerLayerPipe
    10: ParallelTransformerLayerPipe
    11: ParallelTransformerLayerPipe
stage=1 layers=11
    12: ParallelTransformerLayerPipe
    13: ParallelTransformerLayerPipe
    14: ParallelTransformerLayerPipe
    15: ParallelTransformerLayerPipe
    16: ParallelTransformerLayerPipe
    17: ParallelTransformerLayerPipe
    18: ParallelTransformerLayerPipe
    19: ParallelTransformerLayerPipe
    20: ParallelTransformerLayerPipe
    21: ParallelTransformerLayerPipe
    22: ParallelTransformerLayerPipe
stage=2 layers=11
    23: ParallelTransformerLayerPipe
    24: ParallelTransformerLayerPipe
    25: ParallelTransformerLayerPipe
    26: ParallelTransformerLayerPipe
    27: ParallelTransformerLayerPipe
    28: ParallelTransformerLayerPipe
    29: ParallelTransformerLayerPipe
    30: ParallelTransformerLayerPipe
    31: ParallelTransformerLayerPipe
    32: ParallelTransformerLayerPipe
    33: ParallelTransformerLayerPipe
stage=3 layers=11
    34: ParallelTransformerLayerPipe
    35: ParallelTransformerLayerPipe
    36: ParallelTransformerLayerPipe
    37: ParallelTransformerLayerPipe
    38: ParallelTransformerLayerPipe
    39: ParallelTransformerLayerPipe
    40: ParallelTransformerLayerPipe
    41: ParallelTransformerLayerPipe
    42: _post_transformer_block
    43: NormPipe
    44: ParallelLinearPipe
  loss: partial
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
Configuring Optimizer type: Adam with params: {'lr': 0.0002, 'betas': [0.9, 0.95], 'eps': 1e-08}
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home1/08775/byz2022/.cache/torch_extensions/py39_cu124/fused_adam/build.ninja...
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 0.13294196128845215 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.14715909957885742 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.14651989936828613 seconds
Time to load fused_adam op: 0.14644241333007812 seconds
Time to load fused_adam op: 0.1467885971069336 seconds
Time to load fused_adam op: 0.14828085899353027 seconds
Time to load fused_adam op: 0.14886760711669922 seconds
Time to load fused_adam op: 0.1495366096496582 seconds
Time to load fused_adam op: 0.15386009216308594 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.051698684692383 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.049858331680298 seconds
Time to load fused_adam op: 3.0498404502868652 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0516281127929688 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.050722599029541 seconds
Time to load fused_adam op: 3.051515817642212 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.051969528198242 seconds
Time to load fused_adam op: 3.048862934112549 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.054866313934326 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.050452709197998 seconds
Time to load fused_adam op: 3.056180238723755 seconds
Time to load fused_adam op: 3.0502195358276367 seconds
Time to load fused_adam op: 3.054636001586914 seconds
Time to load fused_adam op: 3.0498785972595215 seconds
Time to load fused_adam op: 3.049129009246826 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.048884153366089 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.049283742904663 seconds
Time to load fused_adam op: 3.048753499984741 seconds
Time to load fused_adam op: 3.0507924556732178 seconds
Time to load fused_adam op: 3.0538313388824463 seconds
Time to load fused_adam op: 3.0529048442840576 seconds
Time to load fused_adam op: 3.054673433303833 seconds
Time to load fused_adam op: 3.051464319229126 seconds
Time to load fused_adam op: 3.0550308227539062 seconds
Time to load fused_adam op: 3.04951810836792 seconds
Time to load fused_adam op: 3.054767608642578 seconds
Time to load fused_adam op: 3.049318790435791 seconds
Time to load fused_adam op: 3.0531094074249268 seconds
Time to load fused_adam op: 3.050386667251587 seconds
Time to load fused_adam op: 3.057011127471924 seconds
Time to load fused_adam op: 3.0506248474121094 seconds
Time to load fused_adam op: 3.0524239540100098 seconds
Time to load fused_adam op: 3.057999849319458 seconds
Time to load fused_adam op: 3.0532920360565186 seconds
Time to load fused_adam op: 3.05509877204895 seconds
Time to load fused_adam op: 3.0544958114624023 seconds
Time to load fused_adam op: 3.050234794616699 seconds
Time to load fused_adam op: 3.053339958190918 seconds
Time to load fused_adam op: 3.0569803714752197 seconds
Time to load fused_adam op: 3.056180238723755 seconds
Time to load fused_adam op: 3.050812244415283 seconds
Time to load fused_adam op: 3.0531551837921143 seconds
Time to load fused_adam op: 3.051487684249878 seconds
Time to load fused_adam op: 3.0519702434539795 seconds
Time to load fused_adam op: 3.0508956909179688 seconds
> learning rate decay style: cosine
DeepSpeed is enabled.
[2025-01-31 15:22:29,831] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4+02e2ebf, git-hash=02e2ebf, git-branch=HEAD
Time to load fused_adam op: 3.0574991703033447 seconds
Time to load fused_adam op: 3.0569214820861816 seconds
Time to load fused_adam op: 3.0552258491516113 seconds
Time to load fused_adam op: 3.060516834259033 seconds
Time to load fused_adam op: 3.0586910247802734 seconds
Time to load fused_adam op: 3.054518461227417 seconds
Time to load fused_adam op: 3.0558879375457764 seconds
Time to load fused_adam op: 3.057846784591675 seconds
Time to load fused_adam op: 3.054663896560669 seconds
Time to load fused_adam op: 3.0531420707702637 seconds
[2025-01-31 15:22:29,941] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-01-31 15:22:29,941] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-01-31 15:22:29,941] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-01-31 15:22:29,942] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2025-01-31 15:22:29,942] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2025-01-31 15:22:29,942] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer
[2025-01-31 15:22:29,942] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000
[2025-01-31 15:22:29,942] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000
[2025-01-31 15:22:29,942] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2025-01-31 15:22:29,942] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2025-01-31 15:22:31,899] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,899] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,900] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,899] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,900] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,900] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,900] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,900] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,900] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,900] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,900] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,900] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,900] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,901] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,948] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:31,967] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,234] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,243] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,243] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,248] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,249] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,257] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,267] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,273] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,276] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,279] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,279] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,281] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,282] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,284] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,284] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,285] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,285] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,286] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,287] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,287] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,287] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,287] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,288] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,288] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,288] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,293] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,294] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,299] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,308] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,309] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,310] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,311] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,313] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,317] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,318] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,318] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,321] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,321] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,323] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,325] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,326] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,326] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,326] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,329] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,333] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,335] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,349] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,419] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states
[2025-01-31 15:22:32,420] [INFO] [utils.py:803:see_memory_usage] MA 1.59 GB         Max_MA 1.59 GB         CA 1.59 GB         Max_CA 2 GB 
[2025-01-31 15:22:32,420] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 23.19 GB, percent = 10.9%
[2025-01-31 15:22:32,481] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states
[2025-01-31 15:22:32,482] [INFO] [utils.py:803:see_memory_usage] MA 3.18 GB         Max_MA 3.97 GB         CA 3.98 GB         Max_CA 4 GB 
[2025-01-31 15:22:32,482] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 25.57 GB, percent = 12.0%
[2025-01-31 15:22:32,482] [INFO] [stage_1_and_2.py:517:__init__] optimizer state initialized
[2025-01-31 15:22:32,532] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer
[2025-01-31 15:22:32,533] [INFO] [utils.py:803:see_memory_usage] MA 3.18 GB         Max_MA 3.18 GB         CA 3.98 GB         Max_CA 4 GB 
[2025-01-31 15:22:32,533] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 25.57 GB, percent = 12.0%
[2025-01-31 15:22:32,535] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[2025-01-31 15:22:32,535] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-01-31 15:22:32,535] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x40032343c640>
[2025-01-31 15:22:32,535] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-01-31 15:22:32,535] [INFO] [config.py:979:print] DeepSpeedEngine configuration:
[2025-01-31 15:22:32,535] [INFO] [config.py:983:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-01-31 15:22:32,535] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   amp_enabled .................. False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   amp_params ................... False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   bfloat16_enabled ............. False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x40033ff1eca0>
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   communication_data_type ...... None
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   dataloader_drop_last ......... False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   disable_allgather ............ False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   dump_state ................... False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   elasticity_enabled ........... False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   fp16_auto_cast ............... False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   fp16_enabled ................. True
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   global_rank .................. 0
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   grad_accum_dtype ............. None
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 16
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   gradient_clipping ............ 0.0
[2025-01-31 15:22:32,536] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 65536
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   load_universal_checkpoint .... False
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   loss_scale ................... 0
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   memory_breakdown ............. False
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   mics_shard_size .............. -1
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   optimizer_name ............... adam
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   optimizer_params ............. {'lr': 0.0002, 'betas': [0.9, 0.95], 'eps': 1e-08}
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   pld_enabled .................. False
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   pld_params ................... False
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   prescale_gradients ........... False
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   scheduler_name ............... None
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   scheduler_params ............. None
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   sparse_attention ............. None
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   steps_per_print .............. 1
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   train_batch_size ............. 128
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  4
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   use_node_local_storage ....... False
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   wall_clock_breakdown ......... True
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   weight_quantization_config ... None
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   world_size ................... 2
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   zero_enabled ................. True
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True
[2025-01-31 15:22:32,537] [INFO] [config.py:983:print]   zero_optimization_stage ...... 1
[2025-01-31 15:22:32,537] [INFO] [config.py:969:print_user_config]   json = {
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 16, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.0002, 
            "betas": [0.9, 0.95], 
            "eps": 1e-08
        }
    }, 
    "fp16": {
        "fp16": true, 
        "enabled": true, 
        "loss_scale": 0, 
        "loss_scale_window": 1000, 
        "hysteresis": 2, 
        "min_loss_scale": 1
    }, 
    "zero_optimization": {
        "stage": 1, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 5.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 5.000000e+08, 
        "contiguous_gradients": true
    }, 
    "steps_per_print": 1, 
    "wall_clock_breakdown": true
}
[2025-01-31 15:22:32,538] [INFO] [engine.py:99:__init__] CONFIG: micro_batches=16 micro_batch_size=4
[2025-01-31 15:22:32,538] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-01-31 15:22:32,808] [INFO] [engine.py:158:__init__] RANK=0 STAGE=0 LAYERS=12 [0, 12) STAGE_PARAMS=426163200 (426.163M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=20 STAGE=1 LAYERS=11 [12, 23) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=16 STAGE=1 LAYERS=11 [12, 23) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=22 STAGE=1 LAYERS=11 [12, 23) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=19 STAGE=1 LAYERS=11 [12, 23) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=36 STAGE=2 LAYERS=11 [23, 34) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=54 STAGE=3 LAYERS=11 [34, 45) STAGE_PARAMS=347489280 (347.489M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=4 STAGE=0 LAYERS=12 [0, 12) STAGE_PARAMS=426163200 (426.163M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=50 STAGE=3 LAYERS=11 [34, 45) STAGE_PARAMS=347489280 (347.489M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=32 STAGE=2 LAYERS=11 [23, 34) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=48 STAGE=3 LAYERS=11 [34, 45) STAGE_PARAMS=347489280 (347.489M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=39 STAGE=2 LAYERS=11 [23, 34) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=18 STAGE=1 LAYERS=11 [12, 23) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=6 STAGE=0 LAYERS=12 [0, 12) STAGE_PARAMS=426163200 (426.163M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,808] [INFO] [engine.py:158:__init__] RANK=2 STAGE=0 LAYERS=12 [0, 12) STAGE_PARAMS=426163200 (426.163M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=38 STAGE=2 LAYERS=11 [23, 34) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=52 STAGE=3 LAYERS=11 [34, 45) STAGE_PARAMS=347489280 (347.489M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=34 STAGE=2 LAYERS=11 [23, 34) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=35 STAGE=2 LAYERS=11 [23, 34) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=3 STAGE=0 LAYERS=12 [0, 12) STAGE_PARAMS=426163200 (426.163M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=21 STAGE=1 LAYERS=11 [12, 23) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=7 STAGE=0 LAYERS=12 [0, 12) STAGE_PARAMS=426163200 (426.163M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=1 STAGE=0 LAYERS=12 [0, 12) STAGE_PARAMS=426163200 (426.163M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=33 STAGE=2 LAYERS=11 [23, 34) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=23 STAGE=1 LAYERS=11 [12, 23) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=55 STAGE=3 LAYERS=11 [34, 45) STAGE_PARAMS=347489280 (347.489M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=53 STAGE=3 LAYERS=11 [34, 45) STAGE_PARAMS=347489280 (347.489M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=37 STAGE=2 LAYERS=11 [23, 34) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=17 STAGE=1 LAYERS=11 [12, 23) STAGE_PARAMS=432734720 (432.735M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=49 STAGE=3 LAYERS=11 [34, 45) STAGE_PARAMS=347489280 (347.489M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=5 STAGE=0 LAYERS=12 [0, 12) STAGE_PARAMS=426163200 (426.163M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
[2025-01-31 15:22:32,809] [INFO] [engine.py:158:__init__] RANK=51 STAGE=3 LAYERS=11 [34, 45) STAGE_PARAMS=347489280 (347.489M) TOTAL_PARAMS=13112975360 (13112.975M) UNIQUE_PARAMS=13112975360 (13112.975M)
 > number of parameters on model parallel rank 7: 426163200
 > number of parameters on model parallel rank 0: 426163200
 > number of parameters on model parallel rank 4: 347489280
 > number of parameters on model parallel rank 0: 347489280
 > number of parameters on model parallel rank 4: 426163200
 > number of parameters on model parallel rank 3: 347489280
 > number of parameters on model parallel rank 3: 426163200
 > number of parameters on model parallel rank 0: 432734720
 > number of parameters on model parallel rank 0: 432734720
 > number of parameters on model parallel rank 4: 432734720
 > number of parameters on model parallel rank 4: 432734720
 > number of parameters on model parallel rank 3: 432734720
 > number of parameters on model parallel rank 3: 432734720
 > number of parameters on model parallel rank 7: 347489280
 > number of parameters on model parallel rank 1: 426163200
 > number of parameters on model parallel rank 6: 426163200
 > number of parameters on model parallel rank 5: 426163200
 > number of parameters on model parallel rank 7: 432734720
 > number of parameters on model parallel rank 7: 432734720
 > number of parameters on model parallel rank 6: 347489280
 > number of parameters on model parallel rank 1: 347489280
 > number of parameters on model parallel rank 5: 347489280
 > number of parameters on model parallel rank 2: 347489280
 > number of parameters on model parallel rank 2: 426163200
 > number of parameters on model parallel rank 1: 432734720
 > number of parameters on model parallel rank 1: 432734720
 > number of parameters on model parallel rank 6: 432734720
 > number of parameters on model parallel rank 6: 432734720
 > number of parameters on model parallel rank 5: 432734720
 > number of parameters on model parallel rank 5: 432734720
 > number of parameters on model parallel rank 2: 432734720
 > number of parameters on model parallel rank 2: 432734720
 > total params: 13,112,975,360
[2025-01-31 15:22:32,960] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Loading checkpoint and starting from iteration 0
[2025-01-31 15:22:32,960] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,960] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
setting training data start iteration to 0
Unable to load checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
setting validation data start iteration to 0
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-01-31 15:22:32,961] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
done with setups ...
time (ms) | train/valid/test data loaders: 1232.05 | model and optimizer: 11665.18 | train/valid/test data iterators: 149.26
training ...
[2025-01-31 15:22:34,181] [INFO] [checkpointing.py:540:forward] Activation Checkpointing Information
[2025-01-31 15:22:34,181] [INFO] [checkpointing.py:541:forward] ----Partition Activations True, CPU CHECKPOINTING False
[2025-01-31 15:22:34,181] [INFO] [checkpointing.py:542:forward] ----contiguous Memory Checkpointing False with 40 total layers
[2025-01-31 15:22:34,181] [INFO] [checkpointing.py:544:forward] ----Synchronization True
[2025-01-31 15:22:34,181] [INFO] [checkpointing.py:545:forward] ----Profiling time in checkpointing False
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[2025-01-31 15:22:46,057] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 9.58 | optimizer_gradients: 3.09 | optimizer_step: 2.37
[2025-01-31 15:22:46,057] [INFO] [logging.py:96:log_dist] [Rank 0] step=1, skipped=0, lr=[0.00019407330742385963, 0.00019407330742385963], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-01-31 15:22:46,058] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 562.49 | fwd_microstep: 3769.87 | bwd_microstep: 4175.06 | bwd_inner_microstep: 4174.95 | bwd_allreduce_microstep: 0.00 | step_microstep: 23.68
[2025-01-31 15:22:46,059] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3769.92 | bwd: 4175.07 | bwd_inner: 4174.96 | bwd_allreduce: 0.00 | step: 23.69
steps: 1 loss: 11.0432 iter time (s): 12.996 samples/sec: 9.849
[2025-01-31 15:22:46,110] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 1202.36 | pipe_recv_grad: 3182.94
 samples/sec: 9.846 | iteration        1/       8 | elapsed time per iteration (ms): 12999.6 | learning rate: 1.941E-04 | approx flops per GPU: 34.3TFLOPS | lm_loss: 1.104324E+01 | loss scale: 65536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
after 1 iterations memory (MB) | allocated: 3343.8798828125 | max allocated: 5924.8271484375 | reserved: 8092.0 | max reserved: 8092.0
time (ms)
[2025-01-31 15:23:01,010] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 11.48 | optimizer_gradients: 1.61 | optimizer_step: 2.37
[2025-01-31 15:23:01,010] [INFO] [logging.py:96:log_dist] [Rank 0] step=2, skipped=0, lr=[0.00017513606342945632, 0.00017513606342945632], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-01-31 15:23:01,011] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 16.14 | fwd_microstep: 1626.84 | bwd_microstep: 3679.92 | bwd_inner_microstep: 3679.83 | bwd_allreduce_microstep: 0.00 | step_microstep: 23.51
[2025-01-31 15:23:01,012] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1626.90 | bwd: 3679.92 | bwd_inner: 3679.83 | bwd_allreduce: 0.00 | step: 23.52
steps: 2 loss: 11.0416 iter time (s): 14.900 samples/sec: 8.591
[2025-01-31 15:23:01,013] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 24.62 | pipe_recv_grad: 9499.17
 samples/sec: 8.589 | iteration        2/       8 | elapsed time per iteration (ms): 14903.1 | learning rate: 1.751E-04 | approx flops per GPU: 29.9TFLOPS | lm_loss: 1.104165E+01 | loss scale: 65536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[rank63]:[W131 15:23:01.586396046 CPUAllocator.cpp:245] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
[rank16]:[W131 15:23:02.827526391 CPUAllocator.cpp:245] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
[rank0]:[W131 15:23:03.313509348 CPUAllocator.cpp:245] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
[2025-01-31 15:23:19,857] [INFO] [loss_scaler.py:190:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1
[2025-01-31 15:23:19,858] [INFO] [logging.py:96:log_dist] [Rank 0] step=3, skipped=1, lr=[0.00017513606342945632, 0.00017513606342945632], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-01-31 15:23:19,859] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 38.76 | fwd_microstep: 2458.03 | bwd_microstep: 3786.29 | bwd_inner_microstep: 3786.20 | bwd_allreduce_microstep: 0.00 | step_microstep: 5.78
[2025-01-31 15:23:19,861] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2458.08 | bwd: 3786.29 | bwd_inner: 3786.20 | bwd_allreduce: 0.00 | step: 5.81
steps: 3 loss: 12.2399 iter time (s): 18.846 samples/sec: 6.792
[2025-01-31 15:23:19,862] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 27.86 | pipe_recv_grad: 12495.15
 samples/sec: 6.791 | iteration        3/       8 | elapsed time per iteration (ms): 18849.1 | learning rate: 1.751E-04 | approx flops per GPU: 23.7TFLOPS | lm_loss: 0.000000E+00 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms)
[2025-01-31 15:23:27,108] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768
[2025-01-31 15:23:27,108] [INFO] [logging.py:96:log_dist] [Rank 0] step=4, skipped=2, lr=[0.00017513606342945632, 0.00017513606342945632], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-01-31 15:23:27,110] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 27.04 | fwd_microstep: 1597.22 | bwd_microstep: 3785.95 | bwd_inner_microstep: 3785.86 | bwd_allreduce_microstep: 0.00 | step_microstep: 5.73
[2025-01-31 15:23:27,111] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1597.27 | bwd: 3785.95 | bwd_inner: 3785.86 | bwd_allreduce: 0.00 | step: 5.75
steps: 4 loss: 12.6440 iter time (s): 7.248 samples/sec: 17.659
[2025-01-31 15:23:27,113] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 24.83 | pipe_recv_grad: 1773.28
 samples/sec: 17.653 | iteration        4/       8 | elapsed time per iteration (ms): 7250.7 | learning rate: 1.751E-04 | approx flops per GPU: 61.5TFLOPS | lm_loss: 0.000000E+00 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms)
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
[2025-01-31 15:23:38,030] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 9.57 | optimizer_gradients: 1.70 | optimizer_step: 2.40
[2025-01-31 15:23:38,030] [INFO] [logging.py:96:log_dist] [Rank 0] step=5, skipped=2, lr=[0.00014608374818659523, 0.00014608374818659523], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-01-31 15:23:38,032] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 26.80 | fwd_microstep: 1593.76 | bwd_microstep: 3785.97 | bwd_inner_microstep: 3785.88 | bwd_allreduce_microstep: 0.00 | step_microstep: 26.31
[2025-01-31 15:23:38,033] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1593.82 | bwd: 3786.02 | bwd_inner: 3785.88 | bwd_allreduce: 0.00 | step: 26.34
steps: 5 loss: 12.6724 iter time (s): 10.919 samples/sec: 11.722
[2025-01-31 15:23:38,035] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 24.60 | pipe_recv_grad: 5428.24
 samples/sec: 11.720 | iteration        5/       8 | elapsed time per iteration (ms): 10921.8 | learning rate: 1.461E-04 | approx flops per GPU: 40.9TFLOPS | lm_loss: 1.267242E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-01-31 15:23:45,712] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 9.37 | optimizer_gradients: 1.66 | optimizer_step: 2.37
[2025-01-31 15:23:45,713] [INFO] [logging.py:96:log_dist] [Rank 0] step=6, skipped=2, lr=[0.00011142793674513272, 0.00011142793674513272], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-01-31 15:23:45,714] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 26.81 | fwd_microstep: 1592.99 | bwd_microstep: 3794.16 | bwd_inner_microstep: 3794.07 | bwd_allreduce_microstep: 0.00 | step_microstep: 25.98
[2025-01-31 15:23:45,716] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1593.11 | bwd: 3794.16 | bwd_inner: 3794.07 | bwd_allreduce: 0.00 | step: 26.00
steps: 6 loss: 27.9454 iter time (s): 7.680 samples/sec: 16.667
[2025-01-31 15:23:45,717] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 25.50 | pipe_recv_grad: 2178.26
 samples/sec: 16.662 | iteration        6/       8 | elapsed time per iteration (ms): 7682.3 | learning rate: 1.114E-04 | approx flops per GPU: 58.1TFLOPS | lm_loss: 2.794538E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-01-31 15:23:54,908] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384
[2025-01-31 15:23:54,908] [INFO] [logging.py:96:log_dist] [Rank 0] step=7, skipped=3, lr=[0.00011142793674513272, 0.00011142793674513272], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-01-31 15:23:54,910] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 26.74 | fwd_microstep: 1594.59 | bwd_microstep: 3788.61 | bwd_inner_microstep: 3788.52 | bwd_allreduce_microstep: 0.00 | step_microstep: 5.91
[2025-01-31 15:23:54,911] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1594.64 | bwd: 3788.61 | bwd_inner: 3788.52 | bwd_allreduce: 0.00 | step: 5.94
steps: 7 loss: 21.0187 iter time (s): 9.193 samples/sec: 13.923
[2025-01-31 15:23:54,913] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 25.72 | pipe_recv_grad: 3717.46
 samples/sec: 13.920 | iteration        7/       8 | elapsed time per iteration (ms): 9195.6 | learning rate: 1.114E-04 | approx flops per GPU: 48.5TFLOPS | lm_loss: 0.000000E+00 | loss scale: 16384.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms)
[2025-01-31 15:24:34,823] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 9.35 | optimizer_gradients: 1.61 | optimizer_step: 2.38
[2025-01-31 15:24:34,823] [INFO] [logging.py:96:log_dist] [Rank 0] step=8, skipped=3, lr=[7.655037899057054e-05, 7.655037899057054e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-01-31 15:24:34,824] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 15.78 | fwd_microstep: 1487.51 | bwd_microstep: 3649.29 | bwd_inner_microstep: 3649.20 | bwd_allreduce_microstep: 0.00 | step_microstep: 20.52
[2025-01-31 15:24:34,825] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1487.57 | bwd: 3649.29 | bwd_inner: 3649.20 | bwd_allreduce: 0.00 | step: 20.53
steps: 8 loss: 20.9447 iter time (s): 22.158 samples/sec: 5.777
[2025-01-31 15:24:34,826] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 1971.57 | pipe_recv_grad: 14984.03
 samples/sec: 3.207 | iteration        8/       8 | elapsed time per iteration (ms): 39913.2 | learning rate: 7.655E-05 | approx flops per GPU: 11.2TFLOPS | lm_loss: 2.094467E+01 | loss scale: 16384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[rank15]: Traceback (most recent call last):
[rank15]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank15]:     main()
[rank15]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank15]:     pretrain(neox_args=neox_args)
[rank15]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank15]:     evaluate_and_print_results(
[rank15]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank15]:     total_loss_dict = evaluate(
[rank15]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank15]:     loss, metric_dict = forward_step_fn(
[rank15]: ValueError: not enough values to unpack (expected 2, got 1)
[rank14]: Traceback (most recent call last):
[rank14]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank14]:     main()
[rank14]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank14]:     pretrain(neox_args=neox_args)
[rank14]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank14]:     evaluate_and_print_results(
[rank14]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank14]:     total_loss_dict = evaluate(
[rank14]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank14]:     loss, metric_dict = forward_step_fn(
[rank14]: ValueError: not enough values to unpack (expected 2, got 1)
[rank8]: Traceback (most recent call last):
[rank8]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank8]:     main()
[rank8]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank8]:     pretrain(neox_args=neox_args)
[rank8]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank8]:     evaluate_and_print_results(
[rank8]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank8]:     total_loss_dict = evaluate(
[rank8]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank8]:     loss, metric_dict = forward_step_fn(
[rank8]: ValueError: not enough values to unpack (expected 2, got 1)
[rank11]: Traceback (most recent call last):
[rank11]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank11]:     main()
[rank11]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank11]:     pretrain(neox_args=neox_args)
[rank11]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank11]:     evaluate_and_print_results(
[rank11]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank11]:     total_loss_dict = evaluate(
[rank11]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank11]:     loss, metric_dict = forward_step_fn(
[rank11]: ValueError: not enough values to unpack (expected 2, got 1)
[rank12]: Traceback (most recent call last):
[rank12]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank12]:     main()
[rank12]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank12]:     pretrain(neox_args=neox_args)
[rank12]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank12]:     evaluate_and_print_results(
[rank12]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank12]:     total_loss_dict = evaluate(
[rank12]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank12]:     loss, metric_dict = forward_step_fn(
[rank12]: ValueError: not enough values to unpack (expected 2, got 1)
[rank10]: Traceback (most recent call last):
[rank10]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank10]:     main()
[rank10]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank10]:     pretrain(neox_args=neox_args)
[rank10]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank10]:     evaluate_and_print_results(
[rank10]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank10]:     total_loss_dict = evaluate(
[rank10]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank10]:     loss, metric_dict = forward_step_fn(
[rank10]: ValueError: not enough values to unpack (expected 2, got 1)
[rank9]: Traceback (most recent call last):
[rank9]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank9]:     main()
[rank9]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank9]:     pretrain(neox_args=neox_args)
[rank9]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank9]:     evaluate_and_print_results(
[rank9]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank9]:     total_loss_dict = evaluate(
[rank9]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank9]:     loss, metric_dict = forward_step_fn(
[rank9]: ValueError: not enough values to unpack (expected 2, got 1)
[rank13]: Traceback (most recent call last):
[rank13]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank13]:     main()
[rank13]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank13]:     pretrain(neox_args=neox_args)
[rank13]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank13]:     evaluate_and_print_results(
[rank13]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank13]:     total_loss_dict = evaluate(
[rank13]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank13]:     loss, metric_dict = forward_step_fn(
[rank13]: ValueError: not enough values to unpack (expected 2, got 1)
[rank29]: Traceback (most recent call last):
[rank29]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank29]:     main()
[rank29]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank29]:     pretrain(neox_args=neox_args)
[rank29]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank29]:     evaluate_and_print_results(
[rank29]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank29]:     total_loss_dict = evaluate(
[rank29]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank29]:     loss, metric_dict = forward_step_fn(
[rank29]: ValueError: not enough values to unpack (expected 2, got 1)
[rank27]: Traceback (most recent call last):
[rank27]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank27]:     main()
[rank27]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank27]:     pretrain(neox_args=neox_args)
[rank27]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank27]:     evaluate_and_print_results(
[rank27]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank27]:     total_loss_dict = evaluate(
[rank27]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank27]:     loss, metric_dict = forward_step_fn(
[rank27]: ValueError: not enough values to unpack (expected 2, got 1)
[rank25]: Traceback (most recent call last):
[rank25]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank25]:     main()
[rank25]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank25]:     pretrain(neox_args=neox_args)
[rank25]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank25]:     evaluate_and_print_results(
[rank25]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank25]:     total_loss_dict = evaluate(
[rank25]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank25]:     loss, metric_dict = forward_step_fn(
[rank25]: ValueError: not enough values to unpack (expected 2, got 1)
[rank26]: Traceback (most recent call last):
[rank26]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank26]:     main()
[rank26]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank26]:     pretrain(neox_args=neox_args)
[rank26]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank26]:     evaluate_and_print_results(
[rank26]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank26]:     total_loss_dict = evaluate(
[rank26]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank26]:     loss, metric_dict = forward_step_fn(
[rank26]: ValueError: not enough values to unpack (expected 2, got 1)
[rank30]: Traceback (most recent call last):
[rank30]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank30]:     main()
[rank30]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank30]:     pretrain(neox_args=neox_args)
[rank30]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank30]:     evaluate_and_print_results(
[rank30]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank30]:     total_loss_dict = evaluate(
[rank30]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank30]:     loss, metric_dict = forward_step_fn(
[rank30]: ValueError: not enough values to unpack (expected 2, got 1)
[rank28]: Traceback (most recent call last):
[rank28]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank28]:     main()
[rank28]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank28]:     pretrain(neox_args=neox_args)
[rank28]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank28]:     evaluate_and_print_results(
[rank28]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank28]:     total_loss_dict = evaluate(
[rank28]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank28]:     loss, metric_dict = forward_step_fn(
[rank28]: ValueError: not enough values to unpack (expected 2, got 1)
[rank24]: Traceback (most recent call last):
[rank24]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank24]:     main()
[rank24]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank24]:     pretrain(neox_args=neox_args)
[rank24]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank24]:     evaluate_and_print_results(
[rank24]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank24]:     total_loss_dict = evaluate(
[rank24]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank24]:     loss, metric_dict = forward_step_fn(
[rank24]: ValueError: not enough values to unpack (expected 2, got 1)
[rank31]: Traceback (most recent call last):
[rank31]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank31]:     main()
[rank31]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank31]:     pretrain(neox_args=neox_args)
[rank31]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank31]:     evaluate_and_print_results(
[rank31]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank31]:     total_loss_dict = evaluate(
[rank31]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank31]:     loss, metric_dict = forward_step_fn(
[rank31]: ValueError: not enough values to unpack (expected 2, got 1)
[rank44]: Traceback (most recent call last):
[rank44]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank44]:     main()
[rank44]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank44]:     pretrain(neox_args=neox_args)
[rank44]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank44]:     evaluate_and_print_results(
[rank44]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank44]:     total_loss_dict = evaluate(
[rank44]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank44]:     loss, metric_dict = forward_step_fn(
[rank44]: ValueError: not enough values to unpack (expected 2, got 1)
[rank42]: Traceback (most recent call last):
[rank42]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank42]:     main()
[rank42]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank42]:     pretrain(neox_args=neox_args)
[rank42]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank42]:     evaluate_and_print_results(
[rank42]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank42]:     total_loss_dict = evaluate(
[rank42]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank42]:     loss, metric_dict = forward_step_fn(
[rank42]: ValueError: not enough values to unpack (expected 2, got 1)
[rank46]: Traceback (most recent call last):
[rank46]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank46]:     main()
[rank46]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank46]:     pretrain(neox_args=neox_args)
[rank46]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank46]:     evaluate_and_print_results(
[rank46]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank46]:     total_loss_dict = evaluate(
[rank46]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank46]:     loss, metric_dict = forward_step_fn(
[rank46]: ValueError: not enough values to unpack (expected 2, got 1)
[rank40]: Traceback (most recent call last):
[rank40]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank40]:     main()
[rank40]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank40]:     pretrain(neox_args=neox_args)
[rank40]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank40]:     evaluate_and_print_results(
[rank40]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank40]:     total_loss_dict = evaluate(
[rank40]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank40]:     loss, metric_dict = forward_step_fn(
[rank40]: ValueError: not enough values to unpack (expected 2, got 1)
[rank45]: Traceback (most recent call last):
[rank45]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank45]:     main()
[rank45]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank45]:     pretrain(neox_args=neox_args)
[rank45]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank45]:     evaluate_and_print_results(
[rank45]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank45]:     total_loss_dict = evaluate(
[rank45]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank45]:     loss, metric_dict = forward_step_fn(
[rank45]: ValueError: not enough values to unpack (expected 2, got 1)
[rank41]: Traceback (most recent call last):
[rank41]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank41]:     main()
[rank41]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank41]:     pretrain(neox_args=neox_args)
[rank41]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank41]:     evaluate_and_print_results(
[rank41]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank41]:     total_loss_dict = evaluate(
[rank41]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank41]:     loss, metric_dict = forward_step_fn(
[rank41]: ValueError: not enough values to unpack (expected 2, got 1)
[rank47]: Traceback (most recent call last):
[rank47]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank47]:     main()
[rank47]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank47]:     pretrain(neox_args=neox_args)
[rank47]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank47]:     evaluate_and_print_results(
[rank47]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank47]:     total_loss_dict = evaluate(
[rank47]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank47]:     loss, metric_dict = forward_step_fn(
[rank47]: ValueError: not enough values to unpack (expected 2, got 1)
[rank43]: Traceback (most recent call last):
[rank43]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank43]:     main()
[rank43]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank43]:     pretrain(neox_args=neox_args)
[rank43]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank43]:     evaluate_and_print_results(
[rank43]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank43]:     total_loss_dict = evaluate(
[rank43]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank43]:     loss, metric_dict = forward_step_fn(
[rank43]: ValueError: not enough values to unpack (expected 2, got 1)
[rank14]:[W131 15:24:36.762218465 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank58]: Traceback (most recent call last):
[rank58]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank58]:     main()
[rank58]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank58]:     pretrain(neox_args=neox_args)
[rank58]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank58]:     evaluate_and_print_results(
[rank58]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank58]:     total_loss_dict = evaluate(
[rank58]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank58]:     loss, metric_dict = forward_step_fn(
[rank58]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank57]: Traceback (most recent call last):
[rank57]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank57]:     main()
[rank57]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank57]:     pretrain(neox_args=neox_args)
[rank57]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank57]:     evaluate_and_print_results(
[rank57]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank57]:     total_loss_dict = evaluate(
[rank57]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank57]:     loss, metric_dict = forward_step_fn(
[rank57]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank62]: Traceback (most recent call last):
[rank62]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank62]:     main()
[rank62]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank62]:     pretrain(neox_args=neox_args)
[rank62]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank62]:     evaluate_and_print_results(
[rank62]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank62]:     total_loss_dict = evaluate(
[rank62]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank62]:     loss, metric_dict = forward_step_fn(
[rank62]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank56]: Traceback (most recent call last):
[rank56]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank56]:     main()
[rank56]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank56]:     pretrain(neox_args=neox_args)
[rank56]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank56]:     evaluate_and_print_results(
[rank56]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank56]:     total_loss_dict = evaluate(
[rank56]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank56]:     loss, metric_dict = forward_step_fn(
[rank56]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank60]: Traceback (most recent call last):
[rank60]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank60]:     main()
[rank60]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank60]:     pretrain(neox_args=neox_args)
[rank60]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank60]:     evaluate_and_print_results(
[rank60]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank60]:     total_loss_dict = evaluate(
[rank60]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank60]:     loss, metric_dict = forward_step_fn(
[rank60]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank59]: Traceback (most recent call last):
[rank59]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank59]:     main()
[rank59]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank59]:     pretrain(neox_args=neox_args)
[rank59]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank59]:     evaluate_and_print_results(
[rank59]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank59]:     total_loss_dict = evaluate(
[rank59]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank59]:     loss, metric_dict = forward_step_fn(
[rank59]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank63]: Traceback (most recent call last):
[rank63]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank63]:     main()
[rank63]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank63]:     pretrain(neox_args=neox_args)
[rank63]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank63]:     evaluate_and_print_results(
[rank63]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank63]:     total_loss_dict = evaluate(
[rank63]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank63]:     loss, metric_dict = forward_step_fn(
[rank63]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank57]:     raise TypeError("iteration over a 0-d tensor")
[rank57]: TypeError: iteration over a 0-d tensor
[rank61]: Traceback (most recent call last):
[rank61]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank61]:     main()
[rank61]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank61]:     pretrain(neox_args=neox_args)
[rank61]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank61]:     evaluate_and_print_results(
[rank61]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank61]:     total_loss_dict = evaluate(
[rank61]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank61]:     loss, metric_dict = forward_step_fn(
[rank61]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank62]:     raise TypeError("iteration over a 0-d tensor")
[rank62]: TypeError: iteration over a 0-d tensor
[rank56]:     raise TypeError("iteration over a 0-d tensor")
[rank56]: TypeError: iteration over a 0-d tensor
[rank58]:     raise TypeError("iteration over a 0-d tensor")
[rank58]: TypeError: iteration over a 0-d tensor
[rank60]:     raise TypeError("iteration over a 0-d tensor")
[rank60]: TypeError: iteration over a 0-d tensor
[rank59]:     raise TypeError("iteration over a 0-d tensor")
[rank59]: TypeError: iteration over a 0-d tensor
[rank61]:     raise TypeError("iteration over a 0-d tensor")
[rank61]: TypeError: iteration over a 0-d tensor
[rank63]:     raise TypeError("iteration over a 0-d tensor")
[rank63]: TypeError: iteration over a 0-d tensor
[rank15]:[W131 15:24:36.929376022 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank10]:[W131 15:24:36.350109747 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank43]:[W131 15:24:36.115698174 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank62]:[W131 15:24:37.006070567 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank11]:[W131 15:24:37.984597838 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank29]:[W131 15:24:37.033404620 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank46]:[W131 15:24:37.209301086 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank8]:[W131 15:24:37.097182133 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank25]:[W131 15:24:37.109967571 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank61]:[W131 15:24:37.155556550 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank12]:[W131 15:24:37.516460693 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank26]:[W131 15:24:37.484693277 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank31]:[W131 15:24:37.508624890 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank56]:[W131 15:24:37.409920953 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank30]:[W131 15:24:37.572764955 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank57]:[W131 15:24:37.771721208 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank58]:[W131 15:24:37.997372488 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank42]:[W131 15:24:37.257585279 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank47]:[W131 15:24:37.254200777 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank60]:[W131 15:24:37.652674930 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank45]:[W131 15:24:37.923371166 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank28]:[W131 15:24:37.606178039 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank9]:[W131 15:24:37.347144920 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank13]:[W131 15:24:37.606160866 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank41]:[W131 15:24:37.439426423 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank44]:[W131 15:24:37.146882209 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank27]:[W131 15:24:37.510747452 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank59]:[W131 15:24:37.585235369 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank40]:[W131 15:24:37.016620262 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank24]:[W131 15:24:37.761465800 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank0]: Traceback (most recent call last):
[rank0]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank0]:     main()
[rank0]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank0]:     pretrain(neox_args=neox_args)
[rank0]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank0]:     evaluate_and_print_results(
[rank0]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank0]:     total_loss_dict = evaluate(
[rank0]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank0]:     loss, metric_dict = forward_step_fn(
[rank0]: ValueError: not enough values to unpack (expected 2, got 1)
[rank7]: Traceback (most recent call last):
[rank7]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank7]:     main()
[rank7]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank7]:     pretrain(neox_args=neox_args)
[rank7]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank7]:     evaluate_and_print_results(
[rank7]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank7]:     total_loss_dict = evaluate(
[rank7]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank7]:     loss, metric_dict = forward_step_fn(
[rank7]: ValueError: not enough values to unpack (expected 2, got 1)
[rank6]: Traceback (most recent call last):
[rank6]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank6]:     main()
[rank6]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank6]:     pretrain(neox_args=neox_args)
[rank6]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank6]:     evaluate_and_print_results(
[rank6]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank6]:     total_loss_dict = evaluate(
[rank6]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank6]:     loss, metric_dict = forward_step_fn(
[rank6]: ValueError: not enough values to unpack (expected 2, got 1)
[rank4]: Traceback (most recent call last):
[rank4]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank4]:     main()
[rank4]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank4]:     pretrain(neox_args=neox_args)
[rank4]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank4]:     evaluate_and_print_results(
[rank4]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank4]:     total_loss_dict = evaluate(
[rank4]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank4]:     loss, metric_dict = forward_step_fn(
[rank4]: ValueError: not enough values to unpack (expected 2, got 1)
[rank2]: Traceback (most recent call last):
[rank2]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank2]:     main()
[rank2]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank2]:     pretrain(neox_args=neox_args)
[rank2]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank2]:     evaluate_and_print_results(
[rank2]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank2]:     total_loss_dict = evaluate(
[rank2]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank2]:     loss, metric_dict = forward_step_fn(
[rank2]: ValueError: not enough values to unpack (expected 2, got 1)
[rank1]: Traceback (most recent call last):
[rank1]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank1]:     main()
[rank1]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank1]:     pretrain(neox_args=neox_args)
[rank1]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank1]:     evaluate_and_print_results(
[rank1]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank1]:     total_loss_dict = evaluate(
[rank1]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank1]:     loss, metric_dict = forward_step_fn(
[rank1]: ValueError: not enough values to unpack (expected 2, got 1)
[rank5]: Traceback (most recent call last):
[rank5]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank5]:     main()
[rank5]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank5]:     pretrain(neox_args=neox_args)
[rank5]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank5]:     evaluate_and_print_results(
[rank5]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank5]:     total_loss_dict = evaluate(
[rank5]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank5]:     loss, metric_dict = forward_step_fn(
[rank5]: ValueError: not enough values to unpack (expected 2, got 1)
[rank3]: Traceback (most recent call last):
[rank3]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank3]:     main()
[rank3]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank3]:     pretrain(neox_args=neox_args)
[rank3]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank3]:     evaluate_and_print_results(
[rank3]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank3]:     total_loss_dict = evaluate(
[rank3]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank3]:     loss, metric_dict = forward_step_fn(
[rank3]: ValueError: not enough values to unpack (expected 2, got 1)
[rank16]: Traceback (most recent call last):
[rank16]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank16]:     main()
[rank16]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank16]:     pretrain(neox_args=neox_args)
[rank16]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank16]:     evaluate_and_print_results(
[rank16]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank16]:     total_loss_dict = evaluate(
[rank16]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank16]:     loss, metric_dict = forward_step_fn(
[rank16]: ValueError: not enough values to unpack (expected 2, got 1)
[rank18]: Traceback (most recent call last):
[rank18]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank18]:     main()
[rank18]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank18]:     pretrain(neox_args=neox_args)
[rank18]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank18]:     evaluate_and_print_results(
[rank18]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank18]:     total_loss_dict = evaluate(
[rank18]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank18]:     loss, metric_dict = forward_step_fn(
[rank18]: ValueError: not enough values to unpack (expected 2, got 1)
[rank17]: Traceback (most recent call last):
[rank17]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank17]:     main()
[rank17]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank17]:     pretrain(neox_args=neox_args)
[rank17]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank17]:     evaluate_and_print_results(
[rank17]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank17]:     total_loss_dict = evaluate(
[rank17]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank17]:     loss, metric_dict = forward_step_fn(
[rank17]: ValueError: not enough values to unpack (expected 2, got 1)
[rank21]: Traceback (most recent call last):
[rank21]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank21]:     main()
[rank21]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank21]:     pretrain(neox_args=neox_args)
[rank21]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank21]:     evaluate_and_print_results(
[rank21]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank21]:     total_loss_dict = evaluate(
[rank21]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank21]:     loss, metric_dict = forward_step_fn(
[rank21]: ValueError: not enough values to unpack (expected 2, got 1)
[rank20]: Traceback (most recent call last):
[rank20]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank20]:     main()
[rank20]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank20]:     pretrain(neox_args=neox_args)
[rank20]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank20]:     evaluate_and_print_results(
[rank20]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank20]:     total_loss_dict = evaluate(
[rank20]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank20]:     loss, metric_dict = forward_step_fn(
[rank20]: ValueError: not enough values to unpack (expected 2, got 1)
[rank23]: Traceback (most recent call last):
[rank23]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank23]:     main()
[rank23]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank23]:     pretrain(neox_args=neox_args)
[rank23]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank23]:     evaluate_and_print_results(
[rank23]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank23]:     total_loss_dict = evaluate(
[rank23]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank23]:     loss, metric_dict = forward_step_fn(
[rank23]: ValueError: not enough values to unpack (expected 2, got 1)
[rank19]: Traceback (most recent call last):
[rank19]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank19]:     main()
[rank19]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank19]:     pretrain(neox_args=neox_args)
[rank19]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank19]:     evaluate_and_print_results(
[rank19]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank19]:     total_loss_dict = evaluate(
[rank19]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank19]:     loss, metric_dict = forward_step_fn(
[rank19]: ValueError: not enough values to unpack (expected 2, got 1)
[rank22]: Traceback (most recent call last):
[rank22]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank22]:     main()
[rank22]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank22]:     pretrain(neox_args=neox_args)
[rank22]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank22]:     evaluate_and_print_results(
[rank22]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank22]:     total_loss_dict = evaluate(
[rank22]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank22]:     loss, metric_dict = forward_step_fn(
[rank22]: ValueError: not enough values to unpack (expected 2, got 1)
[rank5]:[W131 15:24:38.958758538 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank34]: Traceback (most recent call last):
[rank34]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank34]:     main()
[rank34]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank34]:     pretrain(neox_args=neox_args)
[rank34]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank34]:     evaluate_and_print_results(
[rank34]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank34]:     total_loss_dict = evaluate(
[rank34]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank34]:     loss, metric_dict = forward_step_fn(
[rank34]: ValueError: not enough values to unpack (expected 2, got 1)
[rank32]: Traceback (most recent call last):
[rank32]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank32]:     main()
[rank32]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank32]:     pretrain(neox_args=neox_args)
[rank32]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank32]:     evaluate_and_print_results(
[rank32]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank32]:     total_loss_dict = evaluate(
[rank32]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank32]:     loss, metric_dict = forward_step_fn(
[rank32]: ValueError: not enough values to unpack (expected 2, got 1)
[rank33]: Traceback (most recent call last):
[rank33]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank33]:     main()
[rank33]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank33]:     pretrain(neox_args=neox_args)
[rank33]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank33]:     evaluate_and_print_results(
[rank33]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank33]:     total_loss_dict = evaluate(
[rank33]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank33]:     loss, metric_dict = forward_step_fn(
[rank33]: ValueError: not enough values to unpack (expected 2, got 1)
[rank4]:[W131 15:24:39.491740536 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank18]:[W131 15:24:39.516240440 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank7]:[W131 15:24:39.080980800 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank63]:[W131 15:24:39.309922936 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank21]:[W131 15:24:39.196249288 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank3]:[W131 15:24:39.204314668 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank17]:[W131 15:24:39.854383200 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank1]:[W131 15:24:39.200115700 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank34]:[W131 15:24:39.204710659 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank6]:[W131 15:24:39.242281394 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank19]:[W131 15:24:39.291860293 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank32]:[W131 15:24:39.610983516 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank33]:[W131 15:24:39.693251403 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank22]:[W131 15:24:39.351888413 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank20]:[W131 15:24:39.397982826 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank2]:[W131 15:24:39.419417321 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank23]:[W131 15:24:39.608864261 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank36]: Traceback (most recent call last):
[rank36]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank36]:     main()
[rank36]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank36]:     pretrain(neox_args=neox_args)
[rank36]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank36]:     evaluate_and_print_results(
[rank36]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank36]:     total_loss_dict = evaluate(
[rank36]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank36]:     loss, metric_dict = forward_step_fn(
[rank36]: ValueError: not enough values to unpack (expected 2, got 1)
[rank37]: Traceback (most recent call last):
[rank37]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank37]:     main()
[rank37]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank37]:     pretrain(neox_args=neox_args)
[rank37]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank37]:     evaluate_and_print_results(
[rank37]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank37]:     total_loss_dict = evaluate(
[rank37]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank37]:     loss, metric_dict = forward_step_fn(
[rank37]: ValueError: not enough values to unpack (expected 2, got 1)
[rank35]: Traceback (most recent call last):
[rank35]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank35]:     main()
[rank35]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank35]:     pretrain(neox_args=neox_args)
[rank35]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank35]:     evaluate_and_print_results(
[rank35]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank35]:     total_loss_dict = evaluate(
[rank35]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank35]:     loss, metric_dict = forward_step_fn(
[rank35]: ValueError: not enough values to unpack (expected 2, got 1)
[rank38]: Traceback (most recent call last):
[rank38]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank38]:     main()
[rank38]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank38]:     pretrain(neox_args=neox_args)
[rank38]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank38]:     evaluate_and_print_results(
[rank38]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank38]:     total_loss_dict = evaluate(
[rank38]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank38]:     loss, metric_dict = forward_step_fn(
[rank38]: ValueError: not enough values to unpack (expected 2, got 1)
[rank39]: Traceback (most recent call last):
[rank39]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank39]:     main()
[rank39]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank39]:     pretrain(neox_args=neox_args)
[rank39]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank39]:     evaluate_and_print_results(
[rank39]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank39]:     total_loss_dict = evaluate(
[rank39]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank39]:     loss, metric_dict = forward_step_fn(
[rank39]: ValueError: not enough values to unpack (expected 2, got 1)
[rank53]: Traceback (most recent call last):
[rank53]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank53]:     main()
[rank53]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank53]:     pretrain(neox_args=neox_args)
[rank53]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank53]:     evaluate_and_print_results(
[rank53]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank53]:     total_loss_dict = evaluate(
[rank53]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank53]:     loss, metric_dict = forward_step_fn(
[rank53]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank54]: Traceback (most recent call last):
[rank54]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank54]:     main()
[rank54]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank54]:     pretrain(neox_args=neox_args)
[rank54]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank54]:     evaluate_and_print_results(
[rank54]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank54]:     total_loss_dict = evaluate(
[rank54]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank54]:     loss, metric_dict = forward_step_fn(
[rank54]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank49]: Traceback (most recent call last):
[rank49]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank49]:     main()
[rank49]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank49]:     pretrain(neox_args=neox_args)
[rank49]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank49]:     evaluate_and_print_results(
[rank49]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank49]:     total_loss_dict = evaluate(
[rank49]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank49]:     loss, metric_dict = forward_step_fn(
[rank49]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank53]:     raise TypeError("iteration over a 0-d tensor")
[rank53]: TypeError: iteration over a 0-d tensor
[rank54]:     raise TypeError("iteration over a 0-d tensor")
[rank54]: TypeError: iteration over a 0-d tensor
[rank50]: Traceback (most recent call last):
[rank50]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank50]:     main()
[rank50]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank50]:     pretrain(neox_args=neox_args)
[rank50]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank50]:     evaluate_and_print_results(
[rank50]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank50]:     total_loss_dict = evaluate(
[rank50]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank50]:     loss, metric_dict = forward_step_fn(
[rank50]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank49]:     raise TypeError("iteration over a 0-d tensor")
[rank49]: TypeError: iteration over a 0-d tensor
[rank52]: Traceback (most recent call last):
[rank52]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank52]:     main()
[rank52]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank52]:     pretrain(neox_args=neox_args)
[rank52]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank52]:     evaluate_and_print_results(
[rank52]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank52]:     total_loss_dict = evaluate(
[rank52]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank52]:     loss, metric_dict = forward_step_fn(
[rank52]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank51]: Traceback (most recent call last):
[rank51]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank51]:     main()
[rank51]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank51]:     pretrain(neox_args=neox_args)
[rank51]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank51]:     evaluate_and_print_results(
[rank51]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank51]:     total_loss_dict = evaluate(
[rank51]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank51]:     loss, metric_dict = forward_step_fn(
[rank51]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank55]: Traceback (most recent call last):
[rank55]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank55]:     main()
[rank55]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank55]:     pretrain(neox_args=neox_args)
[rank55]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank55]:     evaluate_and_print_results(
[rank55]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank55]:     total_loss_dict = evaluate(
[rank55]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank55]:     loss, metric_dict = forward_step_fn(
[rank55]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank50]:     raise TypeError("iteration over a 0-d tensor")
[rank50]: TypeError: iteration over a 0-d tensor
[rank52]:     raise TypeError("iteration over a 0-d tensor")
[rank52]: TypeError: iteration over a 0-d tensor
[rank55]:     raise TypeError("iteration over a 0-d tensor")
[rank55]: TypeError: iteration over a 0-d tensor
[rank51]:     raise TypeError("iteration over a 0-d tensor")
[rank51]: TypeError: iteration over a 0-d tensor
[rank48]: Traceback (most recent call last):
[rank48]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank48]:     main()
[rank48]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank48]:     pretrain(neox_args=neox_args)
[rank48]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank48]:     evaluate_and_print_results(
[rank48]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank48]:     total_loss_dict = evaluate(
[rank48]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank48]:     loss, metric_dict = forward_step_fn(
[rank48]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank48]:     raise TypeError("iteration over a 0-d tensor")
[rank48]: TypeError: iteration over a 0-d tensor
[rank39]:[W131 15:24:40.609733625 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank37]:[W131 15:24:40.219483436 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank50]:[W131 15:24:40.166518408 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank53]:[W131 15:24:40.002083693 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank49]:[W131 15:24:40.233626497 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank38]:[W131 15:24:40.516945229 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank54]:[W131 15:24:40.637768880 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank36]:[W131 15:24:40.323693155 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank48]:[W131 15:24:40.370780992 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank35]:[W131 15:24:40.730091194 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank55]:[W131 15:24:40.435817933 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank52]:[W131 15:24:40.519611063 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank51]:[W131 15:24:40.557690929 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank0]:[W131 15:24:41.758308830 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank16]:[W131 15:24:41.745218775 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
srun: error: c637-132: task 50: Exited with exit code 1
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
srun: error: c636-052: task 6: Exited with exit code 1
srun: error: c637-152: task 54: Exited with exit code 1
srun: error: c637-131: task 49: Exited with exit code 1
srun: error: c637-151: task 53: Exited with exit code 1
srun: error: c636-051: task 5: Exited with exit code 1
srun: error: c636-071: task 9: Exited with exit code 1
srun: error: c636-032: task 2: Exited with exit code 1
srun: error: c636-042: task 4: Exited with exit code 1
srun: error: c636-041: task 3: Exited with exit code 1
srun: error: c637-141: task 51: Exited with exit code 1
srun: error: c636-031: task 1: Exited with exit code 1
srun: error: c637-142: task 52: Exited with exit code 1
srun: error: c637-091: task 45: Exited with exit code 1
srun: error: c636-062: task 8: Exited with exit code 1
srun: error: c636-061: task 7: Exited with exit code 1
srun: error: c637-092: task 46: Exited with exit code 1
srun: error: c637-071: task 41: Exited with exit code 1
srun: error: c637-072: task 42: Exited with exit code 1
srun: error: c637-022: task 32: Exited with exit code 1
srun: error: c637-042: task 36: Exited with exit code 1
srun: error: c637-062: task 40: Exited with exit code 1
srun: error: c637-041: task 35: Exited with exit code 1
srun: error: c637-101: task 47: Exited with exit code 1
srun: error: c637-081: task 43: Exited with exit code 1
srun: error: c638-032: task 62: Exited with exit code 1
srun: error: c636-082: task 12: Exited with exit code 1
srun: error: c638-021: task 59: Exited with exit code 1
srun: error: c636-131: task 21: Exited with exit code 1
srun: error: c638-002: task 56: Exited with exit code 1
srun: error: c637-012: task 30: Exited with exit code 1
srun: error: c636-101: task 15: Exited with exit code 1
srun: error: c637-052: task 38: Exited with exit code 1
srun: error: c636-112: task 18: Exited with exit code 1
srun: error: c637-001: task 27: Exited with exit code 1
srun: error: c638-012: task 58: Exited with exit code 1
srun: error: c638-041: task 63: Exited with exit code 1
srun: error: c637-031: task 33: Exited with exit code 1
srun: error: c638-011: task 57: Exited with exit code 1
srun: error: c636-072: task 10: Exited with exit code 1
srun: error: c637-082: task 44: Exited with exit code 1
srun: error: c636-081: task 11: Exited with exit code 1
srun: error: c636-141: task 23: Exited with exit code 1
srun: error: c638-022: task 60: Exited with exit code 1
srun: error: c636-152: task 26: Exited with exit code 1
srun: error: c636-092: task 14: Exited with exit code 1
srun: error: c636-111: task 17: Exited with exit code 1
srun: error: c636-142: task 24: Exited with exit code 1
srun: error: c637-032: task 34: Exited with exit code 1
srun: error: c637-021: task 31: Exited with exit code 1
srun: error: c636-121: task 19: Exited with exit code 1
srun: error: c637-011: task 29: Exited with exit code 1
srun: error: c637-061: task 39: Exited with exit code 1
srun: error: c638-001: task 55: Exited with exit code 1
srun: error: c636-151: task 25: Exited with exit code 1
srun: error: c638-031: task 61: Exited with exit code 1
srun: error: c636-132: task 22: Exited with exit code 1
srun: error: c637-002: task 28: Exited with exit code 1
srun: error: c636-091: task 13: Exited with exit code 1
srun: error: c637-102: task 48: Exited with exit code 1
srun: error: c637-051: task 37: Exited with exit code 1
srun: error: c636-122: task 20: Exited with exit code 1
srun: error: c636-102: task 16: Exited with exit code 1
srun: error: c636-022: task 0: Exited with exit code 1
