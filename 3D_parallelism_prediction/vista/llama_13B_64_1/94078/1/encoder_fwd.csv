cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
aten::clone,425649,"[[5242880], []]",aten::copy_,425651,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),425651,0,9.568997727272734
aten::to,425654,"[[], [], [], [], [], []]",aten::copy_,425657,"[[], [], []]",Memcpy HtoD (Pageable -> Device),425657,32599.706217447918,0.76228863636363
aten::linalg_vector_norm,425661,"[[2048, 4, 5120], [], [], [], []]",aten::linalg_vector_norm,425661,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",425661,21122.6123046875,33.36033409090908
aten::mul,425662,"[[2048, 4, 1], []]",aten::mul,425662,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",425662,699.5655924479166,1.4130090909090864
aten::add,425663,"[[2048, 4, 1], [], []]",aten::add,425663,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",425663,7360.007486979167,1.336097727272732
aten::div,425664,"[[2048, 4, 5120], [2048, 4, 1]]",aten::div,425664,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",425664,6183.066569010417,114.15914090909095
aten::mul,425665,"[[5120], [2048, 4, 5120]]",aten::mul,425665,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",425665,615.1969401041666,109.90613068181824
aten::linear,425670,"[[2048, 4, 5120], [1920, 5120], []]",aten::mm,425677,"[[8192, 5120], [5120, 1920]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,425677,1127.3162434895833,211.61400227272733
aten::to,425690,"[[2048, 1, 1, 128], [], [], [], [], [], [], []]",aten::copy_,425693,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),425693,1332.9720052083333,4.289998863636365
aten::to,425694,"[[2048, 1, 1, 128], [], [], [], [], [], [], []]",aten::copy_,425697,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),425697,12503.80419921875,4.1845784090909115
None,None,None,None,None,None,kernel_0,425707,33779.008463541664,6.950588636363649
None,None,None,None,None,None,kernel_1,425715,8509.3623046875,9.556500000000007
None,None,None,None,None,None,kernel_0,425725,14508.184895833334,7.0128261363636515
None,None,None,None,None,None,kernel_1,425733,7311.746744791667,9.573999999999991
aten::baddbmm,425748,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",aten::baddbmm,425748,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,425748,37764.86083984375,67.09360454545464
ScaledUpperTriangMaskedSoftmax,425751,"[[20, 2048, 2048], []]",ScaledUpperTriangMaskedSoftmax,425751,"[[20, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",425751,19381.082356770832,109.60493636363654
aten::bmm,425768,"[[20, 2048, 2048], [20, 2048, 128]]",aten::bmm,425768,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,425768,25674.876139322918,65.40074659090912
aten::contiguous,425772,"[[2048, 4, 5, 128], []]",aten::copy_,425776,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",425776,4491.324381510417,15.300352272727284
aten::linear,425778,"[[2048, 4, 640], [5120, 640], []]",aten::mm,425785,"[[8192, 640], [640, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,425785,28102.481608072918,73.10437272727265
_ReduceFromModelParallelRegion,425787,"[[2048, 4, 5120]]",nccl:all_reduce,425790,"[[2048, 4, 5120]]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",425789,14181.084635416666,3102.1572602272727
aten::add,425795,"[[2048, 4, 5120], [2048, 4, 5120], []]",aten::add,425795,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",425795,453.1695963541667,71.5524272727273
aten::linalg_vector_norm,425796,"[[2048, 4, 5120], [], [], [], []]",aten::linalg_vector_norm,425796,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",425796,413.1064453125,33.977413636363586
aten::mul,425797,"[[2048, 4, 1], []]",aten::mul,425797,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",425797,423.7307942708333,1.5972909090909024
aten::add,425798,"[[2048, 4, 1], [], []]",aten::add,425798,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",425798,323.57275390625,1.3400931818181836
aten::div,425799,"[[2048, 4, 5120], [2048, 4, 1]]",aten::div,425799,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",425799,319.1389973958333,113.16103295454555
aten::mul,425800,"[[5120], [2048, 4, 5120]]",aten::mul,425800,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",425800,460.16455078125,109.28413636363624
aten::to,425803,"[[], [], [], [], [], []]",aten::copy_,425806,"[[], [], []]",Memcpy HtoD (Pageable -> Device),425806,244.53483072916666,0.7478136363636273
aten::linear,425813,"[[2048, 4, 5120], [2560, 5120], []]",aten::mm,425820,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,425820,43450.840006510414,269.07248636363636
aten::add,425822,"[[2048, 4, 2560], [2560], []]",aten::add,425822,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",425822,531.1653645833334,55.89771818181818
aten::gelu,425823,"[[2048, 4, 2560], []]",aten::gelu,425823,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",425823,416.3968098958333,35.8956613636364
aten::linear,425824,"[[2048, 4, 2560], [5120, 2560], []]",aten::mm,425831,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,425831,959.4308268229166,262.64977045454555
_ReduceFromModelParallelRegion,425833,"[[2048, 4, 5120]]",record_param_comms,425835,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",425835,788.32080078125,3117.129948863636
aten::add,425843,"[[2048, 4, 5120], [2048, 4, 5120], []]",aten::add,425843,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",425843,451.7107747395833,108.47421704545461
aten::add,425845,"[[2048, 4, 5120], [2048, 4, 5120], []]",aten::add,425845,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",425845,414.66015625,70.05082840909084
