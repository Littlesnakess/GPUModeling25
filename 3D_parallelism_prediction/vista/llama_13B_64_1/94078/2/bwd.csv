cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
aten::ones_like,324302,"[[], [], [], [], [], []]",aten::fill_,324305,"[[], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)",324305,0,0.9591466666666664
autograd::engine::evaluate_function: MulBackward0,322275,,aten::mul,322277,"[[], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",322277,2850.18994140625,1.273173333333333
autograd::engine::evaluate_function: DivBackward0,322278,,aten::div,322280,"[[], []]","void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",322280,1140.06884765625,1.2787066666666662
autograd::engine::evaluate_function: DivBackward0,322281,,aten::div,322283,"[[], []]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::DivFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::DivFunctor<float> >, std::array<char*, 3ul>)",322283,924.2586263020834,1.4216399999999998
autograd::engine::evaluate_function: MulBackward0,322288,,aten::mul,322290,"[[8192], [8192]]","void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",322290,1745.2599283854167,2.2331600000000007
autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward,322295,,aten::arange,322300,"[[], [], [], [0]]","void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)",322300,3028.10546875,1.1622399999999997
autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward,322295,,aten::index,322302,"[[8192, 6400], []]","void at::native::index_elementwise_kernel<128, 4, at::native::gpu_index_kernel<at::native::index_kernel_impl<at::native::OpaqueType<4> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1}>(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>, at::native::index_kernel_impl<at::native::OpaqueType<4> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1} const&)::{lambda(int)#1}>(long, at::native::gpu_index_kernel<at::native::index_kernel_impl<at::native::OpaqueType<4> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1}>(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>, at::native::index_kernel_impl<at::native::OpaqueType<4> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1} const&)::{lambda(int)#1})",322302,1225.9265950520833,8.187640000000002
autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward,322295,,aten::copy_,322312,"[[8192], [8192], []]","void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, std::array<char*, 2ul>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1> >(int, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, std::array<char*, 2ul>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1>)",322312,1086.64599609375,3.563506666666667
autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward,322295,,aten::sub,322314,"[[], [8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnOther_add<float>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnOther_add<float>, std::array<char*, 2ul>)",322314,1008.4158528645834,1.3746933333333338
autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward,322295,,aten::sub_,322315,"[[8192], [8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",322315,613.5685221354166,1.4075733333333336
autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward,322295,,aten::_index_put_impl_,322317,"[[8192, 6400], [], [8192], [], []]","void at::native::index_elementwise_kernel<128, 4, at::native::gpu_index_kernel<at::native::index_put_kernel_impl<at::native::OpaqueType<4> >(at::TensorIterator&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1}>(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>, at::native::index_put_kernel_impl<at::native::OpaqueType<4> >(at::TensorIterator&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1} const&)::{lambda(int)#1}>(long, at::native::gpu_index_kernel<at::native::index_put_kernel_impl<at::native::OpaqueType<4> >(at::TensorIterator&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1}>(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>, at::native::index_put_kernel_impl<at::native::OpaqueType<4> >(at::TensorIterator&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1} const&)::{lambda(int)#1})",322317,1383.8131510416667,5.416853333333331
autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward,322295,,aten::mul_,322325,"[[4, 2048, 6400], [4, 2048, 1]]","void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",322325,909.1612955729166,167.81689333333333
autograd::engine::evaluate_function: ToCopyBackward0,322326,,aten::copy_,322331,"[[4, 2048, 6400], [4, 2048, 6400], []]","void at::native::vectorized_elementwise_kernel<4, at::native::float16_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda(float)#1}, std::array<char*, 2ul> >(int, at::native::float16_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda(float)#1}, std::array<char*, 2ul>)",322331,75.8505859375,90.01074666666665
autograd::engine::evaluate_function: MmBackward0,322336,,aten::mm,322341,"[[6400, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,322341,138.95393880208334,627.7716133333333
autograd::engine::evaluate_function: MmBackward0,322336,,aten::mm,322348,"[[8192, 6400], [6400, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,322348,105.78059895833333,621.30608
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,322358,,aten::add_,322360,"[[6400, 5120], [6400, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",322360,39.923665364583336,50.97674666666666
autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward,322361,,record_param_comms,322364,"[[[4, 2048, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",322364,53.013346354166664,3100.9828666666676
autograd::engine::evaluate_function: MulBackward0,322367,,aten::mul,322369,"[[4, 2048, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",322369,36.958658854166664,108.20362666666668
autograd::engine::evaluate_function: MulBackward0,322367,,aten::mul,322370,"[[4, 2048, 5120], [4, 2048, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",322370,42.388671875,70.10910666666669
autograd::engine::evaluate_function: MulBackward0,322367,,aten::sum,322371,"[[4, 2048, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",322371,104.83089192708333,41.31149333333333
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,322373,,aten::add_,322375,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",322375,39.47607421875,1.8056266666666658
autograd::engine::evaluate_function: DivBackward0,322376,,aten::neg,322378,"[[4, 2048, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",322378,38.67626953125,51.763533333333335
autograd::engine::evaluate_function: DivBackward0,322376,,aten::div,322379,"[[4, 2048, 5120], [4, 2048, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",322379,46.539713541666664,117.02992
autograd::engine::evaluate_function: DivBackward0,322376,,aten::div,322380,"[[4, 2048, 5120], [4, 2048, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",322380,47.253092447916664,116.53930666666672
autograd::engine::evaluate_function: DivBackward0,322376,,aten::mul,322381,"[[4, 2048, 5120], [4, 2048, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",322381,47.029622395833336,70.15644
autograd::engine::evaluate_function: DivBackward0,322376,,aten::div,322382,"[[4, 2048, 5120], [4, 2048, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",322382,46.23779296875,117.82493333333335
autograd::engine::evaluate_function: DivBackward0,322376,,aten::sum,322383,"[[4, 2048, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",322383,47.048665364583336,36.57349333333333
autograd::engine::evaluate_function: MulBackward0,322386,,aten::mul,322388,"[[4, 2048, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",322388,48.096028645833336,1.5875866666666663
autograd::engine::evaluate_function: LinalgVectorNormBackward0,322389,,aten::div,322391,"[[4, 2048, 5120], [4, 2048, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",322391,36.000651041666664,114.01388000000004
autograd::engine::evaluate_function: LinalgVectorNormBackward0,322389,,aten::eq,322392,"[[4, 2048, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",322392,47.01806640625,1.8470399999999996
autograd::engine::evaluate_function: LinalgVectorNormBackward0,322389,,aten::masked_fill_,322393,"[[4, 2048, 5120], [4, 2048, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",322393,36.07470703125,119.19570666666667
autograd::engine::evaluate_function: LinalgVectorNormBackward0,322389,,aten::mul,322396,"[[4, 2048, 1], [4, 2048, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",322396,47.071940104166664,110.31345333333333
autograd::engine::evaluate_function: LinalgVectorNormBackward0,322389,,aten::add_,322397,"[[4, 2048, 5120], [4, 2048, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",322397,47.338216145833336,68.56968
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::fill_,322409,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",322409,38.623046875,2.806573333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::fill_,322413,"[[41943040], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",322413,1865.6116536458333,26.233346666666677
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,322438,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),322438,2478.3194986979165,8.8242
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,record_param_comms,322440,"[[[5242880]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",322440,3176.6482747395835,1585.2478133333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,322453,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),322453,35.497395833333336,7.454200000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,322456,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),322456,27.4345703125,8.774319999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,322459,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),322459,27.210286458333332,10.297426666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,322462,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),322462,27.006998697916668,10.306000000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,322465,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),322465,27.019694010416668,10.07308
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,322468,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),322468,27.144856770833332,9.922466666666658
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,322471,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),322471,27.178385416666668,9.940839999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,322474,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),322474,27.20947265625,9.929333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,322491,"[[], [], []]",Memcpy HtoD (Pageable -> Device),322491,20.853515625,0.7466533333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::linalg_vector_norm,322495,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",322495,2364.5183919270835,33.822666666666656
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,322496,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",322496,302.43994140625,1.4340000000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add,322497,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",322497,759.8427734375,1.4084266666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::div,322498,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",322498,681.357421875,113.39509333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,322499,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",322499,39.359700520833336,109.76646666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mm,322511,"[[8192, 5120], [5120, 1920]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,322511,231.11165364583334,211.5949866666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,322527,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),322527,141.56754557291666,3.92616
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,322531,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),322531,1091.2596028645833,3.8770799999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::neg,322541,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",322541,2838.24462890625,8.55452
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::cat,322553,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",322553,1636.7693684895833,25.736759999999997
None,None,None,None,None,None,kernel_1,322554,679.4601236979166,9.83664
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::neg,324612,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",324612,1467.3854166666667,9.918639999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::cat,324623,"[[2048, 4, 5, 128], [[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",324623,1338.94873046875,26.314853333333335
None,None,None,None,None,None,kernel_1,324624,589.73388671875,9.919506666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::baddbmm,324639,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,324639,4122.087727864583,67.50129333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,ScaledUpperTriangMaskedSoftmax,324642,"[[20, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",324642,2217.7996419270835,109.58389333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::bmm,324659,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,324659,3075.64697265625,65.41490666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,324667,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",324667,789.63623046875,14.954039999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mm,324676,"[[8192, 640], [640, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,324676,2861.5662434895835,73.53822666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,record_param_comms,324680,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",324680,1562.17138671875,3094.018386666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add,324686,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",324686,37.609700520833336,71.46841333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::linalg_vector_norm,324687,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",324687,38.324869791666664,33.888933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,324688,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",324688,40.170572916666664,1.615346666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add,324689,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",324689,30.998046875,1.4041599999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::div,324690,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",324690,30.74951171875,113.43351999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,324691,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",324691,41.802571614583336,109.54375999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,324697,"[[], [], []]",Memcpy HtoD (Pageable -> Device),324697,23.029134114583332,0.7436799999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mm,324711,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,324711,4272.966796875,269.57611999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add,324713,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",324713,48.7890625,56.01007999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::gelu,324714,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",324714,42.485514322916664,35.9424
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mm,324722,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,324722,86.38785807291667,262.67871999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,record_param_comms,324726,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",324726,56.564290364583336,3110.9236533333324
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add,324734,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",324734,37.833821614583336,108.71689333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add,324736,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",324736,42.730143229166664,70.15174666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::sum,324743,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",324743,97.42838541666667,42.466120000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,324747,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",324747,39.456217447916664,1.815466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,324756,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",324756,31.050944010416668,106.95607999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mm,324763,"[[5120, 8192], [8192, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,324763,97.5859375,284.2251466666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mm,324770,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,324770,100.99088541666667,265.2464266666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,324782,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",324782,47.454427083333336,19.84743999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::gelu_backward,324785,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul>)",324785,39.872233072916664,47.03356000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::sum,324788,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",324788,100.86295572916667,28.836746666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,324792,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",324792,33.769856770833336,1.5671066666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mm,324802,"[[2560, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,324802,103.35579427083333,284.81696000000017
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mm,324809,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,324809,102.900390625,258.4568666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,324821,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",324821,44.5634765625,20.781439999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,record_param_comms,324825,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",324825,61.053548177083336,3121.761266666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,324830,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",324830,36.85400390625,108.14988000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,324831,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",324831,38.9443359375,70.00578666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::sum,324832,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",324832,106.88932291666667,41.07992000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,324836,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",324836,48.128092447916664,1.819693333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::neg,324839,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",324839,34.443196614583336,51.73828
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::div,324840,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",324840,42.677571614583336,117.02959999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::div,324841,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",324841,39.4228515625,116.54185333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,324842,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",324842,38.91162109375,69.99389333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::div,324843,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",324843,38.4755859375,118.27789333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::sum,324844,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",324844,44.074381510416664,36.31070666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add,324845,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",324845,47.859700520833336,126.13961333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,324850,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",324850,47.317545572916664,1.8423333333333327
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::div,324853,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",324853,34.036458333333336,115.62065333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::eq,324854,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",324854,42.21923828125,1.865386666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::masked_fill_,324855,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",324855,30.804850260416668,119.22864000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,324858,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",324858,38.153645833333336,110.33734666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,324859,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",324859,38.325520833333336,141.70977333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,324870,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",324870,43.840657552083336,110.29557333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mm,324877,"[[5120, 8192], [8192, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,324877,44.630533854166664,84.89930666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mm,324884,"[[8192, 5120], [5120, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,324884,121.58740234375,79.98248
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,324896,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",324896,44.533040364583336,6.653800000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::bmm,324915,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,324915,107.35986328125,59.25345333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::bmm,324918,"[[20, 2048, 128], [20, 128, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,324918,107.94563802083333,68.20366666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,ScaledUpperTriangMaskedSoftmaxBackward,324936,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",324936,39.764973958333336,178.1975466666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::bmm,324953,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,324953,106.94156901041667,64.70246666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,324955,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",324955,39.712890625,8.193186666666671
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::bmm,324958,"[[20, 128, 2048], [20, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,324958,106.8984375,59.98997333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,324960,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",324960,47.487630208333336,8.149719999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,324984,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",324984,38.962565104166664,32.650706666666686
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,324988,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",324988,33.397135416666664,32.41009333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::neg,324991,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",324991,30.153971354166668,7.538680000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::fill_,324998,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",324998,30.240559895833332,4.435173333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,325001,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325001,30.559407552083332,19.68916
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,325002,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",325002,35.31787109375,35.78534666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::fill_,325009,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",325009,36.287760416666664,4.382253333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,325012,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325012,34.860514322916664,19.774986666666656
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,325013,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",325013,36.010416666666664,35.46199999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,325017,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325017,31.946451822916668,16.306506666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,325021,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325021,30.527018229166668,13.335360000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::neg,325024,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325024,30.357584635416668,7.254520000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::fill_,325031,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",325031,30.272298177083332,4.390813333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,325034,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325034,35.777180989583336,7.660293333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,325035,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",325035,35.230631510416664,16.300626666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::fill_,325042,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",325042,35.798177083333336,4.374133333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,325045,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325045,34.060221354166664,8.53746666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,325046,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",325046,31.370442708333332,15.492093333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::cat,325049,"[[[2048, 4, 5, 128], [2048, 4, 5, 128], [2048, 4, 5, 128]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",325049,30.45361328125,73.1422533333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mm,325063,"[[1920, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325063,108.0302734375,202.64305333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mm,325070,"[[8192, 1920], [1920, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325070,107.40234375,189.5992133333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,325082,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325082,44.896647135416664,15.78228
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,record_param_comms,325086,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",325086,59.1767578125,3105.138533333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,325091,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325091,53.50390625,108.18867999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,325092,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",325092,42.057779947916664,70.03653333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::sum,325093,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",325093,106.1337890625,41.084533333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,325097,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325097,48.159830729166664,1.8508666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::neg,325100,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",325100,34.312825520833336,51.6977733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::div,325101,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325101,46.5068359375,116.99801333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::div,325102,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325102,47.455891927083336,116.54860000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,325103,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",325103,47.59521484375,69.95770666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::div,325104,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325104,46.953938802083336,120.12234666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::sum,325105,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",325105,46.774251302083336,36.44125333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,325106,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",325106,46.846516927083336,138.39633333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,325111,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",325111,47.49755859375,1.8448933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::div,325114,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325114,33.994140625,116.08541333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::eq,325115,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",325115,47.413248697916664,1.8653733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::masked_fill_,325116,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",325116,34.047688802083336,119.24565333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::mul,325119,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325119,47.443684895833336,110.30954666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::add_,325120,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",325120,47.156901041666664,141.75082666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,322404,,aten::copy_,325125,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325125,39.02001953125,110.32198666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::fill_,325131,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",325131,3608.7908528645835,2.5518666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::fill_,325135,"[[41943040], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",325135,2560.5607096354165,26.232466666666674
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325160,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325160,2520.2600911458335,8.849786666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,record_param_comms,325162,"[[[5242880]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",325162,3095.4441731770835,1582.6485866666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325175,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325175,35.305501302083336,7.417893333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325178,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325178,27.15673828125,8.795653333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325181,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325181,27.28515625,10.312453333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325184,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325184,27.189290364583332,10.352066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325187,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325187,27.177083333333332,10.07942666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325190,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325190,27.08154296875,9.976186666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325193,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325193,27.0185546875,9.934853333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325196,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325196,26.868977864583332,9.865786666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325213,"[[], [], []]",Memcpy HtoD (Pageable -> Device),325213,21.109375,0.7688533333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::linalg_vector_norm,325217,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",325217,2341.80810546875,33.708813333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325218,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",325218,300.4772135416667,1.4289066666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add,325219,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",325219,779.23046875,1.3960533333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::div,325220,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325220,696.1072591145834,113.44434666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325221,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325221,38.3994140625,109.83899999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mm,325233,"[[8192, 5120], [5120, 1920]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325233,92.47802734375,211.63810666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325249,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),325249,117.73697916666667,4.034466666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325253,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),325253,1056.1271158854167,4.173626666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::neg,325263,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325263,2797.14208984375,8.554133333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::cat,325275,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",325275,1543.8115234375,25.766093333333338
None,None,None,None,None,None,kernel_1,325276,669.96728515625,9.842253333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::neg,325286,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325286,1444.6764322916667,9.869933333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::cat,325297,"[[2048, 4, 5, 128], [[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",325297,1362.1515299479167,26.32333333333333
None,None,None,None,None,None,kernel_1,325298,512.5478515625,9.898173333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::baddbmm,325313,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325313,4092.6598307291665,67.51753333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,ScaledUpperTriangMaskedSoftmax,325316,"[[20, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",325316,2211.65673828125,109.52841333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::bmm,325333,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325333,3174.8684895833335,65.55870666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325341,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325341,754.8504231770834,14.965213333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mm,325350,"[[8192, 640], [640, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325350,2916.9052734375,73.48144000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,record_param_comms,325354,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",325354,1583.3336588541667,3093.7730533333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add,325360,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325360,38.143717447916664,71.45776
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::linalg_vector_norm,325361,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",325361,38.730631510416664,33.96957333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325362,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",325362,40.042317708333336,1.5905866666666661
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add,325363,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",325363,30.816731770833332,1.3883466666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::div,325364,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325364,30.8564453125,113.35557333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325365,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325365,41.867024739583336,109.45626666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325371,"[[], [], []]",Memcpy HtoD (Pageable -> Device),325371,23.156412760416668,0.7441066666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mm,325385,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325385,4226.930826822917,269.25568000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add,325387,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",325387,48.38427734375,55.949519999999985
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::gelu,325388,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",325388,42.8798828125,35.96204
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mm,325396,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325396,84.41471354166667,262.5549866666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,record_param_comms,325400,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",325400,55.732096354166664,3109.5224799999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add,325408,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",325408,37.7265625,108.68833333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add,325410,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325410,38.96484375,70.06255999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::sum,325417,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",325417,96.44710286458333,42.126920000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325421,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325421,39.785970052083336,1.8256933333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mm,325433,"[[5120, 8192], [8192, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325433,97.33186848958333,284.8010933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mm,325440,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325440,100.29671223958333,265.42177333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325452,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325452,39.475423177083336,19.820999999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::gelu_backward,325455,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul>)",325455,37.16162109375,47.03779999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::sum,325458,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",325458,100.50130208333333,28.729640000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325462,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325462,34.4306640625,1.5748133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mm,325472,"[[2560, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325472,102.22770182291667,284.79008
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mm,325479,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325479,101.73844401041667,258.24521333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325491,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325491,43.027994791666664,20.842093333333345
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,record_param_comms,325495,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",325495,63.29541015625,3115.5925999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325500,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325500,41.951985677083336,108.16137333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325501,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",325501,43.794921875,70.05837333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::sum,325502,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",325502,108.78873697916667,40.77904
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325506,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325506,48.159505208333336,1.794093333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::neg,325509,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",325509,30.890787760416668,51.76907999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::div,325510,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325510,37.791341145833336,116.96977333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::div,325511,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325511,38.4326171875,116.59854666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325512,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",325512,38.592936197916664,70.04001333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::div,325513,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325513,43.242513020833336,118.33209333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::sum,325514,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",325514,46.784342447916664,36.26546666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add,325515,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325515,48.278483072916664,65.7413866666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325520,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",325520,47.30517578125,1.863666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::div,325523,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325523,30.590657552083332,116.12457333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::eq,325524,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",325524,38.793294270833336,1.8627999999999993
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::masked_fill_,325525,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",325525,30.666341145833332,119.23789333333329
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325528,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325528,38.591959635416664,110.32844000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325529,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325529,44.255859375,68.34737333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mm,325543,"[[5120, 8192], [8192, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,325543,43.72265625,85.15579999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mm,325550,"[[8192, 5120], [5120, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325550,118.69498697916667,79.85069333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325562,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325562,44.340169270833336,6.572706666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::bmm,325581,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325581,108.48030598958333,59.23910666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::bmm,325584,"[[20, 2048, 128], [20, 128, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325584,109.66178385416667,68.10978666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,ScaledUpperTriangMaskedSoftmaxBackward,325602,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",325602,39.764973958333336,178.13994666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::bmm,325619,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325619,109.67317708333333,64.6644
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325621,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",325621,39.30615234375,8.214573333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::bmm,325624,"[[20, 128, 2048], [20, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325624,110.01578776041667,60.09743999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325626,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",325626,47.891927083333336,8.139
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325650,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325650,38.84521484375,32.69434666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325654,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325654,33.802571614583336,32.34568
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::neg,325657,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325657,30.228190104166668,7.580066666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::fill_,325664,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",325664,30.730305989583332,4.43344
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325667,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325667,30.901041666666668,19.729759999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325668,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",325668,35.232747395833336,36.00261333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::fill_,325675,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",325675,37.641276041666664,4.377093333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325678,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325678,34.401692708333336,19.794159999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325679,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",325679,35.006673177083336,35.563586666666644
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325683,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325683,32.213541666666664,16.53017333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325687,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325687,30.44189453125,13.39582666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::neg,325690,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325690,30.18505859375,7.418840000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::fill_,325697,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",325697,30.72119140625,4.386079999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325700,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325700,35.424641927083336,7.654706666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325701,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",325701,34.717122395833336,16.20029333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::fill_,325708,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",325708,37.429850260416664,4.377999999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::copy_,325711,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325711,33.25,8.61222666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325712,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",325712,31.861165364583332,15.494640000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::cat,325715,"[[[2048, 4, 5, 128], [2048, 4, 5, 128], [2048, 4, 5, 128]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",325715,30.34765625,73.36070666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mm,325729,"[[1920, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325729,106.52766927083333,202.35253333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mm,325736,"[[8192, 1920], [1920, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325736,109.07552083333333,189.52918666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325748,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325748,45.398111979166664,15.750719999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,record_param_comms,325752,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",325752,62.261555989583336,3103.266706666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325757,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325757,53.641927083333336,108.16426666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325758,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",325758,41.82275390625,70.14972000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::sum,325759,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",325759,106.28238932291667,41.233880000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325763,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325763,47.678548177083336,1.7992533333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::neg,325766,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",325766,33.951171875,51.76556
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::div,325767,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325767,46.826334635416664,116.97666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::div,325768,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325768,46.90087890625,116.50769333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325769,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",325769,47.295084635416664,69.97690666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::div,325770,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325770,46.795084635416664,120.33227999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::sum,325771,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",325771,47.102376302083336,36.354960000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325772,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325772,47.124674479166664,64.2668933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325777,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",325777,46.30517578125,1.8679333333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::div,325780,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325780,34.100423177083336,116.61945333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::eq,325781,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",325781,47.412272135416664,1.8482933333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::masked_fill_,325782,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",325782,34.155598958333336,119.19746666666661
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::mul,325785,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325785,47.785319010416664,110.32666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325126,,aten::add_,325786,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",325786,38.83740234375,68.37263999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::fill_,325796,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",325796,3593.7301432291665,2.5540000000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::fill_,325800,"[[41943040], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",325800,2569.9148763020835,26.247453333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,325825,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325825,2609.70849609375,8.833186666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,record_param_comms,325827,"[[[5242880]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",325827,3163.60302734375,1584.8206399999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,325840,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325840,35.6376953125,7.463586666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,325843,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325843,27.455078125,8.854986666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,325846,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325846,26.922688802083332,10.2894
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,325849,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325849,27.24267578125,10.357640000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,325852,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325852,26.963541666666668,10.074320000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,325855,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325855,27.338053385416668,9.86869333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,325858,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325858,27.157389322916668,9.920759999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,325861,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),325861,27.146158854166668,9.891733333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,325878,"[[], [], []]",Memcpy HtoD (Pageable -> Device),325878,21.152018229166668,0.7688400000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::linalg_vector_norm,325882,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",325882,2339.6964518229165,33.87530666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,325883,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",325883,305.6162109375,1.4254666666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add,325884,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",325884,768.07568359375,1.4015733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::div,325885,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",325885,707.95751953125,113.35694666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,325886,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",325886,38.601725260416664,109.77791999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mm,325898,"[[8192, 5120], [5120, 1920]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325898,87.21012369791667,211.42552000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,325914,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),325914,131.9248046875,4.03876
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,325918,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),325918,1061.3972981770833,4.259760000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::neg,325928,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325928,2779.8946940104165,8.614320000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::cat,325940,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",325940,1528.2078450520833,25.80318666666667
None,None,None,None,None,None,kernel_1,325941,629.0817057291666,9.816666666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::neg,325951,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",325951,1432.1552734375,9.870373333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::cat,325962,"[[2048, 4, 5, 128], [[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",325962,1304.4339192708333,26.291746666666665
None,None,None,None,None,None,kernel_1,325963,534.9596354166666,9.895986666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::baddbmm,325978,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325978,4041.5680338541665,67.41085333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,ScaledUpperTriangMaskedSoftmax,325981,"[[20, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",325981,2199.4435221354165,109.60136000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::bmm,325998,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,325998,3000.3499348958335,65.61381333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,326006,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",326006,774.5310872395834,14.926759999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mm,326015,"[[8192, 640], [640, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326015,2859.5830078125,73.43970666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,record_param_comms,326019,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",326019,1545.8907877604167,3095.1614266666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add,326025,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326025,38.111165364583336,71.61136
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::linalg_vector_norm,326026,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",326026,38.516927083333336,33.94350666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326027,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",326027,39.8076171875,1.6337066666666658
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add,326028,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",326028,30.85791015625,1.4071066666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::div,326029,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326029,30.98681640625,113.37132000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326030,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326030,43.252766927083336,109.53395999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,326036,"[[], [], []]",Memcpy HtoD (Pageable -> Device),326036,22.655436197916668,0.7436533333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mm,326050,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326050,4164.6064453125,269.1567066666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add,326052,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",326052,49.02490234375,55.98358666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::gelu,326053,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",326053,41.71630859375,35.92922666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mm,326061,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326061,84.32747395833333,262.5818933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,record_param_comms,326065,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",326065,55.56298828125,3115.072493333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add,326073,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",326073,37.940266927083336,108.61881333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add,326075,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326075,38.635091145833336,70.14234666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::sum,326082,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",326082,96.07307942708333,42.47253333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326086,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326086,39.178385416666664,1.8060533333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mm,326098,"[[5120, 8192], [8192, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326098,97.994140625,284.9039599999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mm,326105,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326105,100.91487630208333,265.40560000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326117,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326117,39.883463541666664,19.828199999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::gelu_backward,326120,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul>)",326120,38.8359375,47.02073333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::sum,326123,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",326123,99.33805338541667,28.786839999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326127,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326127,33.076985677083336,1.5931733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mm,326137,"[[2560, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326137,101.56803385416667,284.73584
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mm,326144,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326144,103.40185546875,258.4014533333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326156,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326156,44.500651041666664,20.852240000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,record_param_comms,326160,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",326160,62.7626953125,3126.1067866666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326165,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326165,40.213053385416664,108.10128000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326166,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",326166,42.163899739583336,69.99810666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::sum,326167,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",326167,106.66666666666667,41.13066666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326171,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326171,47.97705078125,1.8449066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::neg,326174,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",326174,30.8701171875,51.65808
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::div,326175,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326175,38.8154296875,117.02105333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::div,326176,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326176,38.923014322916664,116.57348
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326177,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",326177,38.70849609375,70.01814666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::div,326178,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326178,42.01513671875,118.22296
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::sum,326179,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",326179,47.893717447916664,36.26154666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add,326180,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326180,47.295572916666664,65.77629333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326185,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",326185,46.5380859375,1.8670799999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::div,326188,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326188,30.387532552083332,116.15025333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::eq,326189,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",326189,38.837890625,1.8692133333333323
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::masked_fill_,326190,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",326190,30.731119791666668,119.21362666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326193,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326193,39.146321614583336,110.25582666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326194,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326194,41.8134765625,68.46003999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mm,326208,"[[5120, 8192], [8192, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,326208,42.611653645833336,85.15573333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mm,326215,"[[8192, 5120], [5120, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326215,122.388671875,79.86594666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326227,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326227,43.104166666666664,6.565066666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::bmm,326246,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326246,107.63785807291667,59.1754533333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::bmm,326249,"[[20, 2048, 128], [20, 128, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326249,110.72005208333333,68.13743999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,ScaledUpperTriangMaskedSoftmaxBackward,326267,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",326267,39.274739583333336,178.25638666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::bmm,326284,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326284,107.52897135416667,64.81466666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326286,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",326286,39.29638671875,8.205119999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::bmm,326289,"[[20, 128, 2048], [20, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326289,111.71044921875,59.9187733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326291,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",326291,47.744466145833336,8.147533333333339
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326315,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326315,38.5146484375,32.63490666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326319,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326319,35.252766927083336,32.35251999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::neg,326322,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",326322,30.271158854166668,7.615093333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::fill_,326329,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",326329,30.634114583333332,4.427506666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,326332,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",326332,30.634114583333332,19.78811999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326333,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",326333,33.34619140625,36.13910666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::fill_,326340,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",326340,37.01171875,4.378426666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,326343,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",326343,34.209798177083336,19.840600000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326344,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",326344,36.78955078125,35.61986666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326348,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326348,33.34326171875,16.470413333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326352,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326352,30.334798177083332,13.326413333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::neg,326355,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",326355,30.23974609375,7.281413333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::fill_,326362,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",326362,30.645182291666668,4.385559999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,326365,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",326365,33.84619140625,7.650920000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326366,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",326366,36.319661458333336,16.292946666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::fill_,326373,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",326373,35.52880859375,4.382666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::copy_,326376,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",326376,34.019694010416664,8.633920000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326377,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",326377,32.765950520833336,15.686639999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::cat,326380,"[[[2048, 4, 5, 128], [2048, 4, 5, 128], [2048, 4, 5, 128]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",326380,30.379069010416668,73.12649333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mm,326394,"[[1920, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326394,105.0859375,202.3658133333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mm,326401,"[[8192, 1920], [1920, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326401,104.927734375,189.4819066666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326413,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326413,42.815104166666664,15.811586666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,record_param_comms,326417,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",326417,60.885091145833336,3105.6240399999992
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326422,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326422,53.993001302083336,108.11537333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326423,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",326423,43.732421875,70.05533333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::sum,326424,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",326424,109.19254557291667,41.04235999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326428,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326428,48.7685546875,1.7928266666666661
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::neg,326431,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",326431,35.692057291666664,51.72933333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::div,326432,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326432,46.654947916666664,116.91145333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::div,326433,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326433,47.040364583333336,116.53370666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326434,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",326434,46.847981770833336,69.98445333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::div,326435,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326435,47.094075520833336,120.40917333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::sum,326436,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",326436,47.210123697916664,36.36564
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326437,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326437,47.594075520833336,64.33591999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326442,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",326442,46.676920572916664,1.8542933333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::div,326445,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326445,35.741373697916664,116.64901333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::eq,326446,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",326446,47.029947916666664,1.81376
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::masked_fill_,326447,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",326447,35.56201171875,119.12655999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::mul,326450,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326450,47.348470052083336,110.31171999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,325791,,aten::add_,326451,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326451,38.826822916666664,68.46774666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::fill_,326461,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",326461,3520.1222330729165,2.540773333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::fill_,326465,"[[41943040], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",326465,2502.31884765625,26.242720000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326490,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),326490,2584.4736328125,8.818693333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,record_param_comms,326492,"[[[5242880]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",326492,3120.6573893229165,1583.621786666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326505,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),326505,35.7548828125,7.48962666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326508,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),326508,27.423828125,8.868599999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326511,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),326511,27.18896484375,10.312413333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326514,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),326514,26.9423828125,10.355893333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326517,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),326517,27.093912760416668,10.02738666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326520,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),326520,27.10546875,9.882373333333327
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326523,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),326523,27.134440104166668,9.907986666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326526,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),326526,26.99658203125,9.881879999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326543,"[[], [], []]",Memcpy HtoD (Pageable -> Device),326543,20.832356770833332,0.7722533333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::linalg_vector_norm,326547,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",326547,2289.5550130208335,33.853919999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,326548,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",326548,283.8673502604167,1.4327333333333339
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add,326549,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",326549,748.9181315104166,1.4054399999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::div,326550,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326550,677.1853841145834,113.35044000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,326551,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326551,38.687174479166664,109.77453333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mm,326563,"[[8192, 5120], [5120, 1920]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326563,89.09765625,211.41190666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326579,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),326579,118.53678385416667,3.901413333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326583,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),326583,1084.59619140625,3.937706666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::neg,326593,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",326593,2820.7176106770835,8.579720000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::cat,326605,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",326605,1516.69482421875,25.724733333333326
None,None,None,None,None,None,kernel_1,326606,643.97314453125,9.845693333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::neg,326616,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",326616,1414.54248046875,9.904933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::cat,326627,"[[2048, 4, 5, 128], [[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",326627,1286.6627604166667,26.278560000000002
None,None,None,None,None,None,kernel_1,326628,496.6774088541667,9.87121333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::baddbmm,326643,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326643,4245.766438802083,67.51366666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,ScaledUpperTriangMaskedSoftmax,326646,"[[20, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",326646,2194.7076822916665,109.55958666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::bmm,326663,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326663,2980.1072591145835,65.41277333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326671,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",326671,769.16748046875,14.965986666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mm,326680,"[[8192, 640], [640, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326680,2897.4928385416665,73.58898666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,record_param_comms,326684,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",326684,1545.6253255208333,3095.9998
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add,326690,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326690,37.245930989583336,71.41982666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::linalg_vector_norm,326691,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",326691,38.347493489583336,34.02289333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,326692,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",326692,39.785807291666664,1.619613333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add,326693,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",326693,30.9873046875,1.416093333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::div,326694,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326694,30.919921875,113.31331999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,326695,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326695,41.429850260416664,109.51088000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326701,"[[], [], []]",Memcpy HtoD (Pageable -> Device),326701,22.5908203125,0.7415333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mm,326715,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326715,4196.317220052083,269.16441333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add,326717,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",326717,48.894694010416664,55.97040000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::gelu,326718,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",326718,42.409342447916664,35.93134666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mm,326726,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326726,84.958984375,262.4927333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,record_param_comms,326730,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",326730,57.185546875,3115.122880000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add,326738,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",326738,37.55859375,108.63920000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add,326740,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326740,38.7080078125,70.17481333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::sum,326747,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",326747,95.5400390625,42.47932000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,326751,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326751,40.704752604166664,1.8538133333333329
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mm,326763,"[[5120, 8192], [8192, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326763,97.26822916666667,284.90949333333316
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mm,326770,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326770,100.98030598958333,265.4529066666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,326782,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326782,39.283854166666664,19.80872
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::gelu_backward,326785,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul>)",326785,38.742350260416664,47.01857333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::sum,326788,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",326788,98.90966796875,28.649026666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,326792,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326792,33.844075520833336,1.61792
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mm,326802,"[[2560, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326802,102.88460286458333,284.5601066666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mm,326809,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326809,102.6650390625,258.17102666666676
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,326821,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326821,42.549641927083336,20.816373333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,record_param_comms,326825,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",326825,63.208333333333336,3125.879013333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,326830,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326830,41.888997395833336,108.05644000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,326831,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",326831,43.892740885416664,70.04894666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::sum,326832,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",326832,107.67822265625,40.84990666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,326836,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326836,48.756998697916664,1.8111866666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::neg,326839,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",326839,31.146484375,51.75495999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::div,326840,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326840,38.271809895833336,117.05256000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::div,326841,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326841,38.697916666666664,116.52141333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,326842,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",326842,38.740885416666664,70.08394666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::div,326843,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326843,43.32763671875,118.24894666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::sum,326844,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",326844,47.62646484375,36.33069333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add,326845,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326845,47.637044270833336,65.68842666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,326850,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",326850,47.0166015625,1.8713466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::div,326853,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",326853,30.815266927083332,116.12929333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::eq,326854,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",326854,38.794921875,1.8606933333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::masked_fill_,326855,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",326855,30.878743489583332,119.21142666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,326858,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326858,38.518229166666664,110.34723999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,326859,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326859,44.189615885416664,68.29999999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mm,326873,"[[5120, 8192], [8192, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,326873,44.875162760416664,85.15280000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mm,326880,"[[8192, 5120], [5120, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326880,121.74755859375,79.8464666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,326892,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",326892,44.137858072916664,6.542413333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::bmm,326911,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326911,106.80257161458333,59.43278666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::bmm,326914,"[[20, 2048, 128], [20, 128, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326914,106.24983723958333,68.18139999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,ScaledUpperTriangMaskedSoftmaxBackward,326932,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",326932,39.413248697916664,177.89841333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::bmm,326949,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326949,108.93815104166667,64.86713333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,326951,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",326951,38.710774739583336,8.21964
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::bmm,326954,"[[20, 128, 2048], [20, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,326954,109.60774739583333,60.09399999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,326956,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",326956,47.680826822916664,8.134773333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,326980,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326980,39.176106770833336,32.66141333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,326984,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",326984,33.47119140625,32.40925333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::neg,326987,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",326987,30.229654947916668,7.779706666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::fill_,326994,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",326994,30.400390625,4.424893333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,326997,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",326997,30.335774739583332,19.69778666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,326998,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",326998,35.4560546875,36.22015999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::fill_,327005,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",327005,36.575846354166664,4.377999999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,327008,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327008,34.870279947916664,19.841466666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,327009,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",327009,37.449869791666664,35.63569333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,327013,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327013,33.663899739583336,16.519093333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,327017,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327017,30.411295572916668,13.320813333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::neg,327020,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327020,30.345865885416668,7.318546666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::fill_,327027,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",327027,30.8896484375,4.390346666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,327030,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327030,35.457194010416664,7.654693333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,327031,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",327031,34.580240885416664,16.270386666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::fill_,327038,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",327038,36.212239583333336,4.376719999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::copy_,327041,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327041,33.98388671875,8.409506666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,327042,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",327042,33.38525390625,15.504053333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::cat,327045,"[[[2048, 4, 5, 128], [2048, 4, 5, 128], [2048, 4, 5, 128]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",327045,30.540690104166668,73.20155999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mm,327059,"[[1920, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327059,103.40901692708333,202.27150666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mm,327066,"[[8192, 1920], [1920, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327066,104.79052734375,189.41872
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,327078,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327078,44.767740885416664,15.795053333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,record_param_comms,327082,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",327082,61.427083333333336,3108.7562133333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,327087,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327087,53.844889322916664,108.14808000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,327088,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",327088,41.984049479166664,70.03618666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::sum,327089,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",327089,108.1904296875,41.127706666666676
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,327093,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327093,48.596842447916664,1.8167333333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::neg,327096,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",327096,34.123372395833336,51.79286666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::div,327097,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327097,46.420572916666664,116.90625333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::div,327098,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327098,46.453287760416664,116.51029333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,327099,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",327099,46.8154296875,70.05370666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::div,327100,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327100,46.5283203125,120.30246666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::sum,327101,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",327101,46.976236979166664,36.334053333333344
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,327102,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327102,47.539876302083336,64.28778666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,327107,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",327107,47.2626953125,1.8482933333333342
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::div,327110,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327110,33.792154947916664,116.58324000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::eq,327111,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",327111,46.752115885416664,1.8918133333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::masked_fill_,327112,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",327112,33.824381510416664,119.23665333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::mul,327115,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327115,47.337890625,110.30197333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,326456,,aten::add_,327116,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327116,38.3984375,68.34055999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::fill_,327126,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",327126,3534.6070963541665,2.548453333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::fill_,327130,"[[41943040], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",327130,2495.6630859375,26.248746666666676
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327155,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327155,2533.0691731770835,8.834000000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,record_param_comms,327157,"[[[5242880]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",327157,3121.6207682291665,1582.153973333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327170,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327170,35.65869140625,7.467506666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327173,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327173,27.125,8.81268
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327176,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327176,26.869303385416668,10.31412
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327179,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327179,27.253255208333332,10.333693333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327182,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327182,27.071940104166668,10.097840000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327185,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327185,27.45556640625,9.895506666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327188,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327188,26.99658203125,9.900679999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327191,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327191,26.93408203125,9.902826666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327208,"[[], [], []]",Memcpy HtoD (Pageable -> Device),327208,20.88427734375,0.7744000000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::linalg_vector_norm,327212,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",327212,2290.9274088541665,33.76993333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327213,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",327213,278.771484375,1.4306000000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add,327214,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",327214,742.7259114583334,1.4011733333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::div,327215,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327215,669.2736002604166,113.35518666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327216,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327216,38.49658203125,109.73955999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mm,327228,"[[8192, 5120], [5120, 1920]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327228,85.17203776041667,211.34779999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327244,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),327244,129.85432942708334,4.169773333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327248,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),327248,1117.12158203125,3.905226666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::neg,327258,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327258,2804.2981770833335,8.618133333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::cat,327270,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",327270,1556.4012044270833,25.701626666666662
None,None,None,None,None,None,kernel_1,327271,647.8963216145834,9.839279999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::neg,327281,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327281,1438.9609375,9.858373333333327
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::cat,327292,"[[2048, 4, 5, 128], [[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",327292,1281.5579427083333,26.2806
None,None,None,None,None,None,kernel_1,327293,509.6131184895833,9.90544
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::baddbmm,327308,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327308,3961.8883463541665,67.37850666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,ScaledUpperTriangMaskedSoftmax,327311,"[[20, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",327311,2198.6842447916665,109.51053333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::bmm,327328,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327328,2957.5003255208335,65.48161333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327336,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327336,747.8951822916666,14.975866666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mm,327345,"[[8192, 640], [640, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327345,2927.84033203125,73.47498666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,record_param_comms,327349,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",327349,1556.3349609375,3094.578626666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add,327355,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327355,37.8671875,71.55593333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::linalg_vector_norm,327356,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",327356,38.409342447916664,33.839360000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327357,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",327357,39.424479166666664,1.6183466666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add,327358,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",327358,30.944173177083332,1.3917733333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::div,327359,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327359,30.92041015625,113.29755999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327360,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327360,43.0927734375,109.46526666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327366,"[[], [], []]",Memcpy HtoD (Pageable -> Device),327366,23.103515625,0.7564666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mm,327380,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327380,4152.66943359375,269.00782666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add,327382,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",327382,48.064778645833336,55.91451999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::gelu,327383,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",327383,41.684244791666664,35.98637333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mm,327391,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327391,85.11735026041667,262.52685333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,record_param_comms,327395,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",327395,55.60400390625,3110.124479999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add,327403,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",327403,38.282389322916664,108.60470666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add,327405,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327405,38.932779947916664,69.98023999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::sum,327412,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",327412,94.18538411458333,42.66234666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327416,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327416,39.689615885416664,1.7855866666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mm,327428,"[[5120, 8192], [8192, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327428,97.27945963541667,284.7679200000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mm,327435,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327435,101.50341796875,264.90969333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327447,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327447,39.9052734375,19.86029333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::gelu_backward,327450,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul>)",327450,39.036946614583336,46.99973333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::sum,327453,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",327453,98.9130859375,28.68541333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327457,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327457,33.353515625,1.5897466666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mm,327467,"[[2560, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327467,103.474609375,284.62709333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mm,327474,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327474,102.1962890625,258.12924
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327486,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327486,44.692708333333336,20.798440000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,record_param_comms,327490,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",327490,61.86572265625,3119.561440000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327495,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327495,40.6513671875,108.05674666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327496,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",327496,42.356770833333336,70.11558666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::sum,327497,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",327497,106.85774739583333,40.88786666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327501,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327501,48.054036458333336,1.794106666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::neg,327504,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",327504,30.688802083333332,51.659386666666656
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::div,327505,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327505,38.696940104166664,116.89389333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::div,327506,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327506,38.484375,116.56280000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327507,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",327507,39.040201822916664,70.00711999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::div,327508,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327508,41.963053385416664,118.2070933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::sum,327509,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",327509,47.2216796875,36.43392
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add,327510,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327510,47.252115885416664,65.61342666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327515,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",327515,47.337076822916664,1.8888266666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::div,327518,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327518,30.901204427083332,116.18047999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::eq,327519,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",327519,39.274251302083336,1.8645333333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::masked_fill_,327520,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",327520,30.561686197916668,119.18037333333329
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327523,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327523,39.081868489583336,110.25880000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327524,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327524,42.17578125,68.43108000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mm,327538,"[[5120, 8192], [8192, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,327538,43.14599609375,85.16301333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mm,327545,"[[8192, 5120], [5120, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327545,117.90901692708333,79.84250666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327557,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327557,42.590494791666664,6.5548399999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::bmm,327576,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327576,104.55436197916667,59.208239999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::bmm,327579,"[[20, 2048, 128], [20, 128, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327579,106.82666015625,68.20962666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,ScaledUpperTriangMaskedSoftmaxBackward,327597,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",327597,39.273763020833336,178.11258666666674
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::bmm,327614,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327614,110.39990234375,64.65973333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327616,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",327616,39.081380208333336,8.20684
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::bmm,327619,"[[20, 128, 2048], [20, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327619,112.36116536458333,60.121839999999985
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327621,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",327621,48.000162760416664,8.11210666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327645,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327645,39.20947265625,32.641360000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327649,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327649,34.814778645833336,32.39685333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::neg,327652,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327652,30.175618489583332,7.637666666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::fill_,327659,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",327659,30.55859375,4.42024
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327662,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327662,30.869140625,19.720679999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327663,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",327663,33.632486979166664,36.16294666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::fill_,327670,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",327670,37.95166015625,4.3801466666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327673,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327673,33.943522135416664,19.91107999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327674,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",327674,38.474283854166664,35.670599999999986
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327678,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327678,35.028971354166664,16.51270666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327682,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327682,30.441569010416668,13.350693333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::neg,327685,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327685,30.206705729166668,7.263960000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::fill_,327692,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",327692,30.7412109375,4.386533333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327695,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327695,33.94140625,7.640653333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327696,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",327696,36.052571614583336,16.22805333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::fill_,327703,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",327703,35.882975260416664,4.367293333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::copy_,327706,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327706,35.330240885416664,8.610853333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327707,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",327707,34.334635416666664,15.595839999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::cat,327710,"[[[2048, 4, 5, 128], [2048, 4, 5, 128], [2048, 4, 5, 128]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",327710,30.571126302083332,73.10163999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mm,327724,"[[1920, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327724,106.63346354166667,202.1985466666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mm,327731,"[[8192, 1920], [1920, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327731,107.39046223958333,189.46441333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327743,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327743,43.007161458333336,15.718253333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,record_param_comms,327747,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",327747,61.898274739583336,3106.2150533333343
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327752,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327752,53.738118489583336,108.20316
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327753,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",327753,43.63720703125,70.00032
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::sum,327754,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",327754,109.97298177083333,41.11992
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327758,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327758,48.073079427083336,1.8286666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::neg,327761,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",327761,35.75439453125,51.69865333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::div,327762,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327762,46.368326822916664,116.93176000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::div,327763,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327763,47.561686197916664,116.52149333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327764,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",327764,46.965494791666664,69.93581333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::div,327765,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327765,46.1865234375,120.65149333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::sum,327766,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",327766,47.0615234375,36.42030666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327767,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327767,47.743977864583336,64.25917333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327772,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",327772,47.252115885416664,1.861533333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::div,327775,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327775,34.963704427083336,116.61649333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::eq,327776,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",327776,46.7734375,1.8448933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::masked_fill_,327777,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",327777,35.914388020833336,119.15303999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::mul,327780,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327780,47.230794270833336,110.26442666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,327121,,aten::add_,327781,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",327781,39.19970703125,68.50310666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::fill_,327791,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",327791,3536.6544596354165,2.5462933333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::fill_,327795,"[[41943040], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",327795,2508.0677083333335,26.24656000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,327820,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327820,2579.5343424479165,8.863959999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,record_param_comms,327822,"[[[5242880]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",327822,3098.3665364583335,1582.9684666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,327835,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327835,35.316731770833336,7.461933333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,327838,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327838,27.381022135416668,8.829333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,327841,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327841,27.072265625,10.260400000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,327844,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327844,26.826497395833332,10.324786666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,327847,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327847,26.900065104166668,10.060253333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,327850,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327850,26.836588541666668,9.906666666666661
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,327853,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327853,27.21044921875,9.920706666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,327856,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),327856,26.996744791666668,9.88916
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,327873,"[[], [], []]",Memcpy HtoD (Pageable -> Device),327873,21.121256510416668,0.7714000000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::linalg_vector_norm,327877,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",327877,2305.1376953125,33.90644000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,327878,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",327878,269.5673828125,1.435733333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add,327879,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",327879,759.5068359375,1.401999999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::div,327880,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",327880,677.3131510416666,113.30869333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,327881,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",327881,38.493977864583336,109.7588
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mm,327893,"[[8192, 5120], [5120, 1920]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327893,85.71565755208333,211.28681333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,327909,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),327909,109.61083984375,4.836173333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,327913,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),327913,1062.271484375,4.4893600000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::neg,327923,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327923,2755.6708984375,8.659093333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::cat,327935,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",327935,1527.9615885416667,25.76657333333333
None,None,None,None,None,None,kernel_1,327936,616.6429036458334,9.8256
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::neg,327946,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",327946,1450.08642578125,9.894253333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::cat,327957,"[[2048, 4, 5, 128], [[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",327957,1307.548828125,26.29302666666667
None,None,None,None,None,None,kernel_1,327958,498.0634765625,9.868706666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::baddbmm,327973,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327973,3972.7247721354165,67.50307999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,ScaledUpperTriangMaskedSoftmax,327976,"[[20, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",327976,2154.6754557291665,109.50363999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::bmm,327993,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,327993,2941.5240885416665,65.49901333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,328001,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",328001,737.7960611979166,14.982613333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mm,328010,"[[8192, 640], [640, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328010,2893.9417317708335,73.45969333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,record_param_comms,328014,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",328014,1527.8868815104167,3092.499053333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add,328020,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328020,38.10107421875,71.46969333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::linalg_vector_norm,328021,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",328021,38.709309895833336,33.978586666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328022,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",328022,40.20263671875,1.6473333333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add,328023,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",328023,31.350748697916668,1.3955999999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::div,328024,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328024,30.9951171875,113.31458666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328025,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328025,41.939453125,109.44901333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,328031,"[[], [], []]",Memcpy HtoD (Pageable -> Device),328031,23.007486979166668,0.7440933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mm,328045,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328045,4196.701822916667,269.2621199999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add,328047,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",328047,48.383138020833336,55.93627999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::gelu,328048,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",328048,41.930989583333336,35.973973333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mm,328056,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328056,92.56429036458333,262.677
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,record_param_comms,328060,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",328060,57.114095052083336,3109.673146666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add,328068,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",328068,38.133626302083336,108.62718666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add,328070,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328070,38.644856770833336,70.13522666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::sum,328077,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",328077,95.77473958333333,42.509573333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328081,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328081,39.210123697916664,1.8227066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mm,328093,"[[5120, 8192], [8192, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328093,97.50260416666667,284.85191999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mm,328100,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328100,101.06819661458333,265.0142533333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328112,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328112,39.658203125,19.858119999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::gelu_backward,328115,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul>)",328115,38.942220052083336,47.07356000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::sum,328118,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",328118,99.32796223958333,28.692626666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328122,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328122,35.136555989583336,1.5871866666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mm,328132,"[[2560, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328132,102.18489583333333,284.6181199999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mm,328139,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328139,101.73763020833333,258.16633333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328151,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328151,42.5380859375,20.746439999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,record_param_comms,328155,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",328155,61.673990885416664,3121.301720000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328160,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328160,41.791829427083336,108.12554666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328161,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",328161,43.743489583333336,70.13089333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::sum,328162,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",328162,109.08512369791667,40.74715999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328166,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328166,48.298014322916664,1.8026666666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::neg,328169,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",328169,30.687337239583332,51.74466666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::div,328170,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328170,37.907552083333336,116.92337333333342
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::div,328171,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328171,38.751953125,116.54701333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328172,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",328172,38.44287109375,70.00712
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::div,328173,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328173,43.200032552083336,118.32958666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::sum,328174,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",328174,47.133951822916664,36.369506666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add,328175,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328175,47.61572265625,65.64840000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328180,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",328180,47.1875,1.8482800000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::div,328183,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328183,30.369303385416668,116.15953333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::eq,328184,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",328184,38.740234375,1.8786
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::masked_fill_,328185,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",328185,30.64501953125,119.23673333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328188,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328188,38.721354166666664,110.32407999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328189,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328189,43.731770833333336,68.27493333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mm,328203,"[[5120, 8192], [8192, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,328203,44.223470052083336,85.18262666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mm,328210,"[[8192, 5120], [5120, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328210,122.04736328125,79.80878666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328222,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328222,44.437337239583336,6.6158399999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::bmm,328241,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328241,106.69921875,59.39169333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::bmm,328244,"[[20, 2048, 128], [20, 128, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328244,106.40983072916667,68.11227999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,ScaledUpperTriangMaskedSoftmaxBackward,328262,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",328262,39.883138020833336,177.93000000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::bmm,328279,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328279,110.20670572916667,64.84841333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328281,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",328281,39.30517578125,8.212386666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::bmm,328284,"[[20, 128, 2048], [20, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328284,111.24104817708333,60.12992
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328286,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",328286,48.06298828125,8.109573333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328310,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328310,39.199055989583336,32.71124
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328314,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328314,33.68408203125,32.338466666666655
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::neg,328317,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",328317,30.719075520833332,7.7204666666666695
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::fill_,328324,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",328324,30.431803385416668,4.43048
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,328327,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",328327,30.408854166666668,19.75954666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328328,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",328328,35.2216796875,35.98249333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::fill_,328335,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",328335,37.24853515625,4.375853333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,328338,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",328338,36.064778645833336,19.87226666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328339,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",328339,38.5595703125,35.43597333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328343,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328343,33.428385416666664,16.558733333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328347,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328347,30.388671875,13.316560000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::neg,328350,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",328350,30.452962239583332,7.381280000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::fill_,328357,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",328357,30.7841796875,4.389933333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,328360,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",328360,34.934244791666664,7.650066666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328361,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",328361,36.031412760416664,16.26564
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::fill_,328368,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",328368,36.521647135416664,4.371586666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::copy_,328371,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",328371,34.197591145833336,8.416360000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328372,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",328372,31.263671875,15.563306666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::cat,328375,"[[[2048, 4, 5, 128], [2048, 4, 5, 128], [2048, 4, 5, 128]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",328375,30.591145833333332,73.08599999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mm,328389,"[[1920, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328389,105.7578125,202.35593333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mm,328396,"[[8192, 1920], [1920, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328396,107.81787109375,189.47081333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328408,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328408,44.607747395833336,15.769879999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,record_param_comms,328412,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",328412,61.641927083333336,3106.32292
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328417,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328417,53.69482421875,108.1165866666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328418,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",328418,42.335774739583336,70.11078666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::sum,328419,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",328419,109.26806640625,40.99076000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328423,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328423,48.180013020833336,1.872173333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::neg,328426,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",328426,34.101399739583336,51.743013333333316
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::div,328427,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328427,47.01806640625,116.88961333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::div,328428,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328428,47.3720703125,116.52555999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328429,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",328429,47.114583333333336,70.03750666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::div,328430,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328430,46.216959635416664,120.7013066666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::sum,328431,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",328431,47.392740885416664,36.51550666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328432,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328432,47.776041666666664,64.23524000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328437,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",328437,46.741861979166664,1.87048
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::div,328440,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328440,34.23779296875,116.67329333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::eq,328441,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",328441,46.965494791666664,1.851266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::masked_fill_,328442,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",328442,33.9521484375,119.17005333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::mul,328445,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328445,46.62353515625,110.31131999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,327786,,aten::add_,328446,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328446,38.581868489583336,68.4275866666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::fill_,328456,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",328456,3548.5374348958335,2.5420266666666684
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::fill_,328460,"[[41943040], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",328460,2528.0066731770835,26.241386666666678
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328485,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),328485,2453.5633138020835,8.842959999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,record_param_comms,328487,"[[[5242880]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",328487,3194.4085286458335,1583.2727333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328500,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),328500,35.861653645833336,7.478080000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328503,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),328503,27.4345703125,8.855813333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328506,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),328506,27.072265625,10.300413333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328509,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),328509,27.18798828125,10.375973333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328512,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),328512,27.200032552083332,10.07688
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328515,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),328515,27.040201822916668,9.896026666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328518,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),328518,26.835774739583332,9.855506666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328521,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),328521,27.094075520833332,9.907879999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328538,"[[], [], []]",Memcpy HtoD (Pageable -> Device),328538,20.895670572916668,0.7722666666666671
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::linalg_vector_norm,328542,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",328542,2309.29736328125,33.78394666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,328543,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",328543,274.1931966145833,1.4344266666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add,328544,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",328544,748.8766276041666,1.4045466666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::div,328545,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328545,669.6217447916666,113.34403999999992
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,328546,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328546,38.494954427083336,109.78140000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mm,328558,"[[8192, 5120], [5120, 1920]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328558,93.09798177083333,211.39484000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328574,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),328574,119.51904296875,4.944959999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328578,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),328578,1062.9544270833333,3.8663866666666658
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::neg,328588,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",328588,2771.4588216145835,8.625373333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::cat,328600,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",328600,1495.42919921875,25.723493333333323
None,None,None,None,None,None,kernel_1,328601,646.33935546875,9.857959999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::neg,328611,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",328611,1428.7215169270833,9.910079999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::cat,328622,"[[2048, 4, 5, 128], [[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",328622,1346.0724283854167,26.26328000000001
None,None,None,None,None,None,kernel_1,328623,530.6920572916666,9.868693333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::baddbmm,328638,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328638,4029.3326822916665,67.61268000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,ScaledUpperTriangMaskedSoftmax,328641,"[[20, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",328641,2154.7376302083335,109.59328
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::bmm,328658,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328658,2879.0960286458335,65.40981333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328666,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",328666,733.6783854166666,15.006106666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mm,328675,"[[8192, 640], [640, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328675,3010.8780924479165,73.5284133333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,record_param_comms,328679,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",328679,1522.8538411458333,3092.0967066666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add,328685,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328685,37.94091796875,71.54563999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::linalg_vector_norm,328686,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",328686,38.047200520833336,33.92010666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,328687,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",328687,39.475748697916664,1.645226666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add,328688,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",328688,30.762858072916668,1.4028799999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::div,328689,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328689,30.772298177083332,113.29448
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,328690,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328690,43.34814453125,109.47885333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328696,"[[], [], []]",Memcpy HtoD (Pageable -> Device),328696,22.613444010416668,0.7479333333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mm,328710,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328710,4204.1787109375,269.225
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add,328712,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",328712,48.224283854166664,55.92137333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::gelu,328713,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",328713,40.894856770833336,35.95517333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mm,328721,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328721,97.01123046875,262.66849333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,record_param_comms,328725,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",328725,56.890462239583336,3113.0053733333343
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add,328733,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",328733,38.31298828125,108.64944000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add,328735,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328735,38.784016927083336,70.0677466666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::sum,328742,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",328742,96.20231119791667,42.569733333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,328746,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328746,40.884602864583336,1.7877333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mm,328758,"[[5120, 8192], [8192, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328758,98.03759765625,284.8719733333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mm,328765,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328765,102.32307942708333,265.21954666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,328777,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328777,39.348958333333336,19.95452
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::gelu_backward,328780,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul>)",328780,38.15576171875,46.961333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::sum,328783,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",328783,98.984375,28.624399999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,328787,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328787,34.1240234375,1.625573333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mm,328797,"[[2560, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328797,104.07291666666667,284.6117333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mm,328804,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328804,101.58870442708333,258.0426266666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,328816,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328816,44.904459635416664,20.844960000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,record_param_comms,328820,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",328820,62.23876953125,3129.2116533333324
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,328825,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328825,40.351399739583336,108.10037333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,328826,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",328826,41.867350260416664,70.0429466666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::sum,328827,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",328827,107.50862630208333,40.95502666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,328831,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328831,48.265950520833336,1.8192666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::neg,328834,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",328834,31.092610677083332,51.65926666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::div,328835,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328835,38.580729166666664,116.95286666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::div,328836,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328836,38.730143229166664,116.54947999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,328837,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",328837,38.70947265625,69.96884
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::div,328838,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328838,41.717936197916664,118.28898666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::sum,328839,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",328839,47.604654947916664,36.35874666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add,328840,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328840,48.042154947916664,65.77172
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,328845,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",328845,47.347819010416664,1.8627866666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::div,328848,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",328848,30.45166015625,116.09688000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::eq,328849,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",328849,39.105305989583336,1.8769066666666674
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::masked_fill_,328850,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",328850,30.698567708333332,119.15134666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,328853,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328853,38.78466796875,110.28275999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,328854,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328854,42.4833984375,68.44983999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mm,328868,"[[5120, 8192], [8192, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,328868,42.132161458333336,85.0183733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mm,328875,"[[8192, 5120], [5120, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328875,122.35514322916667,79.88826666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,328887,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",328887,43.051920572916664,6.511226666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::bmm,328906,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328906,105.47151692708333,59.36227999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::bmm,328909,"[[20, 2048, 128], [20, 128, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328909,106.48502604166667,68.15831999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,ScaledUpperTriangMaskedSoftmaxBackward,328927,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",328927,39.64892578125,178.12540000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::bmm,328944,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328944,110.35677083333333,64.62359999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,328946,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",328946,38.494954427083336,8.248186666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::bmm,328949,"[[20, 128, 2048], [20, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,328949,109.58919270833333,59.99977333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,328951,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",328951,48.052897135416664,8.12874666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,328975,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328975,38.771321614583336,32.648093333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,328979,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",328979,35.199544270833336,32.440960000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::neg,328982,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",328982,30.368815104166668,7.610733333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::fill_,328989,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",328989,30.66552734375,4.430879999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,328992,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",328992,30.592122395833332,19.736106666666657
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,328993,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",328993,33.716796875,36.181746666666676
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::fill_,329000,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",329000,37.887532552083336,4.377573333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,329003,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",329003,33.580240885416664,19.85261333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,329004,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",329004,37.610188802083336,35.53323999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,329008,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",329008,33.333821614583336,16.56508000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,329012,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",329012,30.59130859375,13.331533333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::neg,329015,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",329015,30.442545572916668,7.174373333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::fill_,329022,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",329022,30.378255208333332,4.4014533333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,329025,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",329025,34.208170572916664,7.655106666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,329026,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",329026,37.02294921875,16.304013333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::fill_,329033,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",329033,36.128092447916664,4.369906666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::copy_,329036,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",329036,35.072265625,8.457706666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,329037,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",329037,33.2060546875,15.51848
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::cat,329040,"[[[2048, 4, 5, 128], [2048, 4, 5, 128], [2048, 4, 5, 128]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",329040,30.36767578125,73.22933333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mm,329054,"[[1920, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329054,106.83463541666667,202.40201333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mm,329061,"[[8192, 1920], [1920, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329061,107.64811197916667,189.35774666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,329073,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329073,43.167154947916664,15.770319999999993
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,record_param_comms,329077,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",329077,60.57470703125,3113.359826666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,329082,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",329082,53.92041015625,108.17369333333329
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,329083,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",329083,44.320475260416664,70.00585333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::sum,329084,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",329084,109.50309244791667,41.22402666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,329088,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329088,48.053548177083336,1.8244133333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::neg,329091,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",329091,36.29833984375,51.66244
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::div,329092,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",329092,47.731770833333336,116.94166666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::div,329093,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",329093,47.00634765625,116.55381333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,329094,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",329094,47.263346354166664,69.97134666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::div,329095,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",329095,46.900390625,120.77904
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::sum,329096,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",329096,47.264485677083336,36.35076
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,329097,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329097,47.390950520833336,64.23139999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,329102,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",329102,46.997395833333336,1.8670799999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::div,329105,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",329105,35.614908854166664,116.6007066666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::eq,329106,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",329106,47.733561197916664,1.84448
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::masked_fill_,329107,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",329107,35.47705078125,119.21567999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::mul,329110,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",329110,46.570638020833336,110.30836000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,328451,,aten::add_,329111,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329111,38.218587239583336,68.44974666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::fill_,329121,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",329121,3555.3564453125,2.545480000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::fill_,329125,"[[41943040], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",329125,2527.1826171875,26.23757333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329150,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),329150,2551.6739908854165,8.816973333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,record_param_comms,329152,"[[[5242880]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",329152,3070.0568033854165,1584.070613333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329165,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),329165,35.423502604166664,7.4802133333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329168,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),329168,26.99658203125,8.786706666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329171,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),329171,27.263997395833332,10.2868
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329174,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),329174,26.99609375,10.374706666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329177,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),329177,27.273600260416668,10.048266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329180,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),329180,27.231119791666668,9.893919999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329183,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),329183,27.455729166666668,9.913026666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329186,"[[5242880], [5242880], []]",Memcpy DtoD (Device -> Device),329186,27.071940104166668,9.874719999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329203,"[[], [], []]",Memcpy HtoD (Pageable -> Device),329203,20.852864583333332,0.7603200000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::linalg_vector_norm,329207,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",329207,2297.9158528645835,33.802266666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329208,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",329208,282.7918294270833,1.4357199999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add,329209,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",329209,738.4412434895834,1.3943333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::div,329210,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",329210,662.8406575520834,113.33889333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329211,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",329211,39.10302734375,109.7668933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mm,329223,"[[8192, 5120], [5120, 1920]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329223,90.78304036458333,211.35085333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329239,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),329239,106.93196614583333,5.017586666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329243,"[[2048, 1, 1, 128], [2048, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),329243,1058.2679036458333,4.67112
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::neg,329253,"[[2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",329253,2746.9982096354165,8.668039999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::cat,329265,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",329265,1486.9085286458333,25.74602666666667
None,None,None,None,None,None,kernel_1,329266,613.7975260416666,9.823426666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::neg,329276,"[[2048, 4, 5, 128], [2048, 1, 1, 128], [2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",329276,1414.9705403645833,9.91264
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::cat,329287,"[[2048, 4, 5, 128], [[2048, 4, 5, 64], [2048, 4, 5, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",329287,1228.8167317708333,26.265786666666674
None,None,None,None,None,None,kernel_1,329288,512.16748046875,9.893399999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::baddbmm,329303,"[[20, 2048, 2048], [20, 2048, 128], [20, 128, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329303,4142.3984375,67.38138666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,ScaledUpperTriangMaskedSoftmax,329306,"[[20, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",329306,2271.9864908854165,109.44094666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::bmm,329323,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329323,2983.9358723958335,65.45416000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329331,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",329331,731.6953125,15.027813333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mm,329340,"[[8192, 640], [640, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329340,3019.4345703125,73.4780266666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,record_param_comms,329344,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",329344,1553.7229817708333,3096.056133333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add,329350,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329350,38.0048828125,71.45647999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::linalg_vector_norm,329351,"[[2048, 4, 5120], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",329351,38.6552734375,33.90520000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329352,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",329352,40.107584635416664,1.631573333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add,329353,"[[2048, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",329353,30.75146484375,1.3938666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::div,329354,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",329354,30.577311197916668,113.32990666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329355,"[[5120], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",329355,42.292805989583336,109.53400000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329361,"[[], [], []]",Memcpy HtoD (Pageable -> Device),329361,23.072102864583332,0.7475066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mm,329375,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329375,4202.695149739583,269.1324533333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add,329377,"[[2048, 4, 2560], [2560], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",329377,49.439778645833336,55.939653333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::gelu,329378,"[[2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",329378,42.985677083333336,35.99789333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mm,329386,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329386,85.65120442708333,262.4197466666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,record_param_comms,329390,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",329390,55.190755208333336,3114.2541066666654
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add,329398,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",329398,37.85546875,108.64528000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add,329400,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329400,38.64404296875,69.96995999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::sum,329407,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",329407,97.0654296875,42.609120000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329411,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329411,39.616048177083336,1.7885733333333327
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mm,329423,"[[5120, 8192], [8192, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329423,97.55631510416667,284.95518666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mm,329430,"[[8192, 5120], [5120, 2560]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329430,100.03108723958333,264.96648000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329442,"[[5120, 2560], [5120, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329442,39.69189453125,19.88956
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::gelu_backward,329445,"[[2048, 4, 2560], [2048, 4, 2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul>)",329445,37.427734375,46.940599999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::sum,329448,"[[2048, 4, 2560], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",329448,98.7080078125,28.64696000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329452,"[[2560], [2560], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329452,33.53662109375,1.562866666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mm,329462,"[[2560, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329462,103.62369791666667,284.6006266666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mm,329469,"[[8192, 2560], [2560, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329469,102.21744791666667,258.21112000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329481,"[[2560, 5120], [2560, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329481,42.527994791666664,20.758826666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,record_param_comms,329485,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",329485,63.722005208333336,3119.409093333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329490,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",329490,42.20751953125,108.04322666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329491,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",329491,43.830403645833336,70.03438666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::sum,329492,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",329492,108.2861328125,40.66906666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329496,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329496,47.882975260416664,1.8068933333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::neg,329499,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",329499,31.177571614583332,51.652093333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::div,329500,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",329500,38.998046875,117.03468000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::div,329501,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",329501,39.017415364583336,116.50001333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329502,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",329502,38.96533203125,70.06737333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::div,329503,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",329503,43.381022135416664,118.29621333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::sum,329504,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",329504,47.463541666666664,36.445973333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add,329505,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329505,47.6484375,65.51305333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329510,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",329510,46.761393229166664,1.8922266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::div,329513,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",329513,30.60205078125,116.23132000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::eq,329514,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",329514,38.667154947916664,1.8756266666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::masked_fill_,329515,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",329515,31.070963541666668,119.19951999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329518,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",329518,38.8359375,110.26731999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329519,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329519,44.0537109375,68.43411999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mm,329533,"[[5120, 8192], [8192, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,329533,44.702473958333336,85.13318666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mm,329540,"[[8192, 5120], [5120, 640]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329540,120.1806640625,79.85405333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329552,"[[5120, 640], [5120, 640], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329552,44.266764322916664,6.617066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::bmm,329571,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329571,104.87483723958333,59.32183999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::bmm,329574,"[[20, 2048, 128], [20, 128, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329574,105.94075520833333,68.24025333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,ScaledUpperTriangMaskedSoftmaxBackward,329592,"[[20, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",329592,38.857584635416664,177.9210266666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::bmm,329609,"[[20, 2048, 2048], [20, 2048, 128]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329609,104.49039713541667,64.63879999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329611,"[[20, 2048, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",329611,39.189453125,8.211533333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::bmm,329614,"[[20, 128, 2048], [20, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329614,108.17936197916667,60.09410666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329616,"[[20, 128, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",329616,47.530924479166664,8.130800000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329640,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",329640,38.900716145833336,32.710960000000014
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329644,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",329644,33.214518229166664,32.44166666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::neg,329647,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",329647,30.15478515625,7.698266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::fill_,329654,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",329654,30.05908203125,4.436
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329657,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",329657,30.515950520833332,19.718946666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329658,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",329658,35.092447916666664,36.219879999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::fill_,329665,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",329665,37.857259114583336,4.380986666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329668,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",329668,35.243489583333336,19.891800000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329669,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",329669,36.565592447916664,35.644133333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329673,"[[2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",329673,32.138509114583336,16.528493333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329677,"[[[2048, 4, 5, 64], [2048, 4, 5, 64]], [2048, 4, 5, 128], [2048, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",329677,30.517903645833332,13.334506666666671
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::neg,329680,"[[2048, 4, 5, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",329680,30.485026041666668,7.2822
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::fill_,329687,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",329687,30.5498046875,4.3942
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329690,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",329690,35.670735677083336,7.652186666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329691,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",329691,36.243489583333336,16.17893333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::fill_,329698,"[[2048, 4, 5, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",329698,36.031901041666664,4.3707199999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::copy_,329701,"[[2048, 4, 5, 64], [2048, 4, 5, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",329701,33.069173177083336,8.48761333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329702,"[[2048, 4, 5, 128], [2048, 4, 5, 128], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",329702,32.447102864583336,15.54804
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::cat,329705,"[[[2048, 4, 5, 128], [2048, 4, 5, 128], [2048, 4, 5, 128]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",329705,30.475260416666668,73.23604000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mm,329719,"[[1920, 8192], [8192, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329719,106.0048828125,202.24127999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mm,329726,"[[8192, 1920], [1920, 5120]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,329726,107.25244140625,189.47462666666658
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329738,"[[1920, 5120], [1920, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329738,45.375651041666664,15.824839999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,record_param_comms,329742,"[[[2048, 4, 5120]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",329742,62.985188802083336,3106.9193733333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329747,"[[2048, 4, 5120], [5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",329747,53.151204427083336,108.15115999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329748,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",329748,42.005208333333336,70.07536
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::sum,329749,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",329749,106.61116536458333,41.15834666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329753,"[[5120], [5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329753,47.90478515625,1.8073466666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::neg,329756,"[[2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",329756,34.21826171875,51.662359999999985
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::div,329757,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",329757,47.413248697916664,116.9262933333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::div,329758,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",329758,47.626302083333336,116.54790666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329759,"[[2048, 4, 5120], [2048, 4, 5120]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",329759,48.181640625,69.97293333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::div,329760,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",329760,46.96435546875,121.09226666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::sum,329761,"[[2048, 4, 5120], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",329761,47.33935546875,36.49962666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329762,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329762,47.59375,64.12473333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329767,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",329767,47.443359375,1.857693333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::div,329770,"[[2048, 4, 5120], [2048, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",329770,33.781087239583336,116.64384000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::eq,329771,"[[2048, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",329771,47.305989583333336,1.8372000000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::masked_fill_,329772,"[[2048, 4, 5120], [2048, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",329772,34.293294270833336,119.19829333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::mul,329775,"[[2048, 4, 1], [2048, 4, 5120]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",329775,46.964680989583336,110.29041333333329
autograd::engine::evaluate_function: CheckpointFunctionBackward,329116,,aten::add_,329776,"[[2048, 4, 5120], [2048, 4, 5120], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",329776,38.836751302083336,68.39988000000002
