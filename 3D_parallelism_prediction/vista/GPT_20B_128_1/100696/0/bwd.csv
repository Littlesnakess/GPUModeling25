cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::fill_,728887,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",728887,0,2.80916
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::copy_,728896,"[[], [], []]",Memcpy HtoD (Pageable -> Device),728896,4983.942545572917,0.7637333333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::native_layer_norm,728901,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",728901,2369.14208984375,91.09125333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::native_layer_norm,728908,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",728908,37.515462239583336,91.28280000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::addmm,728923,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,728923,1712.8917643229167,572.4671733333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::copy_,728948,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),728948,123.34814453125,2.8317733333333353
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::copy_,728952,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),728952,1024.0634765625,2.90132
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::neg,728962,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",728962,2723.6446940104165,7.490066666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::cat,728974,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",728974,1545.8331705729167,16.23498666666667
None,None,None,None,None,None,kernel_1,728975,842.9129231770834,7.024186666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::neg,728985,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",728985,1388.73388671875,9.320066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::cat,728996,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",728996,1242.4192708333333,16.19014666666667
None,None,None,None,None,None,kernel_1,728997,739.4498697916666,6.988319999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::cat,729003,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",729003,1424.7864583333333,66.17162666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::cat,729004,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",729004,28.29833984375,66.59094666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::baddbmm,729014,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,729014,1220.89599609375,213.0699333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,ScaledUpperTriangMaskedSoftmax,729017,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",729017,41.994791666666664,335.20212
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::bmm,729034,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,729034,83.76188151041667,184.2218266666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::copy_,729042,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",729042,40.309407552083336,34.520520000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mm,729051,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,729051,83.0380859375,193.24580000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add,729056,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",729056,48.87548828125,131.15452
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mm,729068,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,729068,86.34505208333333,795.1232000000001
None,None,None,None,None,None,kernel_2,729072,36.009602864583336,87.92295999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mm,729083,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,729083,95.47607421875,795.8114000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add,729088,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",729088,36.404947916666664,128.94302666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add,731650,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",731650,36.1279296875,83.42713333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,record_param_comms,731653,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",731653,57.642578125,3218.647106666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add,731658,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",731658,49.25732421875,85.47847999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::sum,731669,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",731669,97.44921875,46.98541333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,731673,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",731673,36.779296875,1.8295066666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mm,731683,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,731683,102.29248046875,726.9344533333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mm,731690,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,731690,118.77360026041667,783.8930799999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,731702,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",731702,45.630696614583336,59.10813333333334
None,None,None,None,None,None,kernel_3,731706,39.606282552083336,95.55709333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::sum,731710,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",731710,107.28352864583333,46.18925333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,731714,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",731714,37.514485677083336,1.8500133333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mm,731724,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,731724,104.69287109375,714.3133866666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mm,731731,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,731731,119.77408854166667,773.4936800000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,731743,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",731743,37.279296875,59.09484000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,record_param_comms,731747,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",731747,66.46337890625,3240.7909066666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::sum,731754,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",731754,94.6884765625,49.663973333333324
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,731758,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",731758,40.12841796875,1.808186666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mm,731768,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,731768,2230.14453125,208.02501333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mm,731775,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,731775,105.88736979166667,189.0231066666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,731787,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",731787,37.013834635416664,14.28177333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::bmm,731806,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,731806,105.59912109375,174.72304000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::bmm,731809,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,731809,109.77083333333333,208.05190666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,ScaledUpperTriangMaskedSoftmaxBackward,731827,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",731827,40.372884114583336,558.3655333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::bmm,731844,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,731844,109.994140625,178.7418533333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mul,731846,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",731846,41.13037109375,16.89754666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::bmm,731849,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,731849,106.66682942708333,173.69019999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mul,731851,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",731851,37.206380208333336,16.964480000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mul,731891,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",731891,34.240397135416664,11.63769333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mul,731895,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",731895,31.679361979166668,10.676813333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::neg,731898,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",731898,35.60546875,5.326039999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::fill_,731905,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",731905,33.749837239583336,3.1718266666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::copy_,731908,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",731908,34.450358072916664,12.806239999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,731909,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",731909,29.471354166666668,23.320933333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::fill_,731916,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",731916,27.658203125,3.112520000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::copy_,731919,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",731919,27.328776041666668,12.98382666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,731920,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",731920,27.765787760416668,23.095653333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mul,731924,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",731924,29.323404947916668,12.002839999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mul,731928,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",731928,35.62548828125,10.161853333333339
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::neg,731931,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",731931,32.917805989583336,5.405826666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::fill_,731938,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",731938,33.322265625,3.1398266666666674
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::copy_,731941,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",731941,30.558756510416668,5.790613333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,731942,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",731942,27.956217447916668,10.361546666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::fill_,731949,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",731949,27.945475260416668,3.1056400000000024
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::copy_,731952,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",731952,27.6171875,5.945133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,731953,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",731953,29.876302083333332,10.241213333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::fill_,731960,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",731960,31.87060546875,8.75174666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::copy_,731963,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",731963,35.275716145833336,64.82965333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::fill_,731970,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",731970,42.36767578125,8.965039999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::copy_,731973,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",731973,31.539876302083332,22.904093333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,731974,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",731974,27.6689453125,19.57318666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::fill_,731981,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",731981,34.5400390625,8.926586666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::copy_,731984,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",731984,27.710774739583332,29.45853333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::fill_,731991,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",731991,42.72900390625,9.018773333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::copy_,731994,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",731994,38.548177083333336,11.535240000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,731995,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",731995,36.832356770833336,19.621773333333344
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::cat,731998,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",731998,45.354329427083336,146.80402666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mm,732012,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732012,102.33479817708333,544.2801333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::mm,732016,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732016,116.29654947916667,543.1627466666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::sum,732020,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",732020,104.34977213541667,36.66357333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,732024,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732024,37.216145833333336,1.8491599999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,732032,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732032,31.924967447916668,42.639800000000015
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,record_param_comms,732040,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",732040,74.63297526041667,3258.260239999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::native_layer_norm_backward,732045,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",732045,53.215657552083336,140.87035999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::native_layer_norm_backward,732045,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",732045,43.85107421875,88.81710666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add,732049,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732049,43.520833333333336,78.93262666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,732052,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732052,44.329915364583336,1.8508800000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,732055,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732055,31.838704427083332,1.7279866666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::native_layer_norm_backward,732058,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",732058,31.6923828125,137.46053333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::native_layer_norm_backward,732058,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",732058,43.5302734375,89.00699999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,732062,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732062,43.626302083333336,77.68670666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,732069,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732069,43.924153645833336,1.8487466666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,728882,,aten::add_,732072,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732072,27.914388020833332,1.7459200000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::fill_,732078,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",732078,3379.0421549479165,2.5531600000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::copy_,732087,"[[], [], []]",Memcpy HtoD (Pageable -> Device),732087,4922.698404947917,0.7586133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::native_layer_norm,732092,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",732092,2341.3017578125,91.70520000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::native_layer_norm,732099,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",732099,33.26953125,91.38946666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::addmm,732114,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732114,1274.27197265625,571.89932
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::copy_,732139,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),732139,115.01708984375,3.420573333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::copy_,732143,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),732143,1007.58642578125,2.734906666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::neg,732153,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732153,2600.1451822916665,7.545920000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::cat,732165,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",732165,1451.8079427083333,16.21622666666667
None,None,None,None,None,None,kernel_1,732166,805.0891927083334,7.007493333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::neg,732176,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732176,1383.7019856770833,9.326453333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::cat,732187,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",732187,1206.537109375,16.201200000000004
None,None,None,None,None,None,kernel_1,732188,681.0734049479166,6.9558800000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::cat,732194,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",732194,1402.0452473958333,66.16133333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::cat,732195,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",732195,28.020833333333332,66.63405333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::baddbmm,732205,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,732205,1150.1663411458333,213.0741333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,ScaledUpperTriangMaskedSoftmax,732208,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",732208,41.963216145833336,335.26908000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::bmm,732225,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,732225,851.7361653645834,184.20270666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::copy_,732233,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732233,40.62890625,34.538799999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mm,732242,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,732242,101.18180338541667,193.09475999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add,732247,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",732247,48.4892578125,131.14298666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mm,732259,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732259,86.43196614583333,794.2724933333334
None,None,None,None,None,None,kernel_2,732263,36.33154296875,87.85969333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mm,732274,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732274,94.59244791666667,795.1710933333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add,732279,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",732279,36.45849609375,128.84271999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add,732281,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732281,36.619140625,83.41517333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,record_param_comms,732284,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",732284,58.1396484375,3217.9733866666656
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add,732289,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732289,49.40625,85.52376000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::sum,732300,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",732300,97.38411458333333,46.93967999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732304,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732304,37.2041015625,1.7757733333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mm,732314,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732314,100.90625,727.0271066666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mm,732321,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732321,113.865234375,783.4494000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732333,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732333,44.92724609375,58.999786666666644
None,None,None,None,None,None,kernel_3,732337,40.320149739583336,95.68634666666661
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::sum,732341,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",732341,102.10970052083333,46.29548
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732345,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732345,37.108723958333336,1.8103466666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mm,732355,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732355,105.49300130208333,714.1819066666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mm,732362,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732362,113.48160807291667,773.39548
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732374,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732374,37.118977864583336,59.04889333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,record_param_comms,732378,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",732378,67.50944010416667,3239.180280000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::sum,732385,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",732385,95.06966145833333,49.57353333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732389,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732389,39.69970703125,1.7962666666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mm,732399,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,732399,101.4091796875,208.0531466666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mm,732406,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,732406,104.15869140625,188.96684000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732418,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732418,37.013671875,14.201053333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::bmm,732437,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,732437,102.51627604166667,174.61605333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::bmm,732440,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,732440,108.60709635416667,207.9212933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,ScaledUpperTriangMaskedSoftmaxBackward,732458,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",732458,41.332356770833336,558.1897733333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::bmm,732475,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,732475,110.67692057291667,178.75718666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mul,732477,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",732477,40.43701171875,16.942813333333344
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::bmm,732480,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,732480,104.59765625,173.62315999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mul,732482,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",732482,37.791178385416664,16.952146666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mul,732522,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",732522,34.539225260416664,11.738359999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mul,732526,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",732526,31.679361979166668,10.675546666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::neg,732529,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732529,35.254231770833336,5.336266666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::fill_,732536,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",732536,34.334147135416664,3.173040000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::copy_,732539,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732539,34.8681640625,12.808893333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732540,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",732540,29.237630208333332,23.303866666666647
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::fill_,732547,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",732547,28.236002604166668,3.1061066666666686
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::copy_,732550,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732550,27.360677083333332,13.025599999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732551,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",732551,27.678873697916668,23.075639999999993
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mul,732555,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",732555,28.777669270833332,12.004639999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mul,732559,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",732559,35.358072916666664,10.142626666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::neg,732562,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732562,33.53662109375,5.4531333333333345
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::fill_,732569,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",732569,33.675130208333336,3.1445333333333347
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::copy_,732572,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732572,31.272135416666668,5.795799999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732573,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",732573,27.94677734375,10.378160000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::fill_,732580,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",732580,28.08544921875,3.1009866666666692
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::copy_,732583,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732583,27.446451822916668,5.946346666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732584,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",732584,31.048990885416668,10.26977333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::fill_,732591,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",732591,31.561848958333332,8.73764
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::copy_,732594,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732594,35.925944010416664,64.74183999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::fill_,732601,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",732601,43.519205729166664,8.957786666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::copy_,732604,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732604,31.263671875,22.89042666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732605,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732605,27.646321614583332,19.495533333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::fill_,732612,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",732612,34.036946614583336,8.917239999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::copy_,732615,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732615,27.934733072916668,29.479439999999983
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::fill_,732622,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",732622,39.402669270833336,8.998346666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::copy_,732625,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732625,35.273274739583336,11.511840000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732626,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732626,34.984700520833336,19.72888
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::cat,732629,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",732629,38.090983072916664,146.79973333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mm,732643,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732643,100.8740234375,544.4742400000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::mm,732647,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732647,111.4765625,543.2527466666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::sum,732651,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",732651,102.14225260416667,36.78261333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732655,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732655,36.958984375,1.8265466666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732663,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732663,31.80908203125,42.65944000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,record_param_comms,732671,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",732671,74.82503255208333,3243.0035599999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::native_layer_norm_backward,732676,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",732676,53.588216145833336,140.77056000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::native_layer_norm_backward,732676,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",732676,44.490559895833336,88.85852
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add,732680,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732680,43.563151041666664,78.951
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732683,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732683,43.465169270833336,1.903773333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732686,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732686,31.6787109375,1.697266666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::native_layer_norm_backward,732689,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",732689,31.711588541666668,137.55822666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::native_layer_norm_backward,732689,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",732689,44.224772135416664,88.78078666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732693,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732693,43.82861328125,77.6664266666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732700,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732700,43.87060546875,1.8926666666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,732073,,aten::add_,732703,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732703,28.009765625,1.6776533333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::fill_,732709,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",732709,3355.0515950520835,2.5616933333333343
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::copy_,732718,"[[], [], []]",Memcpy HtoD (Pageable -> Device),732718,4888.193033854167,0.7637333333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::native_layer_norm,732723,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",732723,2311.8751627604165,91.65266666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::native_layer_norm,732730,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",732730,38.934244791666664,91.23246666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::addmm,732745,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732745,1251.626953125,572.2119466666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::copy_,732770,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),732770,122.974609375,2.832186666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::copy_,732774,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),732774,986.60498046875,2.6960933333333323
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::neg,732784,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732784,2623.9332682291665,7.531040000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::cat,732796,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",732796,1445.7890625,16.274186666666672
None,None,None,None,None,None,kernel_1,732797,805.2003580729166,7.0113600000000025
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::neg,732807,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732807,1374.8997395833333,9.34346666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::cat,732818,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",732818,1204.7908528645833,16.186760000000007
None,None,None,None,None,None,kernel_1,732819,674.8955078125,6.965280000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::cat,732825,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",732825,1413.3955078125,66.14421333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::cat,732826,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",732826,28.212727864583332,66.59574666666671
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::baddbmm,732836,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,732836,1099.9357096354167,213.1586133333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,ScaledUpperTriangMaskedSoftmax,732839,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",732839,39.999348958333336,335.32201333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::bmm,732856,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,732856,84.65983072916667,184.21857333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::copy_,732864,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",732864,40.254557291666664,34.50713333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mm,732873,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,732873,83.115234375,193.1831466666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add,732878,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",732878,48.190755208333336,131.14718666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mm,732890,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732890,87.33821614583333,794.8992799999999
None,None,None,None,None,None,kernel_2,732894,36.191569010416664,87.85412000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mm,732905,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732905,95.21956380208333,795.0891599999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add,732910,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",732910,36.693359375,128.88755999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add,732912,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732912,36.3193359375,83.37586666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,record_param_comms,732915,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",732915,58.453450520833336,3216.168213333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add,732920,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732920,49.652994791666664,85.54165333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::sum,732931,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",732931,98.19710286458333,46.79045333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,732935,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732935,37.119954427083336,1.7932666666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mm,732945,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732945,103.71142578125,727.6059733333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mm,732952,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732952,115.15592447916667,784.0940933333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,732964,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732964,44.843424479166664,59.205853333333316
None,None,None,None,None,None,kernel_3,732968,39.573893229166664,95.54091999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::sum,732972,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",732972,107.6474609375,46.169146666666684
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,732976,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",732976,36.8525390625,1.8350533333333339
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mm,732986,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732986,106.44156901041667,714.6330000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mm,732993,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,732993,114.52620442708333,773.9322399999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733005,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733005,37.25927734375,59.12729333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,record_param_comms,733009,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",733009,67.68994140625,3261.601893333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::sum,733016,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",733016,96.12630208333333,49.397639999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733020,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733020,40.182454427083336,1.7783466666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mm,733030,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733030,101.2685546875,208.32578666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mm,733037,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733037,102.34554036458333,189.24161333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733049,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733049,36.72412109375,14.243253333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::bmm,733068,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733068,103.70133463541667,174.70489333333342
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::bmm,733071,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733071,107.72281901041667,208.14015999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,ScaledUpperTriangMaskedSoftmaxBackward,733089,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",733089,40.650065104166664,556.9434666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::bmm,733106,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733106,109.03352864583333,178.8240933333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mul,733108,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",733108,41.343587239583336,16.87797333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::bmm,733111,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733111,107.33870442708333,173.66279999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mul,733113,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",733113,36.639485677083336,16.88642666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mul,733153,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",733153,33.751302083333336,11.7674
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mul,733157,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",733157,31.764973958333332,10.676426666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::neg,733160,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733160,35.456217447916664,5.318759999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::fill_,733167,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733167,34.559895833333336,3.171360000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::copy_,733170,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733170,34.697428385416664,12.808919999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733171,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",733171,29.323567708333332,23.31793333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::fill_,733178,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733178,27.700846354166668,3.0996400000000026
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::copy_,733181,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733181,27.146809895833332,12.976079999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733182,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",733182,27.58349609375,23.11959999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mul,733186,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",733186,29.204427083333332,12.02336
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mul,733190,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",733190,35.179361979166664,10.143066666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::neg,733193,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733193,33.558756510416664,5.418186666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::fill_,733200,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733200,34.15380859375,3.1342800000000013
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::copy_,733203,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733203,31.102864583333332,5.80008
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733204,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",733204,27.627278645833332,10.367493333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::fill_,733211,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733211,28.019856770833332,3.1022666666666683
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::copy_,733214,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733214,27.4775390625,5.944266666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733215,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",733215,31.028483072916668,10.271773333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::fill_,733222,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733222,31.689778645833332,8.734666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::copy_,733225,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733225,35.820963541666664,64.81489333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::fill_,733232,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733232,42.708821614583336,8.962053333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::copy_,733235,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733235,31.828287760416668,22.88731999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733236,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733236,27.63623046875,19.604759999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::fill_,733243,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733243,34.603515625,8.946706666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::copy_,733246,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733246,28.0947265625,29.600199999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::fill_,733253,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733253,39.2216796875,9.019706666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::copy_,733256,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733256,35.369140625,11.488359999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733257,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733257,35.060546875,19.663959999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::cat,733260,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",733260,37.758626302083336,146.92515999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mm,733274,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,733274,101.41780598958333,544.6875466666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::mm,733278,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,733278,114.228515625,543.9413733333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::sum,733282,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",733282,107.12353515625,36.63593333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733286,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733286,37.47216796875,1.832493333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733294,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733294,31.57177734375,42.62572000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,record_param_comms,733302,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",733302,71.91341145833333,3241.639146666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::native_layer_norm_backward,733307,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",733307,53.375162760416664,140.75482666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::native_layer_norm_backward,733307,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",733307,44.489908854166664,88.83249333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add,733311,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733311,44.095540364583336,79.01569333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733314,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733314,43.893229166666664,1.88244
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733317,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733317,31.97705078125,1.6929866666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::native_layer_norm_backward,733320,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",733320,31.552571614583332,137.51954666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::native_layer_norm_backward,733320,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",733320,43.72314453125,88.73042666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733324,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733324,43.679850260416664,77.67483999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733331,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733331,42.805013020833336,1.853853333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,732704,,aten::add_,733334,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733334,27.9140625,1.7028000000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::fill_,733340,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",733340,3336.4609375,2.5514533333333342
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::copy_,733349,"[[], [], []]",Memcpy HtoD (Pageable -> Device),733349,4907.7431640625,0.7684266666666661
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::native_layer_norm,733354,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",733354,2268.7413736979165,91.63177333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::native_layer_norm,733361,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",733361,33.1005859375,91.35875999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::addmm,733376,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,733376,1213.3515625,572.5473466666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::copy_,733401,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),733401,117.78125,3.2904533333333346
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::copy_,733405,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),733405,1001.43310546875,2.7967733333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::neg,733415,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733415,2643.4319661458335,7.518706666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::cat,733427,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",733427,1477.1494140625,16.201600000000003
None,None,None,None,None,None,kernel_1,733428,817.3284505208334,7.002853333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::neg,733438,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733438,1372.8816731770833,9.307226666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::cat,733449,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",733449,1164.171875,16.174733333333343
None,None,None,None,None,None,kernel_1,733450,713.7633463541666,6.960146666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::cat,733456,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",733456,1401.7706705729167,66.15872
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::cat,733457,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",733457,28.061686197916668,66.65633333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::baddbmm,733467,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733467,1107.34912109375,213.09380000000013
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,ScaledUpperTriangMaskedSoftmax,733470,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",733470,41.8876953125,335.20936000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::bmm,733487,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733487,84.83072916666667,184.14428
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::copy_,733495,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733495,40.73583984375,34.59762666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mm,733504,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733504,83.828125,193.38113333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add,733509,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",733509,48.566080729166664,131.21033333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mm,733521,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,733521,86.69710286458333,795.4594533333332
None,None,None,None,None,None,kernel_2,733525,35.9775390625,87.85974666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mm,733536,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,733536,96.43684895833333,795.9479733333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add,733541,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",733541,36.30908203125,128.88169333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add,733543,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733543,36.41650390625,83.50934666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,record_param_comms,733546,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",733546,56.215169270833336,3223.203866666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add,733551,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733551,49.972819010416664,85.54973333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::sum,733562,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",733562,98.04606119791667,46.54337333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733566,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733566,36.298177083333336,1.8120399999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mm,733576,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,733576,101.50406901041667,727.5147733333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mm,733583,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,733583,116.42415364583333,784.3556133333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733595,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733595,45.322102864583336,59.03561333333332
None,None,None,None,None,None,kernel_3,733599,39.55078125,95.62879999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::sum,733603,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",733603,105.39713541666667,46.14654666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733607,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733607,36.98095703125,1.8103199999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mm,733617,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,733617,103.42268880208333,715.1231466666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mm,733624,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,733624,113.37548828125,774.1903333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733636,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733636,36.938802083333336,59.07956000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,nccl:all_reduce,733641,"[[2048, 4, 6144]]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",733640,66.15462239583333,3244.068506666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::sum,733647,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",733647,95.52978515625,49.57565333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733651,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733651,40.15966796875,1.797546666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mm,733661,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733661,100.44759114583333,208.28401333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mm,733668,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733668,102.41943359375,189.2044666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733680,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733680,36.640462239583336,14.282493333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::bmm,733699,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733699,104.90690104166667,174.65101333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::bmm,733702,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733702,106.05745442708333,208.32024
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,ScaledUpperTriangMaskedSoftmaxBackward,733720,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",733720,41.013346354166664,552.7438133333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::bmm,733737,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733737,109.89762369791667,178.99106666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mul,733739,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",733739,41.95166015625,16.920586666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::bmm,733742,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,733742,105.92936197916667,173.60483999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mul,733744,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",733744,37.215983072916664,16.95520000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mul,733784,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",733784,34.5078125,11.692279999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mul,733788,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",733788,31.7421875,10.650786666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::neg,733791,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733791,34.400716145833336,5.318719999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::fill_,733798,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733798,34.186197916666664,3.1667066666666686
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::copy_,733801,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733801,35.080729166666664,12.813999999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733802,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",733802,29.206705729166668,23.28641333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::fill_,733809,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733809,27.99951171875,3.106106666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::copy_,733812,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733812,27.04150390625,13.000386666666671
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733813,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",733813,27.82958984375,23.071413333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mul,733817,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",733817,29.909830729166668,12.018613333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mul,733821,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",733821,34.986328125,10.15153333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::neg,733824,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733824,33.6865234375,5.443799999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::fill_,733831,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733831,33.56787109375,3.1453733333333354
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::copy_,733834,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733834,30.52587890625,5.795386666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733835,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",733835,27.712890625,10.377720000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::fill_,733842,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733842,28.159505208333332,3.095880000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::copy_,733845,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733845,27.446126302083332,5.930599999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733846,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",733846,30.7197265625,10.259533333333339
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::fill_,733853,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733853,32.44677734375,8.735880000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::copy_,733856,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733856,35.808268229166664,64.82972000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::fill_,733863,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733863,42.474609375,8.95905333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::copy_,733866,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733866,31.68994140625,22.902000000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733867,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733867,27.753580729166668,19.557373333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::fill_,733874,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733874,34.015625,8.927119999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::copy_,733877,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733877,27.9765625,29.505760000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::fill_,733884,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",733884,39.263997395833336,8.978279999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::copy_,733887,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",733887,35.359049479166664,11.520786666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733888,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733888,35.401692708333336,19.634613333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::cat,733891,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",733891,37.803873697916664,146.91668
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mm,733905,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,733905,107.13427734375,544.9247866666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::mm,733909,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,733909,117.19319661458333,544.4584399999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::sum,733913,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",733913,105.52457682291667,36.61358666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733917,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733917,36.788411458333336,1.8107599999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733925,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733925,31.754557291666668,42.65562666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,record_param_comms,733933,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",733933,75.11376953125,3250.204373333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::native_layer_norm_backward,733938,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",733938,53.248209635416664,140.84777333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::native_layer_norm_backward,733938,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",733938,45.15185546875,88.87985333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add,733942,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733942,44.148763020833336,78.96888000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733945,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733945,43.893717447916664,1.8675066666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733948,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733948,31.572265625,1.6823199999999991
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::native_layer_norm_backward,733951,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",733951,31.766927083333332,137.44135999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::native_layer_norm_backward,733951,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",733951,44.41552734375,88.82476000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733955,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733955,44.5009765625,77.63594666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733962,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733962,43.88330078125,1.8841333333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,733335,,aten::add_,733965,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",733965,27.96630859375,1.6836266666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::fill_,733971,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",733971,3334.0078125,2.5471866666666676
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::copy_,733980,"[[], [], []]",Memcpy HtoD (Pageable -> Device),733980,4861.513346354167,0.7761066666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::native_layer_norm,733985,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",733985,2296.2399088541665,91.60405333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::native_layer_norm,733992,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",733992,49.951334635416664,91.29557333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::addmm,734007,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734007,1251.95703125,572.8200133333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::copy_,734032,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),734032,122.25048828125,2.8440933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::copy_,734036,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),734036,1010.2314453125,2.6841333333333344
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::neg,734046,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734046,2593.1516927083335,7.538253333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::cat,734058,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",734058,1432.9908854166667,16.239213333333335
None,None,None,None,None,None,kernel_1,734059,804.3447265625,7.020306666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::neg,734069,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734069,1393.8992513020833,9.325986666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::cat,734080,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",734080,1187.14453125,16.201640000000005
None,None,None,None,None,None,kernel_1,734081,679.62109375,6.97597333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::cat,734087,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",734087,1372.7766927083333,66.31753333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::cat,734088,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",734088,29.780110677083332,66.65706666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::baddbmm,734098,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734098,1090.6474609375,213.39708000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,ScaledUpperTriangMaskedSoftmax,734101,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",734101,40.117024739583336,335.37448
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::bmm,734118,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734118,85.14241536458333,184.23681333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::copy_,734126,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734126,41.001302083333336,34.60920000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mm,734135,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734135,83.88264973958333,193.42076
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add,734140,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",734140,48.26708984375,131.1723066666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mm,734152,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734152,86.66666666666667,795.6033199999998
None,None,None,None,None,None,kernel_2,734156,36.436686197916664,87.9804
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mm,734167,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734167,96.40559895833333,796.2224133333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add,734172,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",734172,36.117513020833336,128.91269333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add,734174,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734174,35.913736979166664,83.50482666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,record_param_comms,734177,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",734177,59.37109375,3229.463386666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add,734182,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734182,49.344075520833336,85.64319999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::sum,734193,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",734193,98.03678385416667,46.74509333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734197,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734197,37.248046875,1.8256933333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mm,734207,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734207,103.33707682291667,727.9580666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mm,734214,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734214,116.81005859375,784.3155066666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734226,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734226,45.172526041666664,59.09224000000001
None,None,None,None,None,None,kernel_3,734230,39.94677734375,95.63395999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::sum,734234,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",734234,106.03662109375,46.30968000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734238,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734238,36.927083333333336,1.8265466666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mm,734248,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734248,103.99837239583333,715.2932933333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mm,734255,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734255,113.75927734375,773.9915599999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734267,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734267,37.066243489583336,59.10870666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,record_param_comms,734271,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",734271,67.22102864583333,3248.7169999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::sum,734278,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",734278,94.70784505208333,49.45310666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734282,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734282,40.202962239583336,1.7719199999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mm,734292,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734292,101.6533203125,208.4768933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mm,734299,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734299,101.138671875,189.20114666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734311,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734311,36.619303385416664,14.185266666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::bmm,734330,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734330,101.26790364583333,174.55798666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::bmm,734333,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734333,104.755859375,208.36117333333343
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,ScaledUpperTriangMaskedSoftmaxBackward,734351,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",734351,41.012532552083336,552.7378399999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::bmm,734368,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734368,106.45279947916667,178.90909333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mul,734370,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",734370,40.895833333333336,16.864693333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::bmm,734373,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734373,106.93391927083333,173.66503999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mul,734375,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",734375,37.204752604166664,16.91889333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mul,734415,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",734415,34.251790364583336,11.690080000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mul,734419,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",734419,31.722330729166668,10.633306666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::neg,734422,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734422,34.901041666666664,5.323506666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::fill_,734429,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",734429,34.111328125,3.1611200000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::copy_,734432,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734432,35.20849609375,12.793519999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734433,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",734433,29.642415364583332,23.29243999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::fill_,734440,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",734440,27.85009765625,3.106093333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::copy_,734443,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734443,27.372233072916668,12.999106666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734444,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",734444,27.6904296875,23.109293333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mul,734448,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",734448,29.1416015625,12.010520000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mul,734452,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",734452,35.44384765625,10.155466666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::neg,734455,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734455,33.941243489583336,5.429679999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::fill_,734462,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",734462,33.557291666666664,3.1329866666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::copy_,734465,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734465,30.921061197916668,5.805173333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734466,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",734466,27.733723958333332,10.361546666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::fill_,734473,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",734473,27.870442708333332,3.1039733333333355
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::copy_,734476,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734476,27.446940104166668,5.963493333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734477,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",734477,31.03857421875,10.283826666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::fill_,734484,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",734484,30.473795572916668,8.764919999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::copy_,734487,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734487,35.509928385416664,64.71402666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::fill_,734494,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",734494,42.5810546875,8.951413333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::copy_,734497,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734497,31.4873046875,22.911373333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734498,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734498,27.68994140625,19.582106666666657
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::fill_,734505,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",734505,34.677408854166664,8.944946666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::copy_,734508,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734508,27.732584635416668,29.538693333333327
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::fill_,734515,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",734515,39.922688802083336,9.02436
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::copy_,734518,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734518,35.849772135416664,11.523346666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734519,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734519,34.858723958333336,19.63677333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::cat,734522,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",734522,37.632486979166664,146.94517333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mm,734536,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734536,102.1650390625,544.9482666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::mm,734540,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734540,111.67919921875,544.4090133333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::sum,734544,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",734544,100.541015625,36.70450666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734548,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734548,36.916178385416664,1.836346666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734556,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734556,31.787434895833332,42.65827999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,record_param_comms,734564,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",734564,72.53141276041667,3242.80388
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::native_layer_norm_backward,734569,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",734569,53.033203125,140.77821333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::native_layer_norm_backward,734569,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",734569,43.743326822916664,88.85641333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add,734573,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734573,43.87255859375,79.02609333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734576,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734576,43.91357421875,1.8529866666666657
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734579,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734579,31.658203125,1.6878799999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::native_layer_norm_backward,734582,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",734582,31.351236979166668,137.46430666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::native_layer_norm_backward,734582,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",734582,44.542643229166664,88.78476000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734586,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734586,43.818522135416664,77.72424000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734593,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734593,43.83935546875,1.843613333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,733966,,aten::add_,734596,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734596,27.678873697916668,1.6844666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::fill_,734602,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",734602,3322.1061197916665,2.5582800000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::copy_,734611,"[[], [], []]",Memcpy HtoD (Pageable -> Device),734611,4903.112630208333,0.7714133333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::native_layer_norm,734616,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",734616,2270.46630859375,91.56698666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::native_layer_norm,734623,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",734623,41.994791666666664,91.44452000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::addmm,734638,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734638,1247.41162109375,572.5921733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::copy_,734663,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),734663,105.42854817708333,2.7950666666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::copy_,734667,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),734667,1025.9539388020833,2.6576800000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::neg,734677,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734677,2626.1227213541665,7.519893333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::cat,734689,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",734689,1446.3328450520833,16.23326666666667
None,None,None,None,None,None,kernel_1,734690,809.3816731770834,7.016413333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::neg,734700,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734700,1385.5662434895833,9.316586666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::cat,734711,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",734711,1199.5089518229167,16.15689333333334
None,None,None,None,None,None,kernel_1,734712,679.6946614583334,6.949493333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::cat,734718,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",734718,1390.1114908854167,66.2018
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::cat,734719,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",734719,28.075358072916668,66.59390666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::baddbmm,734729,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734729,1098.8382161458333,213.18720000000008
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,ScaledUpperTriangMaskedSoftmax,734732,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",734732,41.60986328125,335.17734666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::bmm,734749,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734749,84.27718098958333,184.08709333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::copy_,734757,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",734757,40.767740885416664,34.59125333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mm,734766,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734766,83.11474609375,193.3345733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add,734771,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",734771,47.903971354166664,131.13524
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mm,734783,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734783,86.88916015625,795.4433200000002
None,None,None,None,None,None,kernel_2,734787,36.212239583333336,87.98896
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mm,734798,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734798,95.4453125,795.6322933333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add,734803,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",734803,36.052897135416664,128.8603333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add,734805,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734805,36.300130208333336,83.59555999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,record_param_comms,734808,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",734808,58.352864583333336,3254.502133333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add,734813,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734813,49.684733072916664,85.57061333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::sum,734824,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",734824,97.41975911458333,46.93498666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,734828,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734828,37.5771484375,1.8154666666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mm,734838,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734838,101.85595703125,727.8966266666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mm,734845,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734845,117.29931640625,783.85516
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,734857,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734857,44.789388020833336,59.09530666666666
None,None,None,None,None,None,kernel_3,734861,39.851236979166664,95.69065333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::sum,734865,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",734865,104.92757161458333,46.467013333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,734869,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734869,36.99267578125,1.8209866666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mm,734879,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734879,104.4365234375,714.9161733333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mm,734886,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,734886,115.4873046875,773.5085600000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,734898,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734898,36.49072265625,59.028386666666655
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,record_param_comms,734902,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",734902,66.07991536458333,3267.2294266666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::sum,734909,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",734909,96.20231119791667,49.563266666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,734913,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734913,40.266438802083336,1.8261333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mm,734923,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734923,101.07779947916667,208.36669333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mm,734930,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734930,103.57194010416667,189.24337333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,734942,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",734942,36.553873697916664,14.24328
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::bmm,734961,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734961,102.89990234375,174.73430666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::bmm,734964,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734964,106.50618489583333,208.34502666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,ScaledUpperTriangMaskedSoftmaxBackward,734982,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",734982,40.884765625,553.2123199999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::bmm,734999,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,734999,109.4267578125,178.92353333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mul,735001,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",735001,41.130696614583336,16.881399999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::bmm,735004,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,735004,105.00325520833333,173.61672000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mul,735006,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",735006,37.695963541666664,16.975626666666674
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mul,735046,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",735046,34.0693359375,11.66456
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mul,735050,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",735050,31.957356770833332,10.659346666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::neg,735053,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735053,35.594401041666664,5.3324533333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::fill_,735060,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735060,34.176432291666664,3.1611200000000017
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::copy_,735063,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735063,34.781901041666664,12.789653333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,735064,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",735064,29.184244791666668,23.324293333333323
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::fill_,735071,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735071,27.44384765625,3.1069600000000035
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::copy_,735074,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735074,27.307942708333332,12.97310666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,735075,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",735075,27.712239583333332,23.052133333333323
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mul,735079,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",735079,28.7900390625,12.00293333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mul,735083,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",735083,35.348795572916664,10.143080000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::neg,735086,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735086,33.216959635416664,5.421586666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::fill_,735093,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735093,33.5244140625,3.1300266666666676
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::copy_,735096,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735096,30.569661458333332,5.797479999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,735097,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",735097,27.765299479166668,10.369653333333341
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::fill_,735104,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735104,27.975911458333332,3.1039466666666686
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::copy_,735107,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735107,27.542154947916668,5.9548799999999975
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,735108,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",735108,30.537272135416668,10.242520000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::fill_,735115,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735115,31.914388020833332,8.736306666666671
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::copy_,735118,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735118,35.476725260416664,64.75938666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::fill_,735125,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735125,42.613606770833336,8.959946666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::copy_,735128,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735128,31.78564453125,22.89253333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,735129,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735129,27.5302734375,19.552640000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::fill_,735136,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735136,34.600911458333336,8.945813333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::copy_,735139,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735139,27.945963541666668,29.46629333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::fill_,735146,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735146,39.43359375,9.040146666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::copy_,735149,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735149,35.56103515625,11.550600000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,735150,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735150,34.18798828125,19.633640000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::cat,735153,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",735153,38.730794270833336,146.81848
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mm,735167,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,735167,102.66650390625,544.8624933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::mm,735171,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,735171,116.11637369791667,544.7302666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::sum,735175,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",735175,106.55810546875,36.74978666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,735179,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735179,36.8115234375,1.8457600000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,735187,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735187,31.540852864583332,42.65341333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,record_param_comms,735195,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",735195,71.20930989583333,3279.598466666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::native_layer_norm_backward,735200,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",735200,53.406901041666664,140.89642666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::native_layer_norm_backward,735200,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",735200,44.318684895833336,88.76078666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add,735204,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735204,44.0849609375,78.95873333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,735207,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735207,44.062662760416664,1.8871066666666658
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,735210,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735210,31.710774739583332,1.6836266666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::native_layer_norm_backward,735213,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",735213,31.766438802083332,137.51761333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::native_layer_norm_backward,735213,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",735213,43.574055989583336,88.82225333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,735217,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735217,43.689290364583336,77.58394666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,735224,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735224,44.263997395833336,1.857706666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,734597,,aten::add_,735227,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735227,27.679361979166668,1.6938666666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::fill_,735233,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",735233,3345.0372721354165,2.557
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::copy_,735242,"[[], [], []]",Memcpy HtoD (Pageable -> Device),735242,4851.607259114583,0.7795066666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::native_layer_norm,735247,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",735247,2285.08935546875,91.71027999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::native_layer_norm,735254,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",735254,43.487141927083336,91.32419999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::addmm,735269,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,735269,1209.2928059895833,572.3220933333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::copy_,735294,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),735294,121.95133463541667,2.846253333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::copy_,735298,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),735298,1011.43408203125,2.7549733333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::neg,735308,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735308,2601.7220052083335,7.537426666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::cat,735320,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",735320,1434.697265625,16.180360000000004
None,None,None,None,None,None,kernel_1,735321,812.4812825520834,7.036960000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::neg,735331,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735331,1384.5760091145833,9.352480000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::cat,735342,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",735342,1183.8274739583333,16.18334666666667
None,None,None,None,None,None,kernel_1,735343,700.6246744791666,6.949840000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::cat,735349,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",735349,1407.5275065104167,66.16948000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::cat,735350,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",735350,28.15966796875,66.58838666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::baddbmm,735360,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,735360,1070.62451171875,213.1782933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,ScaledUpperTriangMaskedSoftmax,735363,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",735363,41.502278645833336,335.10868000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::bmm,735380,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,735380,84.86328125,184.11011999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::copy_,735388,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735388,40.628580729166664,34.52514666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mm,735397,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,735397,83.69970703125,193.24201333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add,735402,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",735402,48.555338541666664,131.13868000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mm,735414,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,735414,87.30533854166667,794.7439066666665
None,None,None,None,None,None,kernel_2,735418,35.9052734375,87.88705333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mm,735429,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,735429,95.81803385416667,795.3813199999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add,735434,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",735434,35.956705729166664,128.90977333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add,735436,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735436,36.19189453125,83.50092000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,record_param_comms,735439,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",735439,57.2958984375,3289.356666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add,735444,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735444,49.406901041666664,85.53645333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::sum,735455,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",735455,99.08089192708333,46.880559999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735459,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735459,37.132486979166664,1.8188799999999992
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mm,735469,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,735469,104.0703125,728.24676
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mm,735476,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,735476,118.47623697916667,783.8167466666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735488,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735488,44.72509765625,58.96606666666668
None,None,None,None,None,None,kernel_3,735492,39.232259114583336,95.65357333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::sum,735496,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",735496,106.29182942708333,46.32014666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735500,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735500,36.6396484375,1.7881600000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mm,735510,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,735510,106.1015625,715.1027333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mm,735517,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,735517,115.33723958333333,773.7436799999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735529,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735529,37.045247395833336,59.11919999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,record_param_comms,735533,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",735533,65.40706380208333,3290.5594799999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::sum,735540,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",735540,95.10205078125,49.51168000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735544,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735544,40.43798828125,1.7642266666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mm,735554,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,735554,102.271484375,208.35392
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mm,735561,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,735561,104.38330078125,189.13574666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735573,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735573,37.236490885416664,14.25650666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::bmm,735592,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,735592,105.44108072916667,174.66469333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::bmm,735595,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,735595,109.66373697916667,208.22293333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,ScaledUpperTriangMaskedSoftmaxBackward,735613,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",735613,40.789713541666664,553.1734666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::bmm,735630,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,735630,108.42659505208333,178.93425333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mul,735632,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",735632,41.407063802083336,16.906053333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::bmm,735635,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,735635,103.45556640625,173.62875999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mul,735637,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",735637,37.908040364583336,16.947933333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mul,735677,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",735677,34.4443359375,11.695706666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mul,735681,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",735681,31.561197916666668,10.655413333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::neg,735684,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735684,35.2548828125,5.334973333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::fill_,735691,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735691,34.656412760416664,3.1607200000000018
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::copy_,735694,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735694,33.821451822916664,12.812333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735695,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",735695,30.517903645833332,23.32433333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::fill_,735702,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735702,27.882649739583332,3.100560000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::copy_,735705,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735705,27.403483072916668,12.99228
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735706,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",735706,27.56298828125,23.063746666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mul,735710,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",735710,29.140787760416668,12.0054
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mul,735714,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",735714,35.946614583333336,10.126000000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::neg,735717,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735717,33.834147135416664,5.451039999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::fill_,735724,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735724,33.49365234375,3.1295733333333344
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::copy_,735727,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735727,31.092447916666668,5.815880000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735728,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",735728,27.818196614583332,10.354693333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::fill_,735735,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735735,28.136881510416668,3.092893333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::copy_,735738,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735738,27.839680989583332,5.945519999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735739,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",735739,30.271158854166668,10.250133333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::fill_,735746,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735746,32.168131510416664,8.747866666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::copy_,735749,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735749,35.466796875,64.76108000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::fill_,735756,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735756,42.9970703125,8.963773333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::copy_,735759,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735759,31.838704427083332,22.938200000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735760,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735760,27.711100260416668,19.597053333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::fill_,735767,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735767,34.64501953125,8.92624
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::copy_,735770,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735770,27.944498697916668,29.539120000000015
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::fill_,735777,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",735777,39.273600260416664,9.026080000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::copy_,735780,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735780,35.507975260416664,11.504133333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735781,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735781,35.672037760416664,19.670800000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::cat,735784,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",735784,38.13232421875,146.90215999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mm,735798,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,735798,102.88883463541667,545.3075200000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::mm,735802,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,735802,115.1455078125,545.0511066666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::sum,735806,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",735806,104.79931640625,36.56540000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735810,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735810,37.002604166666664,1.853826666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735818,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735818,31.316731770833332,42.75335999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,record_param_comms,735826,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",735826,74.55680338541667,3289.0012799999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::native_layer_norm_backward,735831,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",735831,53.163248697916664,140.89001333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::native_layer_norm_backward,735831,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",735831,44.214029947916664,88.72968000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add,735835,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735835,43.90380859375,79.03622666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735838,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735838,43.54052734375,1.8807466666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735841,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735841,31.7314453125,1.7028266666666658
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::native_layer_norm_backward,735844,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",735844,31.702473958333332,137.46694666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::native_layer_norm_backward,735844,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",735844,44.448079427083336,88.70916000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735848,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735848,43.435221354166664,77.69222666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735855,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735855,43.360026041666664,1.87264
autograd::engine::evaluate_function: CheckpointFunctionBackward,735228,,aten::add_,735858,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",735858,27.732584635416668,1.6861599999999992
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::fill_,735864,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",735864,3311.0760091145835,2.5591466666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::copy_,735873,"[[], [], []]",Memcpy HtoD (Pageable -> Device),735873,4826.505045572917,0.7701333333333329
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::native_layer_norm,735878,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",735878,2295.0963541666665,91.58666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::native_layer_norm,735885,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",735885,37.651529947916664,91.36942666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::addmm,735900,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,735900,1243.3146158854167,571.8860533333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::copy_,735925,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),735925,123.87141927083333,3.649226666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::copy_,735929,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),735929,1017.4869791666666,2.6589600000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::neg,735939,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735939,2602.1959635416665,7.533626666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::cat,735951,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",735951,1440.3694661458333,16.228573333333337
None,None,None,None,None,None,kernel_1,735952,816.3658854166666,7.013933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::neg,735962,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",735962,1371.1316731770833,9.323026666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::cat,735973,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",735973,1183.3297526041667,16.145853333333335
None,None,None,None,None,None,kernel_1,735974,698.9879557291666,6.964826666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::cat,735980,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",735980,1401.7718098958333,66.10918666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::cat,735981,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",735981,28.085123697916668,66.56505333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::baddbmm,735991,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,735991,1064.4459635416667,212.90222666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,ScaledUpperTriangMaskedSoftmax,735994,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",735994,41.332845052083336,335.24689333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::bmm,736011,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736011,84.73616536458333,184.24164000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::copy_,736019,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736019,41.055826822916664,34.55148
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mm,736028,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736028,82.77213541666667,192.96089333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add,736033,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",736033,48.554036458333336,131.03493333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mm,736045,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736045,86.13134765625,793.7468933333331
None,None,None,None,None,None,kernel_2,736049,36.117513020833336,87.82299999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mm,736060,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736060,95.36962890625,794.0220533333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add,736065,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",736065,35.958333333333336,128.83685333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add,736067,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736067,36.3837890625,83.51621333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,record_param_comms,736070,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",736070,59.850748697916664,3283.3552666666656
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add,736075,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736075,48.948567708333336,85.57530666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::sum,736086,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",736086,96.39534505208333,46.95078666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736090,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736090,37.066080729166664,1.8163199999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mm,736100,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736100,105.24690755208333,727.8266799999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mm,736107,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736107,120.21256510416667,782.866973333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736119,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736119,45.109049479166664,59.143986666666656
None,None,None,None,None,None,kernel_3,736123,39.935546875,95.51610666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::sum,736127,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",736127,108.11637369791667,46.27549333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736131,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736131,36.24462890625,1.8466000000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mm,736141,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736141,108.21272786458333,714.3503866666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mm,736148,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736148,118.99739583333333,772.7708666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736160,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736160,36.596028645833336,59.03101333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,record_param_comms,736164,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",736164,67.41438802083333,3292.435773333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::sum,736171,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",736171,94.43115234375,49.63925333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736175,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736175,40.842936197916664,1.7778933333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mm,736185,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736185,101.35335286458333,208.30325333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mm,736192,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736192,102.06819661458333,189.01499999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736204,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736204,36.745279947916664,14.204920000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::bmm,736223,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736223,104.46891276041667,174.62496
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::bmm,736226,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736226,109.279296875,208.3117466666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,ScaledUpperTriangMaskedSoftmaxBackward,736244,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",736244,40.405110677083336,553.7746266666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::bmm,736261,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736261,105.80240885416667,178.71242666666674
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mul,736263,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",736263,41.248046875,16.925720000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::bmm,736266,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736266,104.28792317708333,173.6163466666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mul,736268,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",736268,36.799479166666664,16.97992
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mul,736308,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",736308,33.30224609375,11.71906666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mul,736312,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",736312,31.77685546875,10.667879999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::neg,736315,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736315,34.976399739583336,5.335426666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::fill_,736322,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",736322,33.940755208333336,3.174360000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::copy_,736325,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736325,35.741048177083336,12.794773333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736326,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",736326,29.441569010416668,23.294946666666654
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::fill_,736333,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",736333,27.59423828125,3.105240000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::copy_,736336,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736336,27.53076171875,13.017053333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736337,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",736337,27.65869140625,23.09786666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mul,736341,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",736341,29.70654296875,12.007079999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mul,736345,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",736345,35.295247395833336,10.13797333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::neg,736348,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736348,33.462076822916664,5.454866666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::fill_,736355,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",736355,33.844563802083336,3.1257333333333346
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::copy_,736358,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736358,30.932779947916668,5.820959999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736359,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",736359,27.850260416666668,10.34828
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::fill_,736366,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",736366,28.136555989583332,3.1095066666666686
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::copy_,736369,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736369,27.52099609375,5.93745333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736370,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",736370,30.931315104166668,10.264653333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::fill_,736377,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",736377,32.2548828125,8.748720000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::copy_,736380,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736380,35.254231770833336,64.75247999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::fill_,736387,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",736387,42.37890625,8.96502666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::copy_,736390,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736390,31.999674479166668,22.92629333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736391,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736391,27.669270833333332,19.562920000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::fill_,736398,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",736398,34.250162760416664,8.942040000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::copy_,736401,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736401,27.689290364583332,29.504920000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::fill_,736408,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",736408,39.615397135416664,9.00174666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::copy_,736411,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736411,34.84765625,11.480226666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736412,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736412,35.060872395833336,19.703306666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::cat,736415,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",736415,39.253092447916664,146.8514133333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mm,736429,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736429,102.17431640625,545.0447199999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::mm,736433,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736433,117.02392578125,544.9537866666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::sum,736437,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",736437,106.44010416666667,36.523146666666676
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736441,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736441,36.928059895833336,1.838933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736449,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736449,31.9775390625,42.67785333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,record_param_comms,736457,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",736457,73.48291015625,3285.598586666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::native_layer_norm_backward,736462,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",736462,53.331705729166664,140.75182666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::native_layer_norm_backward,736462,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",736462,43.945475260416664,88.81370666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add,736466,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736466,44.511555989583336,78.96334666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736469,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736469,44.191080729166664,1.87264
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736472,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736472,31.476236979166668,1.7100800000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::native_layer_norm_backward,736475,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",736475,31.989908854166668,137.50618666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::native_layer_norm_backward,736475,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",736475,44.191080729166664,88.85634666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736479,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736479,43.745768229166664,77.66890666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736486,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736486,43.722005208333336,1.8709066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,735859,,aten::add_,736489,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736489,27.90478515625,1.699826666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::fill_,736495,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",736495,3253.06884765625,2.5535733333333344
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::copy_,736504,"[[], [], []]",Memcpy HtoD (Pageable -> Device),736504,4769.270670572917,0.7688399999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::native_layer_norm,736509,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",736509,2261.5384114583335,91.46934666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::native_layer_norm,736516,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",736516,37.861165364583336,91.27422666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::addmm,736531,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736531,1355.4759114583333,571.9197733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::copy_,736556,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),736556,107.80712890625,2.8744266666666674
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::copy_,736560,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),736560,1003.5520833333334,2.639346666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::neg,736570,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736570,2630.2498372395835,7.548533333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::cat,736582,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",736582,1429.3855794270833,16.21362666666667
None,None,None,None,None,None,kernel_1,736583,1639.8663736979167,6.999440000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::neg,736593,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736593,1398.1974283854167,9.332399999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::cat,736604,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",736604,1170.4296875,16.127426666666665
None,None,None,None,None,None,kernel_1,736605,687.5045572916666,6.96525333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::cat,736611,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",736611,1363.56005859375,66.16729333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::cat,736612,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",736612,28.26611328125,66.62078666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::baddbmm,736622,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736622,1043.5022786458333,213.12662666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,ScaledUpperTriangMaskedSoftmax,736625,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",736625,81.17236328125,335.17481333333313
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::bmm,736642,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736642,211.33626302083334,184.18899999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::copy_,736650,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736650,41.173502604166664,34.53413333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mm,736659,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736659,94.73958333333333,193.07726666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add,736664,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",736664,48.11669921875,131.09772
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mm,736676,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736676,86.95540364583333,793.5808933333335
None,None,None,None,None,None,kernel_2,736680,36.222981770833336,87.83237333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mm,736691,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736691,95.73258463541667,793.9593733333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add,736696,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",736696,36.052083333333336,128.84705333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add,736698,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736698,36.27734375,83.5047333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,record_param_comms,736701,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",736701,57.37548828125,3276.378360000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add,736706,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736706,49.45068359375,85.65090666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::sum,736717,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",736717,97.28841145833333,46.697440000000014
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,736721,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736721,36.405436197916664,1.8299066666666661
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mm,736731,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736731,102.06754557291667,727.81684
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mm,736738,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736738,117.55777994791667,781.7230933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,736750,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736750,44.799479166666664,59.20880000000001
None,None,None,None,None,None,kernel_3,736754,39.392578125,95.53409333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::sum,736758,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",736758,102.51578776041667,46.252013333333316
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,736762,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736762,36.682779947916664,1.8141466666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mm,736772,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736772,104.13802083333333,713.6614399999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mm,736779,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,736779,112.75504557291667,771.5736666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,736791,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736791,37.546061197916664,59.112426666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,record_param_comms,736795,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",736795,65.91829427083333,3280.3767333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::sum,736802,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",736802,94.97591145833333,49.418186666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,736806,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736806,40.436360677083336,1.7778799999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mm,736816,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736816,102.68831380208333,208.14363999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mm,736823,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736823,102.63395182291667,188.96678666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,736835,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",736835,36.862630208333336,14.267653333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::bmm,736854,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736854,103.31624348958333,174.70305333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::bmm,736857,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736857,106.92301432291667,208.31937333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,ScaledUpperTriangMaskedSoftmaxBackward,736875,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",736875,40.939290364583336,554.0472799999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::bmm,736892,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736892,107.46468098958333,178.87497333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mul,736894,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",736894,40.93798828125,16.915466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::bmm,736897,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,736897,104.77962239583333,173.5595866666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mul,736899,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",736899,38.014485677083336,16.953906666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mul,736939,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",736939,33.3857421875,11.735359999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mul,736943,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",736943,32.085774739583336,10.672533333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::neg,736946,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736946,35.370768229166664,5.332440000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::fill_,736953,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",736953,34.26123046875,3.157693333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::copy_,736956,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736956,34.673665364583336,12.780279999999992
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,736957,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",736957,29.846842447916668,23.35256
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::fill_,736964,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",736964,27.957194010416668,3.101360000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::copy_,736967,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736967,27.328125,12.973960000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,736968,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",736968,27.627278645833332,23.112319999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mul,736972,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",736972,29.791666666666668,12.003746666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mul,736976,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",736976,35.4345703125,10.135786666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::neg,736979,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736979,33.419596354166664,5.438653333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::fill_,736986,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",736986,32.883626302083336,3.129560000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::copy_,736989,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",736989,30.579915364583332,5.800079999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,736990,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",736990,27.78662109375,10.360240000000008
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::fill_,736997,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",736997,27.700358072916668,3.1108266666666693
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::copy_,737000,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737000,27.41455078125,5.957906666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,737001,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",737001,30.60205078125,10.236000000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::fill_,737008,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",737008,31.624674479166668,8.738080000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::copy_,737011,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737011,35.44580078125,64.65008
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::fill_,737018,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",737018,41.994303385416664,8.953973333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::copy_,737021,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737021,31.455240885416668,22.909186666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,737022,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737022,27.700032552083332,19.60222666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::fill_,737029,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",737029,33.96337890625,8.970559999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::copy_,737032,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737032,27.689778645833332,29.501186666666655
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::fill_,737039,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",737039,39.861002604166664,9.021759999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::copy_,737042,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737042,34.858561197916664,11.523773333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,737043,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737043,35.41259765625,19.680626666666658
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::cat,737046,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",737046,37.365071614583336,146.76350666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mm,737060,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737060,104.82063802083333,545.0310800000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::mm,737064,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737064,112.94742838541667,545.49356
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::sum,737068,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",737068,104.93668619791667,36.600413333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,737072,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737072,36.939290364583336,1.82484
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,737080,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737080,32.19140625,42.674813333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,record_param_comms,737088,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",737088,74.30338541666667,3281.258106666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::native_layer_norm_backward,737093,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",737093,53.33154296875,140.91442666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::native_layer_norm_backward,737093,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",737093,44.1181640625,88.72874666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add,737097,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737097,44.2451171875,78.91943999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,737100,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737100,44.009114583333336,1.8888
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,737103,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737103,31.9033203125,1.6789200000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::native_layer_norm_backward,737106,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",737106,31.392903645833332,137.52324
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::native_layer_norm_backward,737106,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",737106,43.871907552083336,88.80729333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,737110,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737110,43.796223958333336,77.65435999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,737117,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737117,44.07373046875,1.8679466666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,736490,,aten::add_,737120,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737120,27.80712890625,1.680626666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::fill_,737126,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",737126,3237.1575520833335,2.5556933333333327
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::copy_,737135,"[[], [], []]",Memcpy HtoD (Pageable -> Device),737135,4789.877604166667,0.7547599999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::native_layer_norm,737140,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",737140,2243.0133463541665,91.42956
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::native_layer_norm,737147,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",737147,35.359375,91.24392000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::addmm,737162,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737162,1152.5574544270833,571.7622933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::copy_,737187,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),737187,122.17529296875,2.8547866666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::copy_,737191,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),737191,1008.2247721354166,2.6905333333333346
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::neg,737201,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737201,2554.45361328125,7.529293333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::cat,737213,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",737213,1414.0787760416667,16.227653333333343
None,None,None,None,None,None,kernel_1,737214,802.9488932291666,7.044199999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::neg,737224,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737224,1352.7565104166667,9.333226666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::cat,737235,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",737235,1185.0979817708333,16.155160000000002
None,None,None,None,None,None,kernel_1,737236,660.1842447916666,6.932453333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::cat,737242,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",737242,1351.2106119791667,66.09944
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::cat,737243,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",737243,28.501302083333332,66.60678666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::baddbmm,737253,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,737253,994.3777669270834,213.28873333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,ScaledUpperTriangMaskedSoftmax,737256,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",737256,40.500651041666664,335.12062666666674
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::bmm,737273,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,737273,84.4365234375,184.39649333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::copy_,737281,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737281,40.991373697916664,34.50546666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mm,737290,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,737290,85.22639973958333,193.14513333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add,737295,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",737295,47.92236328125,131.03631999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mm,737307,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737307,87.58349609375,793.6209866666666
None,None,None,None,None,None,kernel_2,737311,36.437337239583336,87.79567999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mm,737322,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737322,96.82112630208333,793.920506666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add,737327,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",737327,35.956705729166664,128.84070666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add,737329,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737329,36.063151041666664,83.44838666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,record_param_comms,737332,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",737332,57.278483072916664,3269.4720266666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add,737337,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737337,49.268717447916664,85.58469333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::sum,737348,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",737348,98.51643880208333,46.84085333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737352,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737352,36.832356770833336,1.7851600000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mm,737362,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737362,102.6650390625,728.7456000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mm,737369,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737369,117.19303385416667,781.6497199999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737381,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737381,45.196614583333336,59.33897333333333
None,None,None,None,None,None,kernel_3,737385,40.22412109375,95.53792000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::sum,737389,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",737389,105.0126953125,46.24765333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737393,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737393,36.811197916666664,1.8291066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mm,737403,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737403,106.46321614583333,713.6815599999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mm,737410,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737410,116.42529296875,771.6585600000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737422,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737422,36.9697265625,59.12345333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,record_param_comms,737426,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",737426,67.59521484375,3290.3913066666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::sum,737433,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",737433,94.37858072916667,49.46473333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737437,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737437,39.401041666666664,1.8192533333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mm,737447,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,737447,101.20524088541667,208.24349333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mm,737454,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,737454,103.08235677083333,188.9996933333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737466,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737466,36.649088541666664,14.25309333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::bmm,737485,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,737485,101.98307291666667,174.83030666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::bmm,737488,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,737488,108.06201171875,208.44228000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,ScaledUpperTriangMaskedSoftmaxBackward,737506,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",737506,40.65087890625,554.3173599999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::bmm,737523,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,737523,107.88199869791667,178.87068
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mul,737525,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",737525,41.0439453125,16.893306666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::bmm,737528,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,737528,103.97770182291667,173.7021866666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mul,737530,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",737530,37.4619140625,16.914560000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mul,737570,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",737570,35.093912760416664,11.725533333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mul,737574,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",737574,32.1494140625,10.672999999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::neg,737577,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737577,35.477864583333336,5.311893333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::fill_,737584,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",737584,34.197591145833336,3.167573333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::copy_,737587,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737587,35.1650390625,12.79350666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737588,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",737588,29.302408854166668,23.358986666666652
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::fill_,737595,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",737595,27.8603515625,3.095000000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::copy_,737598,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737598,27.319173177083332,13.031960000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737599,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",737599,27.45556640625,23.10845333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mul,737603,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",737603,29.0771484375,11.993920000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mul,737607,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",737607,35.572916666666664,10.132746666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::neg,737610,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737610,33.419759114583336,5.448520000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::fill_,737617,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",737617,34.079264322916664,3.1445066666666674
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::copy_,737620,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737620,30.601725260416668,5.817146666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737621,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",737621,27.850748697916668,10.367506666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::fill_,737628,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",737628,28.105794270833332,3.0971333333333355
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::copy_,737631,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737631,27.723470052083332,5.949413333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737632,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",737632,30.96435546875,10.259946666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::fill_,737639,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",737639,30.965006510416668,8.747853333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::copy_,737642,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737642,35.584309895833336,64.66926666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::fill_,737649,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",737649,42.869791666666664,8.963333333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::copy_,737652,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737652,31.33740234375,22.914786666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737653,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737653,27.828776041666668,19.582906666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::fill_,737660,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",737660,34.53857421875,8.945840000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::copy_,737663,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737663,27.465006510416668,29.459320000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::fill_,737670,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",737670,39.435709635416664,9.00688
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::copy_,737673,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737673,35.827473958333336,11.498560000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737674,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737674,34.742513020833336,19.615426666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::cat,737677,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",737677,38.29296875,146.80356000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mm,737691,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737691,102.85693359375,545.7708399999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::mm,737695,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737695,117.76106770833333,546.0034133333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::sum,737699,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",737699,107.64632161458333,36.72538666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737703,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737703,36.597330729166664,1.8598133333333324
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737711,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737711,31.498209635416668,42.67910666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,record_param_comms,737719,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",737719,72.92724609375,3279.5868533333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::native_layer_norm_backward,737724,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",737724,53.43994140625,140.82478666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::native_layer_norm_backward,737724,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",737724,44.78857421875,88.80388000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add,737728,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737728,44.437337239583336,78.96974666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737731,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737731,43.892740885416664,1.8725866666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737734,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737734,31.923014322916668,1.7075199999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::native_layer_norm_backward,737737,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",737737,31.393229166666668,137.54075999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::native_layer_norm_backward,737737,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",737737,43.5625,88.80085333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737741,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737741,43.967936197916664,77.55198666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737748,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737748,43.679036458333336,1.8692133333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,737121,,aten::add_,737751,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737751,27.96630859375,1.7232933333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::fill_,737757,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",737757,3226.6046549479165,2.5531600000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::copy_,737766,"[[], [], []]",Memcpy HtoD (Pageable -> Device),737766,4793.1767578125,0.7564799999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::native_layer_norm,737771,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",737771,2221.8245442708335,91.47437333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::native_layer_norm,737778,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",737778,36.299641927083336,91.30199999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::addmm,737793,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737793,1086.4025065104167,572.5269066666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::copy_,737818,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),737818,109.10807291666667,2.850506666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::copy_,737822,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),737822,974.84814453125,2.6943600000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::neg,737832,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737832,2542.5812174479165,7.551520000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::cat,737844,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",737844,1418.7083333333333,16.188026666666666
None,None,None,None,None,None,kernel_1,737845,774.02734375,7.028453333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::neg,737855,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737855,1337.3430989583333,9.350746666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::cat,737866,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",737866,1161.9845377604167,16.15514666666667
None,None,None,None,None,None,kernel_1,737867,668.2071940104166,6.964839999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::cat,737873,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",737873,1333.4905598958333,66.10379999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::cat,737874,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",737874,28.34130859375,66.58882666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::baddbmm,737884,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,737884,992.0231119791666,213.8421733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,ScaledUpperTriangMaskedSoftmax,737887,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",737887,41.450520833333336,335.18331999999987
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::bmm,737904,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,737904,84.59651692708333,184.1190666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::copy_,737912,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",737912,40.479329427083336,34.50126666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mm,737921,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,737921,83.57242838541667,193.69509333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add,737926,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",737926,47.775065104166664,131.03717333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mm,737938,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737938,86.76106770833333,793.9529200000002
None,None,None,None,None,None,kernel_2,737942,35.893229166666664,87.7582
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mm,737953,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737953,96.38297526041667,793.9682799999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add,737958,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",737958,36.234049479166664,128.81546666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add,737960,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737960,35.6689453125,83.43527999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,record_param_comms,737963,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",737963,57.630696614583336,3268.604586666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add,737968,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737968,49.684733072916664,85.63974666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::sum,737979,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",737979,97.55615234375,46.98666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,737983,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",737983,36.468587239583336,1.8085999999999993
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mm,737993,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,737993,101.64111328125,731.3748133333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mm,738000,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,738000,120.22281901041667,782.56272
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738012,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738012,45.5673828125,59.046826666666675
None,None,None,None,None,None,kernel_3,738016,39.669759114583336,95.57961333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::sum,738020,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",738020,107.19026692708333,46.320640000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738024,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738024,36.67138671875,1.7821866666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mm,738034,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,738034,108.79850260416667,718.8884266666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mm,738041,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,738041,120.40494791666667,772.3979733333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738053,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738053,37.23681640625,59.04585333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,record_param_comms,738057,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",738057,67.38020833333333,3284.423546666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::sum,738064,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",738064,94.46402994791667,49.47544000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738068,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738068,40.392903645833336,1.7646799999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mm,738078,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,738078,101.04638671875,209.14928
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mm,738085,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,738085,102.16487630208333,189.12218666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738097,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738097,36.980794270833336,14.242040000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::bmm,738116,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,738116,100.24365234375,174.63862666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::bmm,738119,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,738119,105.77994791666667,208.9235733333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,ScaledUpperTriangMaskedSoftmaxBackward,738137,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",738137,41.855794270833336,554.3869200000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::bmm,738154,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,738154,104.47867838541667,179.02777333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mul,738156,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",738156,41.4169921875,16.905706666666685
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::bmm,738159,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,738159,101.87776692708333,173.77931999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mul,738161,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",738161,36.50146484375,16.947000000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mul,738201,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",738201,34.283203125,11.704226666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mul,738205,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",738205,31.616373697916668,10.66149333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::neg,738208,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",738208,35.210774739583336,5.348666666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::fill_,738215,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",738215,34.782389322916664,3.1777600000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::copy_,738218,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",738218,34.792643229166664,12.790440000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738219,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",738219,29.909993489583332,23.278333333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::fill_,738226,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",738226,27.635579427083332,3.1078133333333353
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::copy_,738229,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",738229,27.0625,13.006400000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738230,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",738230,27.775553385416668,23.09097333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mul,738234,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",738234,29.354654947916668,12.015253333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mul,738238,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",738238,35.296549479166664,10.146080000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::neg,738241,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",738241,33.3759765625,5.443346666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::fill_,738248,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",738248,34.271809895833336,3.1274266666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::copy_,738251,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",738251,30.4736328125,5.795746666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738252,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",738252,28.031412760416668,10.370906666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::fill_,738259,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",738259,27.89404296875,3.101800000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::copy_,738262,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",738262,27.63671875,5.956680000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738263,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",738263,31.220377604166668,10.24889333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::fill_,738270,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",738270,31.732584635416668,8.740613333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::copy_,738273,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",738273,35.466796875,64.75376000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::fill_,738280,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",738280,42.632975260416664,8.960373333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::copy_,738283,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",738283,31.647623697916668,22.915653333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738284,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738284,27.6474609375,19.5958
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::fill_,738291,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",738291,33.7587890625,8.976506666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::copy_,738294,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",738294,27.594075520833332,29.50508
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::fill_,738301,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",738301,39.62548828125,9.027293333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::copy_,738304,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",738304,35.571451822916664,11.502373333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738305,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738305,34.94482421875,19.665319999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::cat,738308,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",738308,37.32177734375,146.82531999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mm,738322,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,738322,99.63834635416667,548.7941866666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::mm,738326,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,738326,116.5634765625,551.3823333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::sum,738330,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",738330,107.88199869791667,36.59021333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738334,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738334,37.50341796875,1.8047600000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738342,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738342,31.125813802083332,42.65776000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,record_param_comms,738350,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",738350,71.57096354166667,3278.3380533333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::native_layer_norm_backward,738355,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",738355,53.1201171875,140.81745333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::native_layer_norm_backward,738355,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",738355,44.39404296875,88.91226666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add,738359,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738359,43.764485677083336,79.08069333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738362,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738362,43.584635416666664,1.8675200000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738365,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738365,31.754069010416668,1.6857466666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::native_layer_norm_backward,738368,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",738368,32.2900390625,137.48053333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::native_layer_norm_backward,738368,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",738368,44.608235677083336,88.84015999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738372,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738372,43.977864583333336,77.65389333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738379,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738379,43.445638020833336,1.887986666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,737752,,aten::add_,738382,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738382,27.987630208333332,1.6844666666666666
autograd::engine::evaluate_function: torch::autograd::CopySlices,738391,,aten::copy_,738395,"[[4, 2048, 6144], [4, 2048, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",738395,4586.083333333333,132.80476000000002
autograd::engine::evaluate_function: torch::autograd::CopySlices,738391,,aten::copy_,738400,"[[4, 2048, 6144], [4, 2048, 6144], []]",Memcpy DtoD (Device -> Device),738400,36.76708984375,71.00821333333339
autograd::engine::evaluate_function: torch::autograd::CopySlices,738391,,aten::copy_,738408,"[[4, 2048, 6144], [4, 2048, 6144], []]",Memcpy DtoD (Device -> Device),738408,35.81884765625,71.42168000000001
autograd::engine::evaluate_function: torch::autograd::CopySlices,738391,,aten::masked_fill_,738415,"[[4, 2048, 6144], [4, 2048, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",738415,38.1650390625,140.54312
autograd::engine::evaluate_function: torch::autograd::CopySlices,738391,,aten::copy_,738418,"[[4, 2048, 6144], [4, 2048, 6144], []]",Memcpy DtoD (Device -> Device),738418,36.693359375,72.30146666666664
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::arange,738430,"[[], [], [], [0]]","void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)",738430,41.140787760416664,1.41436
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortHistogramKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, unsigned long long, at_cuda_detail::cub::detail::identity_decomposer_t>(unsigned long long*, long const*, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",738422,152.37141927083334,3.680786666666667
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(unsigned long long*)",738422,31.63671875,1.5722533333333328
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",738422,91.65885416666667,8.651853333333332
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",738422,101.99283854166667,8.127493333333335
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",738422,92.404296875,7.897973333333335
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",738422,90.59228515625,7.914599999999999
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",738422,90.99641927083333,7.711093333333333
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",738422,90.86783854166667,7.747746666666669
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",738422,91.17757161458333,7.71236
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",738422,92.75618489583333,7.73924
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::fill_,738435,"[[12672, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",738435,27.892578125,47.2866
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, true>, long*>(at_cuda_detail::cub::ScanTileState<int, true>, int, long*)",738422,102.59000651041667,1.6989733333333332
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceUniqueByKeySweepKernel<at_cuda_detail::cub::DeviceUniqueByKeyPolicy<long const*, thrust::THRUST_200302_500_800_860_890_900_NS::counting_iterator<int, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default> >::Policy900, long const*, thrust::THRUST_200302_500_800_860_890_900_NS::counting_iterator<int, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, cuda::std::__4::equal_to<void>, int>(long const*, thrust::THRUST_200302_500_800_860_890_900_NS::counting_iterator<int, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, cuda::std::__4::equal_to<void>, int, int)",738422,35.946940104166664,4.888706666666666
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::krn_partials_per_segment<long>(long*, long const*, long const*, long)",738422,45.683919270833336,1.874346666666667
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceScanInitKernel<at_cuda_detail::cub::ScanTileState<long, true> >(at_cuda_detail::cub::ScanTileState<long, true>, int)",738422,37.247233072916664,1.3495333333333328
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceScanKernel<at_cuda_detail::cub::DeviceScanPolicy<long, at::cuda::cub::(anonymous namespace)::SumOp<long> >::Policy900, long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int, long>(long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, int, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int)",738422,34.1015625,3.0403999999999995
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::compute_num_of_partial_segments<long>(long const*, long const*, long const*, long*)",738422,31.97900390625,1.45064
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::krn_partial_segment_offset<long>(long*, long const*, long const*, long const*, long const*)",738422,31.402018229166668,2.731093333333334
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::compute_grad_weight<c10::Half, long>(long const*, c10::Half const*, long const*, long, long, long const*, long const*, at::AccumulateType<c10::Half, true>::type*, long)",738422,31.274576822916668,230.67949333333334
autograd::engine::evaluate_function: EmbeddingBackward0,738419,,aten::embedding_dense_backward,738422,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::sum_and_scatter<c10::Half, long>(long const*, c10::Half*, long, long const*, long const*, at::AccumulateType<c10::Half, true>::type const*, long const*, long const*, long, long)",738422,43.1025390625,167.26340000000008
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,738443,,aten::add_,738445,"[[12672, 6144], [12672, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",738445,39.05078125,124.22747999999994
