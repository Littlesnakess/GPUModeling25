[2025-02-12 14:46:44,352] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
NeoXArgs.from_ymls() ['/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/configs/targets/vista/GPT_20B_8_4_4.yml', '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/configs/targets/vista/local_setup.yml']
INFO:root:NeoXArgs.calculate_derived() Total number of GPUs determined to be: 128
-------------------- arguments --------------------
  attention_config ................ ['global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global']updated
  batch_size ...................... 4...........................updated
  bias_gelu_fusion ................ True........................updated
  checkpoint_activations .......... True........................updated
  checkpoint_factor ............... 500.........................updated
  config_files .................... {'GPT_20B_8_4_4.yml': '# DISCLAIMER: This is the configuration file for the GPT-NeoX-20B model as it was trained on 96x 40GB A100\n# GPUs. Depending on your system configuration, you may need to change some parameters in order to fit\n# the model in memory.\n\n{\n  # Tokenizer /  checkpoint settings - you will need to change these to the location you have them saved in\n  # "vocab_file": "./20B_checkpoints/20B_tokenizer.json",\n  # "save": "./20B_checkpoints",\n  # "load": "./20B_checkpoints",\n\n  # If finetuning, edit the following to the location of your finetuning dataset:\n  # "data_path": "./data/pile_20B_tokenizer/pile_20B_tokenizer_text_document",\n\n  # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\n  # across the node boundaries )\n  "pipe_parallel_size": 8,\n  "model_parallel_size": 4,\n\n  # model settings\n  "num_layers": 44,\n  "hidden_size": 6144,\n  "num_attention_heads": 64,\n  "seq_length": 2048,\n  "max_position_embeddings": 2048,\n  "norm": "layernorm",\n  "pos_emb": "rotary",\n  "rotary_pct": 0.25,\n  "no_weight_tying": true,\n  "gpt_j_residual": true,\n  "output_layer_parallelism": "column",\n  "scaled_upper_triang_masked_softmax_fusion": true,\n  "bias_gelu_fusion": true,\n  "rope_fusion": false,\n  "layernorm_fusion": false,\n\n  # init methods\n  "init_method": "small_init",\n  "output_layer_init_method": "wang_init",\n\n  # optimizer settings\n  "optimizer": {\n    "type": "Adam",\n    "params": {\n      "lr": 0.97e-4,\n      "betas": [0.9, 0.95],\n      "eps": 1.0e-8,\n      }\n      },\n\n  "min_lr": 0.97e-5,\n\n  # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training\n  "zero_optimization": {\n  "stage": 1,\n  "allgather_partitions": True,\n  "allgather_bucket_size": 1260000000,\n  "overlap_comm": True,\n  "reduce_scatter": True,\n  "reduce_bucket_size": 1260000000,\n  "contiguous_gradients": True,\n  },\n\n  # batch / data settings (assuming 96 GPUs)\n  "train_micro_batch_size_per_gpu": 4,\n  "gradient_accumulation_steps": 16,\n  "data_impl": "mmap",\n  "split": "995,4,1",\n\n  # activation checkpointing\n  "checkpoint_activations": true,\n  "checkpoint_num_layers": 1,\n  "partition_activations": false,\n  "synchronize_each_layer": true,\n\n  # regularization\n  "gradient_clipping": 1.0,\n  "weight_decay": 0.01,\n  "hidden_dropout": 0,\n  "attention_dropout": 0,\n\n  # precision settings\n  "fp16": {\n    "fp16": true,\n    "enabled": true,\n    "loss_scale": 0,\n    "loss_scale_window": 1000,\n    "initial_scale_power": 12,\n    "hysteresis": 2,\n    "min_loss_scale": 1\n    },\n\n  # misc. training settings\n  "train_iters": 53,\n  "lr_decay_iters": 53,\n\n  "distributed_backend": "nccl",\n  "lr_decay_style": "cosine",\n  "warmup": 0.01,\n  "checkpoint_factor": 500, # this variable previously called `save-interval`\n  "eval_interval": 1000,\n  "eval_iters": 10,\n\n  # logging\n  "log_interval": 1,\n  "steps_per_print": 1,\n  "wall_clock_breakdown": true,\n\n  ### NEW DATA: ####\n  # "tokenizer_type": "HFTokenizer",\n  # "tensorboard-dir": "./tensorboard",\n  # "log_dir": "./logs",\n\n  # distributed training settings\n  "launcher": "slurm",\n  "deepspeed_slurm": true,\n\n  # profiling settings\n  "profile": True,\n  "profile_step_start": 2,\n  "profile_step_stop": 52,\n}', 'local_setup.yml': '# Suggested data paths when using GPT-NeoX locally\n{\n  "data_path": "/work/08775/byz2022/vista/data/gpt-neox/data/test_text_document",\n\n  # or for weighted datasets:\n  # "train-data-paths": ["data/enwik8/enwik8_text_document", "data/enwik8/enwik8_text_document"],\n  # "test-data-paths": ["data/enwik8/enwik8_text_document", "data/enwik8/enwik8_text_document"],\n  # "valid-data-paths": ["data/enwik8/enwik8_text_document", "data/enwik8/enwik8_text_document"],\n  # "train-data-weights": [1., 2.],\n  # "test-data-weights": [2., 1.],\n  # "valid-data-weights": [0.5, 0.4],\n\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\n  # WARNING: setting this to True will override any user provided weights\n  # "weight_by_num_documents": false,\n  # "weighted_sampler_alpha": 0.3,\n\n  "vocab_file": "/work/08775/byz2022/vista/data/gpt-neox/data/gpt2-vocab.json",\n  "merge_file": "/work/08775/byz2022/vista/data/gpt-neox/data/gpt2-merges.txt",\n\n  "save": "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test",\n  "load": "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2",\n  "checkpoint_validation_with_forward_pass": False,\n\n  # "tensorboard_dir": "tensorboard",\n  # "log_dir": "logs",\n  "use_wandb": False,\n  "wandb_host": "https://api.wandb.ai",\n  "wandb_project": "neox"\n}'}updated
  data_impl ....................... mmap........................updated
  data_path ....................... /work/08775/byz2022/vista/data/gpt-neox/data/test_text_documentupdated
  deepspeed_slurm ................. True........................updated
  dynamic_loss_scale .............. True........................updated
  eval_iters ...................... 10..........................updated
  fp16 ............................ {'fp16': True, 'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 12, 'hysteresis': 2, 'min_loss_scale': 1}updated
  global_num_gpus ................. 128.........................updated
  gpt_j_residual .................. True........................updated
  gradient_accumulation_steps ..... 16..........................updated
  hidden_size ..................... 6144........................updated
  init_method ..................... small_init..................updated
  is_pipe_parallel ................ True........................updated
  launcher ........................ slurm.......................updated
  load ............................ /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2updated
  log_interval .................... 1...........................updated
  lr .............................. 9.7e-05.....................updated
  lr_decay_iters .................. 53..........................updated
  lr_decay_style .................. cosine......................updated
  max_position_embeddings ......... 2048........................updated
  merge_file ...................... /work/08775/byz2022/vista/data/gpt-neox/data/gpt2-merges.txtupdated
  min_lr .......................... 9.7e-06.....................updated
  model_parallel_size ............. 4...........................updated
  no_weight_tying ................. True........................updated
  num_attention_heads ............. 64..........................updated
  num_layers ...................... 44..........................updated
  optimizer ....................... {'type': 'Adam', 'params': {'lr': 9.7e-05, 'betas': [0.9, 0.95], 'eps': 1e-08}}updated
  optimizer_type .................. Adam........................updated
  output_layer_init_method ........ wang_init...................updated
  pipe_parallel_size .............. 8...........................updated
  pos_emb ......................... rotary......................updated
  precision ....................... fp16........................updated
  profile ......................... True........................updated
  profile_step_start .............. 2...........................updated
  profile_step_stop ............... 52..........................updated
  rotary_pct ...................... 0.25........................updated
  save ............................ /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_testupdated
  scaled_upper_triang_masked_softmax_fusion  True...............updated
  seq_length ...................... 2048........................updated
  sparsity_config ................. {}..........................updated
  split ........................... 995,4,1.....................updated
  steps_per_print ................. 1...........................updated
  synchronize_each_layer .......... True........................updated
  text_gen_type ................... unconditional...............updated
  train_batch_size ................ 256.........................updated
  train_iters ..................... 53..........................updated
  train_micro_batch_size_per_gpu .. 4...........................updated
  use_wandb ....................... False.......................updated
  user_script ..................... /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.pyupdated
  vocab_file ...................... /work/08775/byz2022/vista/data/gpt-neox/data/gpt2-vocab.jsonupdated
  wall_clock_breakdown ............ True........................updated
  weight_decay .................... 0.01........................updated
  zero_allgather_bucket_size ...... 1260000000..................updated
  zero_contiguous_gradients ....... True........................updated
  zero_optimization ............... {'stage': 1, 'allgather_partitions': True, 'allgather_bucket_size': 1260000000, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 1260000000, 'contiguous_gradients': True}updated
  zero_reduce_bucket_size ......... 1260000000..................updated
  zero_reduce_scatter ............. True........................updated
  zero_stage ...................... 1...........................updated
  account ......................... None........................default
  activation ...................... gelu........................default
  activation_checkpointing ........ None........................default
  adlr_autoresume ................. False.......................default
  adlr_autoresume_interval ........ 1000........................default
  allow_chopped ................... True........................default
  amp ............................. None........................default
  apply_query_key_layer_scaling ... False.......................default
  attention_dropout ............... 0...........................default
  attention_softmax_in_fp32 ....... False.......................default
  autotuning ...................... None........................default
  autotuning_run .................. None........................default
  base_shapes_file ................ None........................default
  bf16 ............................ None........................default
  bias_dropout_fusion ............. False.......................default
  char_level_ppl .................. False.......................default
  checkpoint ...................... None........................default
  checkpoint_in_cpu ............... False.......................default
  checkpoint_num_layers ........... 1...........................default
  checkpoint_scale ................ linear......................default
  checkpoint_validation_with_forward_pass  False................default
  clip_grad ....................... 1.0.........................default
  comet_experiment ................ None........................default
  comet_experiment_name ........... None........................default
  comet_others .................... None........................default
  comet_project ................... None........................default
  comet_tags ...................... None........................default
  comet_workspace ................. None........................default
  comment ......................... None........................default
  comms_logger .................... None........................default
  communication_data_type ......... None........................default
  compression_training ............ None........................default
  contiguous_checkpointing ........ False.......................default
  coord_check ..................... False.......................default
  create_moe_param_group .......... True........................default
  csv_monitor ..................... None........................default
  curriculum_learning ............. None........................default
  curriculum_seqlen ............... 0...........................default
  data_efficiency ................. None........................default
  data_types ...................... None........................default
  dataset_impl .................... gpt2........................default
  deepscale ....................... False.......................default
  deepscale_config ................ None........................default
  deepspeed ....................... True........................default
  deepspeed_activation_checkpointing  True......................default
  deepspeed_extra_args ............ None........................default
  deepspeed_mpi ................... False.......................default
  detect_nvlink_pairs ............. False.......................default
  dim_att ......................... None........................default
  distributed_backend ............. nccl........................default
  do_test ......................... None........................default
  do_train ........................ None........................default
  do_valid ........................ None........................default
  dpo_beta ........................ 0.1.........................default
  dpo_fp32 ........................ True........................default
  dpo_reference_free .............. False.......................default
  dump_state ...................... False.......................default
  elasticity ...................... None........................default
  enable_expert_tensor_parallelism  False.......................default
  eod_mask_loss ................... False.......................default
  eval_interval ................... 1000........................default
  eval_results_prefix ............. ............................default
  eval_tasks ...................... None........................default
  exclude ......................... None........................default
  exit_interval ................... None........................default
  expansion_factor ................ None........................default
  expert_interval ................. 2...........................default
  extra_save_iters ................ None........................default
  ffn_dim ......................... None........................default
  finetune ........................ False.......................default
  flops_profiler .................. None........................default
  force_multi ..................... False.......................default
  fp16_lm_cross_entropy ........... False.......................default
  fp32_allreduce .................. False.......................default
  git_hash ........................ f5325805....................default
  gmlp_attn_dim ................... 64..........................default
  gpt_j_tied ...................... False.......................default
  gradient_clipping ............... 1.0.........................default
  gradient_noise_scale_cpu_offload  False.......................default
  gradient_noise_scale_n_batches .. 5...........................default
  gradient_predivide_factor ....... 1.0.........................default
  head_size ....................... None........................default
  hidden_dropout .................. 0...........................default
  hostfile ........................ None........................default
  hysteresis ...................... 2...........................default
  include ......................... None........................default
  init_method_std ................. 0.02........................default
  intermediate_size ............... None........................default
  iteration ....................... None........................default
  keep_last_n_checkpoints ......... None........................default
  kto_beta ........................ 0.1.........................default
  kto_desirable_weight ............ 1.0.........................default
  kto_fp32 ........................ True........................default
  kto_undesirable_weight .......... 1.0.........................default
  layernorm_epsilon ............... 1e-05.......................default
  layernorm_fusion ................ False.......................default
  lazy_mpu_init ................... False.......................default
  local_rank ...................... None........................default
  log_dir ......................... None........................default
  log_grad_norm ................... False.......................default
  log_grad_pct_zeros .............. False.......................default
  log_gradient_noise_scale ........ False.......................default
  log_optimizer_states ............ False.......................default
  log_param_norm .................. False.......................default
  loss_scale ...................... None........................default
  loss_scale_window ............... 1000.0......................default
  lr_decay_fraction ............... None........................default
  make_vocab_size_divisible_by .... 128.........................default
  mamba_causal_conv_fusion ........ False.......................default
  mamba_inner_func_fusion ......... False.......................default
  mamba_selective_fp32_params ..... True........................default
  mamba_selective_scan_fusion ..... False.......................default
  mamba_use_bias_in_conv .......... True........................default
  mamba_use_bias_in_linears ....... False.......................default
  master_addr ..................... None........................default
  master_port ..................... 29500.......................default
  maximum_tokens .................. 64..........................default
  memory_profiling ................ False.......................default
  memory_profiling_path ........... None........................default
  min_scale ....................... 1.0.........................default
  mlp_multiple_of ................. 1...........................default
  mmap_warmup ..................... False.......................default
  moe_eval_capacity_factor ........ 1.0.........................default
  moe_expert_parallel_size ........ 1...........................default
  moe_glu ......................... False.......................default
  moe_jitter_eps .................. None........................default
  moe_lbl_in_fp32 ................. False.......................default
  moe_loss_coeff .................. 0.1.........................default
  moe_min_capacity ................ 4...........................default
  moe_num_experts ................. 1...........................default
  moe_token_dropping .............. False.......................default
  moe_top_k ....................... 1...........................default
  moe_train_capacity_factor ....... 1.0.........................default
  moe_type ........................ megablocks..................default
  moe_use_residual ................ True........................default
  mup_attn_temp ................... 1.0.........................default
  mup_embedding_mult .............. 1.0.........................default
  mup_init_scale .................. 1.0.........................default
  mup_output_temp ................. 1.0.........................default
  mup_rp_embedding_mult ........... 1.0.........................default
  mup_width_scale ................. 2...........................default
  neg_test_data_paths ............. None........................default
  neg_test_label_data_paths ....... None........................default
  neg_train_data_paths ............ None........................default
  neg_train_label_data_paths ...... None........................default
  neg_valid_data_paths ............ None........................default
  neg_valid_label_data_paths ...... None........................default
  no_load_optim ................... False.......................default
  no_load_rng ..................... False.......................default
  no_save_optim ................... False.......................default
  no_save_rng ..................... False.......................default
  no_ssh_check .................... False.......................default
  norm ............................ layernorm...................default
  num_gpus ........................ None........................default
  num_kv_heads .................... None........................default
  num_nodes ....................... -1..........................default
  num_samples ..................... 1...........................default
  num_unique_layers ............... None........................default
  num_workers ..................... 2...........................default
  onnx_safe ....................... False.......................default
  opt_pos_emb_offset .............. 0...........................default
  output_layer_parallelism ........ column......................default
  override_lr_scheduler ........... False.......................default
  pack_impl ....................... packed......................default
  padded_vocab_size ............... None........................default
  param_sharing_style ............. grouped.....................default
  partition_activations ........... False.......................default
  pipe_partition_method ........... type:transformer|mlp........default
  pos_test_data_paths ............. None........................default
  pos_test_label_data_paths ....... None........................default
  pos_train_data_paths ............ None........................default
  pos_train_label_data_paths ...... None........................default
  pos_valid_data_paths ............ None........................default
  pos_valid_label_data_paths ...... None........................default
  precompute_model_name ........... None........................default
  prescale_gradients .............. False.......................default
  profile_backward ................ False.......................default
  prompt_end ...................... 
...........................default
  rank ............................ None........................default
  recompute ....................... False.......................default
  return_logits ................... False.......................default
  rms_norm_epsilon ................ 1e-08.......................default
  rmsnorm_fusion .................. False.......................default
  rope_fusion ..................... False.......................default
  rotary_emb_base ................. 10000.......................default
  rotary_save_freqs_buffer ........ False.......................default
  rpe_max_distance ................ 128.........................default
  rpe_num_buckets ................. 32..........................default
  s3_chunk_size ................... 104857600...................default
  s3_path ......................... None........................default
  sample_input_file ............... None........................default
  sample_output_file .............. samples.txt.................default
  save_base_shapes ................ False.......................default
  scaled_masked_softmax_fusion .... False.......................default
  scalenorm_epsilon ............... 1e-08.......................default
  scheduler ....................... None........................default
  seed ............................ 1234........................default
  sequence_parallel ............... False.......................default
  short_seq_prob .................. 0.1.........................default
  sliding_window_width ............ None........................default
  soft_prompt_tuning .............. None........................default
  sparse_attention ................ None........................default
  sparse_gradients ................ False.......................default
  temperature ..................... 0.0.........................default
  tensorboard ..................... None........................default
  tensorboard_dir ................. None........................default
  test_data_paths ................. None........................default
  test_data_weights ............... None........................default
  test_label_data_paths ........... None........................default
  test_reward_data_paths .......... None........................default
  tokenizer_type .................. GPT2BPETokenizer............default
  top_k ........................... 0...........................default
  top_p ........................... 0.0.........................default
  train_data_paths ................ None........................default
  train_data_weights .............. None........................default
  train_epochs .................... None........................default
  train_impl ...................... normal......................default
  train_label_data_paths .......... None........................default
  train_reward_data_paths ......... None........................default
  use_bias_in_attn_linear ......... True........................default
  use_bias_in_mlp ................. True........................default
  use_bias_in_norms ............... True........................default
  use_bnb_optimizer ............... False.......................default
  use_checkpoint_lr_scheduler ..... False.......................default
  use_comet ....................... None........................default
  use_cpu_initialization .......... False.......................default
  use_flashattn_swiglu ............ False.......................default
  use_mup ......................... False.......................default
  use_qk_layernorm ................ False.......................default
  use_shared_fs ................... True........................default
  use_tutel ....................... False.......................default
  valid_data_paths ................ None........................default
  valid_data_weights .............. None........................default
  valid_label_data_paths .......... None........................default
  valid_reward_data_paths ......... None........................default
  wandb ........................... None........................default
  wandb_group ..................... None........................default
  wandb_host ...................... https://api.wandb.ai........default
  wandb_init_all_ranks ............ False.......................default
  wandb_project ................... neox........................default
  wandb_team ...................... None........................default
  warmup .......................... 0.01........................default
  weight_by_num_documents ......... False.......................default
  weighted_sampler_alpha .......... 1.0.........................default
  world_size ...................... None........................default
  z_loss .......................... 0.0.........................default
---------------- end of arguments ----------------
NeoXArgs.configure_distributed_args() using world size: 128 and model-parallel size: 4 
[2025-02-12 14:47:07,764] [INFO] [runner.py:586:main] cmd = srun -n 128 --export=ALL,PYTHONPATH=/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/slurms/GPT20B_128GPUs /work/08775/byz2022/vista/pythonenvs/gptneox/bin/python -u /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py --deepspeed_config eyJ0cmFpbl9iYXRjaF9zaXplIjogMjU2LCAidHJhaW5fbWljcm9fYmF0Y2hfc2l6ZV9wZXJfZ3B1IjogNCwgImdyYWRpZW50X2FjY3VtdWxhdGlvbl9zdGVwcyI6IDE2LCAib3B0aW1pemVyIjogeyJ0eXBlIjogIkFkYW0iLCAicGFyYW1zIjogeyJsciI6IDkuN2UtMDUsICJiZXRhcyI6IFswLjksIDAuOTVdLCAiZXBzIjogMWUtMDh9fSwgImZwMTYiOiB7ImZwMTYiOiB0cnVlLCAiZW5hYmxlZCI6IHRydWUsICJsb3NzX3NjYWxlIjogMCwgImxvc3Nfc2NhbGVfd2luZG93IjogMTAwMCwgImluaXRpYWxfc2NhbGVfcG93ZXIiOiAxMiwgImh5c3RlcmVzaXMiOiAyLCAibWluX2xvc3Nfc2NhbGUiOiAxfSwgInplcm9fb3B0aW1pemF0aW9uIjogeyJzdGFnZSI6IDEsICJhbGxnYXRoZXJfcGFydGl0aW9ucyI6IHRydWUsICJhbGxnYXRoZXJfYnVja2V0X3NpemUiOiAxMjYwMDAwMDAwLCAib3ZlcmxhcF9jb21tIjogdHJ1ZSwgInJlZHVjZV9zY2F0dGVyIjogdHJ1ZSwgInJlZHVjZV9idWNrZXRfc2l6ZSI6IDEyNjAwMDAwMDAsICJjb250aWd1b3VzX2dyYWRpZW50cyI6IHRydWV9LCAic3RlcHNfcGVyX3ByaW50IjogMSwgIndhbGxfY2xvY2tfYnJlYWtkb3duIjogdHJ1ZX0= --megatron_config {"launcher": "slurm", "train_batch_size": 256, "train_micro_batch_size_per_gpu": 4, "gradient_accumulation_steps": 16, "optimizer": {"type": "Adam", "params": {"lr": 9.7e-05, "betas": [0.9, 0.95], "eps": 1e-08}}, "fp16": {"fp16": true, "enabled": true, "loss_scale": 0, "loss_scale_window": 1000, "initial_scale_power": 12, "hysteresis": 2, "min_loss_scale": 1}, "zero_optimization": {"stage": 1, "allgather_partitions": true, "allgather_bucket_size": 1260000000, "overlap_comm": true, "reduce_scatter": true, "reduce_bucket_size": 1260000000, "contiguous_gradients": true}, "steps_per_print": 1, "wall_clock_breakdown": true, "precision": "fp16", "num_layers": 44, "hidden_size": 6144, "num_attention_heads": 64, "seq_length": 2048, "max_position_embeddings": 2048, "pos_emb": "rotary", "no_weight_tying": true, "attention_config": ["global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global", "global"], "sparsity_config": {}, "scaled_upper_triang_masked_softmax_fusion": true, "bias_gelu_fusion": true, "rotary_pct": 0.25, "init_method": "small_init", "output_layer_init_method": "wang_init", "gpt_j_residual": true, "lr_decay_style": "cosine", "lr_decay_iters": 53, "min_lr": 9.7e-06, "optimizer_type": "Adam", "zero_stage": 1, "zero_reduce_scatter": true, "zero_contiguous_gradients": true, "zero_reduce_bucket_size": 1260000000, "zero_allgather_bucket_size": 1260000000, "lr": 9.7e-05, "data_path": "/work/08775/byz2022/vista/data/gpt-neox/data/test_text_document", "data_impl": "mmap", "save": "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test", "config_files": {"GPT_20B_8_4_4.yml": "# DISCLAIMER: This is the configuration file for the GPT-NeoX-20B model as it was trained on 96x 40GB A100\n# GPUs. Depending on your system configuration, you may need to change some parameters in order to fit\n# the model in memory.\n\n{\n  # Tokenizer /  checkpoint settings - you will need to change these to the location you have them saved in\n  # \"vocab_file\": \"./20B_checkpoints/20B_tokenizer.json\",\n  # \"save\": \"./20B_checkpoints\",\n  # \"load\": \"./20B_checkpoints\",\n\n  # If finetuning, edit the following to the location of your finetuning dataset:\n  # \"data_path\": \"./data/pile_20B_tokenizer/pile_20B_tokenizer_text_document\",\n\n  # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\n  # across the node boundaries )\n  \"pipe_parallel_size\": 8,\n  \"model_parallel_size\": 4,\n\n  # model settings\n  \"num_layers\": 44,\n  \"hidden_size\": 6144,\n  \"num_attention_heads\": 64,\n  \"seq_length\": 2048,\n  \"max_position_embeddings\": 2048,\n  \"norm\": \"layernorm\",\n  \"pos_emb\": \"rotary\",\n  \"rotary_pct\": 0.25,\n  \"no_weight_tying\": true,\n  \"gpt_j_residual\": true,\n  \"output_layer_parallelism\": \"column\",\n  \"scaled_upper_triang_masked_softmax_fusion\": true,\n  \"bias_gelu_fusion\": true,\n  \"rope_fusion\": false,\n  \"layernorm_fusion\": false,\n\n  # init methods\n  \"init_method\": \"small_init\",\n  \"output_layer_init_method\": \"wang_init\",\n\n  # optimizer settings\n  \"optimizer\": {\n    \"type\": \"Adam\",\n    \"params\": {\n      \"lr\": 0.97e-4,\n      \"betas\": [0.9, 0.95],\n      \"eps\": 1.0e-8,\n      }\n      },\n\n  \"min_lr\": 0.97e-5,\n\n  # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training\n  \"zero_optimization\": {\n  \"stage\": 1,\n  \"allgather_partitions\": True,\n  \"allgather_bucket_size\": 1260000000,\n  \"overlap_comm\": True,\n  \"reduce_scatter\": True,\n  \"reduce_bucket_size\": 1260000000,\n  \"contiguous_gradients\": True,\n  },\n\n  # batch / data settings (assuming 96 GPUs)\n  \"train_micro_batch_size_per_gpu\": 4,\n  \"gradient_accumulation_steps\": 16,\n  \"data_impl\": \"mmap\",\n  \"split\": \"995,4,1\",\n\n  # activation checkpointing\n  \"checkpoint_activations\": true,\n  \"checkpoint_num_layers\": 1,\n  \"partition_activations\": false,\n  \"synchronize_each_layer\": true,\n\n  # regularization\n  \"gradient_clipping\": 1.0,\n  \"weight_decay\": 0.01,\n  \"hidden_dropout\": 0,\n  \"attention_dropout\": 0,\n\n  # precision settings\n  \"fp16\": {\n    \"fp16\": true,\n    \"enabled\": true,\n    \"loss_scale\": 0,\n    \"loss_scale_window\": 1000,\n    \"initial_scale_power\": 12,\n    \"hysteresis\": 2,\n    \"min_loss_scale\": 1\n    },\n\n  # misc. training settings\n  \"train_iters\": 53,\n  \"lr_decay_iters\": 53,\n\n  \"distributed_backend\": \"nccl\",\n  \"lr_decay_style\": \"cosine\",\n  \"warmup\": 0.01,\n  \"checkpoint_factor\": 500, # this variable previously called `save-interval`\n  \"eval_interval\": 1000,\n  \"eval_iters\": 10,\n\n  # logging\n  \"log_interval\": 1,\n  \"steps_per_print\": 1,\n  \"wall_clock_breakdown\": true,\n\n  ### NEW DATA: ####\n  # \"tokenizer_type\": \"HFTokenizer\",\n  # \"tensorboard-dir\": \"./tensorboard\",\n  # \"log_dir\": \"./logs\",\n\n  # distributed training settings\n  \"launcher\": \"slurm\",\n  \"deepspeed_slurm\": true,\n\n  # profiling settings\n  \"profile\": True,\n  \"profile_step_start\": 2,\n  \"profile_step_stop\": 52,\n}", "local_setup.yml": "# Suggested data paths when using GPT-NeoX locally\n{\n  \"data_path\": \"/work/08775/byz2022/vista/data/gpt-neox/data/test_text_document\",\n\n  # or for weighted datasets:\n  # \"train-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"test-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"valid-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"train-data-weights\": [1., 2.],\n  # \"test-data-weights\": [2., 1.],\n  # \"valid-data-weights\": [0.5, 0.4],\n\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\n  # WARNING: setting this to True will override any user provided weights\n  # \"weight_by_num_documents\": false,\n  # \"weighted_sampler_alpha\": 0.3,\n\n  \"vocab_file\": \"/work/08775/byz2022/vista/data/gpt-neox/data/gpt2-vocab.json\",\n  \"merge_file\": \"/work/08775/byz2022/vista/data/gpt-neox/data/gpt2-merges.txt\",\n\n  \"save\": \"/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test\",\n  \"load\": \"/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2\",\n  \"checkpoint_validation_with_forward_pass\": False,\n\n  # \"tensorboard_dir\": \"tensorboard\",\n  # \"log_dir\": \"logs\",\n  \"use_wandb\": False,\n  \"wandb_host\": \"https://api.wandb.ai\",\n  \"wandb_project\": \"neox\"\n}"}, "load": "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2", "checkpoint_factor": 500, "batch_size": 4, "train_iters": 53, "eval_iters": 10, "split": "995,4,1", "vocab_file": "/work/08775/byz2022/vista/data/gpt-neox/data/gpt2-vocab.json", "merge_file": "/work/08775/byz2022/vista/data/gpt-neox/data/gpt2-merges.txt", "weight_decay": 0.01, "checkpoint_activations": true, "synchronize_each_layer": true, "dynamic_loss_scale": true, "pipe_parallel_size": 8, "model_parallel_size": 4, "world_size": 128, "is_pipe_parallel": true, "use_wandb": false, "log_interval": 1, "profile": true, "profile_step_start": 2, "profile_step_stop": 52, "text_gen_type": "unconditional", "local_rank": 0, "rank": 0, "deepspeed_slurm": true, "user_script": "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", "global_num_gpus": 128}
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
[2025-02-12 14:47:11,225] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
NeoXArgs.configure_distributed_args() using world size: 128 and model-parallel size: 4 
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 431 dummy tokens (new size: 50688)
Detected CUDA files, patching ldflags
Emitting ninja build file /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/fused_kernels/build/build.ninja...
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module scaled_upper_triang_masked_softmax_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[2025-02-12 14:47:21,562] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:21,938] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:21,952] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:21,953] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:21,980] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,032] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,215] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,233] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,284] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,477] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,485] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,610] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,613] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,632] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,722] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,738] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,754] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,759] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,810] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,825] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,870] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,897] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,910] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:22,918] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:23,039] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-02-12 14:47:23,449] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:23,502] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:23,544] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:23,546] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:23,546] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:23,562] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:23,909] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-02-12 14:47:24,084] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,090] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,407] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,485] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,548] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-02-12 14:47:24,603] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,636] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,654] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,700] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,728] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,752] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-02-12 14:47:24,777] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,788] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-02-12 14:47:24,807] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,809] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,810] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,811] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,812] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,817] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,841] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,842] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,844] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,845] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:24,854] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-02-12 14:47:25,002] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-02-12 14:47:25,206] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-02-12 14:47:25,236] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-02-12 14:47:25,377] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,434] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-02-12 14:47:25,466] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,504] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,567] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,606] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,633] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,650] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,704] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,717] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,720] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,726] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,733] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,735] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,736] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,737] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,740] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,745] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,746] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,746] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,752] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,755] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,760] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,765] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,781] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,785] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,791] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,801] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,806] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,821] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,822] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,825] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,825] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,826] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,826] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,827] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,828] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,831] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,833] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,836] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,837] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,839] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,840] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,841] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,842] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,842] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,842] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,843] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,845] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,846] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,849] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,851] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,855] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,856] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,856] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,857] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,859] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,860] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,861] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,861] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,866] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,866] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,866] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,867] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,868] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,871] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,873] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-12 14:47:25,877] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
ninja: no work to do.
Loading extension module scaled_upper_triang_masked_softmax_cuda...
Detected CUDA files, patching ldflags
Emitting ninja build file /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/fused_kernels/build/build.ninja...
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module scaled_masked_softmax_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module scaled_masked_softmax_cuda...
Detected CUDA files, patching ldflags
Emitting ninja build file /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/fused_kernels/build/build.ninja...
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_rotary_positional_embedding...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_rotary_positional_embedding...
> initializing torch distributed ...
[2025-02-12 14:47:34,827] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:47:34,827] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3
For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
[2025-02-12 14:47:45,941] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
[2025-02-12 14:47:47,417] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:47:48,806] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
[2025-02-12 14:47:50,162] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:47:51,567] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:47:51,569] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:47:51,569] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:47:51,569] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:47:51,570] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:47:51,570] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:47:51,572] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:47:53,119] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:47:54,634] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
[2025-02-12 14:47:56,061] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
[2025-02-12 14:47:57,440] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:47:57,443] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:47:58,843] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:47:58,850] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:47:58,850] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:47:58,850] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:47:58,851] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:47:58,851] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:47:58,853] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: python3-config: No such file or directory
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:00,257] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:00,257] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:00,257] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:00,258] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:00,259] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Nothing to be done for 'default'.
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:01,710] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:03,095] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:04,487] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:04,491] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:04,491] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:05,881] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:05,881] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:05,881] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:07,270] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:07,272] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:07,272] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
[2025-02-12 14:48:08,648] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:08,648] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:08,648] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:08,648] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:08,649] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:08,651] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:08,651] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:08,652] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:08,652] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:09,949] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:09,949] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:10,015] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:10,017] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:10,017] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:10,018] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:10,019] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:10,019] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:10,019] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  counts = torch.cuda.LongTensor([1])
[2025-02-12 14:48:11,306] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:11,306] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:11,307] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:11,307] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:11,307] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:12,699] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:12,706] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:14,236] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:14,300] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,315] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,315] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,315] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,316] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
[2025-02-12 14:48:14,327] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,328] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,328] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,328] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,329] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,331] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,332] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,332] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,332] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,333] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,334] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:14,334] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
[2025-02-12 14:48:14,338] [INFO] [comm.py:637:init_distributed] cdb=None
make: python3-config: No such file or directory
[2025-02-12 14:48:14,338] [INFO] [comm.py:637:init_distributed] cdb=None
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  counts = torch.cuda.LongTensor([1])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: python3-config: No such file or directory
make: python3-config: No such file or directory
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Nothing to be done for 'default'.
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:15,875] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:15,876] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:15,938] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:15,946] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:17,394] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:18,704] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:18,754] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,755] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,755] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,755] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,755] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,755] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,756] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,756] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,756] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,756] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,756] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,756] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,756] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,757] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,757] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,757] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,758] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,758] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,758] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,766] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,767] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,767] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,768] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:18,769] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: python3-config: No such file or directory
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  counts = torch.cuda.LongTensor([1])
make: python3-config: No such file or directory
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  counts = torch.cuda.LongTensor([1])
[2025-02-12 14:48:20,225] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  counts = torch.cuda.LongTensor([1])
[2025-02-12 14:48:20,272] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:20,273] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:20,273] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:20,274] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:20,274] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:20,285] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  counts = torch.cuda.LongTensor([1])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  counts = torch.cuda.LongTensor([1])
[2025-02-12 14:48:21,875] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
[2025-02-12 14:48:21,898] [INFO] [comm.py:637:init_distributed] cdb=None
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:23,353] [INFO] [comm.py:637:init_distributed] cdb=None
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
[2025-02-12 14:48:23,404] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:23,404] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-02-12 14:48:23,406] [INFO] [comm.py:637:init_distributed] cdb=None
> initializing model parallel with size 4
MPU DP: [0, 4, 8, 12]
MPU DP: [1, 5, 9, 13]
MPU DP: [2, 6, 10, 14]
MPU DP: [3, 7, 11, 15]
MPU DP: [16, 20, 24, 28]
MPU DP: [17, 21, 25, 29]
MPU DP: [18, 22, 26, 30]
MPU DP: [19, 23, 27, 31]
MPU DP: [32, 36, 40, 44]
MPU DP: [33, 37, 41, 45]
MPU DP: [34, 38, 42, 46]
MPU DP: [35, 39, 43, 47]
MPU DP: [48, 52, 56, 60]
MPU DP: [49, 53, 57, 61]
MPU DP: [50, 54, 58, 62]
MPU DP: [51, 55, 59, 63]
MPU DP: [64, 68, 72, 76]
MPU DP: [65, 69, 73, 77]
MPU DP: [66, 70, 74, 78]
MPU DP: [67, 71, 75, 79]
MPU DP: [80, 84, 88, 92]
MPU DP: [81, 85, 89, 93]
MPU DP: [82, 86, 90, 94]
MPU DP: [83, 87, 91, 95]
MPU DP: [96, 100, 104, 108]
MPU DP: [97, 101, 105, 109]
MPU DP: [98, 102, 106, 110]
MPU DP: [99, 103, 107, 111]
MPU DP: [112, 116, 120, 124]
MPU DP: [113, 117, 121, 125]
MPU DP: [114, 118, 122, 126]
MPU DP: [115, 119, 123, 127]
MPU PP: [0, 16, 32, 48, 64, 80, 96, 112]
MPU PP: [1, 17, 33, 49, 65, 81, 97, 113]
MPU PP: [2, 18, 34, 50, 66, 82, 98, 114]
MPU PP: [3, 19, 35, 51, 67, 83, 99, 115]
MPU PP: [4, 20, 36, 52, 68, 84, 100, 116]
MPU PP: [5, 21, 37, 53, 69, 85, 101, 117]
MPU PP: [6, 22, 38, 54, 70, 86, 102, 118]
MPU PP: [7, 23, 39, 55, 71, 87, 103, 119]
MPU PP: [8, 24, 40, 56, 72, 88, 104, 120]
MPU PP: [9, 25, 41, 57, 73, 89, 105, 121]
MPU PP: [10, 26, 42, 58, 74, 90, 106, 122]
MPU PP: [11, 27, 43, 59, 75, 91, 107, 123]
MPU PP: [12, 28, 44, 60, 76, 92, 108, 124]
MPU PP: [13, 29, 45, 61, 77, 93, 109, 125]
MPU PP: [14, 30, 46, 62, 78, 94, 110, 126]
MPU PP: [15, 31, 47, 63, 79, 95, 111, 127]
MPU IO: [0, 4, 8, 12, 112, 116, 120, 124]
MPU MP: [0, 1, 2, 3]
MPU MP: [4, 5, 6, 7]
MPU MP: [8, 9, 10, 11]
MPU MP: [12, 13, 14, 15]
MPU MP: [16, 17, 18, 19]
MPU MP: [20, 21, 22, 23]
MPU MP: [24, 25, 26, 27]
MPU MP: [28, 29, 30, 31]
MPU MP: [32, 33, 34, 35]
MPU MP: [36, 37, 38, 39]
MPU MP: [40, 41, 42, 43]
MPU MP: [44, 45, 46, 47]
MPU MP: [48, 49, 50, 51]
MPU MP: [52, 53, 54, 55]
MPU MP: [56, 57, 58, 59]
MPU MP: [60, 61, 62, 63]
MPU MP: [64, 65, 66, 67]
MPU MP: [68, 69, 70, 71]
MPU MP: [72, 73, 74, 75]
MPU MP: [76, 77, 78, 79]
MPU MP: [80, 81, 82, 83]
MPU MP: [84, 85, 86, 87]
MPU MP: [88, 89, 90, 91]
MPU MP: [92, 93, 94, 95]
MPU MP: [96, 97, 98, 99]
MPU MP: [100, 101, 102, 103]
MPU MP: [104, 105, 106, 107]
MPU MP: [108, 109, 110, 111]
MPU MP: [112, 113, 114, 115]
MPU MP: [116, 117, 118, 119]
MPU MP: [120, 121, 122, 123]
MPU MP: [124, 125, 126, 127]
> setting random seeds to 1234 ...
[2025-02-12 14:48:23,419] [INFO] [checkpointing.py:227:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: python3-config: No such file or directory
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: Entering directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
make: python3-config: No such file or directory
make: python3-config: No such file or directory
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/data_utils.py:666: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  flags = torch.cuda.LongTensor([0, 0, 0])
make: Nothing to be done for 'default'.
make: Leaving directory '/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data'
> building train, validation, and test datasets ...
    reading sizes...
    reading pointers...
    reading document index...
    creating numpy buffer of mmap...
    creating memory view of numpy buffer...
 > dataset split:
    train:
     document indices in [0, 213502) total of 213502 documents
    validation:
     document indices in [213502, 214360) total of 858 documents
    test:
     document indices in [214360, 214575) total of 215 documents
/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  counts = torch.cuda.LongTensor([1])
 > loading doc-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_train_indexmap_13568ns_2048sl_1234s_packedpi_ac_doc_idx.npy
 > loading sample-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_train_indexmap_13568ns_2048sl_1234s_packedpi_ac_sample_idx.npy
 > loading shuffle-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_train_indexmap_13568ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy
    loaded indexed file in 0.019 seconds
    total number of samples: 181467
    total number of epochs: 1
 > loading doc-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_valid_indexmap_2560ns_2048sl_1234s_packedpi_ac_doc_idx.npy
 > loading sample-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_valid_indexmap_2560ns_2048sl_1234s_packedpi_ac_sample_idx.npy
 > loading shuffle-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_valid_indexmap_2560ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy
    loaded indexed file in 0.012 seconds
    total number of samples: 2779
    total number of epochs: 4
 > loading doc-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_test_indexmap_2560ns_2048sl_1234s_packedpi_ac_doc_idx.npy
 > loading sample-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_test_indexmap_2560ns_2048sl_1234s_packedpi_ac_sample_idx.npy
 > loading shuffle-idx mapping from /work/08775/byz2022/vista/data/gpt-neox/data/test_text_document_test_indexmap_2560ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy
    loaded indexed file in 0.002 seconds
    total number of samples: 2591
    total number of epochs: 23
building GPT2 model ...
SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=0, model=1): 1, ProcessCoord(pipe=0, data=0, model=2): 2, ProcessCoord(pipe=0, data=0, model=3): 3, ProcessCoord(pipe=0, data=1, model=0): 4, ProcessCoord(pipe=0, data=1, model=1): 5, ProcessCoord(pipe=0, data=1, model=2): 6, ProcessCoord(pipe=0, data=1, model=3): 7, ProcessCoord(pipe=0, data=2, model=0): 8, ProcessCoord(pipe=0, data=2, model=1): 9, ProcessCoord(pipe=0, data=2, model=2): 10, ProcessCoord(pipe=0, data=2, model=3): 11, ProcessCoord(pipe=0, data=3, model=0): 12, ProcessCoord(pipe=0, data=3, model=1): 13, ProcessCoord(pipe=0, data=3, model=2): 14, ProcessCoord(pipe=0, data=3, model=3): 15, ProcessCoord(pipe=1, data=0, model=0): 16, ProcessCoord(pipe=1, data=0, model=1): 17, ProcessCoord(pipe=1, data=0, model=2): 18, ProcessCoord(pipe=1, data=0, model=3): 19, ProcessCoord(pipe=1, data=1, model=0): 20, ProcessCoord(pipe=1, data=1, model=1): 21, ProcessCoord(pipe=1, data=1, model=2): 22, ProcessCoord(pipe=1, data=1, model=3): 23, ProcessCoord(pipe=1, data=2, model=0): 24, ProcessCoord(pipe=1, data=2, model=1): 25, ProcessCoord(pipe=1, data=2, model=2): 26, ProcessCoord(pipe=1, data=2, model=3): 27, ProcessCoord(pipe=1, data=3, model=0): 28, ProcessCoord(pipe=1, data=3, model=1): 29, ProcessCoord(pipe=1, data=3, model=2): 30, ProcessCoord(pipe=1, data=3, model=3): 31, ProcessCoord(pipe=2, data=0, model=0): 32, ProcessCoord(pipe=2, data=0, model=1): 33, ProcessCoord(pipe=2, data=0, model=2): 34, ProcessCoord(pipe=2, data=0, model=3): 35, ProcessCoord(pipe=2, data=1, model=0): 36, ProcessCoord(pipe=2, data=1, model=1): 37, ProcessCoord(pipe=2, data=1, model=2): 38, ProcessCoord(pipe=2, data=1, model=3): 39, ProcessCoord(pipe=2, data=2, model=0): 40, ProcessCoord(pipe=2, data=2, model=1): 41, ProcessCoord(pipe=2, data=2, model=2): 42, ProcessCoord(pipe=2, data=2, model=3): 43, ProcessCoord(pipe=2, data=3, model=0): 44, ProcessCoord(pipe=2, data=3, model=1): 45, ProcessCoord(pipe=2, data=3, model=2): 46, ProcessCoord(pipe=2, data=3, model=3): 47, ProcessCoord(pipe=3, data=0, model=0): 48, ProcessCoord(pipe=3, data=0, model=1): 49, ProcessCoord(pipe=3, data=0, model=2): 50, ProcessCoord(pipe=3, data=0, model=3): 51, ProcessCoord(pipe=3, data=1, model=0): 52, ProcessCoord(pipe=3, data=1, model=1): 53, ProcessCoord(pipe=3, data=1, model=2): 54, ProcessCoord(pipe=3, data=1, model=3): 55, ProcessCoord(pipe=3, data=2, model=0): 56, ProcessCoord(pipe=3, data=2, model=1): 57, ProcessCoord(pipe=3, data=2, model=2): 58, ProcessCoord(pipe=3, data=2, model=3): 59, ProcessCoord(pipe=3, data=3, model=0): 60, ProcessCoord(pipe=3, data=3, model=1): 61, ProcessCoord(pipe=3, data=3, model=2): 62, ProcessCoord(pipe=3, data=3, model=3): 63, ProcessCoord(pipe=4, data=0, model=0): 64, ProcessCoord(pipe=4, data=0, model=1): 65, ProcessCoord(pipe=4, data=0, model=2): 66, ProcessCoord(pipe=4, data=0, model=3): 67, ProcessCoord(pipe=4, data=1, model=0): 68, ProcessCoord(pipe=4, data=1, model=1): 69, ProcessCoord(pipe=4, data=1, model=2): 70, ProcessCoord(pipe=4, data=1, model=3): 71, ProcessCoord(pipe=4, data=2, model=0): 72, ProcessCoord(pipe=4, data=2, model=1): 73, ProcessCoord(pipe=4, data=2, model=2): 74, ProcessCoord(pipe=4, data=2, model=3): 75, ProcessCoord(pipe=4, data=3, model=0): 76, ProcessCoord(pipe=4, data=3, model=1): 77, ProcessCoord(pipe=4, data=3, model=2): 78, ProcessCoord(pipe=4, data=3, model=3): 79, ProcessCoord(pipe=5, data=0, model=0): 80, ProcessCoord(pipe=5, data=0, model=1): 81, ProcessCoord(pipe=5, data=0, model=2): 82, ProcessCoord(pipe=5, data=0, model=3): 83, ProcessCoord(pipe=5, data=1, model=0): 84, ProcessCoord(pipe=5, data=1, model=1): 85, ProcessCoord(pipe=5, data=1, model=2): 86, ProcessCoord(pipe=5, data=1, model=3): 87, ProcessCoord(pipe=5, data=2, model=0): 88, ProcessCoord(pipe=5, data=2, model=1): 89, ProcessCoord(pipe=5, data=2, model=2): 90, ProcessCoord(pipe=5, data=2, model=3): 91, ProcessCoord(pipe=5, data=3, model=0): 92, ProcessCoord(pipe=5, data=3, model=1): 93, ProcessCoord(pipe=5, data=3, model=2): 94, ProcessCoord(pipe=5, data=3, model=3): 95, ProcessCoord(pipe=6, data=0, model=0): 96, ProcessCoord(pipe=6, data=0, model=1): 97, ProcessCoord(pipe=6, data=0, model=2): 98, ProcessCoord(pipe=6, data=0, model=3): 99, ProcessCoord(pipe=6, data=1, model=0): 100, ProcessCoord(pipe=6, data=1, model=1): 101, ProcessCoord(pipe=6, data=1, model=2): 102, ProcessCoord(pipe=6, data=1, model=3): 103, ProcessCoord(pipe=6, data=2, model=0): 104, ProcessCoord(pipe=6, data=2, model=1): 105, ProcessCoord(pipe=6, data=2, model=2): 106, ProcessCoord(pipe=6, data=2, model=3): 107, ProcessCoord(pipe=6, data=3, model=0): 108, ProcessCoord(pipe=6, data=3, model=1): 109, ProcessCoord(pipe=6, data=3, model=2): 110, ProcessCoord(pipe=6, data=3, model=3): 111, ProcessCoord(pipe=7, data=0, model=0): 112, ProcessCoord(pipe=7, data=0, model=1): 113, ProcessCoord(pipe=7, data=0, model=2): 114, ProcessCoord(pipe=7, data=0, model=3): 115, ProcessCoord(pipe=7, data=1, model=0): 116, ProcessCoord(pipe=7, data=1, model=1): 117, ProcessCoord(pipe=7, data=1, model=2): 118, ProcessCoord(pipe=7, data=1, model=3): 119, ProcessCoord(pipe=7, data=2, model=0): 120, ProcessCoord(pipe=7, data=2, model=1): 121, ProcessCoord(pipe=7, data=2, model=2): 122, ProcessCoord(pipe=7, data=2, model=3): 123, ProcessCoord(pipe=7, data=3, model=0): 124, ProcessCoord(pipe=7, data=3, model=1): 125, ProcessCoord(pipe=7, data=3, model=2): 126, ProcessCoord(pipe=7, data=3, model=3): 127}
[2025-02-12 14:48:24,680] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer|mlp
stage=0 layers=7
     0: EmbeddingPipe
     1: _pre_transformer_block
     2: ParallelTransformerLayerPipe
     3: ParallelTransformerLayerPipe
     4: ParallelTransformerLayerPipe
     5: ParallelTransformerLayerPipe
     6: ParallelTransformerLayerPipe
stage=1 layers=6
     7: ParallelTransformerLayerPipe
     8: ParallelTransformerLayerPipe
     9: ParallelTransformerLayerPipe
    10: ParallelTransformerLayerPipe
    11: ParallelTransformerLayerPipe
    12: ParallelTransformerLayerPipe
stage=2 layers=6
    13: ParallelTransformerLayerPipe
    14: ParallelTransformerLayerPipe
    15: ParallelTransformerLayerPipe
    16: ParallelTransformerLayerPipe
    17: ParallelTransformerLayerPipe
    18: ParallelTransformerLayerPipe
stage=3 layers=6
    19: ParallelTransformerLayerPipe
    20: ParallelTransformerLayerPipe
    21: ParallelTransformerLayerPipe
    22: ParallelTransformerLayerPipe
    23: ParallelTransformerLayerPipe
    24: ParallelTransformerLayerPipe
stage=4 layers=6
    25: ParallelTransformerLayerPipe
    26: ParallelTransformerLayerPipe
    27: ParallelTransformerLayerPipe
    28: ParallelTransformerLayerPipe
    29: ParallelTransformerLayerPipe
    30: ParallelTransformerLayerPipe
stage=5 layers=6
    31: ParallelTransformerLayerPipe
    32: ParallelTransformerLayerPipe
    33: ParallelTransformerLayerPipe
    34: ParallelTransformerLayerPipe
    35: ParallelTransformerLayerPipe
    36: ParallelTransformerLayerPipe
stage=6 layers=6
    37: ParallelTransformerLayerPipe
    38: ParallelTransformerLayerPipe
    39: ParallelTransformerLayerPipe
    40: ParallelTransformerLayerPipe
    41: ParallelTransformerLayerPipe
    42: ParallelTransformerLayerPipe
stage=7 layers=6
    43: ParallelTransformerLayerPipe
    44: ParallelTransformerLayerPipe
    45: ParallelTransformerLayerPipe
    46: _post_transformer_block
    47: NormPipe
    48: ParallelLinearPipe
  loss: partial
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
Configuring Optimizer type: Adam with params: {'lr': 9.7e-05, 'betas': [0.9, 0.95], 'eps': 1e-08}
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
WARNING: APEX not installed - defaulting to deepspeed's fused adam
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home1/08775/byz2022/.cache/torch_extensions/py39_cu124/fused_adam/build.ninja...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/utils/cpp_extension.py:2010: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
Using /home1/08775/byz2022/.cache/torch_extensions/py39_cu124 as PyTorch extensions root...
ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 0.11631011962890625 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.024923801422119 seconds
Time to load fused_adam op: 3.025329828262329 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.0254666805267334 seconds
Time to load fused_adam op: 3.026055335998535 seconds
Time to load fused_adam op: 3.025193452835083 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.0245261192321777 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.024686336517334 seconds
Time to load fused_adam op: 3.0263264179229736 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.024409055709839 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.025296688079834 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.026197671890259 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.025364637374878 seconds
Time to load fused_adam op: 3.025455951690674 seconds
Time to load fused_adam op: 3.0289576053619385 seconds
Time to load fused_adam op: 3.027819871902466 seconds
Time to load fused_adam op: 3.0266427993774414 seconds
Time to load fused_adam op: 3.029820442199707 seconds
Time to load fused_adam op: 3.0247037410736084 seconds
Time to load fused_adam op: 3.0222890377044678 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0256295204162598 seconds
Time to load fused_adam op: 3.0239312648773193 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.0232863426208496 seconds
Time to load fused_adam op: 3.0228586196899414 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.0222842693328857 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.0262978076934814 seconds
Time to load fused_adam op: 3.0268664360046387 seconds
Time to load fused_adam op: 3.0209217071533203 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0255415439605713 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.024585723876953 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.029524803161621 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0271575450897217 seconds
Time to load fused_adam op: 3.021233081817627 seconds
Time to load fused_adam op: 3.0250155925750732 seconds
Time to load fused_adam op: 3.0305349826812744 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0289604663848877 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.0212533473968506 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0262670516967773 seconds
Time to load fused_adam op: 3.0256121158599854 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.0269277095794678 seconds
Time to load fused_adam op: 3.023844003677368 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.026000738143921 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0259604454040527 seconds
Time to load fused_adam op: 3.027970790863037 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.0277493000030518 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.0218679904937744 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.0265533924102783 seconds
Time to load fused_adam op: 3.0226447582244873 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.036160707473755 seconds
Time to load fused_adam op: 3.023327112197876 seconds
Time to load fused_adam op: 3.026183843612671 seconds
Time to load fused_adam op: 3.025015354156494 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.021820545196533 seconds
Time to load fused_adam op: 3.0220205783843994 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0370054244995117 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.0267059803009033 seconds
Time to load fused_adam op: 3.020493268966675 seconds
Time to load fused_adam op: 3.022015333175659 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0260164737701416 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.028557062149048 seconds
Time to load fused_adam op: 3.030738353729248 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.028379440307617 seconds
Time to load fused_adam op: 3.038057327270508 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.019709825515747 seconds
Time to load fused_adam op: 3.031437635421753 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.022303342819214 seconds
Time to load fused_adam op: 3.0277597904205322 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0359251499176025 seconds
Time to load fused_adam op: 3.0216195583343506 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.02628755569458 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.021925210952759 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.026609182357788 seconds
Time to load fused_adam op: 3.019177198410034 seconds
Time to load fused_adam op: 3.0213334560394287 seconds
Time to load fused_adam op: 3.0260283946990967 seconds
Time to load fused_adam op: 3.0204553604125977 seconds
Time to load fused_adam op: 3.02704119682312 seconds
Time to load fused_adam op: 3.026646375656128 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0225229263305664 seconds
Time to load fused_adam op: 3.036086082458496 seconds
Time to load fused_adam op: 3.0192573070526123 seconds
Time to load fused_adam op: 3.030503749847412 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0318777561187744 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.02504563331604 seconds
> learning rate decay style: cosine
DeepSpeed is enabled.
Time to load fused_adam op: 3.019634485244751 seconds
Loading extension module fused_adam...
[2025-02-12 14:48:32,008] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4+02e2ebf, git-hash=02e2ebf, git-branch=HEAD
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.034304618835449 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0224967002868652 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.0213217735290527 seconds
Time to load fused_adam op: 3.020444631576538 seconds
Time to load fused_adam op: 3.024317502975464 seconds
Time to load fused_adam op: 3.026097059249878 seconds
Time to load fused_adam op: 3.0322306156158447 seconds
Time to load fused_adam op: 3.02482533454895 seconds
Time to load fused_adam op: 3.019782543182373 seconds
Time to load fused_adam op: 3.02775239944458 seconds
Time to load fused_adam op: 3.0253026485443115 seconds
Time to load fused_adam op: 3.0197088718414307 seconds
Time to load fused_adam op: 3.0246357917785645 seconds
Time to load fused_adam op: 3.0245957374572754 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0268712043762207 seconds
Time to load fused_adam op: 3.0293610095977783 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.024625301361084 seconds
Time to load fused_adam op: 3.029731035232544 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.0223476886749268 seconds
Time to load fused_adam op: 3.025369882583618 seconds
Time to load fused_adam op: 3.0293564796447754 seconds
Time to load fused_adam op: 3.0230467319488525 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0264899730682373 seconds
Time to load fused_adam op: 3.0276174545288086 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 3.0241711139678955 seconds
Time to load fused_adam op: 3.0242342948913574 seconds
Time to load fused_adam op: 3.0268821716308594 seconds
Time to load fused_adam op: 3.0403504371643066 seconds
Time to load fused_adam op: 3.031477451324463 seconds
Time to load fused_adam op: 3.0276594161987305 seconds
Time to load fused_adam op: 3.0354762077331543 seconds
Time to load fused_adam op: 3.0387520790100098 seconds
Time to load fused_adam op: 3.043299436569214 seconds
Time to load fused_adam op: 3.0461301803588867 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.033951997756958 seconds
Time to load fused_adam op: 3.03286075592041 seconds
Time to load fused_adam op: 3.040947198867798 seconds
Time to load fused_adam op: 3.0377237796783447 seconds
Time to load fused_adam op: 3.0381226539611816 seconds
Time to load fused_adam op: 3.0357322692871094 seconds
Time to load fused_adam op: 3.0460774898529053 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 3.0433290004730225 seconds
Time to load fused_adam op: 3.0471560955047607 seconds
[2025-02-12 14:48:32,188] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-02-12 14:48:32,188] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-02-12 14:48:32,188] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-02-12 14:48:32,189] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2025-02-12 14:48:32,189] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2025-02-12 14:48:32,189] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer
[2025-02-12 14:48:32,189] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 1260000000
[2025-02-12 14:48:32,189] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 1260000000
[2025-02-12 14:48:32,189] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2025-02-12 14:48:32,189] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2025-02-12 14:48:34,379] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,394] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,396] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,397] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,397] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,399] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,403] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,406] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,411] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,417] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,446] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,455] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,623] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,643] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,649] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:34,671] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,617] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,617] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,618] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,633] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,634] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,644] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,644] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,651] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,678] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,695] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,704] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,714] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,752] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,756] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,760] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,791] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,800] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,811] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,811] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,813] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,815] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,817] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,818] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,819] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,819] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,819] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,820] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,820] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,820] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,822] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,822] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,823] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,824] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,825] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,826] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,826] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,828] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,828] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,828] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,829] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,830] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,831] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,831] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,832] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,832] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,833] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,834] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,835] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,836] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,836] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,836] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,837] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,838] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,839] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,840] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,840] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,840] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,841] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,842] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,842] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,843] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,843] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,844] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,845] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,846] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,847] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,849] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,850] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,850] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,850] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,851] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,855] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,857] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,858] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,858] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,858] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states
[2025-02-12 14:48:35,859] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,859] [INFO] [utils.py:803:see_memory_usage] MA 1.8 GB         Max_MA 1.8 GB         CA 1.8 GB         Max_CA 2 GB 
[2025-02-12 14:48:35,859] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 22.33 GB, percent = 10.5%
[2025-02-12 14:48:35,860] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,861] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,864] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,864] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,864] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,864] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,866] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,866] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,870] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,871] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,873] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,874] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,874] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,875] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,877] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,877] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,878] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,879] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,885] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,887] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,894] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,895] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,897] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,900] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,917] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,918] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states
[2025-02-12 14:48:35,919] [INFO] [utils.py:803:see_memory_usage] MA 3.0 GB         Max_MA 3.6 GB         CA 3.61 GB         Max_CA 4 GB 
[2025-02-12 14:48:35,919] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 24.13 GB, percent = 11.3%
[2025-02-12 14:48:35,919] [INFO] [stage_1_and_2.py:517:__init__] optimizer state initialized
[2025-02-12 14:48:35,921] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,925] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:35,968] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer
[2025-02-12 14:48:35,968] [INFO] [utils.py:803:see_memory_usage] MA 3.0 GB         Max_MA 3.0 GB         CA 3.61 GB         Max_CA 4 GB 
[2025-02-12 14:48:35,969] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 24.13 GB, percent = 11.3%
[2025-02-12 14:48:35,969] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[2025-02-12 14:48:35,969] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-02-12 14:48:35,970] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x400320f7b940>
[2025-02-12 14:48:35,970] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:48:35,970] [INFO] [config.py:979:print] DeepSpeedEngine configuration:
[2025-02-12 14:48:35,970] [INFO] [config.py:983:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-02-12 14:48:35,970] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-02-12 14:48:35,970] [INFO] [config.py:983:print]   amp_enabled .................. False
[2025-02-12 14:48:35,970] [INFO] [config.py:983:print]   amp_params ................... False
[2025-02-12 14:48:35,970] [INFO] [config.py:983:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-02-12 14:48:35,970] [INFO] [config.py:983:print]   bfloat16_enabled ............. False
[2025-02-12 14:48:35,970] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False
[2025-02-12 14:48:35,970] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True
[2025-02-12 14:48:35,970] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False
[2025-02-12 14:48:35,970] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x400320fdbd00>
[2025-02-12 14:48:35,970] [INFO] [config.py:983:print]   communication_data_type ...... None
[2025-02-12 14:48:35,970] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-02-12 14:48:35,970] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False
[2025-02-12 14:48:35,970] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   dataloader_drop_last ......... False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   disable_allgather ............ False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   dump_state ................... False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   elasticity_enabled ........... False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   fp16_auto_cast ............... False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   fp16_enabled ................. True
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   global_rank .................. 0
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   grad_accum_dtype ............. None
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 16
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   gradient_clipping ............ 0.0
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 4096
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   load_universal_checkpoint .... False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   loss_scale ................... 0
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   memory_breakdown ............. False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   mics_shard_size .............. -1
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   optimizer_name ............... adam
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   optimizer_params ............. {'lr': 9.7e-05, 'betas': [0.9, 0.95], 'eps': 1e-08}
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   pld_enabled .................. False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   pld_params ................... False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   prescale_gradients ........... False
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   scheduler_name ............... None
[2025-02-12 14:48:35,971] [INFO] [config.py:983:print]   scheduler_params ............. None
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   sparse_attention ............. None
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   steps_per_print .............. 1
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   train_batch_size ............. 256
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  4
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   use_node_local_storage ....... False
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   wall_clock_breakdown ......... True
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   weight_quantization_config ... None
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   world_size ................... 4
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=1260000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=1260000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   zero_enabled ................. True
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True
[2025-02-12 14:48:35,972] [INFO] [config.py:983:print]   zero_optimization_stage ...... 1
[2025-02-12 14:48:35,972] [INFO] [config.py:969:print_user_config]   json = {
    "train_batch_size": 256, 
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 16, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 9.7e-05, 
            "betas": [0.9, 0.95], 
            "eps": 1e-08
        }
    }, 
    "fp16": {
        "fp16": true, 
        "enabled": true, 
        "loss_scale": 0, 
        "loss_scale_window": 1000, 
        "initial_scale_power": 12, 
        "hysteresis": 2, 
        "min_loss_scale": 1
    }, 
    "zero_optimization": {
        "stage": 1, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 1.260000e+09, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 1.260000e+09, 
        "contiguous_gradients": true
    }, 
    "steps_per_print": 1, 
    "wall_clock_breakdown": true
}
[2025-02-12 14:48:35,972] [INFO] [engine.py:99:__init__] CONFIG: micro_batches=16 micro_batch_size=4
[2025-02-12 14:48:35,972] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:36,114] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:36,137] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:36,154] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:36,171] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:36,248] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:36,253] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:36,260] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:36,280] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=0 STAGE=0 LAYERS=7 [0, 7) STAGE_PARAMS=644325888 (644.326M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=80 STAGE=5 LAYERS=6 [31, 37) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=82 STAGE=5 LAYERS=6 [31, 37) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=34 STAGE=2 LAYERS=6 [13, 19) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=96 STAGE=6 LAYERS=6 [37, 43) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=16 STAGE=1 LAYERS=6 [7, 13) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=32 STAGE=2 LAYERS=6 [13, 19) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=112 STAGE=7 LAYERS=6 [43, 49) STAGE_PARAMS=417750528 (417.751M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=2 STAGE=0 LAYERS=7 [0, 7) STAGE_PARAMS=644325888 (644.326M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=64 STAGE=4 LAYERS=6 [25, 31) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=18 STAGE=1 LAYERS=6 [7, 13) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=19 STAGE=1 LAYERS=6 [7, 13) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=114 STAGE=7 LAYERS=6 [43, 49) STAGE_PARAMS=417750528 (417.751M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=50 STAGE=3 LAYERS=6 [19, 25) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=3 STAGE=0 LAYERS=7 [0, 7) STAGE_PARAMS=644325888 (644.326M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=66 STAGE=4 LAYERS=6 [25, 31) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=81 STAGE=5 LAYERS=6 [31, 37) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=83 STAGE=5 LAYERS=6 [31, 37) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=51 STAGE=3 LAYERS=6 [19, 25) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=35 STAGE=2 LAYERS=6 [13, 19) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=48 STAGE=3 LAYERS=6 [19, 25) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=33 STAGE=2 LAYERS=6 [13, 19) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=98 STAGE=6 LAYERS=6 [37, 43) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=17 STAGE=1 LAYERS=6 [7, 13) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=115 STAGE=7 LAYERS=6 [43, 49) STAGE_PARAMS=417750528 (417.751M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=99 STAGE=6 LAYERS=6 [37, 43) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=65 STAGE=4 LAYERS=6 [25, 31) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=1 STAGE=0 LAYERS=7 [0, 7) STAGE_PARAMS=644325888 (644.326M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=49 STAGE=3 LAYERS=6 [19, 25) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=113 STAGE=7 LAYERS=6 [43, 49) STAGE_PARAMS=417750528 (417.751M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,466] [INFO] [engine.py:158:__init__] RANK=67 STAGE=4 LAYERS=6 [25, 31) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
[2025-02-12 14:48:36,465] [INFO] [engine.py:158:__init__] RANK=97 STAGE=6 LAYERS=6 [37, 43) STAGE_PARAMS=679762944 (679.763M) TOTAL_PARAMS=20562616320 (20562.616M) UNIQUE_PARAMS=20562616320 (20562.616M)
 > number of parameters on model parallel rank 0: 644325888
 > number of parameters on model parallel rank 0: 417750528
 > number of parameters on model parallel rank 3: 644325888
 > number of parameters on model parallel rank 0: 679762944
 > number of parameters on model parallel rank 0: 679762944
 > number of parameters on model parallel rank 0: 679762944
 > number of parameters on model parallel rank 0: 679762944
 > number of parameters on model parallel rank 3: 679762944
 > number of parameters on model parallel rank 3: 679762944
 > number of parameters on model parallel rank 3: 679762944
 > number of parameters on model parallel rank 3: 679762944
 > number of parameters on model parallel rank 0: 679762944
 > number of parameters on model parallel rank 0: 679762944
 > number of parameters on model parallel rank 3: 417750528
 > number of parameters on model parallel rank 2: 417750528
 > number of parameters on model parallel rank 3: 679762944
 > number of parameters on model parallel rank 3: 679762944
 > number of parameters on model parallel rank 2: 644325888
 > number of parameters on model parallel rank 1: 417750528
 > number of parameters on model parallel rank 2: 679762944
 > number of parameters on model parallel rank 2: 679762944
 > number of parameters on model parallel rank 1: 679762944
 > number of parameters on model parallel rank 1: 679762944
 > number of parameters on model parallel rank 1: 679762944
 > number of parameters on model parallel rank 1: 679762944
 > number of parameters on model parallel rank 1: 644325888
 > number of parameters on model parallel rank 2: 679762944
 > number of parameters on model parallel rank 2: 679762944
 > number of parameters on model parallel rank 2: 679762944
 > number of parameters on model parallel rank 2: 679762944
 > number of parameters on model parallel rank 1: 679762944
 > number of parameters on model parallel rank 1: 679762944
 > total params: 20,562,616,320
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
Loading checkpoint and starting from iteration 0
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
setting training data start iteration to 0
Unable to load checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
setting validation data start iteration to 0
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,663] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Unable to load checkpoint.
Unable to load checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2025-02-12 14:48:36,664] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/checkpoints_test2/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
done with setups ...
time (ms) | train/valid/test data loaders: 1235.88 | model and optimizer: 11985.69 | train/valid/test data iterators: 45.78
training ...
[2025-02-12 14:48:36,831] [INFO] [checkpointing.py:540:forward] Activation Checkpointing Information
[2025-02-12 14:48:36,831] [INFO] [checkpointing.py:541:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2025-02-12 14:48:36,831] [INFO] [checkpointing.py:542:forward] ----contiguous Memory Checkpointing False with 44 total layers
[2025-02-12 14:48:36,831] [INFO] [checkpointing.py:544:forward] ----Synchronization True
[2025-02-12 14:48:36,831] [INFO] [checkpointing.py:545:forward] ----Profiling time in checkpointing False
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[2025-02-12 14:48:46,633] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.32 | optimizer_gradients: 11.09 | optimizer_step: 1.79
[2025-02-12 14:48:46,633] [INFO] [logging.py:96:log_dist] [Rank 0] step=1, skipped=0, lr=[9.698271780404732e-05, 9.698271780404732e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:48:46,634] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 79.98 | fwd_microstep: 1395.62 | bwd_microstep: 2011.52 | bwd_inner_microstep: 2011.43 | bwd_allreduce_microstep: 0.00 | step_microstep: 177.56
[2025-02-12 14:48:46,635] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1395.66 | bwd: 2011.52 | bwd_inner: 2011.43 | bwd_allreduce: 0.00 | step: 177.57
steps: 1 loss: 11.0430 iter time (s): 9.992 samples/sec: 25.620
[2025-02-12 14:48:46,705] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 3143.59 | pipe_recv_grad: 2982.11
 samples/sec: 25.611 | iteration        1/      53 | elapsed time per iteration (ms): 9995.6 | learning rate: 9.698E-05 | approx flops per GPU: 69.7TFLOPS | lm_loss: 1.104301E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
after 1 iterations memory (MB) | allocated: 3193.39306640625 | max allocated: 10170.2255859375 | reserved: 12230.0 | max reserved: 12230.0
time (ms)
[2025-02-12 14:48:58,905] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.29 | optimizer_gradients: 1.23 | optimizer_step: 1.78
[2025-02-12 14:48:58,905] [INFO] [logging.py:96:log_dist] [Rank 0] step=2, skipped=0, lr=[9.683103912061546e-05, 9.683103912061546e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:48:58,906] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 14.26 | fwd_microstep: 740.89 | bwd_microstep: 1839.97 | bwd_inner_microstep: 1839.89 | bwd_allreduce_microstep: 0.00 | step_microstep: 29.10
[2025-02-12 14:48:58,907] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 740.94 | bwd: 1839.97 | bwd_inner: 1839.89 | bwd_allreduce: 0.00 | step: 29.12
steps: 2 loss: 11.0398 iter time (s): 12.200 samples/sec: 20.984
[2025-02-12 14:48:58,908] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 57.09 | pipe_recv_grad: 9467.54
 samples/sec: 20.979 | iteration        2/      53 | elapsed time per iteration (ms): 12202.8 | learning rate: 9.683E-05 | approx flops per GPU: 57.1TFLOPS | lm_loss: 1.103985E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[rank127]:[W212 14:48:59.262323783 CPUAllocator.cpp:245] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
[rank16]:[W212 14:49:01.238075831 CPUAllocator.cpp:245] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
[rank0]:[W212 14:49:01.791407584 CPUAllocator.cpp:245] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
[2025-02-12 14:49:06,051] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.44 | optimizer_gradients: 1.24 | optimizer_step: 1.78
[2025-02-12 14:49:06,051] [INFO] [logging.py:96:log_dist] [Rank 0] step=3, skipped=0, lr=[9.65235316159354e-05, 9.65235316159354e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:49:06,053] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 25.52 | fwd_microstep: 699.11 | bwd_microstep: 1868.83 | bwd_inner_microstep: 1868.75 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.53
[2025-02-12 14:49:06,054] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 699.20 | bwd: 1868.83 | bwd_inner: 1868.75 | bwd_allreduce: 0.00 | step: 30.56
steps: 3 loss: 12.3350 iter time (s): 7.145 samples/sec: 35.828
[2025-02-12 14:49:06,056] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 61.21 | pipe_recv_grad: 4404.39
 samples/sec: 35.815 | iteration        3/      53 | elapsed time per iteration (ms): 7147.8 | learning rate: 9.652E-05 | approx flops per GPU: 97.5TFLOPS | lm_loss: 1.233497E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
[2025-02-12 14:49:13,430] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.27 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:49:13,430] [INFO] [logging.py:96:log_dist] [Rank 0] step=4, skipped=0, lr=[9.606129734582155e-05, 9.606129734582155e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:49:13,432] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.16 | fwd_microstep: 1021.66 | bwd_microstep: 1879.19 | bwd_inner_microstep: 1879.11 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.32
[2025-02-12 14:49:13,433] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1021.74 | bwd: 1879.19 | bwd_inner: 1879.11 | bwd_allreduce: 0.00 | step: 30.35
steps: 4 loss: 28.7340 iter time (s): 7.377 samples/sec: 34.703
[2025-02-12 14:49:13,434] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 53.81 | pipe_recv_grad: 4314.10
 samples/sec: 34.694 | iteration        4/      53 | elapsed time per iteration (ms): 7378.8 | learning rate: 9.606E-05 | approx flops per GPU: 94.5TFLOPS | lm_loss: 2.873402E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:49:24,126] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.29 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:49:24,126] [INFO] [logging.py:96:log_dist] [Rank 0] step=5, skipped=0, lr=[9.544599288111281e-05, 9.544599288111281e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:49:24,128] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.88 | fwd_microstep: 702.14 | bwd_microstep: 1874.77 | bwd_inner_microstep: 1874.69 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.44
[2025-02-12 14:49:24,129] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 702.13 | bwd: 1874.77 | bwd_inner: 1874.69 | bwd_allreduce: 0.00 | step: 30.46
steps: 5 loss: 16.6893 iter time (s): 10.694 samples/sec: 23.938
[2025-02-12 14:49:24,131] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 47.98 | pipe_recv_grad: 7961.76
 samples/sec: 23.934 | iteration        5/      53 | elapsed time per iteration (ms): 10696.2 | learning rate: 9.545E-05 | approx flops per GPU: 65.2TFLOPS | lm_loss: 1.668934E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:49:40,362] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.32 | optimizer_gradients: 1.26 | optimizer_step: 1.78
[2025-02-12 14:49:40,362] [INFO] [logging.py:96:log_dist] [Rank 0] step=6, skipped=0, lr=[9.467982337079787e-05, 9.467982337079787e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:49:40,364] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.61 | fwd_microstep: 713.95 | bwd_microstep: 1877.02 | bwd_inner_microstep: 1876.94 | bwd_allreduce_microstep: 0.00 | step_microstep: 31.65
[2025-02-12 14:49:40,365] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 714.02 | bwd: 1877.02 | bwd_inner: 1876.94 | bwd_allreduce: 0.00 | step: 31.67
steps: 6 loss: 11.5615 iter time (s): 16.234 samples/sec: 15.769
[2025-02-12 14:49:40,367] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 55.38 | pipe_recv_grad: 13479.59
 samples/sec: 15.767 | iteration        6/      53 | elapsed time per iteration (ms): 16236.2 | learning rate: 9.468E-05 | approx flops per GPU: 42.9TFLOPS | lm_loss: 1.156151E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:49:53,540] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.31 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:49:53,540] [INFO] [logging.py:96:log_dist] [Rank 0] step=7, skipped=0, lr=[9.376553463912756e-05, 9.376553463912756e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:49:53,542] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.06 | fwd_microstep: 700.01 | bwd_microstep: 1885.88 | bwd_inner_microstep: 1885.79 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.31
[2025-02-12 14:49:53,543] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 700.09 | bwd: 1885.88 | bwd_inner: 1885.79 | bwd_allreduce: 0.00 | step: 30.33
steps: 7 loss: 11.8310 iter time (s): 13.176 samples/sec: 19.429
[2025-02-12 14:49:53,545] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 54.33 | pipe_recv_grad: 10427.59
 samples/sec: 19.426 | iteration        7/      53 | elapsed time per iteration (ms): 13177.9 | learning rate: 9.377E-05 | approx flops per GPU: 52.9TFLOPS | lm_loss: 1.183098E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:50:18,009] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.25 | optimizer_gradients: 1.25 | optimizer_step: 1.78
[2025-02-12 14:50:18,009] [INFO] [logging.py:96:log_dist] [Rank 0] step=8, skipped=0, lr=[9.270640334503684e-05, 9.270640334503684e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:50:18,011] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.49 | fwd_microstep: 10085.39 | bwd_microstep: 1872.49 | bwd_inner_microstep: 1872.41 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.28
[2025-02-12 14:50:18,012] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 10085.46 | bwd: 1872.49 | bwd_inner: 1872.41 | bwd_allreduce: 0.00 | step: 30.30
steps: 8 loss: 11.4981 iter time (s): 24.467 samples/sec: 10.463
[2025-02-12 14:50:18,013] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 50.21 | pipe_recv_grad: 12350.29
 samples/sec: 10.462 | iteration        8/      53 | elapsed time per iteration (ms): 24468.5 | learning rate: 9.271E-05 | approx flops per GPU: 28.5TFLOPS | lm_loss: 1.149812E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:50:31,296] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.41 | optimizer_gradients: 1.24 | optimizer_step: 1.78
[2025-02-12 14:50:31,297] [INFO] [logging.py:96:log_dist] [Rank 0] step=9, skipped=0, lr=[9.150622523914358e-05, 9.150622523914358e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:50:31,298] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.68 | fwd_microstep: 1411.44 | bwd_microstep: 1867.75 | bwd_inner_microstep: 1867.67 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.63
[2025-02-12 14:50:31,300] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1411.56 | bwd: 1867.75 | bwd_inner: 1867.67 | bwd_allreduce: 0.00 | step: 30.65
steps: 9 loss: 11.1015 iter time (s): 13.286 samples/sec: 19.269
[2025-02-12 14:50:31,301] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 54.80 | pipe_recv_grad: 9844.42
 samples/sec: 19.266 | iteration        9/      53 | elapsed time per iteration (ms): 13287.9 | learning rate: 9.151E-05 | approx flops per GPU: 52.5TFLOPS | lm_loss: 1.110148E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:50:38,569] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.28 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:50:38,569] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[9.01693015604087e-05, 9.01693015604087e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:50:38,571] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.03 | fwd_microstep: 697.01 | bwd_microstep: 1865.32 | bwd_inner_microstep: 1865.24 | bwd_allreduce_microstep: 0.00 | step_microstep: 31.29
[2025-02-12 14:50:38,572] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 697.04 | bwd: 1865.32 | bwd_inner: 1865.24 | bwd_allreduce: 0.00 | step: 31.31
steps: 10 loss: 10.5510 iter time (s): 7.270 samples/sec: 35.212
[2025-02-12 14:50:38,573] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 62.82 | pipe_recv_grad: 4536.36
 samples/sec: 35.203 | iteration       10/      53 | elapsed time per iteration (ms): 7272.2 | learning rate: 9.017E-05 | approx flops per GPU: 95.9TFLOPS | lm_loss: 1.055100E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:50:46,069] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.36 | optimizer_gradients: 1.24 | optimizer_step: 1.78
[2025-02-12 14:50:46,069] [INFO] [logging.py:96:log_dist] [Rank 0] step=11, skipped=0, lr=[8.870042362121043e-05, 8.870042362121043e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:50:46,071] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.42 | fwd_microstep: 868.14 | bwd_microstep: 1875.94 | bwd_inner_microstep: 1875.85 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.38
[2025-02-12 14:50:46,072] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 868.21 | bwd: 1875.93 | bwd_inner: 1875.85 | bwd_allreduce: 0.00 | step: 30.40
steps: 11 loss: 10.0950 iter time (s): 7.499 samples/sec: 34.140
[2025-02-12 14:50:46,074] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 57.94 | pipe_recv_grad: 4588.70
 samples/sec: 34.131 | iteration       11/      53 | elapsed time per iteration (ms): 7500.5 | learning rate: 8.870E-05 | approx flops per GPU: 92.9TFLOPS | lm_loss: 1.009496E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:50:52,776] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.36 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:50:52,776] [INFO] [logging.py:96:log_dist] [Rank 0] step=12, skipped=0, lr=[8.710485563607657e-05, 8.710485563607657e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:50:52,778] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.01 | fwd_microstep: 730.08 | bwd_microstep: 1866.12 | bwd_inner_microstep: 1866.04 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.41
[2025-02-12 14:50:52,780] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 730.16 | bwd: 1866.12 | bwd_inner: 1866.04 | bwd_allreduce: 0.00 | step: 30.44
steps: 12 loss: 9.8445 iter time (s): 6.705 samples/sec: 38.180
[2025-02-12 14:50:52,781] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 55.65 | pipe_recv_grad: 3945.59
 samples/sec: 38.169 | iteration       12/      53 | elapsed time per iteration (ms): 6707.1 | learning rate: 8.710E-05 | approx flops per GPU: 103.9TFLOPS | lm_loss: 9.844545E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:50:59,847] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.31 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:50:59,847] [INFO] [logging.py:96:log_dist] [Rank 0] step=13, skipped=0, lr=[8.538831585561413e-05, 8.538831585561413e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:50:59,849] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.89 | fwd_microstep: 697.56 | bwd_microstep: 1869.33 | bwd_inner_microstep: 1869.24 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.26
[2025-02-12 14:50:59,851] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 697.62 | bwd: 1869.32 | bwd_inner: 1869.24 | bwd_allreduce: 0.00 | step: 30.28
steps: 13 loss: 9.6666 iter time (s): 7.069 samples/sec: 36.215
[2025-02-12 14:50:59,852] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 52.14 | pipe_recv_grad: 4342.24
 samples/sec: 36.204 | iteration       13/      53 | elapsed time per iteration (ms): 7070.9 | learning rate: 8.539E-05 | approx flops per GPU: 98.6TFLOPS | lm_loss: 9.666646E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
[2025-02-12 14:51:09,318] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.28 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:51:09,318] [INFO] [logging.py:96:log_dist] [Rank 0] step=14, skipped=0, lr=[8.355695607324906e-05, 8.355695607324906e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:51:09,320] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.94 | fwd_microstep: 3552.01 | bwd_microstep: 1865.86 | bwd_inner_microstep: 1865.78 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.21
[2025-02-12 14:51:09,321] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3552.10 | bwd: 1865.86 | bwd_inner: 1865.78 | bwd_allreduce: 0.00 | step: 30.23
steps: 14 loss: 9.2822 iter time (s): 9.469 samples/sec: 27.036
[2025-02-12 14:51:09,323] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 56.31 | pipe_recv_grad: 3887.10
 samples/sec: 27.030 | iteration       14/      53 | elapsed time per iteration (ms): 9470.8 | learning rate: 8.356E-05 | approx flops per GPU: 73.6TFLOPS | lm_loss: 9.282213E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:51:27,926] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.41 | optimizer_gradients: 1.25 | optimizer_step: 1.78
[2025-02-12 14:51:27,926] [INFO] [logging.py:96:log_dist] [Rank 0] step=15, skipped=0, lr=[8.161733957822048e-05, 8.161733957822048e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:51:27,928] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.97 | fwd_microstep: 697.53 | bwd_microstep: 1863.97 | bwd_inner_microstep: 1863.89 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.53
[2025-02-12 14:51:27,929] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 697.61 | bwd: 1863.97 | bwd_inner: 1863.89 | bwd_allreduce: 0.00 | step: 30.56
steps: 15 loss: 9.0940 iter time (s): 18.606 samples/sec: 13.759
[2025-02-12 14:51:27,931] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 52.55 | pipe_recv_grad: 15883.23
 samples/sec: 13.758 | iteration       15/      53 | elapsed time per iteration (ms): 18607.7 | learning rate: 8.162E-05 | approx flops per GPU: 37.5TFLOPS | lm_loss: 9.093965E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:51:48,656] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.25 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:51:48,656] [INFO] [logging.py:96:log_dist] [Rank 0] step=16, skipped=0, lr=[7.957641763384244e-05, 7.957641763384244e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:51:48,658] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.89 | fwd_microstep: 1637.16 | bwd_microstep: 1867.89 | bwd_inner_microstep: 1867.80 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.35
[2025-02-12 14:51:48,659] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1637.24 | bwd: 1867.89 | bwd_inner: 1867.80 | bwd_allreduce: 0.00 | step: 30.37
steps: 16 loss: 8.8469 iter time (s): 20.728 samples/sec: 12.350
[2025-02-12 14:51:48,660] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 49.78 | pipe_recv_grad: 17065.61
 samples/sec: 12.349 | iteration       16/      53 | elapsed time per iteration (ms): 20729.9 | learning rate: 7.958E-05 | approx flops per GPU: 33.6TFLOPS | lm_loss: 8.846895E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:52:13,366] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.14 | optimizer_gradients: 1.24 | optimizer_step: 1.80
[2025-02-12 14:52:13,366] [INFO] [logging.py:96:log_dist] [Rank 0] step=17, skipped=0, lr=[7.744150456533075e-05, 7.744150456533075e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:52:13,368] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.71 | fwd_microstep: 6576.05 | bwd_microstep: 1865.50 | bwd_inner_microstep: 1865.42 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.37
[2025-02-12 14:52:13,369] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 6576.11 | bwd: 1865.50 | bwd_inner: 1865.41 | bwd_allreduce: 0.00 | step: 30.39
steps: 17 loss: 8.7953 iter time (s): 24.708 samples/sec: 10.361
[2025-02-12 14:52:13,371] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 34.73 | pipe_recv_grad: 16124.90
 samples/sec: 10.360 | iteration       17/      53 | elapsed time per iteration (ms): 24710.2 | learning rate: 7.744E-05 | approx flops per GPU: 28.2TFLOPS | lm_loss: 8.795347E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:52:28,127] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.30 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:52:28,127] [INFO] [logging.py:96:log_dist] [Rank 0] step=18, skipped=0, lr=[7.522025154647663e-05, 7.522025154647663e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:52:28,129] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 23.46 | fwd_microstep: 2351.82 | bwd_microstep: 1864.69 | bwd_inner_microstep: 1864.60 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.23
[2025-02-12 14:52:28,130] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2351.93 | bwd: 1864.69 | bwd_inner: 1864.60 | bwd_allreduce: 0.00 | step: 30.25
steps: 18 loss: 8.6236 iter time (s): 14.759 samples/sec: 17.345
[2025-02-12 14:52:28,132] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 57.61 | pipe_recv_grad: 10375.38
 samples/sec: 17.343 | iteration       18/      53 | elapsed time per iteration (ms): 14760.9 | learning rate: 7.522E-05 | approx flops per GPU: 47.2TFLOPS | lm_loss: 8.623560E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:52:48,827] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.44 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:52:48,827] [INFO] [logging.py:96:log_dist] [Rank 0] step=19, skipped=0, lr=[7.292061917911073e-05, 7.292061917911073e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:52:48,829] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.74 | fwd_microstep: 2400.59 | bwd_microstep: 1876.90 | bwd_inner_microstep: 1876.81 | bwd_allreduce_microstep: 0.00 | step_microstep: 31.21
[2025-02-12 14:52:48,831] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2400.74 | bwd: 1876.90 | bwd_inner: 1876.81 | bwd_allreduce: 0.00 | step: 31.24
steps: 19 loss: 8.4090 iter time (s): 20.698 samples/sec: 12.368
[2025-02-12 14:52:48,832] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 54.11 | pipe_recv_grad: 16258.58
 samples/sec: 12.367 | iteration       19/      53 | elapsed time per iteration (ms): 20700.4 | learning rate: 7.292E-05 | approx flops per GPU: 33.7TFLOPS | lm_loss: 8.409015E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:52:59,727] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.25 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:52:59,727] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[7.055084896362858e-05, 7.055084896362858e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:52:59,729] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.29 | fwd_microstep: 5157.84 | bwd_microstep: 1866.73 | bwd_inner_microstep: 1866.65 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.42
[2025-02-12 14:52:59,730] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 5157.91 | bwd: 1866.73 | bwd_inner: 1866.65 | bwd_allreduce: 0.00 | step: 30.44
steps: 20 loss: 8.3333 iter time (s): 10.898 samples/sec: 23.491
[2025-02-12 14:52:59,732] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 55.46 | pipe_recv_grad: 3709.87
 samples/sec: 23.487 | iteration       20/      53 | elapsed time per iteration (ms): 10899.9 | learning rate: 7.055E-05 | approx flops per GPU: 64.0TFLOPS | lm_loss: 8.333263E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
[2025-02-12 14:53:09,076] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.34 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:53:09,076] [INFO] [logging.py:96:log_dist] [Rank 0] step=21, skipped=0, lr=[6.811943376282227e-05, 6.811943376282227e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:53:09,078] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.12 | fwd_microstep: 2915.71 | bwd_microstep: 1861.85 | bwd_inner_microstep: 1861.76 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.31
[2025-02-12 14:53:09,079] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2915.79 | bwd: 1861.85 | bwd_inner: 1861.76 | bwd_allreduce: 0.00 | step: 30.34
steps: 21 loss: 8.1987 iter time (s): 9.347 samples/sec: 27.390
[2025-02-12 14:53:09,081] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 57.66 | pipe_recv_grad: 4403.67
 samples/sec: 27.384 | iteration       21/      53 | elapsed time per iteration (ms): 9348.5 | learning rate: 6.812E-05 | approx flops per GPU: 74.6TFLOPS | lm_loss: 8.198725E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:53:16,336] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.36 | optimizer_gradients: 1.24 | optimizer_step: 1.78
[2025-02-12 14:53:16,336] [INFO] [logging.py:96:log_dist] [Rank 0] step=22, skipped=0, lr=[6.56350873648709e-05, 6.56350873648709e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:53:16,338] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.26 | fwd_microstep: 696.01 | bwd_microstep: 1864.34 | bwd_inner_microstep: 1864.26 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.41
[2025-02-12 14:53:16,339] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 696.09 | bwd: 1864.34 | bwd_inner: 1864.25 | bwd_allreduce: 0.00 | step: 30.44
steps: 22 loss: 8.1759 iter time (s): 7.258 samples/sec: 35.272
[2025-02-12 14:53:16,340] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 53.61 | pipe_recv_grad: 4535.91
 samples/sec: 35.263 | iteration       22/      53 | elapsed time per iteration (ms): 7259.8 | learning rate: 6.564E-05 | approx flops per GPU: 96.0TFLOPS | lm_loss: 8.175871E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:53:23,268] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.35 | optimizer_gradients: 1.25 | optimizer_step: 1.78
[2025-02-12 14:53:23,268] [INFO] [logging.py:96:log_dist] [Rank 0] step=23, skipped=0, lr=[6.310671325457146e-05, 6.310671325457146e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:53:23,270] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.96 | fwd_microstep: 860.61 | bwd_microstep: 1879.84 | bwd_inner_microstep: 1879.76 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.32
[2025-02-12 14:53:23,271] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 860.68 | bwd: 1879.84 | bwd_inner: 1879.76 | bwd_allreduce: 0.00 | step: 30.34
steps: 23 loss: 8.0253 iter time (s): 6.930 samples/sec: 36.940
[2025-02-12 14:53:23,273] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 202.83 | pipe_recv_grad: 3879.66
 samples/sec: 36.929 | iteration       23/      53 | elapsed time per iteration (ms): 6932.2 | learning rate: 6.311E-05 | approx flops per GPU: 100.6TFLOPS | lm_loss: 8.025267E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:53:30,290] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.42 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:53:30,290] [INFO] [logging.py:96:log_dist] [Rank 0] step=24, skipped=0, lr=[6.05433727047281e-05, 6.05433727047281e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:53:30,293] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.23 | fwd_microstep: 924.98 | bwd_microstep: 1871.96 | bwd_inner_microstep: 1871.88 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.46
[2025-02-12 14:53:30,294] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 925.05 | bwd: 1871.96 | bwd_inner: 1871.88 | bwd_allreduce: 0.00 | step: 30.49
steps: 24 loss: 7.8184 iter time (s): 7.021 samples/sec: 36.461
[2025-02-12 14:53:30,296] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 56.68 | pipe_recv_grad: 4057.89
 samples/sec: 36.451 | iteration       24/      53 | elapsed time per iteration (ms): 7023.1 | learning rate: 6.054E-05 | approx flops per GPU: 99.3TFLOPS | lm_loss: 7.818447E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:53:37,045] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.34 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:53:37,045] [INFO] [logging.py:96:log_dist] [Rank 0] step=25, skipped=0, lr=[5.795425230205587e-05, 5.795425230205587e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:53:37,047] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.09 | fwd_microstep: 1633.89 | bwd_microstep: 1863.60 | bwd_inner_microstep: 1863.51 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.47
[2025-02-12 14:53:37,049] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1633.98 | bwd: 1863.60 | bwd_inner: 1863.51 | bwd_allreduce: 0.00 | step: 30.50
steps: 25 loss: 7.8638 iter time (s): 6.752 samples/sec: 37.912
[2025-02-12 14:53:37,050] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 47.73 | pipe_recv_grad: 3099.32
 samples/sec: 37.901 | iteration       25/      53 | elapsed time per iteration (ms): 6754.5 | learning rate: 5.795E-05 | approx flops per GPU: 103.2TFLOPS | lm_loss: 7.863804E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:53:46,957] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.29 | optimizer_gradients: 1.24 | optimizer_step: 1.78
[2025-02-12 14:53:46,957] [INFO] [logging.py:96:log_dist] [Rank 0] step=26, skipped=0, lr=[5.534863102397978e-05, 5.534863102397978e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:53:46,959] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.82 | fwd_microstep: 1495.43 | bwd_microstep: 1862.25 | bwd_inner_microstep: 1862.17 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.32
[2025-02-12 14:53:46,960] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1495.50 | bwd: 1862.25 | bwd_inner: 1862.17 | bwd_allreduce: 0.00 | step: 30.34
steps: 26 loss: 7.7557 iter time (s): 9.910 samples/sec: 25.833
[2025-02-12 14:53:46,962] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 54.26 | pipe_recv_grad: 6389.71
 samples/sec: 25.828 | iteration       26/      53 | elapsed time per iteration (ms): 9911.7 | learning rate: 5.535E-05 | approx flops per GPU: 70.3TFLOPS | lm_loss: 7.755667E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:53:59,166] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.29 | optimizer_gradients: 1.24 | optimizer_step: 1.80
[2025-02-12 14:53:59,166] [INFO] [logging.py:96:log_dist] [Rank 0] step=27, skipped=0, lr=[5.2735846984321284e-05, 5.2735846984321284e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:53:59,168] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.88 | fwd_microstep: 745.24 | bwd_microstep: 1877.73 | bwd_inner_microstep: 1877.65 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.12
[2025-02-12 14:53:59,169] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 745.33 | bwd: 1877.73 | bwd_inner: 1877.65 | bwd_allreduce: 0.00 | step: 30.14
steps: 27 loss: 7.7952 iter time (s): 12.207 samples/sec: 20.972
[2025-02-12 14:53:59,171] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 53.32 | pipe_recv_grad: 9423.31
 samples/sec: 20.969 | iteration       27/      53 | elapsed time per iteration (ms): 12208.7 | learning rate: 5.274E-05 | approx flops per GPU: 57.1TFLOPS | lm_loss: 7.795191E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:54:05,779] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.67 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:54:05,779] [INFO] [logging.py:96:log_dist] [Rank 0] step=28, skipped=0, lr=[5.012526396704944e-05, 5.012526396704944e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:54:05,781] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.37 | fwd_microstep: 789.80 | bwd_microstep: 1870.09 | bwd_inner_microstep: 1870.00 | bwd_allreduce_microstep: 0.00 | step_microstep: 31.98
[2025-02-12 14:54:05,782] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 789.87 | bwd: 1870.08 | bwd_inner: 1870.00 | bwd_allreduce: 0.00 | step: 32.00
steps: 28 loss: 8.0347 iter time (s): 6.611 samples/sec: 38.723
[2025-02-12 14:54:05,784] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 51.57 | pipe_recv_grad: 3790.08
 samples/sec: 38.711 | iteration       28/      53 | elapsed time per iteration (ms): 6613.2 | learning rate: 5.013E-05 | approx flops per GPU: 105.4TFLOPS | lm_loss: 8.034727E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:54:33,680] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.21 | optimizer_gradients: 1.24 | optimizer_step: 1.78
[2025-02-12 14:54:33,680] [INFO] [logging.py:96:log_dist] [Rank 0] step=29, skipped=0, lr=[4.75262378680347e-05, 4.75262378680347e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:54:33,682] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.71 | fwd_microstep: 4938.40 | bwd_microstep: 1868.65 | bwd_inner_microstep: 1868.56 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.99
[2025-02-12 14:54:33,683] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 4938.46 | bwd: 1868.65 | bwd_inner: 1868.56 | bwd_allreduce: 0.00 | step: 31.02
steps: 29 loss: 8.0048 iter time (s): 27.899 samples/sec: 9.176
[2025-02-12 14:54:33,684] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 55.02 | pipe_recv_grad: 20927.62
 samples/sec: 9.175 | iteration       29/      53 | elapsed time per iteration (ms): 27900.4 | learning rate: 4.753E-05 | approx flops per GPU: 25.0TFLOPS | lm_loss: 8.004796E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:54:50,726] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.44 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:54:50,726] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[4.494808316507232e-05, 4.494808316507232e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:54:50,728] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.81 | fwd_microstep: 784.25 | bwd_microstep: 1866.47 | bwd_inner_microstep: 1866.38 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.39
[2025-02-12 14:54:50,729] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 784.33 | bwd: 1866.47 | bwd_inner: 1866.38 | bwd_allreduce: 0.00 | step: 30.41
steps: 30 loss: 7.9572 iter time (s): 17.044 samples/sec: 15.020
[2025-02-12 14:54:50,731] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 47.24 | pipe_recv_grad: 14238.27
 samples/sec: 15.018 | iteration       30/      53 | elapsed time per iteration (ms): 17046.4 | learning rate: 4.495E-05 | approx flops per GPU: 40.9TFLOPS | lm_loss: 7.957235E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
[2025-02-12 14:55:10,127] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.23 | optimizer_gradients: 1.24 | optimizer_step: 1.80
[2025-02-12 14:55:10,127] [INFO] [logging.py:96:log_dist] [Rank 0] step=31, skipped=0, lr=[4.2400039536341175e-05, 4.2400039536341175e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:55:10,129] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.57 | fwd_microstep: 698.63 | bwd_microstep: 1863.67 | bwd_inner_microstep: 1863.59 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.21
[2025-02-12 14:55:10,130] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 698.69 | bwd: 1863.67 | bwd_inner: 1863.59 | bwd_allreduce: 0.00 | step: 30.23
steps: 31 loss: 7.8200 iter time (s): 19.399 samples/sec: 13.197
[2025-02-12 14:55:10,131] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 51.13 | pipe_recv_grad: 16676.59
 samples/sec: 13.195 | iteration       31/      53 | elapsed time per iteration (ms): 19400.8 | learning rate: 4.240E-05 | approx flops per GPU: 35.9TFLOPS | lm_loss: 7.820020E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:55:22,679] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.38 | optimizer_gradients: 1.25 | optimizer_step: 1.78
[2025-02-12 14:55:22,679] [INFO] [logging.py:96:log_dist] [Rank 0] step=32, skipped=0, lr=[3.989123874693208e-05, 3.989123874693208e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:55:22,681] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.00 | fwd_microstep: 695.43 | bwd_microstep: 1861.79 | bwd_inner_microstep: 1861.71 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.26
[2025-02-12 14:55:22,683] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 695.48 | bwd: 1861.79 | bwd_inner: 1861.70 | bwd_allreduce: 0.00 | step: 30.29
steps: 32 loss: 7.8491 iter time (s): 12.551 samples/sec: 20.397
[2025-02-12 14:55:22,685] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 55.90 | pipe_recv_grad: 9829.54
 samples/sec: 20.393 | iteration       32/      53 | elapsed time per iteration (ms): 12553.1 | learning rate: 3.989E-05 | approx flops per GPU: 55.5TFLOPS | lm_loss: 7.849076E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:55:36,467] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.31 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:55:36,467] [INFO] [logging.py:96:log_dist] [Rank 0] step=33, skipped=0, lr=[3.743067192211866e-05, 3.743067192211866e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:55:36,469] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.66 | fwd_microstep: 699.71 | bwd_microstep: 1863.83 | bwd_inner_microstep: 1863.75 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.41
[2025-02-12 14:55:36,470] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 699.78 | bwd: 1863.83 | bwd_inner: 1863.74 | bwd_allreduce: 0.00 | step: 30.44
steps: 33 loss: 7.7485 iter time (s): 13.785 samples/sec: 18.571
[2025-02-12 14:55:36,472] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 53.22 | pipe_recv_grad: 11061.02
 samples/sec: 18.568 | iteration       33/      53 | elapsed time per iteration (ms): 13787.0 | learning rate: 3.743E-05 | approx flops per GPU: 50.6TFLOPS | lm_loss: 7.748533E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:55:59,937] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.26 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:55:59,937] [INFO] [logging.py:96:log_dist] [Rank 0] step=34, skipped=0, lr=[3.50271573246579e-05, 3.50271573246579e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:55:59,939] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.18 | fwd_microstep: 695.50 | bwd_microstep: 1860.24 | bwd_inner_microstep: 1860.15 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.87
[2025-02-12 14:55:59,940] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 695.57 | bwd: 1860.24 | bwd_inner: 1860.15 | bwd_allreduce: 0.00 | step: 30.89
steps: 34 loss: 7.6574 iter time (s): 23.468 samples/sec: 10.908
[2025-02-12 14:55:59,942] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 56.59 | pipe_recv_grad: 20747.34
 samples/sec: 10.907 | iteration       34/      53 | elapsed time per iteration (ms): 23470.2 | learning rate: 3.503E-05 | approx flops per GPU: 29.7TFLOPS | lm_loss: 7.657383E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:56:09,227] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.35 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:56:09,227] [INFO] [logging.py:96:log_dist] [Rank 0] step=35, skipped=0, lr=[3.268930875160136e-05, 3.268930875160136e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:56:09,229] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.02 | fwd_microstep: 960.81 | bwd_microstep: 1869.20 | bwd_inner_microstep: 1869.12 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.35
[2025-02-12 14:56:09,230] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 960.90 | bwd: 1869.20 | bwd_inner: 1869.12 | bwd_allreduce: 0.00 | step: 30.38
steps: 35 loss: 7.6812 iter time (s): 9.287 samples/sec: 27.564
[2025-02-12 14:56:09,231] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 58.62 | pipe_recv_grad: 6290.54
 samples/sec: 27.558 | iteration       35/      53 | elapsed time per iteration (ms): 9289.4 | learning rate: 3.269E-05 | approx flops per GPU: 75.0TFLOPS | lm_loss: 7.681185E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:56:18,025] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.38 | optimizer_gradients: 1.25 | optimizer_step: 1.78
[2025-02-12 14:56:18,025] [INFO] [logging.py:96:log_dist] [Rank 0] step=36, skipped=0, lr=[3.0425504663877366e-05, 3.0425504663877366e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:56:18,027] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.95 | fwd_microstep: 2390.62 | bwd_microstep: 1865.55 | bwd_inner_microstep: 1865.47 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.49
[2025-02-12 14:56:18,028] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2390.64 | bwd: 1865.55 | bwd_inner: 1865.47 | bwd_allreduce: 0.00 | step: 30.52
steps: 36 loss: 7.6152 iter time (s): 8.796 samples/sec: 29.103
[2025-02-12 14:56:18,030] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 51.31 | pipe_recv_grad: 4381.03
 samples/sec: 29.096 | iteration       36/      53 | elapsed time per iteration (ms): 8798.4 | learning rate: 3.043E-05 | approx flops per GPU: 79.2TFLOPS | lm_loss: 7.615154E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:56:28,518] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.85 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:56:28,518] [INFO] [logging.py:96:log_dist] [Rank 0] step=37, skipped=0, lr=[2.824385815927895e-05, 2.824385815927895e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:56:28,520] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.94 | fwd_microstep: 697.08 | bwd_microstep: 1863.08 | bwd_inner_microstep: 1862.99 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.87
[2025-02-12 14:56:28,521] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 697.09 | bwd: 1863.08 | bwd_inner: 1862.99 | bwd_allreduce: 0.00 | step: 30.90
steps: 37 loss: 7.6976 iter time (s): 10.491 samples/sec: 24.403
[2025-02-12 14:56:28,522] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 55.12 | pipe_recv_grad: 7767.29
 samples/sec: 24.398 | iteration       37/      53 | elapsed time per iteration (ms): 10492.6 | learning rate: 2.824E-05 | approx flops per GPU: 66.4TFLOPS | lm_loss: 7.697647E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:56:35,117] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.26 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:56:35,117] [INFO] [logging.py:96:log_dist] [Rank 0] step=38, skipped=0, lr=[2.6152187896468996e-05, 2.6152187896468996e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:56:35,119] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.12 | fwd_microstep: 696.45 | bwd_microstep: 1865.93 | bwd_inner_microstep: 1865.84 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.37
[2025-02-12 14:56:35,120] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 696.42 | bwd: 1865.92 | bwd_inner: 1865.84 | bwd_allreduce: 0.00 | step: 30.39
steps: 38 loss: 7.7960 iter time (s): 6.598 samples/sec: 38.801
[2025-02-12 14:56:35,122] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 52.23 | pipe_recv_grad: 3875.45
 samples/sec: 38.787 | iteration       38/      53 | elapsed time per iteration (ms): 6600.2 | learning rate: 2.615E-05 | approx flops per GPU: 105.6TFLOPS | lm_loss: 7.796016E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:56:41,505] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.11 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:56:41,505] [INFO] [logging.py:96:log_dist] [Rank 0] step=39, skipped=0, lr=[2.4157990074206423e-05, 2.4157990074206423e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:56:41,507] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 23.27 | fwd_microstep: 833.20 | bwd_microstep: 1869.53 | bwd_inner_microstep: 1869.44 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.20
[2025-02-12 14:56:41,508] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 833.27 | bwd: 1869.53 | bwd_inner: 1869.44 | bwd_allreduce: 0.00 | step: 30.22
steps: 39 loss: 7.7224 iter time (s): 6.385 samples/sec: 40.091
[2025-02-12 14:56:41,510] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 56.31 | pipe_recv_grad: 3517.71
 samples/sec: 40.079 | iteration       39/      53 | elapsed time per iteration (ms): 6387.4 | learning rate: 2.416E-05 | approx flops per GPU: 109.1TFLOPS | lm_loss: 7.722402E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:56:50,149] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.33 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:56:50,149] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[2.2268411566215157e-05, 2.2268411566215157e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:56:50,151] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.88 | fwd_microstep: 1030.46 | bwd_microstep: 1871.25 | bwd_inner_microstep: 1871.17 | bwd_allreduce_microstep: 0.00 | step_microstep: 31.34
[2025-02-12 14:56:50,152] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1030.53 | bwd: 1871.25 | bwd_inner: 1871.17 | bwd_allreduce: 0.00 | step: 31.37
steps: 40 loss: 7.6336 iter time (s): 8.642 samples/sec: 29.624
[2025-02-12 14:56:50,154] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 43.66 | pipe_recv_grad: 5587.98
 samples/sec: 29.617 | iteration       40/      53 | elapsed time per iteration (ms): 8643.8 | learning rate: 2.227E-05 | approx flops per GPU: 80.6TFLOPS | lm_loss: 7.633614E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:57:01,585] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.32 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:57:01,585] [INFO] [logging.py:96:log_dist] [Rank 0] step=41, skipped=0, lr=[2.0490224307975835e-05, 2.0490224307975835e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:57:01,587] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.24 | fwd_microstep: 784.52 | bwd_microstep: 1865.45 | bwd_inner_microstep: 1865.36 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.34
[2025-02-12 14:57:01,588] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 784.59 | bwd: 1865.45 | bwd_inner: 1865.36 | bwd_allreduce: 0.00 | step: 30.37
steps: 41 loss: 7.5779 iter time (s): 11.434 samples/sec: 22.390
[2025-02-12 14:57:01,589] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 44.46 | pipe_recv_grad: 8631.51
 samples/sec: 22.386 | iteration       41/      53 | elapsed time per iteration (ms): 11435.7 | learning rate: 2.049E-05 | approx flops per GPU: 61.0TFLOPS | lm_loss: 7.577865E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
[2025-02-12 14:57:13,364] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.26 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:57:13,364] [INFO] [logging.py:96:log_dist] [Rank 0] step=42, skipped=0, lr=[1.8829801027234023e-05, 1.8829801027234023e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:57:13,366] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 23.13 | fwd_microstep: 1602.98 | bwd_microstep: 1876.39 | bwd_inner_microstep: 1876.30 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.00
[2025-02-12 14:57:13,367] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1603.02 | bwd: 1876.39 | bwd_inner: 1876.30 | bwd_allreduce: 0.00 | step: 30.03
steps: 42 loss: 7.7149 iter time (s): 11.777 samples/sec: 21.737
[2025-02-12 14:57:13,369] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 49.88 | pipe_recv_grad: 8139.29
 samples/sec: 21.733 | iteration       42/      53 | elapsed time per iteration (ms): 11779.3 | learning rate: 1.883E-05 | approx flops per GPU: 59.2TFLOPS | lm_loss: 7.714868E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:57:32,725] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.37 | optimizer_gradients: 1.26 | optimizer_step: 1.78
[2025-02-12 14:57:32,725] [INFO] [logging.py:96:log_dist] [Rank 0] step=43, skipped=0, lr=[1.7293092405202585e-05, 1.7293092405202585e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:57:32,727] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.43 | fwd_microstep: 932.18 | bwd_microstep: 1861.03 | bwd_inner_microstep: 1860.95 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.42
[2025-02-12 14:57:32,728] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 932.25 | bwd: 1861.03 | bwd_inner: 1860.95 | bwd_allreduce: 0.00 | step: 30.45
steps: 43 loss: 7.5918 iter time (s): 19.359 samples/sec: 13.224
[2025-02-12 14:57:32,730] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 52.96 | pipe_recv_grad: 16404.58
 samples/sec: 13.223 | iteration       43/      53 | elapsed time per iteration (ms): 19360.9 | learning rate: 1.729E-05 | approx flops per GPU: 36.0TFLOPS | lm_loss: 7.591790E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:57:45,365] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.46 | optimizer_gradients: 1.24 | optimizer_step: 1.80
[2025-02-12 14:57:45,365] [INFO] [logging.py:96:log_dist] [Rank 0] step=44, skipped=0, lr=[1.588560575030873e-05, 1.588560575030873e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:57:45,367] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.81 | fwd_microstep: 769.76 | bwd_microstep: 1860.80 | bwd_inner_microstep: 1860.71 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.53
[2025-02-12 14:57:45,368] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 769.82 | bwd: 1860.79 | bwd_inner: 1860.71 | bwd_allreduce: 0.00 | step: 30.57
steps: 44 loss: 7.6436 iter time (s): 12.638 samples/sec: 20.257
[2025-02-12 14:57:45,369] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 57.00 | pipe_recv_grad: 9842.74
 samples/sec: 20.254 | iteration       44/      53 | elapsed time per iteration (ms): 12639.7 | learning rate: 1.589E-05 | approx flops per GPU: 55.1TFLOPS | lm_loss: 7.643595E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:58:08,847] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.28 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:58:08,847] [INFO] [logging.py:96:log_dist] [Rank 0] step=45, skipped=0, lr=[1.4612385260915504e-05, 1.4612385260915504e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:58:08,849] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.24 | fwd_microstep: 1138.67 | bwd_microstep: 1863.18 | bwd_inner_microstep: 1863.10 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.35
[2025-02-12 14:58:08,850] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1138.71 | bwd: 1863.18 | bwd_inner: 1863.09 | bwd_allreduce: 0.00 | step: 30.37
steps: 45 loss: 7.6435 iter time (s): 23.480 samples/sec: 10.903
[2025-02-12 14:58:08,852] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 57.33 | pipe_recv_grad: 20313.48
 samples/sec: 10.902 | iteration       45/      53 | elapsed time per iteration (ms): 23482.4 | learning rate: 1.461E-05 | approx flops per GPU: 29.7TFLOPS | lm_loss: 7.643483E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:58:28,276] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.24 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:58:28,276] [INFO] [logging.py:96:log_dist] [Rank 0] step=46, skipped=0, lr=[1.347799394775271e-05, 1.347799394775271e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:58:28,278] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.48 | fwd_microstep: 696.99 | bwd_microstep: 1862.81 | bwd_inner_microstep: 1862.72 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.32
[2025-02-12 14:58:28,279] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 697.06 | bwd: 1862.80 | bwd_inner: 1862.72 | bwd_allreduce: 0.00 | step: 30.34
steps: 46 loss: 7.5831 iter time (s): 19.427 samples/sec: 13.178
[2025-02-12 14:58:28,281] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 53.25 | pipe_recv_grad: 16705.53
 samples/sec: 13.176 | iteration       46/      53 | elapsed time per iteration (ms): 19428.9 | learning rate: 1.348E-05 | approx flops per GPU: 35.9TFLOPS | lm_loss: 7.583108E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:58:49,524] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.18 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:58:49,525] [INFO] [logging.py:96:log_dist] [Rank 0] step=47, skipped=0, lr=[1.2486497280844519e-05, 1.2486497280844519e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:58:49,526] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.81 | fwd_microstep: 749.86 | bwd_microstep: 1866.37 | bwd_inner_microstep: 1866.28 | bwd_allreduce_microstep: 0.00 | step_microstep: 29.83
[2025-02-12 14:58:49,528] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 749.92 | bwd: 1866.36 | bwd_inner: 1866.28 | bwd_allreduce: 0.00 | step: 29.86
steps: 47 loss: 7.6185 iter time (s): 21.246 samples/sec: 12.049
[2025-02-12 14:58:49,529] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 57.57 | pipe_recv_grad: 18465.71
 samples/sec: 12.048 | iteration       47/      53 | elapsed time per iteration (ms): 21248.4 | learning rate: 1.249E-05 | approx flops per GPU: 32.8TFLOPS | lm_loss: 7.618484E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:59:06,748] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.44 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:59:06,749] [INFO] [logging.py:96:log_dist] [Rank 0] step=48, skipped=0, lr=[1.1641448619540221e-05, 1.1641448619540221e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:59:06,750] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.28 | fwd_microstep: 10232.04 | bwd_microstep: 1864.74 | bwd_inner_microstep: 1864.66 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.47
[2025-02-12 14:59:06,752] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 10232.12 | bwd: 1864.74 | bwd_inner: 1864.66 | bwd_allreduce: 0.00 | step: 30.50
steps: 48 loss: 7.6102 iter time (s): 17.222 samples/sec: 14.865
[2025-02-12 14:59:06,753] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 51.37 | pipe_recv_grad: 4965.84
 samples/sec: 14.863 | iteration       48/      53 | elapsed time per iteration (ms): 17224.1 | learning rate: 1.164E-05 | approx flops per GPU: 40.5TFLOPS | lm_loss: 7.610212E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
[2025-02-12 14:59:20,017] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.20 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 14:59:20,017] [INFO] [logging.py:96:log_dist] [Rank 0] step=49, skipped=0, lr=[1.094587647786457e-05, 1.094587647786457e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:59:20,019] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.61 | fwd_microstep: 696.78 | bwd_microstep: 1862.92 | bwd_inner_microstep: 1862.83 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.35
[2025-02-12 14:59:20,021] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 696.82 | bwd: 1862.91 | bwd_inner: 1862.83 | bwd_allreduce: 0.00 | step: 30.37
steps: 49 loss: 7.6639 iter time (s): 13.267 samples/sec: 19.296
[2025-02-12 14:59:20,022] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 53.90 | pipe_recv_grad: 10544.18
 samples/sec: 19.293 | iteration       49/      53 | elapsed time per iteration (ms): 13268.9 | learning rate: 1.095E-05 | approx flops per GPU: 52.5TFLOPS | lm_loss: 7.663946E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:59:39,798] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.31 | optimizer_gradients: 1.24 | optimizer_step: 1.79
[2025-02-12 14:59:39,798] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[1.0402273670826667e-05, 1.0402273670826667e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:59:39,800] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.71 | fwd_microstep: 697.91 | bwd_microstep: 1860.42 | bwd_inner_microstep: 1860.33 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.34
[2025-02-12 14:59:39,801] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 697.92 | bwd: 1860.42 | bwd_inner: 1860.33 | bwd_allreduce: 0.00 | step: 30.37
steps: 50 loss: 7.5953 iter time (s): 19.779 samples/sec: 12.943
[2025-02-12 14:59:39,803] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 54.58 | pipe_recv_grad: 17057.21
 samples/sec: 12.942 | iteration       50/      53 | elapsed time per iteration (ms): 19780.9 | learning rate: 1.040E-05 | approx flops per GPU: 35.2TFLOPS | lm_loss: 7.595257E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 14:59:51,796] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 21.33 | optimizer_gradients: 1.24 | optimizer_step: 1.78
[2025-02-12 14:59:51,797] [INFO] [logging.py:96:log_dist] [Rank 0] step=51, skipped=0, lr=[1.0012588380585005e-05, 1.0012588380585005e-05], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 14:59:51,798] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 21.87 | fwd_microstep: 697.52 | bwd_microstep: 1864.75 | bwd_inner_microstep: 1864.67 | bwd_allreduce_microstep: 0.00 | step_microstep: 31.53
[2025-02-12 14:59:51,800] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 697.60 | bwd: 1864.75 | bwd_inner: 1864.67 | bwd_allreduce: 0.00 | step: 31.55
steps: 51 loss: 7.5770 iter time (s): 11.996 samples/sec: 21.341
[2025-02-12 14:59:51,801] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 56.88 | pipe_recv_grad: 9268.26
 samples/sec: 21.337 | iteration       51/      53 | elapsed time per iteration (ms): 11997.9 | learning rate: 1.001E-05 | approx flops per GPU: 58.1TFLOPS | lm_loss: 7.577006E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[2025-02-12 15:00:04,129] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.32 | optimizer_gradients: 1.25 | optimizer_step: 1.79
[2025-02-12 15:00:04,130] [INFO] [logging.py:96:log_dist] [Rank 0] step=52, skipped=0, lr=[9.77821717448628e-06, 9.77821717448628e-06], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 15:00:04,132] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 22.77 | fwd_microstep: 6573.83 | bwd_microstep: 1880.40 | bwd_inner_microstep: 1880.32 | bwd_allreduce_microstep: 0.00 | step_microstep: 30.54
[2025-02-12 15:00:04,133] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 6573.91 | bwd: 1880.40 | bwd_inner: 1880.32 | bwd_allreduce: 0.00 | step: 30.57
steps: 52 loss: 7.4844 iter time (s): 12.331 samples/sec: 20.760
[2025-02-12 15:00:04,134] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 52.47 | pipe_recv_grad: 3715.78
 samples/sec: 20.757 | iteration       52/      53 | elapsed time per iteration (ms): 12333.3 | learning rate: 9.778E-06 | approx flops per GPU: 56.5TFLOPS | lm_loss: 7.484433E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
[2025-02-12 15:01:55,761] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 20.76 | optimizer_gradients: 1.21 | optimizer_step: 1.78
[2025-02-12 15:01:55,761] [INFO] [logging.py:96:log_dist] [Rank 0] step=53, skipped=0, lr=[9.7e-06, 9.7e-06], mom=[[0.9, 0.95], [0.9, 0.95]]
[2025-02-12 15:01:55,762] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 16.29 | fwd_microstep: 695.52 | bwd_microstep: 1855.24 | bwd_inner_microstep: 1855.15 | bwd_allreduce_microstep: 0.00 | step_microstep: 29.34
[2025-02-12 15:01:55,763] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 695.58 | bwd: 1855.24 | bwd_inner: 1855.15 | bwd_allreduce: 0.00 | step: 29.36
steps: 53 loss: 7.6133 iter time (s): 18.154 samples/sec: 14.102
[2025-02-12 15:01:55,764] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | pipe_send_output: 11145.80 | pipe_recv_grad: 4359.94
 samples/sec: 2.293 | iteration       53/      53 | elapsed time per iteration (ms): 111629.4 | learning rate: 9.700E-06 | approx flops per GPU: 6.2TFLOPS | lm_loss: 7.613254E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms)
[rank4]: Traceback (most recent call last):
[rank4]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank4]:     main()
[rank4]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank4]:     pretrain(neox_args=neox_args)
[rank4]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank4]:     evaluate_and_print_results(
[rank4]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank4]:     total_loss_dict = evaluate(
[rank4]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank4]:     loss, metric_dict = forward_step_fn(
[rank4]: ValueError: not enough values to unpack (expected 2, got 1)
[rank6]: Traceback (most recent call last):
[rank6]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank6]:     main()
[rank6]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank6]:     pretrain(neox_args=neox_args)
[rank6]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank6]:     evaluate_and_print_results(
[rank6]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank6]:     total_loss_dict = evaluate(
[rank6]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank6]:     loss, metric_dict = forward_step_fn(
[rank6]: ValueError: not enough values to unpack (expected 2, got 1)
[rank5]: Traceback (most recent call last):
[rank5]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank5]:     main()
[rank5]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank5]:     pretrain(neox_args=neox_args)
[rank5]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank5]:     evaluate_and_print_results(
[rank5]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank5]:     total_loss_dict = evaluate(
[rank5]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank5]:     loss, metric_dict = forward_step_fn(
[rank5]: ValueError: not enough values to unpack (expected 2, got 1)
[rank7]: Traceback (most recent call last):
[rank7]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank7]:     main()
[rank7]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank7]:     pretrain(neox_args=neox_args)
[rank7]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank7]:     evaluate_and_print_results(
[rank7]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank7]:     total_loss_dict = evaluate(
[rank7]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank7]:     loss, metric_dict = forward_step_fn(
[rank7]: ValueError: not enough values to unpack (expected 2, got 1)
[rank8]: Traceback (most recent call last):
[rank8]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank8]:     main()
[rank8]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank8]:     pretrain(neox_args=neox_args)
[rank8]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank8]:     evaluate_and_print_results(
[rank8]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank8]:     total_loss_dict = evaluate(
[rank8]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank8]:     loss, metric_dict = forward_step_fn(
[rank8]: ValueError: not enough values to unpack (expected 2, got 1)
[rank9]: Traceback (most recent call last):
[rank9]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank9]:     main()
[rank9]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank9]:     pretrain(neox_args=neox_args)
[rank9]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank9]:     evaluate_and_print_results(
[rank9]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank9]:     total_loss_dict = evaluate(
[rank9]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank9]:     loss, metric_dict = forward_step_fn(
[rank9]: ValueError: not enough values to unpack (expected 2, got 1)
[rank10]: Traceback (most recent call last):
[rank10]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank10]:     main()
[rank10]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank10]:     pretrain(neox_args=neox_args)
[rank10]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank10]:     evaluate_and_print_results(
[rank10]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank10]:     total_loss_dict = evaluate(
[rank10]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank10]:     loss, metric_dict = forward_step_fn(
[rank10]: ValueError: not enough values to unpack (expected 2, got 1)
[rank11]: Traceback (most recent call last):
[rank11]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank11]:     main()
[rank11]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank11]:     pretrain(neox_args=neox_args)
[rank11]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank11]:     evaluate_and_print_results(
[rank11]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank11]:     total_loss_dict = evaluate(
[rank11]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank11]:     loss, metric_dict = forward_step_fn(
[rank11]: ValueError: not enough values to unpack (expected 2, got 1)
[rank22]: Traceback (most recent call last):
[rank22]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank22]:     main()
[rank22]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank22]:     pretrain(neox_args=neox_args)
[rank22]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank22]:     evaluate_and_print_results(
[rank22]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank22]:     total_loss_dict = evaluate(
[rank22]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank22]:     loss, metric_dict = forward_step_fn(
[rank22]: ValueError: not enough values to unpack (expected 2, got 1)
[rank20]: Traceback (most recent call last):
[rank20]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank20]:     main()
[rank20]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank20]:     pretrain(neox_args=neox_args)
[rank20]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank20]:     evaluate_and_print_results(
[rank20]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank20]:     total_loss_dict = evaluate(
[rank20]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank20]:     loss, metric_dict = forward_step_fn(
[rank20]: ValueError: not enough values to unpack (expected 2, got 1)
[rank21]: Traceback (most recent call last):
[rank21]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank21]:     main()
[rank21]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank21]:     pretrain(neox_args=neox_args)
[rank21]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank21]:     evaluate_and_print_results(
[rank21]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank21]:     total_loss_dict = evaluate(
[rank21]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank21]:     loss, metric_dict = forward_step_fn(
[rank21]: ValueError: not enough values to unpack (expected 2, got 1)
[rank23]: Traceback (most recent call last):
[rank23]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank23]:     main()
[rank23]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank23]:     pretrain(neox_args=neox_args)
[rank23]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank23]:     evaluate_and_print_results(
[rank23]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank23]:     total_loss_dict = evaluate(
[rank23]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank23]:     loss, metric_dict = forward_step_fn(
[rank23]: ValueError: not enough values to unpack (expected 2, got 1)
[rank24]: Traceback (most recent call last):
[rank24]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank24]:     main()
[rank24]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank24]:     pretrain(neox_args=neox_args)
[rank24]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank24]:     evaluate_and_print_results(
[rank24]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank24]:     total_loss_dict = evaluate(
[rank24]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank24]:     loss, metric_dict = forward_step_fn(
[rank24]: ValueError: not enough values to unpack (expected 2, got 1)
[rank26]: Traceback (most recent call last):
[rank26]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank26]:     main()
[rank26]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank26]:     pretrain(neox_args=neox_args)
[rank26]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank26]:     evaluate_and_print_results(
[rank26]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank26]:     total_loss_dict = evaluate(
[rank26]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank26]:     loss, metric_dict = forward_step_fn(
[rank26]: ValueError: not enough values to unpack (expected 2, got 1)
[rank27]: Traceback (most recent call last):
[rank27]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank27]:     main()
[rank27]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank27]:     pretrain(neox_args=neox_args)
[rank27]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank27]:     evaluate_and_print_results(
[rank27]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank27]:     total_loss_dict = evaluate(
[rank27]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank27]:     loss, metric_dict = forward_step_fn(
[rank27]: ValueError: not enough values to unpack (expected 2, got 1)
[rank25]: Traceback (most recent call last):
[rank25]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank25]:     main()
[rank25]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank25]:     pretrain(neox_args=neox_args)
[rank25]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank25]:     evaluate_and_print_results(
[rank25]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank25]:     total_loss_dict = evaluate(
[rank25]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank25]:     loss, metric_dict = forward_step_fn(
[rank25]: ValueError: not enough values to unpack (expected 2, got 1)
[rank13]: Traceback (most recent call last):
[rank13]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank13]:     main()
[rank13]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank13]:     pretrain(neox_args=neox_args)
[rank13]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank13]:     evaluate_and_print_results(
[rank13]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank13]:     total_loss_dict = evaluate(
[rank13]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank13]:     loss, metric_dict = forward_step_fn(
[rank13]: ValueError: not enough values to unpack (expected 2, got 1)
[rank14]: Traceback (most recent call last):
[rank14]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank14]:     main()
[rank14]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank14]:     pretrain(neox_args=neox_args)
[rank14]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank14]:     evaluate_and_print_results(
[rank14]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank14]:     total_loss_dict = evaluate(
[rank14]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank14]:     loss, metric_dict = forward_step_fn(
[rank14]: ValueError: not enough values to unpack (expected 2, got 1)
[rank15]: Traceback (most recent call last):
[rank15]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank15]:     main()
[rank15]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank15]:     pretrain(neox_args=neox_args)
[rank15]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank15]:     evaluate_and_print_results(
[rank15]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank15]:     total_loss_dict = evaluate(
[rank15]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank15]:     loss, metric_dict = forward_step_fn(
[rank15]: ValueError: not enough values to unpack (expected 2, got 1)
[rank12]: Traceback (most recent call last):
[rank12]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank12]:     main()
[rank12]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank12]:     pretrain(neox_args=neox_args)
[rank12]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank12]:     evaluate_and_print_results(
[rank12]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank12]:     total_loss_dict = evaluate(
[rank12]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank12]:     loss, metric_dict = forward_step_fn(
[rank12]: ValueError: not enough values to unpack (expected 2, got 1)
[rank37]: Traceback (most recent call last):
[rank37]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank37]:     main()
[rank37]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank37]:     pretrain(neox_args=neox_args)
[rank37]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank37]:     evaluate_and_print_results(
[rank37]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank37]:     total_loss_dict = evaluate(
[rank37]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank37]:     loss, metric_dict = forward_step_fn(
[rank37]: ValueError: not enough values to unpack (expected 2, got 1)
[rank38]: Traceback (most recent call last):
[rank38]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank38]:     main()
[rank38]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank38]:     pretrain(neox_args=neox_args)
[rank38]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank38]:     evaluate_and_print_results(
[rank38]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank38]:     total_loss_dict = evaluate(
[rank38]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank38]:     loss, metric_dict = forward_step_fn(
[rank38]: ValueError: not enough values to unpack (expected 2, got 1)
[rank36]: Traceback (most recent call last):
[rank36]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank36]:     main()
[rank36]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank36]:     pretrain(neox_args=neox_args)
[rank36]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank36]:     evaluate_and_print_results(
[rank36]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank36]:     total_loss_dict = evaluate(
[rank36]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank36]:     loss, metric_dict = forward_step_fn(
[rank36]: ValueError: not enough values to unpack (expected 2, got 1)
[rank39]: Traceback (most recent call last):
[rank39]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank39]:     main()
[rank39]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank39]:     pretrain(neox_args=neox_args)
[rank39]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank39]:     evaluate_and_print_results(
[rank39]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank39]:     total_loss_dict = evaluate(
[rank39]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank39]:     loss, metric_dict = forward_step_fn(
[rank39]: ValueError: not enough values to unpack (expected 2, got 1)
[rank40]: Traceback (most recent call last):
[rank40]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank40]:     main()
[rank40]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank40]:     pretrain(neox_args=neox_args)
[rank40]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank40]:     evaluate_and_print_results(
[rank40]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank40]:     total_loss_dict = evaluate(
[rank40]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank40]:     loss, metric_dict = forward_step_fn(
[rank40]: ValueError: not enough values to unpack (expected 2, got 1)
[rank43]: Traceback (most recent call last):
[rank43]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank43]:     main()
[rank43]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank43]:     pretrain(neox_args=neox_args)
[rank43]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank43]:     evaluate_and_print_results(
[rank43]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank43]:     total_loss_dict = evaluate(
[rank43]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank43]:     loss, metric_dict = forward_step_fn(
[rank43]: ValueError: not enough values to unpack (expected 2, got 1)
[rank41]: Traceback (most recent call last):
[rank41]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank41]:     main()
[rank41]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank41]:     pretrain(neox_args=neox_args)
[rank41]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank41]:     evaluate_and_print_results(
[rank41]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank41]:     total_loss_dict = evaluate(
[rank41]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank41]:     loss, metric_dict = forward_step_fn(
[rank41]: ValueError: not enough values to unpack (expected 2, got 1)
[rank42]: Traceback (most recent call last):
[rank42]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank42]:     main()
[rank42]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank42]:     pretrain(neox_args=neox_args)
[rank42]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank42]:     evaluate_and_print_results(
[rank42]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank42]:     total_loss_dict = evaluate(
[rank42]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank42]:     loss, metric_dict = forward_step_fn(
[rank42]: ValueError: not enough values to unpack (expected 2, got 1)
[rank31]: Traceback (most recent call last):
[rank31]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank31]:     main()
[rank31]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank31]:     pretrain(neox_args=neox_args)
[rank31]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank31]:     evaluate_and_print_results(
[rank31]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank31]:     total_loss_dict = evaluate(
[rank31]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank31]:     loss, metric_dict = forward_step_fn(
[rank31]: ValueError: not enough values to unpack (expected 2, got 1)
[rank30]: Traceback (most recent call last):
[rank30]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank30]:     main()
[rank30]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank30]:     pretrain(neox_args=neox_args)
[rank30]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank30]:     evaluate_and_print_results(
[rank30]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank30]:     total_loss_dict = evaluate(
[rank30]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank30]:     loss, metric_dict = forward_step_fn(
[rank30]: ValueError: not enough values to unpack (expected 2, got 1)
[rank28]: Traceback (most recent call last):
[rank28]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank28]:     main()
[rank28]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank28]:     pretrain(neox_args=neox_args)
[rank28]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank28]:     evaluate_and_print_results(
[rank28]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank28]:     total_loss_dict = evaluate(
[rank28]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank28]:     loss, metric_dict = forward_step_fn(
[rank28]: ValueError: not enough values to unpack (expected 2, got 1)
[rank29]: Traceback (most recent call last):
[rank29]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank29]:     main()
[rank29]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank29]:     pretrain(neox_args=neox_args)
[rank29]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank29]:     evaluate_and_print_results(
[rank29]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank29]:     total_loss_dict = evaluate(
[rank29]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank29]:     loss, metric_dict = forward_step_fn(
[rank29]: ValueError: not enough values to unpack (expected 2, got 1)
[rank54]: Traceback (most recent call last):
[rank54]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank54]:     main()
[rank54]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank54]:     pretrain(neox_args=neox_args)
[rank54]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank54]:     evaluate_and_print_results(
[rank54]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank54]:     total_loss_dict = evaluate(
[rank54]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank54]:     loss, metric_dict = forward_step_fn(
[rank54]: ValueError: not enough values to unpack (expected 2, got 1)
[rank53]: Traceback (most recent call last):
[rank53]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank53]:     main()
[rank53]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank53]:     pretrain(neox_args=neox_args)
[rank53]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank53]:     evaluate_and_print_results(
[rank53]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank53]:     total_loss_dict = evaluate(
[rank53]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank53]:     loss, metric_dict = forward_step_fn(
[rank53]: ValueError: not enough values to unpack (expected 2, got 1)
[rank52]: Traceback (most recent call last):
[rank52]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank52]:     main()
[rank52]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank52]:     pretrain(neox_args=neox_args)
[rank52]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank52]:     evaluate_and_print_results(
[rank52]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank52]:     total_loss_dict = evaluate(
[rank52]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank52]:     loss, metric_dict = forward_step_fn(
[rank52]: ValueError: not enough values to unpack (expected 2, got 1)
[rank55]: Traceback (most recent call last):
[rank55]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank55]:     main()
[rank55]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank55]:     pretrain(neox_args=neox_args)
[rank55]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank55]:     evaluate_and_print_results(
[rank55]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank55]:     total_loss_dict = evaluate(
[rank55]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank55]:     loss, metric_dict = forward_step_fn(
[rank55]: ValueError: not enough values to unpack (expected 2, got 1)
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/ops/transformer/inference/triton/matmul_ext.py", line 74, in load
    loaded_dict = pickle.load(handle)
OSError: [Errno 116] Stale file handle
[rank56]: Traceback (most recent call last):
[rank56]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank56]:     main()
[rank56]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank56]:     pretrain(neox_args=neox_args)
[rank56]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank56]:     evaluate_and_print_results(
[rank56]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank56]:     total_loss_dict = evaluate(
[rank56]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank56]:     loss, metric_dict = forward_step_fn(
[rank56]: ValueError: not enough values to unpack (expected 2, got 1)
[rank58]: Traceback (most recent call last):
[rank58]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank58]:     main()
[rank58]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank58]:     pretrain(neox_args=neox_args)
[rank58]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank58]:     evaluate_and_print_results(
[rank58]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank58]:     total_loss_dict = evaluate(
[rank58]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank58]:     loss, metric_dict = forward_step_fn(
[rank58]: ValueError: not enough values to unpack (expected 2, got 1)
[rank57]: Traceback (most recent call last):
[rank57]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank57]:     main()
[rank57]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank57]:     pretrain(neox_args=neox_args)
[rank57]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank57]:     evaluate_and_print_results(
[rank57]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank57]:     total_loss_dict = evaluate(
[rank57]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank57]:     loss, metric_dict = forward_step_fn(
[rank57]: ValueError: not enough values to unpack (expected 2, got 1)
[rank59]: Traceback (most recent call last):
[rank59]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank59]:     main()
[rank59]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank59]:     pretrain(neox_args=neox_args)
[rank59]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank59]:     evaluate_and_print_results(
[rank59]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank59]:     total_loss_dict = evaluate(
[rank59]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank59]:     loss, metric_dict = forward_step_fn(
[rank59]: ValueError: not enough values to unpack (expected 2, got 1)
[rank46]: Traceback (most recent call last):
[rank46]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank46]:     main()
[rank46]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank46]:     pretrain(neox_args=neox_args)
[rank46]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank46]:     evaluate_and_print_results(
[rank46]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank46]:     total_loss_dict = evaluate(
[rank46]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank46]:     loss, metric_dict = forward_step_fn(
[rank46]: ValueError: not enough values to unpack (expected 2, got 1)
[rank44]: Traceback (most recent call last):
[rank44]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank44]:     main()
[rank44]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank44]:     pretrain(neox_args=neox_args)
[rank44]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank44]:     evaluate_and_print_results(
[rank44]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank44]:     total_loss_dict = evaluate(
[rank44]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank44]:     loss, metric_dict = forward_step_fn(
[rank44]: ValueError: not enough values to unpack (expected 2, got 1)
[rank47]: Traceback (most recent call last):
[rank47]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank47]:     main()
[rank47]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank47]:     pretrain(neox_args=neox_args)
[rank47]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank47]:     evaluate_and_print_results(
[rank47]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank47]:     total_loss_dict = evaluate(
[rank47]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank47]:     loss, metric_dict = forward_step_fn(
[rank47]: ValueError: not enough values to unpack (expected 2, got 1)
[rank45]: Traceback (most recent call last):
[rank45]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank45]:     main()
[rank45]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank45]:     pretrain(neox_args=neox_args)
[rank45]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank45]:     evaluate_and_print_results(
[rank45]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank45]:     total_loss_dict = evaluate(
[rank45]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank45]:     loss, metric_dict = forward_step_fn(
[rank45]: ValueError: not enough values to unpack (expected 2, got 1)
[rank69]: Traceback (most recent call last):
[rank69]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank69]:     main()
[rank69]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank69]:     pretrain(neox_args=neox_args)
[rank69]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank69]:     evaluate_and_print_results(
[rank69]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank69]:     total_loss_dict = evaluate(
[rank69]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank69]:     loss, metric_dict = forward_step_fn(
[rank69]: ValueError: not enough values to unpack (expected 2, got 1)
[rank68]: Traceback (most recent call last):
[rank68]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank68]:     main()
[rank68]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank68]:     pretrain(neox_args=neox_args)
[rank68]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank68]:     evaluate_and_print_results(
[rank68]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank68]:     total_loss_dict = evaluate(
[rank68]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank68]:     loss, metric_dict = forward_step_fn(
[rank68]: ValueError: not enough values to unpack (expected 2, got 1)
[rank70]: Traceback (most recent call last):
[rank70]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank70]:     main()
[rank70]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank70]:     pretrain(neox_args=neox_args)
[rank70]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank70]:     evaluate_and_print_results(
[rank70]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank70]:     total_loss_dict = evaluate(
[rank70]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank70]:     loss, metric_dict = forward_step_fn(
[rank70]: ValueError: not enough values to unpack (expected 2, got 1)
[rank71]: Traceback (most recent call last):
[rank71]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank71]:     main()
[rank71]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank71]:     pretrain(neox_args=neox_args)
[rank71]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank71]:     evaluate_and_print_results(
[rank71]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank71]:     total_loss_dict = evaluate(
[rank71]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank71]:     loss, metric_dict = forward_step_fn(
[rank71]: ValueError: not enough values to unpack (expected 2, got 1)
[rank72]: Traceback (most recent call last):
[rank72]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank72]:     main()
[rank72]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank72]:     pretrain(neox_args=neox_args)
[rank72]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank72]:     evaluate_and_print_results(
[rank72]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank72]:     total_loss_dict = evaluate(
[rank72]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank72]:     loss, metric_dict = forward_step_fn(
[rank72]: ValueError: not enough values to unpack (expected 2, got 1)
[rank74]: Traceback (most recent call last):
[rank74]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank74]:     main()
[rank74]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank74]:     pretrain(neox_args=neox_args)
[rank74]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank74]:     evaluate_and_print_results(
[rank74]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank74]:     total_loss_dict = evaluate(
[rank74]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank74]:     loss, metric_dict = forward_step_fn(
[rank74]: ValueError: not enough values to unpack (expected 2, got 1)
[rank73]: Traceback (most recent call last):
[rank73]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank73]:     main()
[rank73]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank73]:     pretrain(neox_args=neox_args)
[rank73]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank73]:     evaluate_and_print_results(
[rank73]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank73]:     total_loss_dict = evaluate(
[rank73]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank73]:     loss, metric_dict = forward_step_fn(
[rank73]: ValueError: not enough values to unpack (expected 2, got 1)
[rank75]: Traceback (most recent call last):
[rank75]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank75]:     main()
[rank75]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank75]:     pretrain(neox_args=neox_args)
[rank75]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank75]:     evaluate_and_print_results(
[rank75]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank75]:     total_loss_dict = evaluate(
[rank75]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank75]:     loss, metric_dict = forward_step_fn(
[rank75]: ValueError: not enough values to unpack (expected 2, got 1)
[rank60]: Traceback (most recent call last):
[rank60]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank60]:     main()
[rank60]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank60]:     pretrain(neox_args=neox_args)
[rank60]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank60]:     evaluate_and_print_results(
[rank60]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank60]:     total_loss_dict = evaluate(
[rank60]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank60]:     loss, metric_dict = forward_step_fn(
[rank60]: ValueError: not enough values to unpack (expected 2, got 1)
[rank62]: Traceback (most recent call last):
[rank62]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank62]:     main()
[rank62]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank62]:     pretrain(neox_args=neox_args)
[rank62]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank62]:     evaluate_and_print_results(
[rank62]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank62]:     total_loss_dict = evaluate(
[rank62]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank62]:     loss, metric_dict = forward_step_fn(
[rank62]: ValueError: not enough values to unpack (expected 2, got 1)
[rank61]: Traceback (most recent call last):
[rank61]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank61]:     main()
[rank61]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank61]:     pretrain(neox_args=neox_args)
[rank61]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank61]:     evaluate_and_print_results(
[rank61]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank61]:     total_loss_dict = evaluate(
[rank61]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank61]:     loss, metric_dict = forward_step_fn(
[rank61]: ValueError: not enough values to unpack (expected 2, got 1)
[rank63]: Traceback (most recent call last):
[rank63]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank63]:     main()
[rank63]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank63]:     pretrain(neox_args=neox_args)
[rank63]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank63]:     evaluate_and_print_results(
[rank63]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank63]:     total_loss_dict = evaluate(
[rank63]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank63]:     loss, metric_dict = forward_step_fn(
[rank63]: ValueError: not enough values to unpack (expected 2, got 1)
[rank87]: Traceback (most recent call last):
[rank87]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank87]:     main()
[rank87]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank87]:     pretrain(neox_args=neox_args)
[rank87]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank87]:     evaluate_and_print_results(
[rank87]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank87]:     total_loss_dict = evaluate(
[rank87]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank87]:     loss, metric_dict = forward_step_fn(
[rank87]: ValueError: not enough values to unpack (expected 2, got 1)
[rank85]: Traceback (most recent call last):
[rank85]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank85]:     main()
[rank85]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank85]:     pretrain(neox_args=neox_args)
[rank85]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank85]:     evaluate_and_print_results(
[rank85]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank85]:     total_loss_dict = evaluate(
[rank85]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank85]:     loss, metric_dict = forward_step_fn(
[rank85]: ValueError: not enough values to unpack (expected 2, got 1)
[rank4]:[W212 15:01:58.026277760 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank84]: Traceback (most recent call last):
[rank84]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank84]:     main()
[rank84]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank84]:     pretrain(neox_args=neox_args)
[rank84]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank84]:     evaluate_and_print_results(
[rank84]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank84]:     total_loss_dict = evaluate(
[rank84]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank84]:     loss, metric_dict = forward_step_fn(
[rank84]: ValueError: not enough values to unpack (expected 2, got 1)
[rank86]: Traceback (most recent call last):
[rank86]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank86]:     main()
[rank86]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank86]:     pretrain(neox_args=neox_args)
[rank86]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank86]:     evaluate_and_print_results(
[rank86]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank86]:     total_loss_dict = evaluate(
[rank86]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank86]:     loss, metric_dict = forward_step_fn(
[rank86]: ValueError: not enough values to unpack (expected 2, got 1)
[rank9]:[W212 15:01:58.121922346 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank90]: Traceback (most recent call last):
[rank90]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank90]:     main()
[rank90]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank90]:     pretrain(neox_args=neox_args)
[rank90]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank90]:     evaluate_and_print_results(
[rank90]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank90]:     total_loss_dict = evaluate(
[rank90]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank90]:     loss, metric_dict = forward_step_fn(
[rank90]: ValueError: not enough values to unpack (expected 2, got 1)
[rank89]: Traceback (most recent call last):
[rank89]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank89]:     main()
[rank89]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank89]:     pretrain(neox_args=neox_args)
[rank89]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank89]:     evaluate_and_print_results(
[rank89]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank89]:     total_loss_dict = evaluate(
[rank89]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank89]:     loss, metric_dict = forward_step_fn(
[rank89]: ValueError: not enough values to unpack (expected 2, got 1)
[rank88]: Traceback (most recent call last):
[rank88]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank88]:     main()
[rank88]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank88]:     pretrain(neox_args=neox_args)
[rank88]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank88]:     evaluate_and_print_results(
[rank88]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank88]:     total_loss_dict = evaluate(
[rank88]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank88]:     loss, metric_dict = forward_step_fn(
[rank88]: ValueError: not enough values to unpack (expected 2, got 1)
[rank91]: Traceback (most recent call last):
[rank91]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank91]:     main()
[rank91]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank91]:     pretrain(neox_args=neox_args)
[rank91]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank91]:     evaluate_and_print_results(
[rank91]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank91]:     total_loss_dict = evaluate(
[rank91]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank91]:     loss, metric_dict = forward_step_fn(
[rank91]: ValueError: not enough values to unpack (expected 2, got 1)
[rank76]: Traceback (most recent call last):
[rank76]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank76]:     main()
[rank76]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank76]:     pretrain(neox_args=neox_args)
[rank76]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank76]:     evaluate_and_print_results(
[rank76]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank76]:     total_loss_dict = evaluate(
[rank76]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank76]:     loss, metric_dict = forward_step_fn(
[rank76]: ValueError: not enough values to unpack (expected 2, got 1)
[rank77]: Traceback (most recent call last):
[rank77]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank77]:     main()
[rank77]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank77]:     pretrain(neox_args=neox_args)
[rank77]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank77]:     evaluate_and_print_results(
[rank77]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank77]:     total_loss_dict = evaluate(
[rank77]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank77]:     loss, metric_dict = forward_step_fn(
[rank77]: ValueError: not enough values to unpack (expected 2, got 1)
[rank79]: Traceback (most recent call last):
[rank79]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank79]:     main()
[rank79]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank79]:     pretrain(neox_args=neox_args)
[rank79]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank79]:     evaluate_and_print_results(
[rank79]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank79]:     total_loss_dict = evaluate(
[rank79]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank79]:     loss, metric_dict = forward_step_fn(
[rank79]: ValueError: not enough values to unpack (expected 2, got 1)
[rank23]:[W212 15:01:58.747906613 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank78]: Traceback (most recent call last):
[rank78]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank78]:     main()
[rank78]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank78]:     pretrain(neox_args=neox_args)
[rank78]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank78]:     evaluate_and_print_results(
[rank78]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank78]:     total_loss_dict = evaluate(
[rank78]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank78]:     loss, metric_dict = forward_step_fn(
[rank78]: ValueError: not enough values to unpack (expected 2, got 1)
[rank102]: Traceback (most recent call last):
[rank102]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank102]:     main()
[rank102]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank102]:     pretrain(neox_args=neox_args)
[rank102]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank102]:     evaluate_and_print_results(
[rank102]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank102]:     total_loss_dict = evaluate(
[rank102]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank102]:     loss, metric_dict = forward_step_fn(
[rank102]: ValueError: not enough values to unpack (expected 2, got 1)
[rank100]: Traceback (most recent call last):
[rank100]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank100]:     main()
[rank100]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank100]:     pretrain(neox_args=neox_args)
[rank100]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank100]:     evaluate_and_print_results(
[rank100]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank100]:     total_loss_dict = evaluate(
[rank100]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank100]:     loss, metric_dict = forward_step_fn(
[rank100]: ValueError: not enough values to unpack (expected 2, got 1)
[rank101]: Traceback (most recent call last):
[rank101]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank101]:     main()
[rank101]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank101]:     pretrain(neox_args=neox_args)
[rank101]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank101]:     evaluate_and_print_results(
[rank101]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank101]:     total_loss_dict = evaluate(
[rank101]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank101]:     loss, metric_dict = forward_step_fn(
[rank101]: ValueError: not enough values to unpack (expected 2, got 1)
[rank103]: Traceback (most recent call last):
[rank103]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank103]:     main()
[rank103]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank103]:     pretrain(neox_args=neox_args)
[rank103]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank103]:     evaluate_and_print_results(
[rank103]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank103]:     total_loss_dict = evaluate(
[rank103]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank103]:     loss, metric_dict = forward_step_fn(
[rank103]: ValueError: not enough values to unpack (expected 2, got 1)
[rank26]:[W212 15:01:58.119609137 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank106]: Traceback (most recent call last):
[rank106]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank106]:     main()
[rank106]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank106]:     pretrain(neox_args=neox_args)
[rank106]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank106]:     evaluate_and_print_results(
[rank106]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank106]:     total_loss_dict = evaluate(
[rank106]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank106]:     loss, metric_dict = forward_step_fn(
[rank106]: ValueError: not enough values to unpack (expected 2, got 1)
[rank105]: Traceback (most recent call last):
[rank105]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank105]:     main()
[rank105]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank105]:     pretrain(neox_args=neox_args)
[rank105]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank105]:     evaluate_and_print_results(
[rank105]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank105]:     total_loss_dict = evaluate(
[rank105]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank105]:     loss, metric_dict = forward_step_fn(
[rank105]: ValueError: not enough values to unpack (expected 2, got 1)
[rank107]: Traceback (most recent call last):
[rank107]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank107]:     main()
[rank107]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank107]:     pretrain(neox_args=neox_args)
[rank107]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank107]:     evaluate_and_print_results(
[rank107]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank107]:     total_loss_dict = evaluate(
[rank107]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank107]:     loss, metric_dict = forward_step_fn(
[rank107]: ValueError: not enough values to unpack (expected 2, got 1)
[rank104]: Traceback (most recent call last):
[rank104]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank104]:     main()
[rank104]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank104]:     pretrain(neox_args=neox_args)
[rank104]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank104]:     evaluate_and_print_results(
[rank104]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank104]:     total_loss_dict = evaluate(
[rank104]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank104]:     loss, metric_dict = forward_step_fn(
[rank104]: ValueError: not enough values to unpack (expected 2, got 1)
[rank15]:[W212 15:01:58.121945998 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank118]: Traceback (most recent call last):
[rank118]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank118]:     main()
[rank118]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank118]:     pretrain(neox_args=neox_args)
[rank118]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank118]:     evaluate_and_print_results(
[rank118]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank118]:     total_loss_dict = evaluate(
[rank118]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank118]:     loss, metric_dict = forward_step_fn(
[rank118]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank117]: Traceback (most recent call last):
[rank117]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank117]:     main()
[rank117]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank117]:     pretrain(neox_args=neox_args)
[rank117]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank117]:     evaluate_and_print_results(
[rank117]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank117]:     total_loss_dict = evaluate(
[rank117]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank117]:     loss, metric_dict = forward_step_fn(
[rank117]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank116]: Traceback (most recent call last):
[rank116]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank116]:     main()
[rank116]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank116]:     pretrain(neox_args=neox_args)
[rank116]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank116]:     evaluate_and_print_results(
[rank116]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank116]:     total_loss_dict = evaluate(
[rank116]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank116]:     loss, metric_dict = forward_step_fn(
[rank116]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank118]:     raise TypeError("iteration over a 0-d tensor")
[rank118]: TypeError: iteration over a 0-d tensor
[rank119]: Traceback (most recent call last):
[rank119]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank119]:     main()
[rank119]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank119]:     pretrain(neox_args=neox_args)
[rank119]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank119]:     evaluate_and_print_results(
[rank119]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank119]:     total_loss_dict = evaluate(
[rank119]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank119]:     loss, metric_dict = forward_step_fn(
[rank119]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank117]:     raise TypeError("iteration over a 0-d tensor")
[rank117]: TypeError: iteration over a 0-d tensor
[rank116]:     raise TypeError("iteration over a 0-d tensor")
[rank116]: TypeError: iteration over a 0-d tensor
[rank119]:     raise TypeError("iteration over a 0-d tensor")
[rank119]: TypeError: iteration over a 0-d tensor
[rank95]: Traceback (most recent call last):
[rank95]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank95]:     main()
[rank95]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank95]:     pretrain(neox_args=neox_args)
[rank95]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank95]:     evaluate_and_print_results(
[rank95]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank95]:     total_loss_dict = evaluate(
[rank95]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank95]:     loss, metric_dict = forward_step_fn(
[rank95]: ValueError: not enough values to unpack (expected 2, got 1)
[rank93]: Traceback (most recent call last):
[rank93]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank93]:     main()
[rank93]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank93]:     pretrain(neox_args=neox_args)
[rank93]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank93]:     evaluate_and_print_results(
[rank93]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank93]:     total_loss_dict = evaluate(
[rank93]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank93]:     loss, metric_dict = forward_step_fn(
[rank93]: ValueError: not enough values to unpack (expected 2, got 1)
[rank94]: Traceback (most recent call last):
[rank94]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank94]:     main()
[rank94]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank94]:     pretrain(neox_args=neox_args)
[rank94]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank94]:     evaluate_and_print_results(
[rank94]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank94]:     total_loss_dict = evaluate(
[rank94]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank94]:     loss, metric_dict = forward_step_fn(
[rank94]: ValueError: not enough values to unpack (expected 2, got 1)
[rank92]: Traceback (most recent call last):
[rank92]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank92]:     main()
[rank92]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank92]:     pretrain(neox_args=neox_args)
[rank92]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank92]:     evaluate_and_print_results(
[rank92]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank92]:     total_loss_dict = evaluate(
[rank92]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank92]:     loss, metric_dict = forward_step_fn(
[rank92]: ValueError: not enough values to unpack (expected 2, got 1)
[rank120]: Traceback (most recent call last):
[rank120]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank120]:     main()
[rank120]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank120]:     pretrain(neox_args=neox_args)
[rank120]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank120]:     evaluate_and_print_results(
[rank120]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank120]:     total_loss_dict = evaluate(
[rank120]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank120]:     loss, metric_dict = forward_step_fn(
[rank120]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank120]:     raise TypeError("iteration over a 0-d tensor")
[rank120]: TypeError: iteration over a 0-d tensor
[rank121]: Traceback (most recent call last):
[rank121]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank121]:     main()
[rank121]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank121]:     pretrain(neox_args=neox_args)
[rank121]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank121]:     evaluate_and_print_results(
[rank121]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank121]:     total_loss_dict = evaluate(
[rank121]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank121]:     loss, metric_dict = forward_step_fn(
[rank121]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank123]: Traceback (most recent call last):
[rank123]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank123]:     main()
[rank123]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank123]:     pretrain(neox_args=neox_args)
[rank123]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank123]:     evaluate_and_print_results(
[rank123]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank123]:     total_loss_dict = evaluate(
[rank123]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank123]:     loss, metric_dict = forward_step_fn(
[rank123]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank122]: Traceback (most recent call last):
[rank122]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank122]:     main()
[rank122]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank122]:     pretrain(neox_args=neox_args)
[rank122]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank122]:     evaluate_and_print_results(
[rank122]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank122]:     total_loss_dict = evaluate(
[rank122]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank122]:     loss, metric_dict = forward_step_fn(
[rank122]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank123]:     raise TypeError("iteration over a 0-d tensor")
[rank123]: TypeError: iteration over a 0-d tensor
[rank121]:     raise TypeError("iteration over a 0-d tensor")
[rank121]: TypeError: iteration over a 0-d tensor
[rank122]:     raise TypeError("iteration over a 0-d tensor")
[rank122]: TypeError: iteration over a 0-d tensor
[rank22]:[W212 15:01:58.581666187 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank55]:[W212 15:01:58.173035611 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank42]:[W212 15:01:58.699579741 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank111]: Traceback (most recent call last):
[rank111]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank111]:     main()
[rank111]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank111]:     pretrain(neox_args=neox_args)
[rank111]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank111]:     evaluate_and_print_results(
[rank111]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank111]:     total_loss_dict = evaluate(
[rank111]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank111]:     loss, metric_dict = forward_step_fn(
[rank111]: ValueError: not enough values to unpack (expected 2, got 1)
[rank108]: Traceback (most recent call last):
[rank108]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank108]:     main()
[rank108]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank108]:     pretrain(neox_args=neox_args)
[rank108]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank108]:     evaluate_and_print_results(
[rank108]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank108]:     total_loss_dict = evaluate(
[rank108]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank108]:     loss, metric_dict = forward_step_fn(
[rank108]: ValueError: not enough values to unpack (expected 2, got 1)
[rank109]: Traceback (most recent call last):
[rank109]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank109]:     main()
[rank109]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank109]:     pretrain(neox_args=neox_args)
[rank109]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank109]:     evaluate_and_print_results(
[rank109]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank109]:     total_loss_dict = evaluate(
[rank109]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank109]:     loss, metric_dict = forward_step_fn(
[rank109]: ValueError: not enough values to unpack (expected 2, got 1)
[rank110]: Traceback (most recent call last):
[rank110]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank110]:     main()
[rank110]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank110]:     pretrain(neox_args=neox_args)
[rank110]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank110]:     evaluate_and_print_results(
[rank110]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank110]:     total_loss_dict = evaluate(
[rank110]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank110]:     loss, metric_dict = forward_step_fn(
[rank110]: ValueError: not enough values to unpack (expected 2, got 1)
[rank29]:[W212 15:01:58.360074867 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank127]: Traceback (most recent call last):
[rank127]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank127]:     main()
[rank127]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank127]:     pretrain(neox_args=neox_args)
[rank127]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank127]:     evaluate_and_print_results(
[rank127]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank127]:     total_loss_dict = evaluate(
[rank127]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank127]:     loss, metric_dict = forward_step_fn(
[rank127]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank124]: Traceback (most recent call last):
[rank124]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank124]:     main()
[rank124]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank124]:     pretrain(neox_args=neox_args)
[rank124]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank124]:     evaluate_and_print_results(
[rank124]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank124]:     total_loss_dict = evaluate(
[rank124]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank124]:     loss, metric_dict = forward_step_fn(
[rank124]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank127]:     raise TypeError("iteration over a 0-d tensor")
[rank127]: TypeError: iteration over a 0-d tensor
[rank126]: Traceback (most recent call last):
[rank126]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank126]:     main()
[rank126]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank126]:     pretrain(neox_args=neox_args)
[rank126]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank126]:     evaluate_and_print_results(
[rank126]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank126]:     total_loss_dict = evaluate(
[rank126]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank126]:     loss, metric_dict = forward_step_fn(
[rank126]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank124]:     raise TypeError("iteration over a 0-d tensor")
[rank124]: TypeError: iteration over a 0-d tensor
[rank126]:     raise TypeError("iteration over a 0-d tensor")
[rank126]: TypeError: iteration over a 0-d tensor
[rank125]: Traceback (most recent call last):
[rank125]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank125]:     main()
[rank125]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank125]:     pretrain(neox_args=neox_args)
[rank125]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank125]:     evaluate_and_print_results(
[rank125]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank125]:     total_loss_dict = evaluate(
[rank125]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank125]:     loss, metric_dict = forward_step_fn(
[rank125]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank125]:     raise TypeError("iteration over a 0-d tensor")
[rank125]: TypeError: iteration over a 0-d tensor
[rank54]:[W212 15:01:58.312740992 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank10]:[W212 15:01:58.032344549 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank71]:[W212 15:01:58.266773164 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank73]:[W212 15:01:58.297941828 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank102]:[W212 15:01:58.867514980 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank91]:[W212 15:01:58.627386015 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank45]:[W212 15:01:58.383935470 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/deepspeed/ops/transformer/inference/triton/matmul_ext.py", line 74, in load
    loaded_dict = pickle.load(handle)
OSError: [Errno 116] Stale file handle
[rank56]:[W212 15:01:58.770087122 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank39]:[W212 15:01:58.437873563 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank86]:[W212 15:01:58.058458027 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank72]:[W212 15:01:58.515518917 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank7]:[W212 15:01:58.865457107 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank85]:[W212 15:01:58.171678815 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank46]:[W212 15:01:58.837214212 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank8]:[W212 15:01:58.992671421 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank14]:[W212 15:01:58.604642690 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank37]:[W212 15:01:58.053139773 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank47]:[W212 15:01:58.867151455 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank43]:[W212 15:01:58.298143267 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank122]:[W212 15:01:58.647076781 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank108]:[W212 15:01:58.799247217 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank103]:[W212 15:01:58.267949953 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank41]:[W212 15:01:58.896268691 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank24]:[W212 15:01:58.603942427 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank69]:[W212 15:01:58.489984090 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank88]:[W212 15:01:58.364738826 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank84]:[W212 15:01:59.238469918 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank44]:[W212 15:01:59.152913932 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank57]:[W212 15:01:59.998688211 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank5]:[W212 15:01:59.045314896 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank52]:[W212 15:01:59.057576813 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank74]:[W212 15:01:59.012613545 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank53]:[W212 15:01:59.415439528 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank111]:[W212 15:01:59.078858973 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank121]:[W212 15:01:59.620373637 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank124]:[W212 15:01:59.144939769 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank27]:[W212 15:01:59.184638165 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank101]:[W212 15:01:59.859149776 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank126]:[W212 15:01:59.868774483 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank61]:[W212 15:01:59.208830076 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank77]:[W212 15:01:59.741379473 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank0]: Traceback (most recent call last):
[rank0]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank0]:     main()
[rank0]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank0]:     pretrain(neox_args=neox_args)
[rank0]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank0]:     evaluate_and_print_results(
[rank0]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank0]:     total_loss_dict = evaluate(
[rank0]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank0]:     loss, metric_dict = forward_step_fn(
[rank0]: ValueError: not enough values to unpack (expected 2, got 1)
[rank3]: Traceback (most recent call last):
[rank3]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank3]:     main()
[rank3]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank3]:     pretrain(neox_args=neox_args)
[rank3]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank3]:     evaluate_and_print_results(
[rank3]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank3]:     total_loss_dict = evaluate(
[rank3]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank3]:     loss, metric_dict = forward_step_fn(
[rank3]: ValueError: not enough values to unpack (expected 2, got 1)
[rank2]: Traceback (most recent call last):
[rank2]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank2]:     main()
[rank2]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank2]:     pretrain(neox_args=neox_args)
[rank2]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank2]:     evaluate_and_print_results(
[rank2]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank2]:     total_loss_dict = evaluate(
[rank2]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank2]:     loss, metric_dict = forward_step_fn(
[rank2]: ValueError: not enough values to unpack (expected 2, got 1)
[rank1]: Traceback (most recent call last):
[rank1]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank1]:     main()
[rank1]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank1]:     pretrain(neox_args=neox_args)
[rank1]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank1]:     evaluate_and_print_results(
[rank1]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank1]:     total_loss_dict = evaluate(
[rank1]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank1]:     loss, metric_dict = forward_step_fn(
[rank1]: ValueError: not enough values to unpack (expected 2, got 1)
[rank106]:[W212 15:01:59.253703093 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank123]:[W212 15:01:59.676446089 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank30]:[W212 15:01:59.376576706 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank13]:[W212 15:01:59.445560274 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank21]:[W212 15:01:59.120572565 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank104]:[W212 15:01:59.422095562 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank119]:[W212 15:01:59.907941639 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank125]:[W212 15:01:59.535401784 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank40]:[W212 15:01:59.407921596 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank28]:[W212 15:01:59.011542131 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank117]:[W212 15:01:59.794602917 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank38]:[W212 15:01:59.657542229 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank12]:[W212 15:01:59.224613328 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank109]:[W212 15:01:59.552580097 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank120]:[W212 15:01:59.198795678 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank6]:[W212 15:01:59.576529307 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank60]:[W212 15:01:59.620872538 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank95]:[W212 15:01:59.547064460 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank75]:[W212 15:01:59.224321057 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank11]:[W212 15:01:59.838716138 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank20]:[W212 15:01:59.846204191 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank68]:[W212 15:01:59.778934300 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank63]:[W212 15:01:59.739371535 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank105]:[W212 15:01:59.729178285 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank78]:[W212 15:01:59.520332703 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank1]:[W212 15:01:59.351253188 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank16]: Traceback (most recent call last):
[rank16]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank16]:     main()
[rank16]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank16]:     pretrain(neox_args=neox_args)
[rank16]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank16]:     evaluate_and_print_results(
[rank16]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank16]:     total_loss_dict = evaluate(
[rank16]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank16]:     loss, metric_dict = forward_step_fn(
[rank16]: ValueError: not enough values to unpack (expected 2, got 1)
[rank18]: Traceback (most recent call last):
[rank18]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank18]:     main()
[rank18]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank18]:     pretrain(neox_args=neox_args)
[rank18]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank18]:     evaluate_and_print_results(
[rank18]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank18]:     total_loss_dict = evaluate(
[rank18]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank18]:     loss, metric_dict = forward_step_fn(
[rank18]: ValueError: not enough values to unpack (expected 2, got 1)
[rank19]: Traceback (most recent call last):
[rank19]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank19]:     main()
[rank19]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank19]:     pretrain(neox_args=neox_args)
[rank19]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank19]:     evaluate_and_print_results(
[rank19]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank19]:     total_loss_dict = evaluate(
[rank19]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank19]:     loss, metric_dict = forward_step_fn(
[rank19]: ValueError: not enough values to unpack (expected 2, got 1)
[rank17]: Traceback (most recent call last):
[rank17]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank17]:     main()
[rank17]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank17]:     pretrain(neox_args=neox_args)
[rank17]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank17]:     evaluate_and_print_results(
[rank17]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank17]:     total_loss_dict = evaluate(
[rank17]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank17]:     loss, metric_dict = forward_step_fn(
[rank17]: ValueError: not enough values to unpack (expected 2, got 1)
[rank59]:[W212 15:01:59.812251641 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank107]:[W212 15:01:59.834537085 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank118]:[W212 15:01:59.157147328 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank94]:[W212 15:01:59.894363265 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank3]:[W212 15:01:59.937128211 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank89]:[W212 15:01:59.915558621 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank100]:[W212 15:01:59.047586166 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank62]:[W212 15:01:59.816992098 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank76]:[W212 15:01:59.108995129 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank58]:[W212 15:02:00.978955336 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank92]:[W212 15:02:00.424924467 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank25]:[W212 15:02:00.045007356 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank87]:[W212 15:02:00.134699510 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank116]:[W212 15:02:00.270855773 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank19]:[W212 15:02:00.162958118 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank70]:[W212 15:02:00.526296537 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank17]:[W212 15:02:00.247906620 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank31]:[W212 15:02:00.856524016 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank32]: Traceback (most recent call last):
[rank32]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank32]:     main()
[rank32]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank32]:     pretrain(neox_args=neox_args)
[rank32]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank32]:     evaluate_and_print_results(
[rank32]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank32]:     total_loss_dict = evaluate(
[rank32]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank32]:     loss, metric_dict = forward_step_fn(
[rank32]: ValueError: not enough values to unpack (expected 2, got 1)
[rank35]: Traceback (most recent call last):
[rank35]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank35]:     main()
[rank35]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank35]:     pretrain(neox_args=neox_args)
[rank35]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank35]:     evaluate_and_print_results(
[rank35]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank35]:     total_loss_dict = evaluate(
[rank35]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank35]:     loss, metric_dict = forward_step_fn(
[rank35]: ValueError: not enough values to unpack (expected 2, got 1)
[rank33]: Traceback (most recent call last):
[rank33]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank33]:     main()
[rank33]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank33]:     pretrain(neox_args=neox_args)
[rank33]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank33]:     evaluate_and_print_results(
[rank33]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank33]:     total_loss_dict = evaluate(
[rank33]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank33]:     loss, metric_dict = forward_step_fn(
[rank33]: ValueError: not enough values to unpack (expected 2, got 1)
[rank34]: Traceback (most recent call last):
[rank34]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank34]:     main()
[rank34]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank34]:     pretrain(neox_args=neox_args)
[rank34]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank34]:     evaluate_and_print_results(
[rank34]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank34]:     total_loss_dict = evaluate(
[rank34]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank34]:     loss, metric_dict = forward_step_fn(
[rank34]: ValueError: not enough values to unpack (expected 2, got 1)
[rank93]:[W212 15:02:00.587533262 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank79]:[W212 15:02:00.308119266 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank18]:[W212 15:02:00.330846843 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank2]:[W212 15:02:00.787791802 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank36]:[W212 15:02:00.649008372 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank110]:[W212 15:02:00.479207191 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank90]:[W212 15:02:00.465925703 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank34]:[W212 15:02:00.412908961 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank35]:[W212 15:02:00.832203126 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank32]:[W212 15:02:00.635816520 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank33]:[W212 15:02:00.914858118 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank49]: Traceback (most recent call last):
[rank49]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank49]:     main()
[rank49]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank49]:     pretrain(neox_args=neox_args)
[rank49]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank49]:     evaluate_and_print_results(
[rank49]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank49]:     total_loss_dict = evaluate(
[rank49]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank49]:     loss, metric_dict = forward_step_fn(
[rank49]: ValueError: not enough values to unpack (expected 2, got 1)
[rank48]: Traceback (most recent call last):
[rank48]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank48]:     main()
[rank48]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank48]:     pretrain(neox_args=neox_args)
[rank48]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank48]:     evaluate_and_print_results(
[rank48]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank48]:     total_loss_dict = evaluate(
[rank48]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank48]:     loss, metric_dict = forward_step_fn(
[rank48]: ValueError: not enough values to unpack (expected 2, got 1)
[rank51]: Traceback (most recent call last):
[rank51]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank51]:     main()
[rank51]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank51]:     pretrain(neox_args=neox_args)
[rank51]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank51]:     evaluate_and_print_results(
[rank51]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank51]:     total_loss_dict = evaluate(
[rank51]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank51]:     loss, metric_dict = forward_step_fn(
[rank51]: ValueError: not enough values to unpack (expected 2, got 1)
[rank50]: Traceback (most recent call last):
[rank50]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank50]:     main()
[rank50]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank50]:     pretrain(neox_args=neox_args)
[rank50]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank50]:     evaluate_and_print_results(
[rank50]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank50]:     total_loss_dict = evaluate(
[rank50]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank50]:     loss, metric_dict = forward_step_fn(
[rank50]: ValueError: not enough values to unpack (expected 2, got 1)
[rank48]:[W212 15:02:01.165281793 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank49]:[W212 15:02:01.259358358 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank64]: Traceback (most recent call last):
[rank64]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank64]:     main()
[rank64]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank64]:     pretrain(neox_args=neox_args)
[rank64]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank64]:     evaluate_and_print_results(
[rank64]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank64]:     total_loss_dict = evaluate(
[rank64]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank64]:     loss, metric_dict = forward_step_fn(
[rank64]: ValueError: not enough values to unpack (expected 2, got 1)
[rank65]: Traceback (most recent call last):
[rank65]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank65]:     main()
[rank65]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank65]:     pretrain(neox_args=neox_args)
[rank65]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank65]:     evaluate_and_print_results(
[rank65]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank65]:     total_loss_dict = evaluate(
[rank65]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank65]:     loss, metric_dict = forward_step_fn(
[rank65]: ValueError: not enough values to unpack (expected 2, got 1)
[rank66]: Traceback (most recent call last):
[rank66]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank66]:     main()
[rank66]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank66]:     pretrain(neox_args=neox_args)
[rank66]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank66]:     evaluate_and_print_results(
[rank66]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank66]:     total_loss_dict = evaluate(
[rank66]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank66]:     loss, metric_dict = forward_step_fn(
[rank66]: ValueError: not enough values to unpack (expected 2, got 1)
[rank67]: Traceback (most recent call last):
[rank67]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank67]:     main()
[rank67]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank67]:     pretrain(neox_args=neox_args)
[rank67]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank67]:     evaluate_and_print_results(
[rank67]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank67]:     total_loss_dict = evaluate(
[rank67]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank67]:     loss, metric_dict = forward_step_fn(
[rank67]: ValueError: not enough values to unpack (expected 2, got 1)
[rank51]:[W212 15:02:01.389795923 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank50]:[W212 15:02:01.414239519 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank67]:[W212 15:02:01.515505357 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank66]:[W212 15:02:01.522463629 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank64]:[W212 15:02:01.455649131 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank65]:[W212 15:02:01.630805033 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank80]: Traceback (most recent call last):
[rank80]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank80]:     main()
[rank80]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank80]:     pretrain(neox_args=neox_args)
[rank80]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank80]:     evaluate_and_print_results(
[rank80]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank80]:     total_loss_dict = evaluate(
[rank80]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank80]:     loss, metric_dict = forward_step_fn(
[rank80]: ValueError: not enough values to unpack (expected 2, got 1)
[rank81]: Traceback (most recent call last):
[rank81]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank81]:     main()
[rank81]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank81]:     pretrain(neox_args=neox_args)
[rank81]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank81]:     evaluate_and_print_results(
[rank81]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank81]:     total_loss_dict = evaluate(
[rank81]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank81]:     loss, metric_dict = forward_step_fn(
[rank81]: ValueError: not enough values to unpack (expected 2, got 1)
[rank82]: Traceback (most recent call last):
[rank82]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank82]:     main()
[rank82]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank82]:     pretrain(neox_args=neox_args)
[rank82]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank82]:     evaluate_and_print_results(
[rank82]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank82]:     total_loss_dict = evaluate(
[rank82]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank82]:     loss, metric_dict = forward_step_fn(
[rank82]: ValueError: not enough values to unpack (expected 2, got 1)
[rank83]: Traceback (most recent call last):
[rank83]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank83]:     main()
[rank83]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank83]:     pretrain(neox_args=neox_args)
[rank83]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank83]:     evaluate_and_print_results(
[rank83]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank83]:     total_loss_dict = evaluate(
[rank83]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank83]:     loss, metric_dict = forward_step_fn(
[rank83]: ValueError: not enough values to unpack (expected 2, got 1)
[rank96]: Traceback (most recent call last):
[rank96]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank96]:     main()
[rank96]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank96]:     pretrain(neox_args=neox_args)
[rank96]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank96]:     evaluate_and_print_results(
[rank96]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank96]:     total_loss_dict = evaluate(
[rank96]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank96]:     loss, metric_dict = forward_step_fn(
[rank96]: ValueError: not enough values to unpack (expected 2, got 1)
[rank97]: Traceback (most recent call last):
[rank97]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank97]:     main()
[rank97]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank97]:     pretrain(neox_args=neox_args)
[rank97]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank97]:     evaluate_and_print_results(
[rank97]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank97]:     total_loss_dict = evaluate(
[rank97]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank97]:     loss, metric_dict = forward_step_fn(
[rank97]: ValueError: not enough values to unpack (expected 2, got 1)
[rank99]: Traceback (most recent call last):
[rank99]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank99]:     main()
[rank99]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank99]:     pretrain(neox_args=neox_args)
[rank99]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank99]:     evaluate_and_print_results(
[rank99]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank99]:     total_loss_dict = evaluate(
[rank99]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank99]:     loss, metric_dict = forward_step_fn(
[rank99]: ValueError: not enough values to unpack (expected 2, got 1)
[rank98]: Traceback (most recent call last):
[rank98]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank98]:     main()
[rank98]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank98]:     pretrain(neox_args=neox_args)
[rank98]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank98]:     evaluate_and_print_results(
[rank98]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank98]:     total_loss_dict = evaluate(
[rank98]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank98]:     loss, metric_dict = forward_step_fn(
[rank98]: ValueError: not enough values to unpack (expected 2, got 1)
[rank115]: Traceback (most recent call last):
[rank115]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank115]:     main()
[rank115]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank115]:     pretrain(neox_args=neox_args)
[rank115]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank115]:     evaluate_and_print_results(
[rank115]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank115]:     total_loss_dict = evaluate(
[rank115]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank115]:     loss, metric_dict = forward_step_fn(
[rank115]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank114]: Traceback (most recent call last):
[rank114]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank114]:     main()
[rank114]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank114]:     pretrain(neox_args=neox_args)
[rank114]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank114]:     evaluate_and_print_results(
[rank114]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank114]:     total_loss_dict = evaluate(
[rank114]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank114]:     loss, metric_dict = forward_step_fn(
[rank114]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank112]: Traceback (most recent call last):
[rank112]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank112]:     main()
[rank112]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank112]:     pretrain(neox_args=neox_args)
[rank112]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank112]:     evaluate_and_print_results(
[rank112]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank112]:     total_loss_dict = evaluate(
[rank112]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank112]:     loss, metric_dict = forward_step_fn(
[rank112]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank115]:     raise TypeError("iteration over a 0-d tensor")
[rank115]: TypeError: iteration over a 0-d tensor
[rank112]:     raise TypeError("iteration over a 0-d tensor")
[rank112]: TypeError: iteration over a 0-d tensor
[rank114]:     raise TypeError("iteration over a 0-d tensor")
[rank114]: TypeError: iteration over a 0-d tensor
[rank113]: Traceback (most recent call last):
[rank113]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 35, in <module>
[rank113]:     main()
[rank113]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/train_profiling.py", line 31, in main
[rank113]:     pretrain(neox_args=neox_args)
[rank113]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 314, in pretrain
[rank113]:     evaluate_and_print_results(
[rank113]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1701, in evaluate_and_print_results
[rank113]:     total_loss_dict = evaluate(
[rank113]:   File "/work/08775/byz2022/vista/gpt-neox_20241210/gpt-neox/megatron/training_profiling.py", line 1635, in evaluate
[rank113]:     loss, metric_dict = forward_step_fn(
[rank113]:   File "/work/08775/byz2022/vista/pythonenvs/gptneox/lib64/python3.9/site-packages/torch/_tensor.py", line 1154, in __iter__
[rank113]:     raise TypeError("iteration over a 0-d tensor")
[rank113]: TypeError: iteration over a 0-d tensor
[rank81]:[W212 15:02:01.960888755 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank82]:[W212 15:02:02.370091875 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank83]:[W212 15:02:02.041379263 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank96]:[W212 15:02:02.693755478 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank99]:[W212 15:02:02.107493517 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank97]:[W212 15:02:02.119432241 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank80]:[W212 15:02:02.150944037 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank98]:[W212 15:02:02.891308204 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank114]:[W212 15:02:02.068722894 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank112]:[W212 15:02:02.301914509 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank113]:[W212 15:02:02.327304707 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank115]:[W212 15:02:02.980995817 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
corrupted size vs. prev_size
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
double free or corruption (!prev)
srun: error: c634-061: task 94: Aborted (core dumped)
srun: error: c610-011: task 25: Aborted (core dumped)
srun: error: c610-032: task 30: Aborted (core dumped)
srun: error: c610-042: task 32: Aborted (core dumped)
srun: error: c609-152: task 22: Aborted (core dumped)
srun: error: c634-051: task 92: Aborted (core dumped)
srun: error: c610-022: task 28: Aborted (core dumped)
srun: error: c611-072: task 48: Aborted (core dumped)
srun: error: c610-041: task 31: Aborted (core dumped)
srun: error: c609-141: task 19: Aborted (core dumped)
srun: error: c634-062: task 95: Aborted (core dumped)
srun: error: c609-151: task 21: Aborted (core dumped)
srun: error: c609-132: task 18: Aborted (core dumped)
srun: error: c610-021: task 27: Aborted (core dumped)
srun: error: c609-131: task 17: Aborted (core dumped)
srun: error: c634-042: task 91: Aborted (core dumped)
srun: error: c621-082: task 58: Aborted (core dumped)
srun: error: c611-032: task 40: Aborted (core dumped)
srun: error: c621-091: task 59: Aborted (core dumped)
srun: error: c621-051: task 51: Aborted (core dumped)
srun: error: c621-072: task 56: Aborted (core dumped)
srun: error: c621-041: task 49: Aborted (core dumped)
srun: error: c621-081: task 57: Aborted (core dumped)
srun: error: c621-052: task 52: Aborted (core dumped)
srun: error: c621-111: task 63: Aborted (core dumped)
srun: error: c634-041: task 90: Aborted (core dumped)
srun: error: c621-071: task 55: Aborted (core dumped)
srun: error: c621-101: task 61: Aborted (core dumped)
srun: error: c634-091: task 100: Aborted (core dumped)
srun: error: c621-102: task 62: Aborted (core dumped)
srun: error: c621-132: task 68: Aborted (core dumped)
srun: error: c634-002: task 85: Aborted (core dumped)
srun: error: c621-062: task 54: Aborted (core dumped)
srun: error: c622-142: task 81: Aborted (core dumped)
srun: error: c634-032: task 89: Aborted (core dumped)
srun: error: c622-151: task 82: Aborted (core dumped)
srun: error: c622-152: task 83: Aborted (core dumped)
srun: error: c638-131: task 121: Exited with exit code 1
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
srun: error: c638-141: task 123: Exited with exit code 1
srun: error: c609-052: task 2: Exited with exit code 1
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
srun: error: c638-091: task 113: Exited with exit code 1
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
srun: error: c609-051: task 1: Exited with exit code 1
srun: error: c609-092: task 10: Exited with exit code 1
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
srun: error: c638-111: task 117: Exited with exit code 1
srun: error: c609-072: task 6: Exited with exit code 1
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
srun: error: c638-112: task 118: Exited with exit code 1
srun: error: c638-132: task 122: Exited with exit code 1
srun: error: c638-101: task 115: Exited with exit code 1
srun: error: c609-081: task 7: Exited with exit code 1
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
srun: error: c638-092: task 114: Exited with exit code 1
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
srun: error: c638-142: task 124: Exited with exit code 1
srun: error: c638-121: task 119: Exited with exit code 1
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
srun: error: c609-061: task 3: Exited with exit code 1
srun: error: c638-122: task 120: Exited with exit code 1
srun: error: c609-071: task 5: Exited with exit code 1
srun: error: c609-082: task 8: Exited with exit code 1
srun: error: c609-091: task 9: Exited with exit code 1
srun: error: c609-062: task 4: Exited with exit code 1
srun: error: c634-142: task 110: Exited with exit code 1
srun: error: c638-102: task 116: Exited with exit code 1
srun: error: c634-052: task 93: Exited with exit code 1
srun: error: c634-102: task 102: Exited with exit code 1
srun: error: c610-031: task 29: Exited with exit code 1
srun: error: c634-151: task 111: Exited with exit code 1
srun: error: c609-112: task 14: Exited with exit code 1
srun: error: c609-121: task 15: Exited with exit code 1
srun: error: c634-021: task 86: Exited with exit code 1
srun: error: c634-112: task 104: Exited with exit code 1
srun: error: c634-092: task 101: Exited with exit code 1
srun: error: c634-131: task 107: Exited with exit code 1
srun: error: c610-051: task 33: Exited with exit code 1
srun: error: c634-122: task 106: Exited with exit code 1
srun: error: c609-142: task 20: Exited with exit code 1
srun: error: c634-022: task 87: Exited with exit code 1
srun: error: c611-062: task 46: Exited with exit code 1
srun: error: c610-002: task 24: Exited with exit code 1
srun: error: c611-002: task 34: Exited with exit code 1
srun: error: c609-101: task 11: Exited with exit code 1
srun: error: c611-021: task 37: Exited with exit code 1
srun: error: c611-042: task 42: Exited with exit code 1
srun: error: c634-031: task 88: Exited with exit code 1
srun: error: c634-132: task 108: Exited with exit code 1
srun: error: c610-012: task 26: Exited with exit code 1
srun: error: c609-102: task 12: Exited with exit code 1
srun: error: c610-001: task 23: Exited with exit code 1
srun: error: c611-071: task 47: Exited with exit code 1
srun: error: c634-072: task 97: Exited with exit code 1
srun: error: c634-141: task 109: Exited with exit code 1
srun: error: c634-121: task 105: Exited with exit code 1
srun: error: c634-111: task 103: Exited with exit code 1
srun: error: c609-111: task 13: Exited with exit code 1
srun: error: c634-071: task 96: Exited with exit code 1
srun: error: c611-022: task 38: Exited with exit code 1
srun: error: c638-151: task 125: Exited with exit code 1
srun: error: c638-152: task 126: Exited with exit code 1
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
srun: error: c621-042: task 50: Exited with exit code 1
srun: error: c622-122: task 77: Exited with exit code 1
srun: error: c621-092: task 60: Exited with exit code 1
srun: error: c622-141: task 80: Exited with exit code 1
srun: error: c611-061: task 45: Exited with exit code 1
srun: error: c621-131: task 67: Exited with exit code 1
srun: error: c621-151: task 71: Exited with exit code 1
srun: error: c611-011: task 35: Exited with exit code 1
srun: error: c622-012: task 76: Exited with exit code 1
srun: error: c634-152: task 112: Exited with exit code 1
srun: error: c611-052: task 44: Exited with exit code 1
srun: error: c622-002: task 74: Exited with exit code 1
srun: error: c622-132: task 79: Exited with exit code 1
srun: error: c611-041: task 41: Exited with exit code 1
srun: error: c634-001: task 84: Exited with exit code 1
srun: error: c622-131: task 78: Exited with exit code 1
srun: error: c634-081: task 98: Exited with exit code 1
srun: error: c622-011: task 75: Exited with exit code 1
srun: error: c621-061: task 53: Exited with exit code 1
srun: error: c621-152: task 72: Exited with exit code 1
srun: error: c621-141: task 69: Exited with exit code 1
srun: error: c621-121: task 65: Exited with exit code 1
srun: error: c611-012: task 36: Exited with exit code 1
srun: error: c621-112: task 64: Exited with exit code 1
srun: error: c634-082: task 99: Exited with exit code 1
srun: error: c621-142: task 70: Exited with exit code 1
srun: error: c611-051: task 43: Exited with exit code 1
srun: error: c611-031: task 39: Exited with exit code 1
srun: error: c622-001: task 73: Exited with exit code 1
srun: error: c621-122: task 66: Exited with exit code 1
[rank127]:[W212 15:02:08.244371926 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
srun: error: c639-001: task 127: Exited with exit code 1
[rank0]:[W212 15:02:11.081335369 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
[rank16]:[W212 15:02:13.407745866 ProcessGroupNCCL.cpp:1488] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())
slurmstepd: error: _get_joules_task: can't get info from slurmd
slurmstepd: error: _get_joules_task: can't get info from slurmd
srun: error: c609-042: task 0: Exited with exit code 1
srun: error: c609-122: task 16: Exited with exit code 1
