cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::fill_,88626,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",88626,0,2.7861333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::copy_,88635,"[[], [], []]",Memcpy HtoD (Pageable -> Device),88635,4348.111490885417,0.7645866666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::native_layer_norm,88640,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",88640,2472.7071940104165,91.02223999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::native_layer_norm,88647,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",88647,33.876953125,91.22949333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::addmm,88662,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,88662,1737.4265950520833,572.0677999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::copy_,88687,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),88687,119.95540364583333,2.7554000000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::copy_,88691,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),88691,1055.9365234375,2.9610400000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::neg,88701,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",88701,2563.9568684895835,7.4926400000000015
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::cat,88713,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",88713,1437.3536783854167,16.15693333333333
None,None,None,None,None,None,kernel_1,88714,799.6173502604166,7.006266666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::neg,88724,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",88724,1276.1276041666667,9.280386666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::cat,88735,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",88735,1145.0354817708333,16.142359999999996
None,None,None,None,None,None,kernel_1,88736,727.4820963541666,6.939226666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::cat,88742,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",88742,1399.53076171875,66.10673333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::cat,88743,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",88743,27.274088541666668,66.43998666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::baddbmm,88753,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,88753,1489.36376953125,212.74489333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,ScaledUpperTriangMaskedSoftmax,88756,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",88756,39.7333984375,335.35898666666657
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::bmm,88773,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,88773,84.6279296875,184.25661333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::copy_,88781,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",88781,39.413411458333336,34.45133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mm,88790,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,88790,83.25260416666667,193.30143999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add,88795,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",88795,46.718912760416664,131.08970666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mm,88807,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,88807,87.67903645833333,792.8177733333331
None,None,None,None,None,None,kernel_2,88811,35.904622395833336,87.58539999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mm,88822,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,88822,97.04280598958333,793.46164
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add,88827,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",88827,35.434244791666664,128.76781333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add,88829,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",88829,34.99658203125,83.55729333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,record_param_comms,88832,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",88832,55.316569010416664,3220.5353066666653
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add,88837,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",88837,49.375,85.56431999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::sum,88848,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",88848,97.55696614583333,46.806213333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,88852,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",88852,36.89501953125,1.8167333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mm,88862,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,88862,102.36767578125,724.14504
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mm,88869,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,88869,117.74918619791667,781.1182400000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,88881,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",88881,44.222819010416664,59.10481333333332
None,None,None,None,None,None,kernel_3,88885,38.9228515625,95.4355866666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::sum,88889,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",88889,105.01220703125,46.47044000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,88893,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",88893,36.628743489583336,1.8423333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mm,88903,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,88903,104.94921875,711.290973333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mm,88910,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,88910,114.259765625,770.0604400000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,88922,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",88922,36.587727864583336,59.12397333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,record_param_comms,88926,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",88926,65.67333984375,3237.1436
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::sum,88933,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",88933,95.08154296875,49.45490666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,88937,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",88937,40.138346354166664,1.7817599999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mm,88947,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,88947,102.21809895833333,207.19448000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mm,88954,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,88954,102.0380859375,188.27065333333329
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,88966,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",88966,36.24462890625,14.299240000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::bmm,88985,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,88985,102.97526041666667,174.43390666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::bmm,88988,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,88988,107.64615885416667,207.97399999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,ScaledUpperTriangMaskedSoftmaxBackward,89006,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",89006,40.885416666666664,555.3917066666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::bmm,89023,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,89023,107.34847005208333,178.9667733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mul,89025,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",89025,41.225423177083336,16.883946666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::bmm,89028,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,89028,105.96451822916667,173.57299999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mul,89030,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",89030,35.9130859375,16.913746666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mul,89070,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",89070,34.593587239583336,11.705093333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mul,89074,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",89074,30.859049479166668,10.643053333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::neg,89077,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",89077,34.795572916666664,5.341359999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::fill_,89084,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",89084,34.666666666666664,3.1744000000000008
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::copy_,89087,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",89087,34.568033854166664,12.8076
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,89088,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",89088,29.473958333333332,23.38712
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::fill_,90631,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",90631,27.189778645833332,3.1018666666666697
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::copy_,90634,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",90634,27.37109375,13.025986666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,90635,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",90635,26.912272135416668,23.16949333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mul,90639,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",90639,28.9384765625,11.953399999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mul,90643,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",90643,34.78564453125,10.116213333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::neg,90646,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",90646,33.566731770833336,5.481733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::fill_,90653,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",90653,33.8232421875,3.1393600000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::copy_,90656,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",90656,30.579264322916668,5.7958133333333315
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,90657,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",90657,27.094401041666668,10.348759999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::fill_,90664,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",90664,27.252604166666668,3.1125200000000013
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::copy_,90667,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",90667,27.113606770833332,5.924613333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,90668,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",90668,29.898274739583332,10.253599999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::fill_,90675,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",90675,30.568522135416668,8.753879999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::copy_,90678,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",90678,34.966634114583336,64.71748
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::fill_,90685,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",90685,42.111165364583336,8.959933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::copy_,90688,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",90688,31.486979166666668,22.919933333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,90689,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",90689,27.242513020833332,19.618893333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::fill_,90696,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",90696,33.822428385416664,8.912106666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::copy_,90699,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",90699,27.08203125,29.555333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::fill_,90706,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",90706,38.293782552083336,9.015439999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::copy_,90709,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",90709,34.51611328125,11.477613333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,90710,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",90710,34.708333333333336,19.748973333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::cat,90713,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",90713,37.974446614583336,146.79902666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mm,90727,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,90727,104.02034505208333,542.7052399999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::mm,90731,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,90731,115.50732421875,542.0094266666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::sum,90735,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",90735,104.255859375,36.720720000000014
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,90739,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",90739,36.383463541666664,1.8013599999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,90747,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",90747,30.6982421875,42.58822666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,record_param_comms,90755,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",90755,72.68245442708333,3238.8186533333346
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::native_layer_norm_backward,90760,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",90760,53.364583333333336,140.6669333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::native_layer_norm_backward,90760,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",90760,44.23486328125,88.94478666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add,90764,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",90764,43.798177083333336,78.98816
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,90767,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",90767,43.4130859375,1.8722133333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,90770,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",90770,31.583658854166668,1.7032266666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::native_layer_norm_backward,90773,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",90773,31.009440104166668,137.40684
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::native_layer_norm_backward,90773,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",90773,43.251953125,88.77071999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,90777,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",90777,43.136555989583336,77.60477333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,90784,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",90784,42.751790364583336,1.8683733333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,88621,,aten::add_,90787,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",90787,27.443033854166668,1.69216
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::fill_,90793,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",90793,3390.7062174479165,2.570240000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::copy_,90802,"[[], [], []]",Memcpy HtoD (Pageable -> Device),90802,4945.322591145833,0.757333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::native_layer_norm,90807,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",90807,2401.2628580729165,91.4590933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::native_layer_norm,90814,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",90814,35.6904296875,91.05502666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::addmm,90829,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,90829,1574.4837239583333,571.69408
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::copy_,90854,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),90854,107.31461588541667,2.8492400000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::copy_,90858,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),90858,1038.048828125,2.75072
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::neg,90868,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",90868,2588.7879231770835,7.5126533333333345
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::cat,90880,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",90880,1377.5266927083333,16.14754666666667
None,None,None,None,None,None,kernel_1,90881,794.701171875,6.996026666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::neg,90891,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",90891,1248.8439127604167,9.301226666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::cat,90902,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",90902,1137.2291666666667,16.13684
None,None,None,None,None,None,kernel_1,90903,696.5574544270834,6.911986666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::cat,90909,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",90909,1383.1769205729167,66.04919999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::cat,90910,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",90910,27.668619791666668,66.5334
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::baddbmm,90920,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,90920,1490.3352864583333,212.70221333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,ScaledUpperTriangMaskedSoftmax,90923,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",90923,39.294759114583336,335.3197066666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::bmm,90940,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,90940,84.83186848958333,184.39695999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::copy_,90948,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",90948,40.736490885416664,34.41929333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mm,90957,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,90957,144.97998046875,192.94097333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add,90962,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",90962,47.5830078125,131.01804
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mm,90974,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,90974,87.15576171875,792.3113199999999
None,None,None,None,None,None,kernel_2,90978,35.114420572916664,87.46373333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mm,90989,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,90989,96.39404296875,792.6663466666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add,90994,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",90994,35.519856770833336,128.7200266666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add,90996,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",90996,35.349934895833336,83.46339999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,record_param_comms,90999,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",90999,57.21533203125,3221.162906666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add,91004,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91004,48.544108072916664,85.52514666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::sum,91015,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",91015,96.052734375,47.074920000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91019,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91019,36.4267578125,1.8342
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mm,91029,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91029,101.41617838541667,724.5700266666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mm,91036,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91036,118.95345052083333,781.1311199999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91048,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91048,44.374186197916664,59.076133333333324
None,None,None,None,None,None,kernel_3,91052,38.986002604166664,95.46206666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::sum,91056,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",91056,105.24674479166667,46.55615999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91060,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91060,36.725911458333336,1.847466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mm,91070,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91070,105.97200520833333,711.4948666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mm,91077,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91077,115.88216145833333,770.0020933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91089,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91089,36.245442708333336,59.050080000000015
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,record_param_comms,91093,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",91093,65.23795572916667,3237.810933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::sum,91100,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",91100,94.68701171875,49.47581333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91104,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91104,39.34814453125,1.7868533333333323
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mm,91114,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91114,102.7001953125,207.2515866666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mm,91121,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91121,103.4208984375,188.28694666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91133,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91133,36.24462890625,14.26552
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::bmm,91152,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91152,102.51692708333333,174.64129333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::bmm,91155,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91155,107.37060546875,208.01533333333342
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,ScaledUpperTriangMaskedSoftmaxBackward,91173,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",91173,39.39208984375,555.400226666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::bmm,91190,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91190,107.82861328125,178.87505333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mul,91192,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",91192,40.362955729166664,16.879666666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::bmm,91195,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91195,104.4150390625,173.54528
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mul,91197,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",91197,36.373372395833336,16.868053333333343
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mul,91237,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",91237,34.070149739583336,11.71277333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mul,91241,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",91241,31.562337239583332,10.64137333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::neg,91244,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91244,34.859049479166664,5.331186666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::fill_,91251,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91251,33.759928385416664,3.176080000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::copy_,91254,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91254,34.590006510416664,12.785386666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91255,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",91255,28.694173177083332,23.40591999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::fill_,91262,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91262,26.85888671875,3.1197600000000025
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::copy_,91265,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91265,27.114095052083332,12.970986666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91266,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",91266,27.009114583333332,23.156666666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mul,91270,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",91270,29.077473958333332,11.978146666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mul,91274,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",91274,34.878743489583336,10.10808
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::neg,91277,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91277,33.67578125,5.477933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::fill_,91284,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91284,32.767415364583336,3.138973333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::copy_,91287,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91287,30.47265625,5.794106666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91288,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",91288,27.14599609375,10.350426666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::fill_,91295,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91295,27.134602864583332,3.1031466666666687
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::copy_,91298,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91298,27.221028645833332,5.908853333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91299,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",91299,29.779296875,10.243773333333339
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::fill_,91306,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91306,31.135579427083332,8.748293333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::copy_,91309,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91309,35.007649739583336,64.71750666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::fill_,91316,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91316,41.909830729166664,8.943306666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::copy_,91319,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91319,30.985514322916668,22.882813333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91320,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91320,27.0615234375,19.649999999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::fill_,91327,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91327,33.866373697916664,8.916866666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::copy_,91330,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91330,27.112955729166668,29.54167999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::fill_,91337,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91337,38.996744791666664,9.039719999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::copy_,91340,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91340,34.686360677083336,11.501520000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91341,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91341,34.197428385416664,19.716106666666658
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::cat,91344,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",91344,37.494140625,146.86604
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mm,91358,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91358,102.76139322916667,542.954
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::mm,91362,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91362,117.15087890625,542.61528
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::sum,91366,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",91366,107.40120442708333,36.69856
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91370,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91370,36.320475260416664,1.8325200000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91378,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91378,31.404134114583332,42.680400000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,record_param_comms,91386,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",91386,72.76497395833333,3241.1960799999993
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::native_layer_norm_backward,91391,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",91391,53.515787760416664,140.79118666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::native_layer_norm_backward,91391,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",91391,43.189127604166664,88.97162666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add,91395,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91395,43.573079427083336,78.94882666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91398,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91398,43.467122395833336,1.874346666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91401,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91401,30.750651041666668,1.6981333333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::native_layer_norm_backward,91404,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",91404,31.521809895833332,137.43670666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::native_layer_norm_backward,91404,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",91404,43.102213541666664,88.90506666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91408,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91408,43.5419921875,77.6676666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91415,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91415,42.473958333333336,1.855546666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,90788,,aten::add_,91418,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91418,27.178385416666668,1.66056
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::fill_,91424,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",91424,3353.8489583333335,2.5663733333333343
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::copy_,91433,"[[], [], []]",Memcpy HtoD (Pageable -> Device),91433,4943.715494791667,0.7577599999999993
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::native_layer_norm,91438,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",91438,2383.0017903645835,91.57336000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::native_layer_norm,91445,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",91445,35.221354166666664,91.25900000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::addmm,91460,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91460,1498.74072265625,571.6773466666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::copy_,91485,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),91485,105.25944010416667,3.2686533333333343
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::copy_,91489,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),91489,1045.6575520833333,2.7096533333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::neg,91499,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91499,2533.5686848958335,7.50504
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::cat,91511,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",91511,1388.65966796875,16.181533333333334
None,None,None,None,None,None,kernel_1,91512,791.7815755208334,6.952946666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::neg,91522,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91522,1278.2828776041667,9.27312
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::cat,91533,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",91533,1122.5255533854167,16.10402666666667
None,None,None,None,None,None,kernel_1,91534,707.8243815104166,6.908106666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::cat,91540,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",91540,1371.3154296875,66.13153333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::cat,91541,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",91541,27.721028645833332,66.58497333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::baddbmm,91551,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91551,1259.0636393229167,212.77946666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,ScaledUpperTriangMaskedSoftmax,91554,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",91554,39.061686197916664,335.32219999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::bmm,91571,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91571,202.62288411458334,184.25319999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::copy_,91579,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91579,39.8935546875,34.50981333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mm,91588,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91588,89.41910807291667,193.21098666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add,91593,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",91593,47.029296875,131.0448533333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mm,91605,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91605,88.67203776041667,792.9858533333335
None,None,None,None,None,None,kernel_2,91609,35.434244791666664,87.5035066666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mm,91620,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91620,97.86588541666667,793.4001733333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add,91625,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",91625,35.677897135416664,128.7720133333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add,91627,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91627,35.7744140625,83.50568000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,record_param_comms,91630,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",91630,57.29345703125,3218.3022133333343
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add,91635,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91635,49.68408203125,85.54001333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::sum,91646,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",91646,96.81982421875,46.965759999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,91650,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91650,36.34033203125,1.8282533333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mm,91660,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91660,103.40299479166667,725.4374266666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mm,91667,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91667,115.8818359375,781.448893333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,91679,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91679,44.534016927083336,59.14742666666666
None,None,None,None,None,None,kernel_3,91683,39.008463541666664,95.45778666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::sum,91687,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",91687,103.82861328125,46.34193333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,91691,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91691,36.212076822916664,1.7915599999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mm,91701,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91701,105.81363932291667,711.7961866666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mm,91708,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91708,115.48567708333333,770.211946666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,91720,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91720,36.224446614583336,59.14273333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,record_param_comms,91724,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",91724,65.64192708333333,3244.812506666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::sum,91731,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",91731,96.28662109375,49.527013333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,91735,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91735,39.5830078125,1.7663866666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mm,91745,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91745,101.68538411458333,207.60619999999992
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mm,91752,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91752,103.47509765625,188.42893333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,91764,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91764,36.30859375,14.213453333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::bmm,91783,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91783,104.12776692708333,174.67839999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::bmm,91786,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91786,111.3173828125,208.44934666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,ScaledUpperTriangMaskedSoftmaxBackward,91804,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",91804,40.309733072916664,555.3160933333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::bmm,91821,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91821,110.01529947916667,178.8243466666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mul,91823,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",91823,40.936848958333336,16.87365333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::bmm,91826,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,91826,103.9794921875,173.73176
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mul,91828,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",91828,35.95751953125,16.93936
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mul,91868,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",91868,34.33544921875,11.659426666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mul,91872,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",91872,30.954427083333332,10.648613333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::neg,91875,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91875,34.966145833333336,5.320039999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::fill_,91882,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91882,33.899088541666664,3.175640000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::copy_,91885,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91885,34.142578125,12.799026666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,91886,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",91886,28.971516927083332,23.34871999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::fill_,91893,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91893,27.16845703125,3.1026933333333364
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::copy_,91896,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91896,27.127115885416668,12.994906666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,91897,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",91897,26.986328125,23.18873333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mul,91901,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",91901,29.000651041666668,11.999933333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mul,91905,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",91905,34.93359375,10.108880000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::neg,91908,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91908,33.183919270833336,5.500133333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::fill_,91915,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91915,34.356608072916664,3.138973333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::copy_,91918,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91918,29.6513671875,5.796213333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,91919,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",91919,27.104329427083332,10.345719999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::fill_,91926,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91926,27.166178385416668,3.104400000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::copy_,91929,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91929,27.488444010416668,5.911866666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,91930,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",91930,29.182942708333332,10.22454666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::fill_,91937,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91937,30.517415364583332,8.747906666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::copy_,91940,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91940,34.751627604166664,64.70946666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::fill_,91947,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91947,42.472981770833336,8.95734666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::copy_,91950,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91950,30.750325520833332,22.941266666666657
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,91951,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91951,26.944498697916668,19.713546666666655
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::fill_,91958,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91958,33.62109375,8.931799999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::copy_,91961,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91961,27.14501953125,29.35061333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::fill_,91968,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",91968,38.143880208333336,9.061893333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::copy_,91971,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",91971,34.514811197916664,11.537400000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,91972,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",91972,34.698893229166664,19.712679999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::cat,91975,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",91975,37.31201171875,146.7413866666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mm,91989,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91989,101.72737630208333,543.31456
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::mm,91993,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,91993,114.974609375,543.70624
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::sum,91997,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",91997,106.32552083333333,36.696039999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,92001,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92001,36.191080729166664,1.8282666666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,92009,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92009,31.179524739583332,42.76777333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,record_param_comms,92017,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",92017,73.03304036458333,3233.4641466666653
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::native_layer_norm_backward,92022,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",92022,53.480305989583336,140.75274666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::native_layer_norm_backward,92022,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",92022,43.542154947916664,89.03478666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add,92026,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92026,43.048665364583336,78.86645333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,92029,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92029,43.510091145833336,1.87732
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,92032,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92032,31.636555989583332,1.693013333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::native_layer_norm_backward,92035,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",92035,30.656575520833332,137.50546666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::native_layer_norm_backward,92035,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",92035,43.881673177083336,88.70961333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,92039,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92039,43.39111328125,77.59259999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,92046,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92046,43.734049479166664,1.8508666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,91419,,aten::add_,92049,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92049,27.40234375,1.6695333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::fill_,92055,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",92055,3414.8937174479165,2.557853333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::copy_,92064,"[[], [], []]",Memcpy HtoD (Pageable -> Device),92064,4974.478352864583,0.7577599999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::native_layer_norm,92069,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",92069,2400.9205729166665,91.51237333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::native_layer_norm,92076,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",92076,39.903157552083336,91.18558666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::addmm,92091,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92091,1549.994140625,572.0775733333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::copy_,92116,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),92116,107.57210286458333,2.8761066666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::copy_,92120,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),92120,1039.1922200520833,2.7784400000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::neg,92130,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92130,2548.9690755208335,7.518706666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::cat,92142,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",92142,1411.04052734375,16.198680000000007
None,None,None,None,None,None,kernel_1,92143,809.8492838541666,6.980546666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::neg,92153,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92153,1265.2509765625,9.278640000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::cat,92164,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",92164,1137.5584309895833,16.14916000000001
None,None,None,None,None,None,kernel_1,92165,695.2392578125,6.923453333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::cat,92171,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",92171,1383.9010416666667,66.05860000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::cat,92172,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",92172,27.392415364583332,66.53252
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::baddbmm,92182,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,92182,1236.83349609375,213.04225333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,ScaledUpperTriangMaskedSoftmax,92185,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",92185,39.071451822916664,335.39049333333344
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::bmm,92202,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,92202,84.97086588541667,184.2704
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::copy_,92210,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92210,40.425618489583336,34.48376000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mm,92219,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,92219,83.87125651041667,193.24726666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add,92224,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",92224,47.188802083333336,131.0564266666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mm,92236,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92236,88.47835286458333,793.2840799999999
None,None,None,None,None,None,kernel_2,92240,35.55126953125,87.52607999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mm,92251,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92251,98.37744140625,793.9651466666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add,92256,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",92256,35.8291015625,128.7669333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add,92258,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92258,35.3486328125,83.47055999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,record_param_comms,92261,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",92261,56.106119791666664,3220.5260666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add,92266,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92266,48.8955078125,85.49597333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::sum,92277,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",92277,98.29264322916667,46.89323999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92281,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92281,36.490071614583336,1.8222933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mm,92291,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92291,102.142578125,726.91752
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mm,92298,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92298,116.72428385416667,781.7484266666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92310,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92310,43.999348958333336,59.08301333333332
None,None,None,None,None,None,kernel_3,92314,39.466471354166664,95.52612000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::sum,92318,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",92318,103.98795572916667,46.37810666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92322,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92322,35.923990885416664,1.8047866666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mm,92332,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92332,105.14176432291667,713.1900266666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mm,92339,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92339,113.79052734375,771.1511066666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92351,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92351,36.416178385416664,59.08977333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,record_param_comms,92355,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",92355,65.90836588541667,3239.692133333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::sum,92362,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",92362,93.8115234375,49.55510666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92366,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92366,39.5107421875,1.8094933333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mm,92376,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,92376,101.69466145833333,207.8831466666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mm,92383,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,92383,102.22705078125,188.55148
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92395,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92395,36.10693359375,14.262120000000008
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::bmm,92414,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,92414,102.9755859375,174.59169333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::bmm,92417,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,92417,106.53873697916667,208.58928000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,ScaledUpperTriangMaskedSoftmaxBackward,92435,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",92435,39.977864583333336,555.6387333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::bmm,92452,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,92452,106.53792317708333,178.81913333333324
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mul,92454,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",92454,39.912272135416664,16.881813333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::bmm,92457,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,92457,105.07958984375,173.6519999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mul,92459,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",92459,36.308268229166664,16.963666666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mul,92499,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",92499,34.273600260416664,11.694839999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mul,92503,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",92503,31.422688802083332,10.644719999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::neg,92506,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92506,35.1259765625,5.32472
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::fill_,92513,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",92513,33.813639322916664,3.1722533333333356
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::copy_,92516,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92516,34.205240885416664,12.80890666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92517,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",92517,28.918619791666668,23.40888
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::fill_,92524,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",92524,27.15673828125,3.106560000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::copy_,92527,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92527,27.307942708333332,13.057186666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92528,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",92528,26.72021484375,23.221999999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mul,92532,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",92532,28.660970052083332,11.968786666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mul,92536,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",92536,34.975423177083336,10.108026666666671
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::neg,92539,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92539,33.8779296875,5.475319999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::fill_,92546,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",92546,33.301106770833336,3.140666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::copy_,92549,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92549,30.20556640625,5.7957866666666655
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92550,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",92550,27.135579427083332,10.35388
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::fill_,92557,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",92557,27.305826822916668,3.099693333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::copy_,92560,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92560,27.25439453125,5.910159999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92561,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",92561,28.916015625,10.263813333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::fill_,92568,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",92568,31.134765625,8.759466666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::copy_,92571,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92571,35.16748046875,64.71744
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::fill_,92578,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",92578,42.497233072916664,8.966319999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::copy_,92581,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92581,30.579264322916668,22.921653333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92582,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92582,27.434407552083332,19.697826666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::fill_,92589,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",92589,33.6220703125,8.92621333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::copy_,92592,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92592,26.9755859375,29.47176
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::fill_,92599,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",92599,38.912923177083336,9.055893333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::copy_,92602,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92602,34.72802734375,11.50745333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92603,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92603,34.454264322916664,19.71186666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::cat,92606,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",92606,37.5888671875,146.8950266666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mm,92620,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92620,102.70979817708333,544.3837333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::mm,92624,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92624,116.53238932291667,545.3275866666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::sum,92628,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",92628,105.0029296875,36.63372
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92632,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92632,36.650065104166664,1.847466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92640,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92640,31.220865885416668,42.615880000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,record_param_comms,92648,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",92648,72.3828125,3235.7885199999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::native_layer_norm_backward,92653,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",92653,53.461751302083336,140.731
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::native_layer_norm_backward,92653,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",92653,44.362467447916664,88.9084933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add,92657,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92657,43.070963541666664,78.96000000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92660,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92660,42.88037109375,1.8581333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92663,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92663,31.01904296875,1.68404
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::native_layer_norm_backward,92666,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",92666,31.306477864583332,137.49817333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::native_layer_norm_backward,92666,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",92666,43.2001953125,88.83937333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92670,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92670,43.48828125,77.63985333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92677,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92677,43.199055989583336,1.8781600000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,92050,,aten::add_,92680,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92680,27.594889322916668,1.681026666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::fill_,92686,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",92686,3368.5183919270835,2.5655066666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::copy_,92695,"[[], [], []]",Memcpy HtoD (Pageable -> Device),92695,4992.2041015625,0.7475199999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::native_layer_norm,92700,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",92700,2360.9013671875,91.69282666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::native_layer_norm,92707,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",92707,40.714680989583336,91.36054666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::addmm,92722,"[[4608], [8192, 6144], [6144, 4608], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92722,1509.3531901041667,573.0656933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::copy_,92747,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),92747,116.77718098958333,2.789973333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::copy_,92751,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),92751,1062.29541015625,2.7664800000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::neg,92761,"[[2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92761,2508.99072265625,7.513120000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::cat,92773,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",92773,1370.51708984375,16.15309333333334
None,None,None,None,None,None,kernel_1,92774,773.2301432291666,7.005413333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::neg,92784,"[[2048, 4, 16, 24], [2048, 1, 1, 24], [2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92784,1278.34814453125,9.299053333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::cat,92795,"[[2048, 4, 16, 24], [[2048, 4, 16, 12], [2048, 4, 16, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",92795,1088.4571940104167,16.136840000000007
None,None,None,None,None,None,kernel_1,92796,697.1173502604166,6.936706666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::cat,92802,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",92802,1354.1735026041667,66.15844000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::cat,92803,"[[[2048, 4, 16, 24], [2048, 4, 16, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",92803,27.338541666666668,66.56105333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::baddbmm,92813,"[[64, 2048, 2048], [64, 2048, 96], [64, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,92813,1200.2369791666667,213.60454666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,ScaledUpperTriangMaskedSoftmax,92816,"[[64, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",92816,39.221354166666664,335.4673066666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::bmm,92833,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,92833,85.82259114583333,184.37149333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::copy_,92841,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",92841,40.288248697916664,34.51095999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mm,92850,"[[8192, 1536], [1536, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,92850,84.69156901041667,193.86642666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add,92855,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",92855,48.096842447916664,131.09180000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mm,92867,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92867,89.42805989583333,793.8050000000002
None,None,None,None,None,None,kernel_2,92871,35.221028645833336,87.50223999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mm,92882,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92882,97.39664713541667,794.6832400000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add,92887,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",92887,36.0,128.74897333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add,92889,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92889,35.391276041666664,83.47620000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,nccl:all_reduce,92893,"[[2048, 4, 6144]]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",92892,55.211263020833336,3221.062653333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add,92897,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92897,49.193684895833336,85.40682666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::sum,92908,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",92908,97.12890625,47.04731999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,92912,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92912,36.832194010416664,1.8461733333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mm,92922,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92922,104.28548177083333,728.4931733333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mm,92929,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92929,119.88199869791667,782.2468133333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,92941,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92941,44.425130208333336,59.14745333333334
None,None,None,None,None,None,kernel_3,92945,38.581217447916664,95.48853333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::sum,92949,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",92949,103.21158854166667,46.47851999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,92953,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92953,36.190592447916664,1.793706666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mm,92963,"[[6144, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92963,105.32259114583333,718.4371733333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mm,92970,"[[8192, 6144], [6144, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,92970,114.93196614583333,771.8771333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,92982,"[[6144, 6144], [6144, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92982,36.008626302083336,59.12565333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,record_param_comms,92986,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",92986,65.82503255208333,3242.175639999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::sum,92993,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",92993,94.76220703125,49.508386666666674
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,92997,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",92997,39.370279947916664,1.7740533333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mm,93007,"[[6144, 8192], [8192, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,93007,102.00455729166667,208.65058666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mm,93014,"[[8192, 6144], [6144, 1536]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,93014,105.34407552083333,188.53609333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,93026,"[[6144, 1536], [6144, 1536], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",93026,36.095052083333336,14.237253333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::bmm,93045,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,93045,104.22265625,174.49293333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::bmm,93048,"[[64, 2048, 96], [64, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,93048,108.41617838541667,209.34093333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,ScaledUpperTriangMaskedSoftmaxBackward,93066,"[[64, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",93066,40.488606770833336,555.1813866666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::bmm,93083,"[[64, 2048, 2048], [64, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,93083,108.76741536458333,178.92838666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mul,93085,"[[64, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",93085,40.894856770833336,16.939439999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::bmm,93088,"[[64, 96, 2048], [64, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,93088,104.15071614583333,173.6338266666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mul,93090,"[[64, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",93090,36.544108072916664,16.94409333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mul,93130,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",93130,34.667317708333336,11.693586666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mul,93134,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",93134,30.708658854166668,10.620493333333327
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::neg,93137,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",93137,34.785319010416664,5.308119999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::fill_,93144,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",93144,33.940266927083336,3.167120000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::copy_,93147,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",93147,34.024739583333336,12.811479999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,93148,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",93148,29.046061197916668,23.396439999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::fill_,93155,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",93155,26.933430989583332,3.1129466666666703
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::copy_,93158,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",93158,27.116048177083332,13.031560000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,93159,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",93159,26.965983072916668,23.198026666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mul,93163,"[[2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",93163,28.863444010416668,11.99266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mul,93167,"[[[2048, 4, 16, 12], [2048, 4, 16, 12]], [2048, 4, 16, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",93167,35.028645833333336,10.112799999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::neg,93170,"[[2048, 4, 16, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",93170,33.131022135416664,5.470653333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::fill_,93177,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",93177,33.87646484375,3.136826666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::copy_,93180,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",93180,29.7470703125,5.801786666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,93181,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",93181,27.157552083333332,10.360293333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::fill_,93188,"[[2048, 4, 16, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",93188,27.4228515625,3.1133600000000023
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::copy_,93191,"[[2048, 4, 16, 12], [2048, 4, 16, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",93191,27.275716145833332,5.940399999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,93192,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",93192,29.065104166666668,10.261693333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::fill_,93199,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",93199,30.162760416666668,8.74365333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::copy_,93202,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",93202,35.17919921875,64.7575733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::fill_,93209,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",93209,42.249837239583336,8.965933333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::copy_,93212,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",93212,31.050455729166668,22.99842666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,93213,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",93213,26.995768229166668,19.706760000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::fill_,93220,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",93220,34.025065104166664,8.939440000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::copy_,93223,"[[2048, 4, 16, 72], [2048, 4, 16, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",93223,26.997233072916668,29.487040000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::fill_,93230,"[[2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",93230,38.1865234375,9.041853333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::copy_,93233,"[[2048, 4, 16, 24], [2048, 4, 16, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",93233,34.888997395833336,11.513946666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,93234,"[[2048, 4, 16, 96], [2048, 4, 16, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",93234,34.314453125,19.831813333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::cat,93237,"[[[2048, 4, 16, 96], [2048, 4, 16, 96], [2048, 4, 16, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",93237,37.493977864583336,146.87489333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mm,93251,"[[8192, 4608], [4608, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,93251,103.23177083333333,549.6321333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::mm,93255,"[[4608, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,93255,117.416015625,552.3850133333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::sum,93259,"[[8192, 4608], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",93259,104.9375,36.64356
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,93263,"[[4608], [4608], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",93263,36.639811197916664,1.823573333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,93271,"[[4608, 6144], [4608, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",93271,30.826171875,42.66801333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,record_param_comms,93279,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",93279,72.21337890625,3237.970906666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::native_layer_norm_backward,93284,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",93284,53.429036458333336,140.79967999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::native_layer_norm_backward,93284,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",93284,43.058919270833336,88.97123999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add,93288,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",93288,43.679036458333336,79.00989333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,93291,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",93291,43.326985677083336,1.8820266666666676
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,93294,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",93294,31.444661458333332,1.6571600000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::native_layer_norm_backward,93297,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",93297,30.827799479166668,137.33904000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::native_layer_norm_backward,93297,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",93297,42.986653645833336,88.86453333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,93301,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",93301,42.965169270833336,77.7435333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,93308,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",93308,42.602701822916664,1.8794533333333339
autograd::engine::evaluate_function: CheckpointFunctionBackward,92681,,aten::add_,93311,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",93311,27.198567708333332,1.6955733333333332
autograd::engine::evaluate_function: torch::autograd::CopySlices,93320,,aten::copy_,93324,"[[4, 2048, 6144], [4, 2048, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",93324,4804.86767578125,132.71400000000008
autograd::engine::evaluate_function: torch::autograd::CopySlices,93320,,aten::copy_,93329,"[[4, 2048, 6144], [4, 2048, 6144], []]",Memcpy DtoD (Device -> Device),93329,35.082356770833336,71.06464
autograd::engine::evaluate_function: torch::autograd::CopySlices,93320,,aten::copy_,93337,"[[4, 2048, 6144], [4, 2048, 6144], []]",Memcpy DtoD (Device -> Device),93337,35.144856770833336,71.48358666666667
autograd::engine::evaluate_function: torch::autograd::CopySlices,93320,,aten::masked_fill_,93344,"[[4, 2048, 6144], [4, 2048, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",93344,36.566731770833336,140.67805333333328
autograd::engine::evaluate_function: torch::autograd::CopySlices,93320,,aten::copy_,93347,"[[4, 2048, 6144], [4, 2048, 6144], []]",Memcpy DtoD (Device -> Device),93347,36.77880859375,72.31045333333333
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::arange,93359,"[[], [], [], [0]]","void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)",93359,41.140950520833336,1.423346666666667
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortHistogramKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, unsigned long long, at_cuda_detail::cub::detail::identity_decomposer_t>(unsigned long long*, long const*, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",93351,151.5927734375,3.666333333333336
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(unsigned long long*)",93351,31.251953125,1.5735333333333332
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",93351,90.48486328125,8.671920000000002
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",93351,101.39469401041667,8.121066666666668
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",93351,93.33251953125,7.9333866666666655
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",93351,91.03971354166667,7.902239999999998
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",93351,90.57177734375,7.759719999999998
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",93351,89.92008463541667,7.734506666666667
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",93351,90.11067708333333,7.759679999999997
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",93351,93.19368489583333,7.735413333333333
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::fill_,93364,"[[12672, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",93364,27.6162109375,47.285826666666686
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, true>, long*>(at_cuda_detail::cub::ScanTileState<int, true>, int, long*)",93351,42.80419921875,1.6763599999999999
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceUniqueByKeySweepKernel<at_cuda_detail::cub::DeviceUniqueByKeyPolicy<long const*, thrust::THRUST_200302_500_800_860_890_900_NS::counting_iterator<int, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default> >::Policy900, long const*, thrust::THRUST_200302_500_800_860_890_900_NS::counting_iterator<int, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, cuda::std::__4::equal_to<void>, int>(long const*, thrust::THRUST_200302_500_800_860_890_900_NS::counting_iterator<int, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, cuda::std::__4::equal_to<void>, int, int)",93351,31.444661458333332,4.889999999999998
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::krn_partials_per_segment<long>(long*, long const*, long const*, long)",93351,31.690592447916668,1.908880000000001
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceScanInitKernel<at_cuda_detail::cub::ScanTileState<long, true> >(at_cuda_detail::cub::ScanTileState<long, true>, int)",93351,27.935384114583332,1.3299199999999993
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceScanKernel<at_cuda_detail::cub::DeviceScanPolicy<long, at::cuda::cub::(anonymous namespace)::SumOp<long> >::Policy900, long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int, long>(long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, int, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int)",93351,27.541829427083332,3.094600000000001
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::compute_num_of_partial_segments<long>(long const*, long const*, long const*, long*)",93351,27.913411458333332,1.4587733333333326
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::krn_partial_segment_offset<long>(long*, long const*, long const*, long const*, long const*)",93351,27.806315104166668,2.7340666666666675
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::compute_grad_weight<c10::Half, long>(long const*, c10::Half const*, long const*, long, long, long const*, long const*, at::AccumulateType<c10::Half, true>::type*, long)",93351,27.200846354166668,231.6128
autograd::engine::evaluate_function: EmbeddingBackward0,93348,,aten::embedding_dense_backward,93351,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::sum_and_scatter<c10::Half, long>(long const*, c10::Half*, long, long const*, long const*, at::AccumulateType<c10::Half, true>::type const*, long const*, long const*, long, long)",93351,42.25048828125,168.7439733333333
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,93372,,aten::add_,93374,"[[12672, 6144], [12672, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",93374,39.560872395833336,124.3450266666667
