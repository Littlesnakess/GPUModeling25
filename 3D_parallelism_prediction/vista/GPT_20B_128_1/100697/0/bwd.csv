cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::fill_,352553,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",352553,0,2.780586666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::copy_,352562,"[[], [], []]",Memcpy HtoD (Pageable -> Device),352562,5101.650390625,0.748373333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::native_layer_norm,352567,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",352567,2548.1962890625,91.26625333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::native_layer_norm,352574,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",352574,49.279296875,91.4313333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::addmm,352589,"[[2304], [8192, 6144], [6144, 2304], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,352589,2047.0320638020833,293.93941333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::copy_,352614,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),352614,139.81722005208334,3.001573333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::copy_,352618,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),352618,1092.3746744791667,2.73064
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::neg,352628,"[[2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",352628,2699.4876302083335,5.609306666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::cat,352640,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",352640,1549.03076171875,10.138000000000007
None,None,None,None,None,None,kernel_1,352641,983.76904296875,4.696746666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::neg,352651,"[[2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",352651,1336.2957356770833,5.036359999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::cat,352662,"[[2048, 4, 8, 24], [[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",352662,1308.90771484375,10.05428
None,None,None,None,None,None,kernel_1,352663,879.1380208333334,4.537973333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::cat,352669,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",352669,1455.1461588541667,35.11778666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::cat,352670,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",352670,68.75520833333333,34.91597333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::baddbmm,352680,"[[32, 2048, 2048], [32, 2048, 96], [32, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,352680,2914.3440755208335,108.49661333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,ScaledUpperTriangMaskedSoftmax,352683,"[[32, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",352683,1026.4876302083333,171.10988
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::bmm,352700,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,352700,1382.3131510416667,99.70985333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::copy_,352708,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",352708,91.76448567708333,18.11018666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mm,352717,"[[8192, 768], [768, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,352717,2513.01318359375,101.91149333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add,352722,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",352722,47.85009765625,132.73024
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mm,352734,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,352734,306.7062174479167,384.76053333333317
None,None,None,None,None,None,kernel_2,352738,43.616048177083336,46.450813333333315
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mm,352749,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,352749,88.24430338541667,394.5636133333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add,352754,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",352754,39.381022135416664,129.25970666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add,352756,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",352756,38.785319010416664,83.61142666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,record_param_comms,352759,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",352759,54.293131510416664,3647.2727200000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add,352764,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",352764,49.920572916666664,85.38598666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::sum,355335,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",355335,96.57438151041667,46.85110666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355339,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355339,41.023111979166664,1.8572666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mm,355349,"[[6144, 8192], [8192, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355349,98.64534505208333,372.45641333333344
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mm,355356,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355356,115.23177083333333,371.8881599999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355368,"[[6144, 3072], [6144, 3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355368,40.809407552083336,28.616706666666676
None,None,None,None,None,None,kernel_3,355372,42.901041666666664,49.70029333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::sum,355376,"[[2048, 4, 3072], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",355376,108.71468098958333,31.40325333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355380,"[[3072], [3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355380,39.1240234375,1.7744933333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mm,355390,"[[3072, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355390,110.99527994791667,397.87236
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mm,355397,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355397,112.81005859375,361.75185333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355409,"[[3072, 6144], [3072, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355409,41.793619791666664,29.497346666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,record_param_comms,355413,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",355413,63.518717447916664,3739.4101333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::sum,355420,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",355420,96.67154947916667,49.47628000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355424,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355424,44.703450520833336,1.7710666666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mm,355434,"[[6144, 8192], [8192, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355434,106.85904947916667,125.60449333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mm,355441,"[[8192, 6144], [6144, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_on_kernel__5x_cublas,355441,110.71891276041667,108.29094666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355453,"[[6144, 768], [6144, 768], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355453,40.18115234375,8.183839999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::bmm,355472,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355472,106.1640625,91.91692
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::bmm,355475,"[[32, 2048, 96], [32, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355475,111.30436197916667,107.35784
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,ScaledUpperTriangMaskedSoftmaxBackward,355493,"[[32, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",355493,44.545247395833336,280.68205333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::bmm,355510,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355510,112.435546875,96.50524
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mul,355512,"[[32, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",355512,44.768717447916664,9.431813333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::bmm,355515,"[[32, 96, 2048], [32, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355515,110.525390625,90.70647999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mul,355517,"[[32, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",355517,40.2861328125,9.439026666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mul,355557,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",355557,30.985514322916668,7.361626666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mul,355561,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",355561,34.902018229166664,7.06044
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::neg,355564,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",355564,38.8251953125,3.67912
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::fill_,355571,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",355571,35.753580729166664,2.1926
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::copy_,355574,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",355574,37.3134765625,7.400906666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355575,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",355575,30.657063802083332,14.025239999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::fill_,355582,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",355582,30.462890625,2.150373333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::copy_,355585,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",355585,30.593912760416668,7.7029999999999985
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355586,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",355586,30.185709635416668,13.773520000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mul,355590,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",355590,30.846842447916668,7.47816
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mul,355594,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",355594,38.92333984375,6.245906666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::neg,355597,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",355597,36.435872395833336,3.565653333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::fill_,355604,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",355604,38.796712239583336,2.08084
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::copy_,355607,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",355607,34.102376302083336,3.912093333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355608,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",355608,30.796549479166668,6.509573333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::fill_,355615,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",355615,30.891927083333332,2.0479466666666677
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::copy_,355618,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",355618,30.1552734375,3.893746666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355619,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",355619,33.152669270833336,6.367066666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::fill_,355626,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",355626,32.341145833333336,4.957399999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::copy_,355629,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",355629,39.229166666666664,35.24701333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::fill_,355636,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",355636,38.912760416666664,4.9796
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::copy_,355639,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",355639,34.303059895833336,12.58652
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355640,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355640,30.409830729166668,9.01161333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::fill_,355647,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",355647,30.366048177083332,5.01028
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::copy_,355650,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",355650,31.145345052083332,14.919586666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::fill_,355657,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",355657,34.773600260416664,5.0316533333333355
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::copy_,355660,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",355660,38.72900390625,6.66488
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355661,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355661,37.737467447916664,9.045666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::cat,355664,"[[[2048, 4, 8, 96], [2048, 4, 8, 96], [2048, 4, 8, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",355664,33.247233072916664,75.98145333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mm,355678,"[[8192, 2304], [2304, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355678,106.49381510416667,274.7766266666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::mm,355682,"[[2304, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,355682,185.85465494791666,288.17208
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::sum,355686,"[[8192, 2304], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",355686,109.6953125,25.62628
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355690,"[[2304], [2304], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355690,31.082845052083332,1.6277066666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355698,"[[2304, 6144], [2304, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355698,34.8681640625,20.62536000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,record_param_comms,355706,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",355706,67.01676432291667,3671.957746666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::native_layer_norm_backward,355711,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",355711,54.42041015625,140.69425333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::native_layer_norm_backward,355711,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",355711,47.796549479166664,89.06006666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add,355715,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355715,47.09326171875,78.99921333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355718,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355718,47.57177734375,1.8465866666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355721,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355721,35.584309895833336,1.6929733333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::native_layer_norm_backward,355724,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",355724,34.6884765625,137.59164
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::native_layer_norm_backward,355724,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",355724,47.34912109375,88.73397333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355728,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355728,47.53076171875,77.61937333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355735,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355735,47.926432291666664,1.8572666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,352548,,aten::add_,355738,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355738,31.081705729166668,1.6750933333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::fill_,355744,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",355744,3447.56640625,2.572773333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::copy_,355753,"[[], [], []]",Memcpy HtoD (Pageable -> Device),355753,5085.205078125,0.7462266666666661
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::native_layer_norm,355758,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",355758,2482.3844401041665,91.62969333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::native_layer_norm,355765,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",355765,34.741048177083336,91.24194666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::addmm,355780,"[[2304], [8192, 6144], [6144, 2304], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355780,1813.9679361979167,292.33259999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::copy_,355805,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),355805,117.45930989583333,2.741720000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::copy_,355809,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),355809,1084.6526692708333,2.650413333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::neg,355819,"[[2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",355819,2590.8396809895835,5.589293333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::cat,355831,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",355831,1499.3564453125,10.15717333333334
None,None,None,None,None,None,kernel_1,355832,943.2884114583334,4.6856399999999985
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::neg,355842,"[[2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",355842,1333.9724934895833,5.0653466666666676
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::cat,355853,"[[2048, 4, 8, 24], [[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",355853,1270.3587239583333,10.059000000000005
None,None,None,None,None,None,kernel_1,355854,859.2467447916666,4.533280000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::cat,355860,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",355860,1422.7097981770833,35.11983999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::cat,355861,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",355861,49.653483072916664,34.91004
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::baddbmm,355871,"[[32, 2048, 2048], [32, 2048, 96], [32, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355871,2843.3038736979165,108.17445333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,ScaledUpperTriangMaskedSoftmax,355874,"[[32, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",355874,947.3518880208334,170.87782666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::bmm,355891,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355891,1303.0501302083333,99.71411999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::copy_,355899,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",355899,74.04817708333333,18.14982666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mm,355908,"[[8192, 768], [768, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355908,2413.5481770833335,101.99249333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add,355913,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",355913,43.946940104166664,132.95462666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mm,355925,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,355925,233.0224609375,384.1474533333333
None,None,None,None,None,None,kernel_2,355929,43.2197265625,46.40265333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mm,355940,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355940,88.26627604166667,395.24322666666677
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add,355945,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",355945,39.4453125,129.2072
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add,355947,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355947,39.147135416666664,83.52658666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,record_param_comms,355950,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",355950,54.71044921875,3664.8742666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add,355955,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355955,49.930826822916664,85.26174666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::sum,355966,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",355966,95.47509765625,46.45129333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,355970,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355970,39.722005208333336,1.85684
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mm,355980,"[[6144, 8192], [8192, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355980,98.2265625,372.4048400000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mm,355987,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,355987,113.88981119791667,371.7546
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,355999,"[[6144, 3072], [6144, 3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",355999,39.978515625,28.476760000000006
None,None,None,None,None,None,kernel_3,356003,42.260904947916664,49.61369333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::sum,356007,"[[2048, 4, 3072], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",356007,102.4091796875,31.448066666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356011,"[[3072], [3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356011,36.630208333333336,1.6989599999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mm,356021,"[[3072, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356021,110.59065755208333,397.71749333333327
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mm,356028,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356028,110.08984375,361.6529200000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356040,"[[3072, 6144], [3072, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356040,41.24658203125,29.60489333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,record_param_comms,356044,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",356044,64.32991536458333,3731.6021600000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::sum,356051,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",356051,96.97005208333333,49.08035999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356055,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356055,43.5625,1.8111733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mm,356065,"[[6144, 8192], [8192, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356065,107.22281901041667,125.61648000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mm,356072,"[[8192, 6144], [6144, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_on_kernel__5x_cublas,356072,110.08805338541667,108.3638933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356084,"[[6144, 768], [6144, 768], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356084,39.520345052083336,8.18856
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::bmm,356103,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356103,108.47737630208333,92.01502666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::bmm,356106,"[[32, 2048, 96], [32, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356106,114.11051432291667,107.40949333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,ScaledUpperTriangMaskedSoftmaxBackward,356124,"[[32, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",356124,43.56201171875,280.71317333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::bmm,356141,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356141,110.63346354166667,96.4774666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mul,356143,"[[32, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",356143,44.052897135416664,9.443346666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::bmm,356146,"[[32, 96, 2048], [32, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356146,106.07796223958333,90.94712000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mul,356148,"[[32, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",356148,39.82666015625,9.39342666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mul,356188,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",356188,31.22998046875,7.320240000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mul,356192,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",356192,34.97705078125,7.014346666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::neg,356195,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356195,38.804850260416664,3.687226666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::fill_,356202,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356202,34.986002604166664,2.2126800000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::copy_,356205,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356205,36.287760416666664,7.398373333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356206,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",356206,30.454264322916668,13.941213333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::fill_,356213,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356213,30.239095052083332,2.1431333333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::copy_,356216,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356216,30.743001302083332,7.704213333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356217,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",356217,30.741048177083332,13.74024
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mul,356221,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",356221,30.772623697916668,7.487120000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mul,356225,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",356225,38.83642578125,6.265133333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::neg,356228,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356228,36.234049479166664,3.572893333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::fill_,356235,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356235,38.988118489583336,2.0812666666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::copy_,356238,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356238,33.64404296875,3.924053333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356239,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",356239,30.891438802083332,6.512986666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::fill_,356246,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356246,30.94384765625,2.048853333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::copy_,356249,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356249,30.26171875,3.889426666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356250,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",356250,33.08935546875,6.376066666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::fill_,356257,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356257,32.178548177083336,4.953573333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::copy_,356260,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356260,39.17626953125,35.22237333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::fill_,356267,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356267,38.7080078125,4.967640000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::copy_,356270,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356270,35.11181640625,12.581
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356271,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356271,30.248860677083332,9.033746666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::fill_,356278,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356278,30.697916666666668,4.99964
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::copy_,356281,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356281,31.304524739583332,14.839826666666676
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::fill_,356288,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356288,35.103190104166664,5.027333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::copy_,356291,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356291,38.185872395833336,6.732746666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356292,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356292,37.161458333333336,9.04057333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::cat,356295,"[[[2048, 4, 8, 96], [2048, 4, 8, 96], [2048, 4, 8, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",356295,32.597493489583336,75.92812
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mm,356309,"[[8192, 2304], [2304, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356309,103.87044270833333,276.18246666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::mm,356313,"[[2304, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,356313,175.49690755208334,288.22292
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::sum,356317,"[[8192, 2304], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",356317,105.83284505208333,25.55538666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356321,"[[2304], [2304], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356321,31.870768229166668,1.6132266666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356329,"[[2304, 6144], [2304, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356329,35.766276041666664,20.710253333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,record_param_comms,356337,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",356337,66.5703125,3691.4839200000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::native_layer_norm_backward,356342,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",356342,54.601725260416664,140.7066933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::native_layer_norm_backward,356342,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",356342,48.693196614583336,88.94307999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add,356346,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356346,48.041829427083336,78.88572
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356349,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356349,47.829264322916664,1.8649466666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356352,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356352,35.49853515625,1.7216
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::native_layer_norm_backward,356355,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",356355,35.754557291666664,137.5800533333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::native_layer_norm_backward,356355,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",356355,48.085123697916664,88.59446666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356359,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356359,47.700032552083336,77.59338666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356366,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356366,48.180338541666664,1.86324
autograd::engine::evaluate_function: CheckpointFunctionBackward,355739,,aten::add_,356369,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356369,31.28515625,1.6819066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::fill_,356375,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",356375,3432.6648763020835,2.5557066666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::copy_,356384,"[[], [], []]",Memcpy HtoD (Pageable -> Device),356384,5145.50537109375,0.7372666666666661
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::native_layer_norm,356389,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",356389,2434.5548502604165,91.55509333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::native_layer_norm,356396,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",356396,47.3173828125,91.2546533333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::addmm,356411,"[[2304], [8192, 6144], [6144, 2304], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356411,1661.5869140625,292.3661599999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::copy_,356436,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),356436,135.29410807291666,2.8177066666666684
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::copy_,356440,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),356440,1084.833984375,2.912000000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::neg,356450,"[[2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356450,2562.80517578125,5.651560000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::cat,356462,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",356462,1474.20654296875,10.141746666666666
None,None,None,None,None,None,kernel_1,356463,949.0511067708334,4.708613333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::neg,356473,"[[2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356473,1333.3225911458333,5.050413333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::cat,356484,"[[2048, 4, 8, 24], [[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",356484,1241.1943359375,10.051346666666667
None,None,None,None,None,None,kernel_1,356485,848.5157877604166,4.521346666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::cat,356491,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",356491,1441.43701171875,35.02987999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::cat,356492,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",356492,60.756184895833336,34.833226666666654
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::baddbmm,356502,"[[32, 2048, 2048], [32, 2048, 96], [32, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356502,2803.7635091145835,108.1040133333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,ScaledUpperTriangMaskedSoftmax,356505,"[[32, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",356505,949.9466145833334,170.96092000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::bmm,356522,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356522,1233.9518229166667,99.69830666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::copy_,356530,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356530,69.11751302083333,18.128133333333327
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mm,356539,"[[8192, 768], [768, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356539,2396.2998046875,102.0847733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add,356544,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",356544,42.783528645833336,132.87308000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mm,356556,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,356556,226.7607421875,383.9973066666668
None,None,None,None,None,None,kernel_2,356560,43.294759114583336,46.36212
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mm,356571,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356571,87.77490234375,394.9257466666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add,356576,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",356576,39.541341145833336,129.17098666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add,356578,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356578,39.968587239583336,83.49505333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,record_param_comms,356581,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",356581,57.525227864583336,3660.8430800000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add,356586,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356586,50.026529947916664,85.44910666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::sum,356597,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",356597,95.71028645833333,46.79513333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356601,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356601,40.296549479166664,1.829546666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mm,356611,"[[6144, 8192], [8192, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356611,98.83626302083333,372.20642666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mm,356618,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356618,115.07145182291667,371.5800666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356630,"[[6144, 3072], [6144, 3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356630,41.397786458333336,28.53996000000001
None,None,None,None,None,None,kernel_3,356634,42.654296875,49.63545333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::sum,356638,"[[2048, 4, 3072], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",356638,107.29557291666667,31.459546666666657
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356642,"[[3072], [3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356642,38.463216145833336,1.7872933333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mm,356652,"[[3072, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356652,110.28287760416667,397.5869466666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mm,356659,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356659,110.15445963541667,361.7211733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356671,"[[3072, 6144], [3072, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356671,41.918782552083336,29.53453333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,record_param_comms,356675,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",356675,64.70247395833333,3719.8297199999993
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::sum,356682,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",356682,97.05517578125,49.39986666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356686,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356686,43.967936197916664,1.81888
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mm,356696,"[[6144, 8192], [8192, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356696,105.51481119791667,125.43298666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mm,356703,"[[8192, 6144], [6144, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_on_kernel__5x_cublas,356703,108.43587239583333,108.1825866666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356715,"[[6144, 768], [6144, 768], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356715,39.914876302083336,8.203013333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::bmm,356734,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356734,106.05598958333333,91.97407999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::bmm,356737,"[[32, 2048, 96], [32, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356737,110.75065104166667,107.45042666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,ScaledUpperTriangMaskedSoftmaxBackward,356755,"[[32, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",356755,43.967610677083336,281.0566533333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::bmm,356772,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356772,110.57161458333333,96.50181333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mul,356774,"[[32, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",356774,44.019856770833336,9.416506666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::bmm,356777,"[[32, 96, 2048], [32, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356777,107.13346354166667,90.85321333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mul,356779,"[[32, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",356779,39.893391927083336,9.391680000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mul,356819,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",356819,30.665201822916668,7.34592
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mul,356823,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",356823,34.633138020833336,7.079613333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::neg,356826,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356826,38.3681640625,3.673946666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::fill_,356833,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356833,34.953776041666664,2.1981599999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::copy_,356836,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356836,36.1728515625,7.395826666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356837,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",356837,30.77392578125,13.933133333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::fill_,356844,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356844,30.804850260416668,2.141853333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::copy_,356847,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356847,31.083984375,7.698266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356848,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",356848,30.60205078125,13.761613333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mul,356852,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",356852,30.3994140625,7.449560000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mul,356856,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",356856,38.891927083333336,6.256586666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::neg,356859,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356859,36.415364583333336,3.5707066666666676
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::fill_,356866,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356866,39.6484375,2.0795466666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::copy_,356869,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356869,34.29443359375,3.9167866666666655
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356870,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",356870,31.009114583333332,6.49336
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::fill_,356877,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356877,30.98583984375,2.0496800000000013
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::copy_,356880,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356880,30.155436197916668,3.8835066666666678
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356881,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",356881,33.099609375,6.375666666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::fill_,356888,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356888,31.65673828125,4.954813333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::copy_,356891,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356891,39.090983072916664,35.24453333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::fill_,356898,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356898,38.837565104166664,4.975319999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::copy_,356901,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356901,35.763346354166664,12.576746666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356902,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356902,30.741373697916668,9.011986666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::fill_,356909,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356909,31.059895833333332,5.006026666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::copy_,356912,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356912,31.145670572916668,14.877253333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::fill_,356919,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",356919,34.271321614583336,5.032053333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::copy_,356922,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",356922,37.170572916666664,6.6998799999999985
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356923,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356923,37.461751302083336,9.056840000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::cat,356926,"[[[2048, 4, 8, 96], [2048, 4, 8, 96], [2048, 4, 8, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",356926,33.8017578125,75.91235999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mm,356940,"[[8192, 2304], [2304, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,356940,105.88704427083333,274.9109333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::mm,356944,"[[2304, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,356944,183.80794270833334,288.07274666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::sum,356948,"[[8192, 2304], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",356948,113.82275390625,25.56862666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356952,"[[2304], [2304], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356952,31.7548828125,1.625146666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356960,"[[2304, 6144], [2304, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356960,35.050130208333336,20.728933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,record_param_comms,356968,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",356968,65.53499348958333,3689.5294533333313
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::native_layer_norm_backward,356973,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",356973,54.325520833333336,140.73655999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::native_layer_norm_backward,356973,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",356973,47.893229166666664,88.84148000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add,356977,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356977,47.412760416666664,78.85754666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356980,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356980,47.1806640625,1.9092800000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356983,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356983,35.582356770833336,1.7049466666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::native_layer_norm_backward,356986,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",356986,35.340006510416664,137.5468266666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::native_layer_norm_backward,356986,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",356986,47.76513671875,88.63329333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356990,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356990,46.463216145833336,77.5797866666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,356997,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",356997,46.806477864583336,1.8500133333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,356370,,aten::add_,357000,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357000,31.081868489583332,1.6673999999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::fill_,357006,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",357006,3413.5511067708335,2.557
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::copy_,357015,"[[], [], []]",Memcpy HtoD (Pageable -> Device),357015,5063.775716145833,0.7487999999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::native_layer_norm,357020,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",357020,2444.3463541666665,91.56956000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::native_layer_norm,357027,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",357027,44.010416666666664,91.29442666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::addmm,357042,"[[2304], [8192, 6144], [6144, 2304], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357042,1639.2833658854167,292.2702266666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::copy_,357067,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),357067,129.57747395833334,3.032746666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::copy_,357071,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),357071,1082.1319986979167,2.7869866666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::neg,357081,"[[2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357081,2594.4952799479165,5.609306666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::cat,357093,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",357093,1480.3829752604167,10.128560000000002
None,None,None,None,None,None,kernel_1,357094,954.4130859375,4.695013333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::neg,357104,"[[2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357104,1355.0403645833333,5.059359999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::cat,357115,"[[2048, 4, 8, 24], [[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",357115,1218.65625,10.0428
None,None,None,None,None,None,kernel_1,357116,845.9571940104166,4.518733333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::cat,357122,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",357122,1419.7503255208333,35.01453333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::cat,357123,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",357123,64.26790364583333,34.88566666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::baddbmm,357133,"[[32, 2048, 2048], [32, 2048, 96], [32, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357133,2802.4099934895835,108.01274666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,ScaledUpperTriangMaskedSoftmax,357136,"[[32, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",357136,895.02197265625,170.96861333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::bmm,357153,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357153,1244.0857747395833,99.83621333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::copy_,357161,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357161,55.424153645833336,18.19674666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mm,357170,"[[8192, 768], [768, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357170,2412.0105794270835,101.85302666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add,357175,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",357175,40.38330078125,132.8804266666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mm,357187,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,357187,222.986328125,383.82830666666683
None,None,None,None,None,None,kernel_2,357191,43.2734375,46.36457333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mm,357202,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357202,88.24430338541667,394.57552000000015
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add,357207,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",357207,39.220703125,129.07842666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add,357209,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357209,39.413248697916664,83.46507999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,record_param_comms,357212,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",357212,56.383138020833336,3654.278106666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add,357217,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357217,49.814453125,85.25752000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::sum,357228,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",357228,95.64713541666667,46.97476
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357232,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357232,39.925130208333336,1.832106666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mm,357242,"[[6144, 8192], [8192, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357242,99.72086588541667,371.92697333333354
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mm,357249,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357249,116.8310546875,371.58515999999986
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357261,"[[6144, 3072], [6144, 3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357261,40.448893229166664,28.559960000000004
None,None,None,None,None,None,kernel_3,357265,42.7197265625,49.571813333333345
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::sum,357269,"[[2048, 4, 3072], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",357269,102.58072916666667,31.522333333333343
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357273,"[[3072], [3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357273,35.7978515625,1.7442
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mm,357283,"[[3072, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357283,108.041015625,397.5254533333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mm,357290,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357290,108.4580078125,361.6669733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357302,"[[3072, 6144], [3072, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357302,42.932779947916664,29.507199999999987
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,record_param_comms,357306,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",357306,63.113932291666664,3719.0822400000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::sum,357313,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",357313,98.4951171875,49.59917333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357317,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357317,44.063151041666664,1.8376533333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mm,357327,"[[6144, 8192], [8192, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357327,107.06070963541667,125.55673333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mm,357334,"[[8192, 6144], [6144, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_on_kernel__5x_cublas,357334,111.486328125,108.29905333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357346,"[[6144, 768], [6144, 768], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357346,39.775716145833336,8.178306666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::bmm,357365,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357365,113.04166666666667,91.95442666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::bmm,357368,"[[32, 2048, 96], [32, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357368,118.16634114583333,107.07710666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,ScaledUpperTriangMaskedSoftmaxBackward,357386,"[[32, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",357386,43.785319010416664,280.7542
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::bmm,357403,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357403,123.48616536458333,96.55214666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mul,357405,"[[32, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",357405,44.5546875,9.420746666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::bmm,357408,"[[32, 96, 2048], [32, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357408,115.72998046875,90.83014666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mul,357410,"[[32, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",357410,39.914225260416664,9.410906666666671
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mul,357450,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",357450,31.04833984375,7.311760000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mul,357454,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",357454,35.189290364583336,7.063013333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::neg,357457,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357457,38.154947916666664,3.684600000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::fill_,357464,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",357464,36.1044921875,2.203733333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::copy_,357467,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357467,36.812174479166664,7.413213333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357468,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",357468,31.009440104166668,14.028239999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::fill_,357475,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",357475,30.25,2.146533333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::copy_,357478,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357478,30.634928385416668,7.708519999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357479,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",357479,30.33544921875,13.751813333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mul,357483,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",357483,30.880045572916668,7.464906666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mul,357487,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",357487,39.018717447916664,6.260853333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::neg,357490,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357490,35.956217447916664,3.570746666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::fill_,357497,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",357497,39.531901041666664,2.0829866666666677
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::copy_,357500,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357500,33.836751302083336,3.9210266666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357501,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",357501,30.965169270833332,6.502359999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::fill_,357508,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",357508,30.496907552083332,2.047120000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::copy_,357511,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357511,30.379720052083332,3.8864800000000015
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357512,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",357512,33.0986328125,6.362413333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::fill_,357519,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",357519,32.126790364583336,4.957853333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::copy_,357522,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357522,39.410319010416664,35.22949333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::fill_,357529,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",357529,38.910807291666664,4.97149333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::copy_,357532,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357532,34.2490234375,12.572519999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357533,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357533,30.237955729166668,9.009453333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::fill_,357540,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",357540,30.58935546875,5.007746666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::copy_,357543,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357543,30.953776041666668,14.890119999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::fill_,357550,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",357550,34.835286458333336,5.027800000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::copy_,357553,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357553,38.132161458333336,6.672999999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357554,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357554,36.820149739583336,9.038466666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::cat,357557,"[[[2048, 4, 8, 96], [2048, 4, 8, 96], [2048, 4, 8, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",357557,32.693033854166664,75.90121333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mm,357571,"[[8192, 2304], [2304, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357571,106.75162760416667,275.79294666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::mm,357575,"[[2304, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,357575,182.66389973958334,288.53477333333353
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::sum,357579,"[[8192, 2304], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",357579,111.20914713541667,25.637359999999987
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357583,"[[2304], [2304], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357583,31.45703125,1.6571599999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357591,"[[2304, 6144], [2304, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357591,35.680013020833336,20.710226666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,record_param_comms,357599,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",357599,67.36979166666667,3672.167680000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::native_layer_norm_backward,357604,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",357604,54.847005208333336,140.72536000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::native_layer_norm_backward,357604,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",357604,47.605631510416664,88.91495999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add,357608,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357608,47.947265625,78.98429333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357611,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357611,48.127766927083336,1.8581333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357614,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357614,34.878092447916664,1.68276
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::native_layer_norm_backward,357617,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",357617,35.201009114583336,137.44229333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::native_layer_norm_backward,357617,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",357617,46.45361328125,88.74764000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357621,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357621,47.220865885416664,77.63984
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357628,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357628,47.21044921875,1.8440533333333329
autograd::engine::evaluate_function: CheckpointFunctionBackward,357001,,aten::add_,357631,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357631,31.413411458333332,1.6968533333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::fill_,357637,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",357637,3562.3206380208335,2.5663866666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::copy_,357646,"[[], [], []]",Memcpy HtoD (Pageable -> Device),357646,5070.667643229167,0.755626666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::native_layer_norm,357651,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",357651,2442.009765625,91.51970666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::native_layer_norm,357658,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",357658,49.599609375,91.18509333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::addmm,357673,"[[2304], [8192, 6144], [6144, 2304], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357673,1644.87353515625,292.1775733333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::copy_,357698,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),357698,133.28987630208334,2.8002133333333346
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::copy_,357702,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),357702,1084.8216145833333,2.671773333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::neg,357712,"[[2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357712,2577.68603515625,5.620026666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::cat,357724,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",357724,1436.7218424479167,10.142200000000003
None,None,None,None,None,None,kernel_1,357725,935.4729817708334,4.6954
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::neg,357735,"[[2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357735,1346.3030598958333,5.032893333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::cat,357746,"[[2048, 4, 8, 24], [[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",357746,1233.9620768229167,10.046666666666667
None,None,None,None,None,None,kernel_1,357747,862.6083984375,4.51068
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::cat,357753,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",357753,1412.2923177083333,35.04412
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::cat,357754,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",357754,65.68522135416667,34.85406666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::baddbmm,357764,"[[32, 2048, 2048], [32, 2048, 96], [32, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357764,2801.0419921875,108.12071999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,ScaledUpperTriangMaskedSoftmax,357767,"[[32, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",357767,892.8986002604166,171.00919999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::bmm,357784,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357784,1253.00341796875,99.8413066666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::copy_,357792,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",357792,50.154947916666664,18.17802666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mm,357801,"[[8192, 768], [768, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357801,2378.2403971354165,101.9217066666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add,357806,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",357806,40.659993489583336,132.89830666666677
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mm,357818,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,357818,219.25179036458334,383.6179999999999
None,None,None,None,None,None,kernel_2,357822,43.187825520833336,46.39235999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mm,357833,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357833,87.77490234375,394.63860000000017
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add,357838,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",357838,39.147135416666664,129.12405333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add,357840,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357840,38.859212239583336,83.51971999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,record_param_comms,357843,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",357843,57.407877604166664,3686.5342399999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add,357848,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357848,50.016276041666664,85.3484
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::sum,357859,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",357859,94.89013671875,46.981600000000014
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,357863,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357863,40.309733072916664,1.831253333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mm,357873,"[[6144, 8192], [8192, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357873,97.80240885416667,372.11002666666656
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mm,357880,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357880,114.28059895833333,371.4008666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,357892,"[[6144, 3072], [6144, 3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357892,40.020833333333336,28.615453333333342
None,None,None,None,None,None,kernel_3,357896,42.581705729166664,49.65761333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::sum,357900,"[[2048, 4, 3072], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",357900,106.62386067708333,31.410479999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,357904,"[[3072], [3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357904,37.930501302083336,1.7352533333333342
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mm,357914,"[[3072, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357914,108.08610026041667,397.5642933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mm,357921,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357921,107.57291666666667,361.2697600000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,357933,"[[3072, 6144], [3072, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357933,42.303385416666664,29.49950666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,record_param_comms,357937,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",357937,64.59684244791667,3728.59892
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::sum,357944,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",357944,97.24641927083333,49.45840000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,357948,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357948,43.669921875,1.8256933333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mm,357958,"[[6144, 8192], [8192, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357958,106.97591145833333,125.46073333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mm,357965,"[[8192, 6144], [6144, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_on_kernel__5x_cublas,357965,108.77799479166667,108.25384000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,357977,"[[6144, 768], [6144, 768], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",357977,40.010416666666664,8.177426666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::bmm,357996,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357996,106.40771484375,92.01245333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::bmm,357999,"[[32, 2048, 96], [32, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,357999,112.3310546875,107.04422666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,ScaledUpperTriangMaskedSoftmaxBackward,358017,"[[32, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",358017,43.838704427083336,280.78193333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::bmm,358034,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358034,112.09358723958333,96.59573333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mul,358036,"[[32, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",358036,43.840983072916664,9.436506666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::bmm,358039,"[[32, 96, 2048], [32, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358039,108.65852864583333,90.86897333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mul,358041,"[[32, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",358041,40.53271484375,9.480906666666671
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mul,358081,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",358081,31.282877604166668,7.304920000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mul,358085,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",358085,35.36083984375,7.054453333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::neg,358088,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358088,38.345540364583336,3.6932000000000023
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::fill_,358095,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358095,35.240559895833336,2.2062533333333345
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::copy_,358098,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358098,36.6845703125,7.404333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,358099,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",358099,30.6982421875,14.002226666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::fill_,358106,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358106,30.453287760416668,2.1525200000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::copy_,358109,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358109,30.859375,7.6897199999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,358110,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",358110,30.484212239583332,13.747519999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mul,358114,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",358114,30.922037760416668,7.465773333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mul,358118,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",358118,39.019856770833336,6.248053333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::neg,358121,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358121,36.6171875,3.5733200000000025
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::fill_,358128,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358128,38.774576822916664,2.0795466666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::copy_,358131,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358131,33.440592447916664,3.915466666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,358132,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",358132,30.710774739583332,6.499813333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::fill_,358139,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358139,31.031412760416668,2.0462666666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::copy_,358142,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358142,30.591145833333332,3.890319999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,358143,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",358143,33.185221354166664,6.356013333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::fill_,358150,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358150,32.106119791666664,4.951413333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::copy_,358153,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358153,39.080078125,35.29609333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::fill_,358160,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358160,38.581705729166664,4.964639999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::copy_,358163,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358163,34.527669270833336,12.561333333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,358164,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358164,30.323893229166668,9.020119999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::fill_,358171,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358171,30.569986979166668,4.995399999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::copy_,358174,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358174,31.347330729166668,14.904146666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::fill_,358181,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358181,34.837076822916664,5.019706666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::copy_,358184,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358184,37.12841796875,6.673440000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,358185,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358185,37.226725260416664,9.036760000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::cat,358188,"[[[2048, 4, 8, 96], [2048, 4, 8, 96], [2048, 4, 8, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",358188,33.257486979166664,75.93106666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mm,358202,"[[8192, 2304], [2304, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358202,105.15152994791667,276.6167866666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::mm,358206,"[[2304, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,358206,179.83968098958334,288.4681866666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::sum,358210,"[[8192, 2304], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",358210,108.02099609375,25.555839999999993
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,358214,"[[2304], [2304], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358214,32.011067708333336,1.6622666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,358222,"[[2304, 6144], [2304, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358222,35.48779296875,20.745626666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,record_param_comms,358230,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",358230,66.38916015625,3678.7881066666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::native_layer_norm_backward,358235,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",358235,54.51708984375,140.8308933333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::native_layer_norm_backward,358235,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",358235,47.765625,89.13923999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add,358239,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358239,47.647623697916664,79.00314666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,358242,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358242,47.626790364583336,1.8517200000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,358245,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358245,35.32666015625,1.70492
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::native_layer_norm_backward,358248,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",358248,35.285807291666664,137.41585333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::native_layer_norm_backward,358248,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",358248,47.498372395833336,88.91059999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,358252,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358252,47.796549479166664,77.63946666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,358259,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358259,47.307779947916664,1.8469866666666659
autograd::engine::evaluate_function: CheckpointFunctionBackward,357632,,aten::add_,358262,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358262,31.080891927083332,1.69984
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::fill_,358268,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",358268,3411.21630859375,2.5552933333333345
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::copy_,358277,"[[], [], []]",Memcpy HtoD (Pageable -> Device),358277,5024.320963541667,0.7423999999999994
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::native_layer_norm,358282,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",358282,2439.3134765625,91.49356000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::native_layer_norm,358289,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",358289,47.189127604166664,91.32812000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::addmm,358304,"[[2304], [8192, 6144], [6144, 2304], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358304,1585.09716796875,292.31368000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::copy_,358329,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),358329,126.73046875,3.1748133333333355
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::copy_,358333,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),358333,1086.5169270833333,2.648319999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::neg,358343,"[[2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358343,2569.1197916666665,5.597853333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::cat,358355,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",358355,1447.28515625,10.125493333333337
None,None,None,None,None,None,kernel_1,358356,945.1355794270834,4.706546666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::neg,358366,"[[2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358366,1322.45166015625,5.070453333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::cat,358377,"[[2048, 4, 8, 24], [[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",358377,1251.5411783854167,10.041533333333332
None,None,None,None,None,None,kernel_1,358378,852.7203776041666,4.526479999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::cat,358384,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",358384,1444.5169270833333,34.999239999999986
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::cat,358385,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",358385,64.37337239583333,34.81096000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::baddbmm,358395,"[[32, 2048, 2048], [32, 2048, 96], [32, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358395,2833.5872395833335,108.03846666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,ScaledUpperTriangMaskedSoftmax,358398,"[[32, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",358398,926.5594075520834,171.0728533333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::bmm,358415,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358415,1318.802734375,99.71509333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::copy_,358423,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358423,79.34912109375,18.17836
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mm,358432,"[[8192, 768], [768, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358432,2372.8463541666665,101.86923999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add,358437,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",358437,39.0068359375,132.94911999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mm,358449,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,358449,203.9658203125,383.66189333333335
None,None,None,None,None,None,kernel_2,358453,43.2109375,46.39782666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mm,358464,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358464,88.79931640625,394.8623199999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add,358469,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",358469,39.25146484375,129.10016
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add,358471,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358471,38.72998046875,83.56409333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,record_param_comms,358474,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",358474,58.688639322916664,3656.883266666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add,358479,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358479,49.311686197916664,85.34029333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::sum,358490,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",358490,95.57177734375,46.973586666666655
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358494,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358494,39.743977864583336,1.8427466666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mm,358504,"[[6144, 8192], [8192, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358504,99.04052734375,372.39112
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mm,358511,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358511,117.544921875,371.61123999999984
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358523,"[[6144, 3072], [6144, 3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358523,40.555338541666664,28.584266666666664
None,None,None,None,None,None,kernel_3,358527,43.08056640625,49.62011999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::sum,358531,"[[2048, 4, 3072], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",358531,110.47574869791667,31.458693333333322
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358535,"[[3072], [3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358535,38.494466145833336,1.714333333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mm,358545,"[[3072, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358545,108.40625,397.83727999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mm,358552,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358552,110.17513020833333,361.64393333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358564,"[[3072, 6144], [3072, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358564,42.217610677083336,29.49821333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,record_param_comms,358568,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",358568,62.667154947916664,3736.8932533333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::sum,358575,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",358575,96.76806640625,49.353893333333346
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358579,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358579,44.2548828125,1.8094533333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mm,358589,"[[6144, 8192], [8192, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358589,106.5703125,125.78714666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mm,358596,"[[8192, 6144], [6144, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_on_kernel__5x_cublas,358596,108.96028645833333,108.32502666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358608,"[[6144, 768], [6144, 768], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358608,39.434733072916664,8.153560000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::bmm,358627,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358627,107.27262369791667,92.03722666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::bmm,358630,"[[32, 2048, 96], [32, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358630,112.17041015625,107.02968000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,ScaledUpperTriangMaskedSoftmaxBackward,358648,"[[32, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",358648,44.107421875,281.22391999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::bmm,358665,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358665,112.67122395833333,96.58076000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mul,358667,"[[32, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",358667,44.010579427083336,9.419426666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::bmm,358670,"[[32, 96, 2048], [32, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358670,111.7734375,90.94496000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mul,358672,"[[32, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",358672,39.743326822916664,9.399800000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mul,358712,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",358712,30.761067708333332,7.332173333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mul,358716,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",358716,35.167154947916664,7.067693333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::neg,358719,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358719,38.251139322916664,3.683813333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::fill_,358726,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358726,35.282552083333336,2.1892
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::copy_,358729,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358729,36.845377604166664,7.38388
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358730,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",358730,31.094075520833332,13.981679999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::fill_,358737,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358737,30.804524739583332,2.158506666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::copy_,358740,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358740,30.9130859375,7.695306666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358741,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",358741,30.45263671875,13.80721333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mul,358745,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",358745,30.89013671875,7.473013333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mul,358749,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",358749,39.0830078125,6.254013333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::neg,358752,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358752,35.986653645833336,3.5690400000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::fill_,358759,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358759,39.225260416666664,2.08
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::copy_,358762,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358762,33.97412109375,3.9244533333333327
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358763,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",358763,31.0517578125,6.50276
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::fill_,358770,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358770,30.7431640625,2.048400000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::copy_,358773,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358773,30.0693359375,3.883066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358774,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",358774,32.19189453125,6.3807199999999975
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::fill_,358781,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358781,31.3271484375,4.95656
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::copy_,358784,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358784,39.0068359375,35.20397333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::fill_,358791,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358791,39.01708984375,4.971053333333329
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::copy_,358794,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358794,34.72900390625,12.567306666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358795,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358795,30.388346354166668,9.018386666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::fill_,358802,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358802,30.847493489583332,5.005613333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::copy_,358805,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358805,30.8349609375,14.882893333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::fill_,358812,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",358812,34.94482421875,5.040586666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::copy_,358815,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358815,38.014485677083336,6.704146666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358816,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358816,37.47119140625,9.054173333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::cat,358819,"[[[2048, 4, 8, 96], [2048, 4, 8, 96], [2048, 4, 8, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",358819,33.076822916666664,75.92429333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mm,358833,"[[8192, 2304], [2304, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358833,105.21549479166667,276.4018133333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::mm,358837,"[[2304, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,358837,178.14111328125,289.0045599999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::sum,358841,"[[8192, 2304], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",358841,108.02018229166667,25.555413333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358845,"[[2304], [2304], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358845,31.253255208333332,1.6251599999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358853,"[[2304, 6144], [2304, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358853,35.508626302083336,20.76404
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,record_param_comms,358861,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",358861,65.87646484375,3711.7035199999987
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::native_layer_norm_backward,358866,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",358866,54.46533203125,140.8137733333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::native_layer_norm_backward,358866,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",358866,47.98828125,88.94303999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add,358870,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358870,47.6044921875,78.97064
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358873,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358873,47.242350260416664,1.8278400000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358876,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358876,35.572428385416664,1.7075200000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::native_layer_norm_backward,358879,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",358879,35.391276041666664,137.45208000000008
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::native_layer_norm_backward,358879,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",358879,47.4140625,88.97162666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358883,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358883,46.9873046875,77.64889333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358890,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358890,46.782063802083336,1.8764399999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,358263,,aten::add_,358893,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",358893,31.199381510416668,1.6716533333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::fill_,358899,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",358899,3426.5550130208335,2.567226666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::copy_,358908,"[[], [], []]",Memcpy HtoD (Pageable -> Device),358908,5074.977864583333,0.7449599999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::native_layer_norm,358913,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",358913,2441.037109375,91.60673333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::native_layer_norm,358920,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",358920,365.6497395833333,91.24530666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::addmm,358935,"[[2304], [8192, 6144], [6144, 2304], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,358935,1622.18310546875,292.49931999999984
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::copy_,358960,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),358960,132.76904296875,2.873573333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::copy_,358964,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),358964,1091.98876953125,2.681146666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::neg,358974,"[[2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358974,2596.15087890625,5.611893333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::cat,358986,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",358986,1541.9425455729167,10.145146666666674
None,None,None,None,None,None,kernel_1,358987,956.2467447916666,4.7091199999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::neg,358997,"[[2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",358997,1333.7511393229167,5.038466666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::cat,359008,"[[2048, 4, 8, 24], [[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",359008,1217.70361328125,10.058080000000002
None,None,None,None,None,None,kernel_1,359009,848.7950846354166,4.537146666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::cat,359015,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",359015,1420.3180338541667,35.11001333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::cat,359016,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",359016,47.050130208333336,34.865693333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::baddbmm,359026,"[[32, 2048, 2048], [32, 2048, 96], [32, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359026,2787.13427734375,108.20728
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,ScaledUpperTriangMaskedSoftmax,359029,"[[32, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",359029,914.1062825520834,171.22969333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::bmm,359046,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359046,1224.59765625,99.81351999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::copy_,359054,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359054,50.4208984375,18.183119999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mm,359063,"[[8192, 768], [768, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359063,2364.54541015625,102.03696000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add,359068,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",359068,36.371419270833336,132.92130666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mm,359080,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,359080,204.0205078125,383.9294266666668
None,None,None,None,None,None,kernel_2,359084,43.26318359375,46.43719999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mm,359095,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359095,88.15869140625,395.27011999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add,359100,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",359100,38.7734375,129.23453333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add,359102,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359102,39.402506510416664,83.46343999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,record_param_comms,359105,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",359105,55.83935546875,3673.671173333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add,359110,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359110,49.716796875,85.48628000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::sum,359121,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",359121,95.18896484375,46.61761333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359125,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359125,40.06201171875,1.8598133333333324
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mm,359135,"[[6144, 8192], [8192, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359135,98.30419921875,372.4244666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mm,359142,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359142,114.1982421875,371.6192666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359154,"[[6144, 3072], [6144, 3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359154,40.81982421875,28.48661333333334
None,None,None,None,None,None,kernel_3,359158,42.027018229166664,49.71347999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::sum,359162,"[[2048, 4, 3072], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",359162,110.080078125,31.47112
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359166,"[[3072], [3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359166,37.8974609375,1.7390800000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mm,359176,"[[3072, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359176,110.1435546875,397.8037066666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mm,359183,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359183,111.71077473958333,362.1998666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359195,"[[3072, 6144], [3072, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359195,41.770670572916664,29.49050666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,record_param_comms,359199,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",359199,63.77490234375,3718.2451466666676
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::sum,359206,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",359206,97.13020833333333,49.50651999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359210,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359210,44.05322265625,1.835946666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mm,359220,"[[6144, 8192], [8192, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359220,107.15771484375,125.69494666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mm,359227,"[[8192, 6144], [6144, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_on_kernel__5x_cublas,359227,111.24137369791667,108.32292000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359239,"[[6144, 768], [6144, 768], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359239,39.635416666666664,8.169760000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::bmm,359258,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359258,108.97005208333333,92.0158666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::bmm,359261,"[[32, 2048, 96], [32, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359261,114.17415364583333,107.00201333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,ScaledUpperTriangMaskedSoftmaxBackward,359279,"[[32, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",359279,44.725260416666664,281.2999066666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::bmm,359296,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359296,114.33528645833333,96.53761333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mul,359298,"[[32, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",359298,44.297526041666664,9.421599999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::bmm,359301,"[[32, 96, 2048], [32, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359301,111.39957682291667,90.7589066666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mul,359303,"[[32, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",359303,40.448404947916664,9.435653333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mul,359343,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",359343,31.0595703125,7.367160000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mul,359347,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",359347,34.944661458333336,7.043813333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::neg,359350,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359350,38.324381510416664,3.687666666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::fill_,359357,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",359357,35.8388671875,2.187506666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::copy_,359360,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359360,36.353841145833336,7.397026666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359361,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",359361,30.849446614583332,14.005640000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::fill_,359368,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",359368,30.229329427083332,2.1435600000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::copy_,359371,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359371,30.580729166666668,7.709786666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359372,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",359372,30.549153645833332,13.753893333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mul,359376,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",359376,31.02783203125,7.435480000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mul,359380,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",359380,39.041829427083336,6.264266666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::neg,359383,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359383,36.883138020833336,3.5622000000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::fill_,359390,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",359390,38.87158203125,2.077853333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::copy_,359393,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359393,34.550618489583336,3.926146666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359394,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",359394,31.008463541666668,6.494693333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::fill_,359401,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",359401,30.560709635416668,2.0488266666666677
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::copy_,359404,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359404,30.315755208333332,3.8975599999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359405,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",359405,33.1513671875,6.372213333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::fill_,359412,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",359412,31.88134765625,4.952719999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::copy_,359415,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359415,39.453938802083336,35.270533333333326
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::fill_,359422,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",359422,38.997721354166664,4.970599999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::copy_,359425,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359425,34.514811197916664,12.573360000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359426,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359426,30.83544921875,9.023053333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::fill_,359433,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",359433,30.366861979166668,5.003493333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::copy_,359436,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359436,31.401041666666668,14.860679999999993
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::fill_,359443,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",359443,34.878255208333336,5.02996
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::copy_,359446,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359446,37.257161458333336,6.665746666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359447,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359447,37.450520833333336,9.043973333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::cat,359450,"[[[2048, 4, 8, 96], [2048, 4, 8, 96], [2048, 4, 8, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",359450,33.299479166666664,75.92045333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mm,359464,"[[8192, 2304], [2304, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359464,107.94694010416667,275.79335999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::mm,359468,"[[2304, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,359468,177.78938802083334,288.86248000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::sum,359472,"[[8192, 2304], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",359472,107.275390625,25.600226666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359476,"[[2304], [2304], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359476,31.78515625,1.5863066666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359484,"[[2304, 6144], [2304, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359484,35.200520833333336,20.681213333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,record_param_comms,359492,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",359492,68.45719401041667,3678.9985466666676
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::native_layer_norm_backward,359497,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",359497,54.516927083333336,140.58974666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::native_layer_norm_backward,359497,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",359497,47.764973958333336,89.03010666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add,359501,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359501,48.16015625,79.02990666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359504,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359504,47.136067708333336,1.8641066666666661
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359507,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359507,35.189127604166664,1.7096400000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::native_layer_norm_backward,359510,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",359510,35.3818359375,137.4043333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::native_layer_norm_backward,359510,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",359510,47.412434895833336,88.85769333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359514,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359514,47.039388020833336,77.68389333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359521,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359521,47.146647135416664,1.8448933333333324
autograd::engine::evaluate_function: CheckpointFunctionBackward,358894,,aten::add_,359524,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359524,31.52880859375,1.6742133333333329
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::fill_,359530,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",359530,3407.5794270833335,2.5659600000000014
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::copy_,359539,"[[], [], []]",Memcpy HtoD (Pageable -> Device),359539,5015.445963541667,0.7547599999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::native_layer_norm,359544,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",359544,2471.1502278645835,91.47566666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::native_layer_norm,359551,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",359551,46.3037109375,91.19888000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::addmm,359566,"[[2304], [8192, 6144], [6144, 2304], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359566,1646.7254231770833,292.3223066666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::copy_,359591,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),359591,132.40348307291666,2.83092
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::copy_,359595,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),359595,1097.7794596354167,2.6858666666666657
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::neg,359605,"[[2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359605,2567.3502604166665,5.605533333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::cat,359617,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",359617,1446.4982096354167,10.139653333333337
None,None,None,None,None,None,kernel_1,359618,933.15283203125,4.691160000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::neg,359628,"[[2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359628,1317.15380859375,5.032466666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::cat,359639,"[[2048, 4, 8, 24], [[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",359639,1227.5618489583333,10.050013333333332
None,None,None,None,None,None,kernel_1,359640,837.6686197916666,4.522626666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::cat,359646,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",359646,1426.2799479166667,35.009746666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::cat,359647,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",359647,62.359049479166664,34.82258666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::baddbmm,359657,"[[32, 2048, 2048], [32, 2048, 96], [32, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359657,2760.9773763020835,108.27514666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,ScaledUpperTriangMaskedSoftmax,359660,"[[32, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",359660,922.7034505208334,171.02022666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::bmm,359677,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359677,1226.1858723958333,99.89168000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::copy_,359685,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359685,81.83430989583333,18.211666666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mm,359694,"[[8192, 768], [768, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359694,2350.2109375,102.02492
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add,359699,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",359699,207.65625,132.98668000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mm,359711,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,359711,229.91715494791666,383.85437333333346
None,None,None,None,None,None,kernel_2,359715,43.764322916666664,46.43722666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mm,359726,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359726,88.34163411458333,394.89710666666656
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add,359731,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",359731,39.0927734375,129.15396000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add,359733,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359733,39.721516927083336,83.51376
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,record_param_comms,359736,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",359736,55.76611328125,3645.635613333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add,359741,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359741,50.152506510416664,85.43937333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::sum,359752,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",359752,96.447265625,46.84925333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,359756,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359756,39.529459635416664,1.8491599999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mm,359766,"[[6144, 8192], [8192, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359766,98.13346354166667,372.3553333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mm,359773,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359773,116.28548177083333,371.5267466666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,359785,"[[6144, 3072], [6144, 3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359785,40.459635416666664,28.467880000000005
None,None,None,None,None,None,kernel_3,359789,43.295572916666664,49.596506666666684
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::sum,359793,"[[2048, 4, 3072], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",359793,107.04850260416667,31.484773333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,359797,"[[3072], [3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359797,37.472981770833336,1.7386666666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mm,359807,"[[3072, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359807,107.74186197916667,397.80112
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mm,359814,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359814,111.20882161458333,361.87564
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,359826,"[[3072, 6144], [3072, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359826,41.920735677083336,29.373973333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,record_param_comms,359830,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",359830,63.337890625,3724.5179999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::sum,359837,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",359837,98.18636067708333,49.491186666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,359841,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359841,43.700846354166664,1.79452
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mm,359851,"[[6144, 8192], [8192, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359851,107.990234375,125.61089333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mm,359858,"[[8192, 6144], [6144, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_on_kernel__5x_cublas,359858,110.33479817708333,108.21502666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,359870,"[[6144, 768], [6144, 768], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",359870,39.755533854166664,8.181693333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::bmm,359889,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359889,107.26090494791667,92.1226
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::bmm,359892,"[[32, 2048, 96], [32, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359892,113.11865234375,106.94434666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,ScaledUpperTriangMaskedSoftmaxBackward,359910,"[[32, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",359910,43.817708333333336,281.24780000000015
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::bmm,359927,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359927,109.013671875,96.56073333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mul,359929,"[[32, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",359929,44.6494140625,9.450559999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::bmm,359932,"[[32, 96, 2048], [32, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,359932,107.71126302083333,90.83148000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mul,359934,"[[32, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",359934,39.849934895833336,9.394706666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mul,359974,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",359974,31.346842447916668,7.298066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mul,359978,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",359978,34.794270833333336,7.042066666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::neg,359981,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359981,38.260579427083336,3.6923333333333344
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::fill_,359988,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",359988,35.177571614583336,2.1828133333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::copy_,359991,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",359991,36.440755208333336,7.422653333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,359992,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",359992,30.668619791666668,13.931880000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::fill_,359999,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",359999,30.857584635416668,2.139733333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::copy_,360002,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360002,31.008463541666668,7.702106666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,360003,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",360003,30.463216145833332,13.708253333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mul,360007,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",360007,30.666666666666668,7.459800000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mul,360011,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",360011,38.998046875,6.228853333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::neg,360014,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360014,36.423990885416664,3.578813333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::fill_,360021,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",360021,39.501953125,2.075306666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::copy_,360024,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360024,34.454264322916664,3.9133733333333316
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,360025,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",360025,31.126627604166668,6.501920000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::fill_,360032,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",360032,30.837239583333332,2.047986666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::copy_,360035,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360035,30.068684895833332,3.8928800000000017
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,360036,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",360036,32.919108072916664,6.361093333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::fill_,360043,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",360043,31.731608072916668,4.9557066666666625
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::copy_,360046,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360046,38.994303385416664,35.28513333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::fill_,360053,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",360053,38.623209635416664,4.979599999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::copy_,360056,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360056,33.94970703125,12.576346666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,360057,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360057,30.313802083333332,9.015399999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::fill_,360064,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",360064,30.836100260416668,5.009426666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::copy_,360067,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360067,30.996256510416668,14.87514666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::fill_,360074,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",360074,34.677571614583336,5.0299200000000015
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::copy_,360077,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360077,37.097330729166664,6.7028799999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,360078,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360078,36.767578125,9.0512
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::cat,360081,"[[[2048, 4, 8, 96], [2048, 4, 8, 96], [2048, 4, 8, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",360081,34.04833984375,75.89231999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mm,360095,"[[8192, 2304], [2304, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360095,104.73470052083333,276.01180000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::mm,360099,"[[2304, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,360099,175.0380859375,289.23416
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::sum,360103,"[[8192, 2304], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",360103,106.25960286458333,25.659933333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,360107,"[[2304], [2304], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360107,31.8505859375,1.6050933333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,360115,"[[2304, 6144], [2304, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360115,35.649088541666664,20.733680000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,record_param_comms,360123,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",360123,67.00699869791667,3690.8576000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::native_layer_norm_backward,360128,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",360128,54.516764322916664,140.77285333333327
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::native_layer_norm_backward,360128,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",360128,46.859049479166664,88.86065333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add,360132,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360132,47.4765625,78.95058666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,360135,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360135,47.051106770833336,1.867493333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,360138,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360138,35.0615234375,1.6972800000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::native_layer_norm_backward,360141,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",360141,35.820638020833336,137.38850666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::native_layer_norm_backward,360141,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",360141,47.401529947916664,88.70495999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,360145,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360145,47.646647135416664,77.70734666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,360152,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360152,47.4990234375,1.8790266666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,359525,,aten::add_,360155,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360155,30.965494791666668,1.6848933333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::fill_,360161,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",360161,3402.3302408854165,2.551013333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::copy_,360170,"[[], [], []]",Memcpy HtoD (Pageable -> Device),360170,5035.234212239583,0.7547733333333327
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::native_layer_norm,360175,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",360175,2437.5071614583335,91.60409333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::native_layer_norm,360182,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",360182,41.162434895833336,91.26710666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::addmm,360197,"[[2304], [8192, 6144], [6144, 2304], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360197,1574.9549153645833,292.50312
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::copy_,360222,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),360222,136.83024088541666,3.1176266666666677
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::copy_,360226,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),360226,1103.86279296875,2.740453333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::neg,360236,"[[2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360236,2594.5592447916665,5.617920000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::cat,360248,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",360248,1601.3720703125,10.141773333333337
None,None,None,None,None,None,kernel_1,360249,950.3943684895834,4.7235733333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::neg,360259,"[[2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360259,1331.9138997395833,5.054626666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::cat,360270,"[[2048, 4, 8, 24], [[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",360270,1241.1536458333333,10.064119999999999
None,None,None,None,None,None,kernel_1,360271,1005.02685546875,4.5222000000000016
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::cat,360277,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",360277,1442.802734375,35.053333333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::cat,360278,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",360278,83.18798828125,34.835319999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::baddbmm,360288,"[[32, 2048, 2048], [32, 2048, 96], [32, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360288,2822.29248046875,108.41040000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,ScaledUpperTriangMaskedSoftmax,360291,"[[32, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",360291,967.2862955729166,171.12523999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::bmm,360308,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360308,1277.1865234375,99.77005333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::copy_,360316,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360316,73.85465494791667,18.242013333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mm,360325,"[[8192, 768], [768, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360325,2423.60595703125,102.14994666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add,360330,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",360330,34.795084635416664,132.88296000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mm,360342,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,360342,192.02132161458334,383.68494666666663
None,None,None,None,None,None,kernel_2,360346,43.497721354166664,46.47289333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mm,360357,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360357,88.04166666666667,395.2693333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add,360362,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",360362,38.986979166666664,129.15693333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add,360364,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360364,39.115234375,83.48079999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,record_param_comms,360367,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",360367,56.319986979166664,3633.2401733333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add,360372,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360372,49.972819010416664,85.40606666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::sum,360383,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",360383,95.42268880208333,46.711079999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360387,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360387,40.214029947916664,1.8359199999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mm,360397,"[[6144, 8192], [8192, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360397,100.87662760416667,372.8255200000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mm,360404,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360404,115.95491536458333,371.85188000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360416,"[[6144, 3072], [6144, 3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360416,41.36572265625,28.52618666666667
None,None,None,None,None,None,kernel_3,360420,42.486653645833336,49.705826666666674
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::sum,360424,"[[2048, 4, 3072], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",360424,106.29329427083333,31.475013333333322
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360428,"[[3072], [3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360428,37.39697265625,1.79112
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mm,360438,"[[3072, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360438,110.42024739583333,398.33393333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mm,360445,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360445,110.5595703125,361.69170666666673
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360457,"[[3072, 6144], [3072, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360457,42.516276041666664,29.514386666666674
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,record_param_comms,360461,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",360461,62.922037760416664,3729.6152933333324
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::sum,360468,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",360468,98.61165364583333,49.511786666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360472,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360472,43.967936197916664,1.7689599999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mm,360482,"[[6144, 8192], [8192, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360482,106.412109375,125.69283999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mm,360489,"[[8192, 6144], [6144, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_on_kernel__5x_cublas,360489,109.83251953125,108.30589333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360501,"[[6144, 768], [6144, 768], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360501,39.413411458333336,8.187240000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::bmm,360520,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360520,110.11979166666667,91.98508000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::bmm,360523,"[[32, 2048, 96], [32, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360523,116.7900390625,107.01691999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,ScaledUpperTriangMaskedSoftmaxBackward,360541,"[[32, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",360541,44.159830729166664,281.2798533333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::bmm,360558,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360558,115.46549479166667,96.66482666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mul,360560,"[[32, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",360560,44.235677083333336,9.44464
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::bmm,360563,"[[32, 96, 2048], [32, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360563,108.935546875,90.72127999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mul,360565,"[[32, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",360565,40.329915364583336,9.460453333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mul,360605,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",360605,30.89990234375,7.370239999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mul,360609,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",360609,35.210123697916664,7.053146666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::neg,360612,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360612,37.940592447916664,3.693133333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::fill_,360619,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",360619,35.87109375,2.1943466666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::copy_,360622,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360622,37.356608072916664,7.406906666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360623,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",360623,30.720052083333332,13.971493333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::fill_,360630,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",360630,30.3896484375,2.14016
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::copy_,360633,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360633,30.6357421875,7.712319999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360634,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",360634,29.951822916666668,13.761506666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mul,360638,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",360638,30.826334635416668,7.467893333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mul,360642,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",360642,38.91357421875,6.272799999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::neg,360645,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360645,36.370930989583336,3.5844133333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::fill_,360652,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",360652,38.61572265625,2.0782800000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::copy_,360655,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360655,34.219563802083336,3.932986666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360656,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",360656,30.667805989583332,6.499786666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::fill_,360663,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",360663,30.753580729166668,2.0475733333333346
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::copy_,360666,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360666,30.443033854166668,3.8912000000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360667,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",360667,32.1943359375,6.3829199999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::fill_,360674,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",360674,32.43505859375,4.953119999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::copy_,360677,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360677,38.748372395833336,35.23896
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::fill_,360684,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",360684,38.90234375,4.9722933333333295
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::copy_,360687,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360687,34.728352864583336,12.589493333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360688,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360688,30.1630859375,9.01665333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::fill_,360695,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",360695,30.6015625,5.004746666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::copy_,360698,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360698,31.018717447916668,14.874773333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::fill_,360705,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",360705,34.911295572916664,5.0252533333333345
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::copy_,360708,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360708,37.927897135416664,6.69781333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360709,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360709,36.639811197916664,9.058546666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::cat,360712,"[[[2048, 4, 8, 96], [2048, 4, 8, 96], [2048, 4, 8, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",360712,33.364908854166664,75.94842666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mm,360726,"[[8192, 2304], [2304, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360726,105.7294921875,276.1207333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::mm,360730,"[[2304, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,360730,190.93196614583334,289.9495733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::sum,360734,"[[8192, 2304], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",360734,111.05045572916667,25.661973333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360738,"[[2304], [2304], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360738,31.9033203125,1.6652799999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360746,"[[2304, 6144], [2304, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360746,35.402994791666664,20.67485333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,record_param_comms,360754,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",360754,67.50911458333333,3696.593293333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::native_layer_norm_backward,360759,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",360759,54.4951171875,140.71098666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::native_layer_norm_backward,360759,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",360759,47.5400390625,88.75362666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add,360763,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360763,47.070963541666664,79.01704000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360766,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360766,47.584309895833336,1.8376533333333327
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360769,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360769,35.34912109375,1.6891600000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::native_layer_norm_backward,360772,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",360772,35.13671875,137.4611333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::native_layer_norm_backward,360772,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",360772,47.307454427083336,88.55940000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360776,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360776,47.337565104166664,77.73641333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360783,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360783,47.263509114583336,1.844013333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360156,,aten::add_,360786,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360786,31.401204427083332,1.6622933333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::fill_,360792,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",360792,3349.8714192708335,2.5574399999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::copy_,360801,"[[], [], []]",Memcpy HtoD (Pageable -> Device),360801,4990.722493489583,0.7543466666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::native_layer_norm,360806,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",360806,2405.6253255208335,91.60539999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::native_layer_norm,360813,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",360813,41.065755208333336,91.39041333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::addmm,360828,"[[2304], [8192, 6144], [6144, 2304], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360828,1540.4690755208333,292.72504
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::copy_,360853,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),360853,127.53922526041667,2.769880000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::copy_,360857,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),360857,1079.3377278645833,2.75456
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::neg,360867,"[[2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360867,2557.2482096354165,5.632813333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::cat,360879,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",360879,1456.3525390625,10.146493333333336
None,None,None,None,None,None,kernel_1,360880,954.62548828125,4.703946666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::neg,360890,"[[2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360890,1310.61572265625,5.037613333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::cat,360901,"[[2048, 4, 8, 24], [[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",360901,1247.43212890625,10.052146666666673
None,None,None,None,None,None,kernel_1,360902,849.4982096354166,4.535893333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::cat,360908,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",360908,1435.900390625,35.03970666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::cat,360909,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",360909,55.15771484375,34.88695999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::baddbmm,360919,"[[32, 2048, 2048], [32, 2048, 96], [32, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360919,2707.1875,108.52904000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,ScaledUpperTriangMaskedSoftmax,360922,"[[32, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",360922,969.29296875,171.16361333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::bmm,360939,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360939,1169.4718424479167,99.93133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::copy_,360947,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",360947,61.8349609375,18.19505333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mm,360956,"[[8192, 768], [768, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360956,2346.1129557291665,102.17994666666671
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add,360961,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",360961,40.437337239583336,132.92982666666668
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mm,360973,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,360973,310.7609049479167,383.9380000000001
None,None,None,None,None,None,kernel_2,360977,43.433430989583336,46.48195999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mm,360988,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,360988,87.57194010416667,395.4109199999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add,360993,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",360993,39.200032552083336,129.21150666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add,360995,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",360995,39.33837890625,83.52183999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,record_param_comms,360998,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",360998,56.2880859375,3634.791573333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add,361003,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361003,49.884602864583336,85.42988000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::sum,361014,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",361014,96.52132161458333,46.70860000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361018,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361018,40.350748697916664,1.8965199999999993
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mm,361028,"[[6144, 8192], [8192, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361028,97.84440104166667,373.20773333333324
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mm,361035,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361035,118.46175130208333,371.5468399999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361047,"[[6144, 3072], [6144, 3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361047,40.767578125,28.513933333333327
None,None,None,None,None,None,kernel_3,361051,42.986490885416664,49.675946666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::sum,361055,"[[2048, 4, 3072], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",361055,107.74397786458333,31.400626666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361059,"[[3072], [3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361059,37.814453125,1.7804800000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mm,361069,"[[3072, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361069,112.70296223958333,398.4167733333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mm,361076,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361076,111.44368489583333,361.5479733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361088,"[[3072, 6144], [3072, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361088,42.19677734375,29.398839999999993
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,record_param_comms,361092,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",361092,63.1455078125,3714.6935599999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::sum,361099,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",361099,97.36409505208333,49.4622
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361103,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361103,43.723470052083336,1.7983866666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mm,361113,"[[6144, 8192], [8192, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361113,107.23046875,125.92273333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mm,361120,"[[8192, 6144], [6144, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_on_kernel__5x_cublas,361120,108.6396484375,108.30594666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361132,"[[6144, 768], [6144, 768], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361132,40.0439453125,8.18714666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::bmm,361151,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361151,108.92643229166667,92.01334666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::bmm,361154,"[[32, 2048, 96], [32, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361154,113.92789713541667,107.17104
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,ScaledUpperTriangMaskedSoftmaxBackward,361172,"[[32, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",361172,43.78662109375,281.30962666666653
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::bmm,361189,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361189,108.91650390625,96.63966666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mul,361191,"[[32, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",361191,43.626790364583336,9.406133333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::bmm,361194,"[[32, 96, 2048], [32, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361194,107.56201171875,90.90705333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mul,361196,"[[32, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",361196,39.743489583333336,9.404906666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mul,361236,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",361236,31.463541666666668,7.336040000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mul,361240,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",361240,35.3818359375,7.093253333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::neg,361243,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361243,39.134440104166664,3.6718800000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::fill_,361250,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361250,35.391276041666664,2.2015733333333327
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::copy_,361253,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361253,36.705891927083336,7.41456
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361254,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",361254,30.912109375,13.954013333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::fill_,361261,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361261,30.612141927083332,2.1461333333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::copy_,361264,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361264,30.72216796875,7.706839999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361265,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",361265,30.55859375,13.776066666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mul,361269,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",361269,31.006673177083332,7.4696266666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mul,361273,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",361273,39.447102864583336,6.23697333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::neg,361276,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361276,36.22314453125,3.568173333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::fill_,361283,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361283,38.924967447916664,2.078706666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::copy_,361286,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361286,33.67578125,3.922706666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361287,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",361287,30.8818359375,6.500173333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::fill_,361294,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361294,30.933919270833332,2.0454000000000008
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::copy_,361297,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361297,30.326009114583332,3.9001599999999983
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361298,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",361298,32.961751302083336,6.374293333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::fill_,361305,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361305,32.42431640625,4.955679999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::copy_,361308,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361308,38.921061197916664,35.22407999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::fill_,361315,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361315,38.100423177083336,4.981746666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::copy_,361318,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361318,34.036295572916664,12.575013333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361319,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361319,30.356119791666668,9.013706666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::fill_,361326,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361326,30.665201822916668,5.0081733333333345
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::copy_,361329,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361329,31.283203125,14.875146666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::fill_,361336,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361336,34.902180989583336,5.03888
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::copy_,361339,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361339,37.993489583333336,6.678133333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361340,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361340,36.522623697916664,9.044373333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::cat,361343,"[[[2048, 4, 8, 96], [2048, 4, 8, 96], [2048, 4, 8, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",361343,33.215006510416664,75.97641333333338
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mm,361357,"[[8192, 2304], [2304, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361357,104.36165364583333,275.82614666666655
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::mm,361361,"[[2304, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,361361,178.2060546875,290.7052533333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::sum,361365,"[[8192, 2304], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",361365,108.61783854166667,25.623733333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361369,"[[2304], [2304], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361369,31.476725260416668,1.6435066666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361377,"[[2304, 6144], [2304, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361377,35.466145833333336,20.69868
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,record_param_comms,361385,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",361385,67.25325520833333,3699.5030800000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::native_layer_norm_backward,361390,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",361390,54.079427083333336,140.66824000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::native_layer_norm_backward,361390,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",361390,47.78759765625,88.90289333333331
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add,361394,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361394,47.423990885416664,79.04837333333337
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361397,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361397,47.41259765625,1.846186666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361400,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361400,36.330078125,1.722
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::native_layer_norm_backward,361403,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",361403,35.788248697916664,137.3833333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::native_layer_norm_backward,361403,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",361403,47.27294921875,88.80324000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361407,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361407,48.020833333333336,77.68717333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361414,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361414,47.296712239583336,1.8803066666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,360787,,aten::add_,361417,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361417,31.36865234375,1.6622933333333325
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::fill_,361423,"[[1, 1, 2048, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",361423,3300.8916015625,2.5634000000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::copy_,361432,"[[], [], []]",Memcpy HtoD (Pageable -> Device),361432,4981.87890625,0.754333333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::native_layer_norm,361437,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",361437,2407.7041015625,91.68612000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::native_layer_norm,361444,"[[2048, 4, 6144], [], [6144], [6144], []]","void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*)",361444,39.029622395833336,91.20223999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::addmm,361459,"[[2304], [8192, 6144], [6144, 2304], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361459,1556.3274739583333,292.8146933333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::copy_,361484,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),361484,261.0231119791667,3.090320000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::copy_,361488,"[[2048, 1, 1, 24], [2048, 1, 1, 24], []]",Memcpy HtoD (Pageable -> Device),361488,1092.5213216145833,2.752413333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::neg,361498,"[[2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361498,2547.9054361979165,5.5884133333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::cat,361510,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",361510,1483.5944010416667,10.132373333333335
None,None,None,None,None,None,kernel_1,361511,937.0709635416666,4.689893333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::neg,361521,"[[2048, 4, 8, 24], [2048, 1, 1, 24], [2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361521,1321.2784830729167,5.0564
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::cat,361532,"[[2048, 4, 8, 24], [[2048, 4, 8, 12], [2048, 4, 8, 12]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",361532,1258.337890625,10.036373333333339
None,None,None,None,None,None,kernel_1,361533,980.4527994791666,4.509386666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::cat,361539,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",361539,1425.939453125,35.04143999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::cat,361540,"[[[2048, 4, 8, 24], [2048, 4, 8, 72]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",361540,47.658365885416664,34.86769333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::baddbmm,361550,"[[32, 2048, 2048], [32, 2048, 96], [32, 96, 2048], [], []]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361550,2785.4923502604165,108.82768
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,ScaledUpperTriangMaskedSoftmax,361553,"[[32, 2048, 2048], []]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)",361553,885.05908203125,171.16412
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::bmm,361570,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361570,1180.2224934895833,99.9284
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::copy_,361578,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361578,67.74300130208333,18.253480000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mm,361587,"[[8192, 768], [768, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361587,2299.03271484375,102.29379999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add,361592,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",361592,48.840983072916664,132.87568000000007
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mm,361604,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,361604,199.10172526041666,384.34713333333326
None,None,None,None,None,None,kernel_2,361608,43.262044270833336,46.520813333333344
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mm,361619,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361619,88.97037760416667,395.36827999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add,361624,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",361624,39.082682291666664,129.18543999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add,361626,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361626,38.79443359375,83.47413333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,record_param_comms,361629,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",361629,56.9931640625,3646.5802266666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add,361634,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361634,50.078125,85.36410666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::sum,361645,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",361645,95.31575520833333,46.54687999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,361649,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361649,40.2236328125,1.8704933333333342
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mm,361659,"[[6144, 8192], [8192, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361659,97.41764322916667,373.65835999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mm,361666,"[[8192, 6144], [6144, 3072]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361666,118.13264973958333,371.8134666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,361678,"[[6144, 3072], [6144, 3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361678,40.383626302083336,28.47633333333335
None,None,None,None,None,None,kernel_3,361682,42.77294921875,49.74084
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::sum,361686,"[[2048, 4, 3072], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",361686,114.21940104166667,31.448026666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,361690,"[[3072], [3072], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361690,36.841634114583336,1.7642533333333343
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mm,361700,"[[3072, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361700,111.9990234375,401.27876000000015
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mm,361707,"[[8192, 3072], [3072, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361707,109.85693359375,362.51605333333316
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,361719,"[[3072, 6144], [3072, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361719,42.271321614583336,29.505933333333328
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,record_param_comms,361723,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",361723,63.657389322916664,3743.56328
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::sum,361730,"[[2048, 4, 6144], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",361730,98.73014322916667,49.38584000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,361734,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361734,43.573567708333336,1.7983733333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mm,361744,"[[6144, 8192], [8192, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361744,107.048828125,126.29867999999992
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mm,361751,"[[8192, 6144], [6144, 768]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_on_kernel__5x_cublas,361751,106.9970703125,108.21116000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,361763,"[[6144, 768], [6144, 768], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361763,39.337565104166664,8.146693333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::bmm,361782,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361782,105.92936197916667,91.87978666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::bmm,361785,"[[32, 2048, 96], [32, 96, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361785,110.44124348958333,107.45728000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,ScaledUpperTriangMaskedSoftmaxBackward,361803,"[[32, 2048, 2048]]","void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_backward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half*, c10::Half const*, float, int, int, int)",361803,44.10546875,281.3399733333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::bmm,361820,"[[32, 2048, 2048], [32, 2048, 96]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361820,114.37825520833333,96.59869333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mul,361822,"[[32, 2048, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",361822,45.044759114583336,9.441226666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::bmm,361825,"[[32, 96, 2048], [32, 2048, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize64x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361825,109.26627604166667,90.9215066666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mul,361827,"[[32, 96, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",361827,40.542643229166664,9.411333333333332
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mul,361867,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",361867,31.13427734375,7.388519999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mul,361871,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",361871,34.965657552083336,7.063000000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::neg,361874,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361874,38.004720052083336,3.678706666666669
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::fill_,361881,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361881,34.824869791666664,2.1968666666666663
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::copy_,361884,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361884,36.0224609375,7.418439999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,361885,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",361885,31.041829427083332,14.047453333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::fill_,361892,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361892,30.560546875,2.1448000000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::copy_,361895,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361895,31.3056640625,7.709786666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,361896,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",361896,30.580403645833332,13.812399999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mul,361900,"[[2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",361900,30.731608072916668,7.457586666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mul,361904,"[[[2048, 4, 8, 12], [2048, 4, 8, 12]], [2048, 4, 8, 24], [2048, 1, 1, 24]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",361904,38.773600260416664,6.2544933333333335
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::neg,361907,"[[2048, 4, 8, 12]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361907,36.585774739583336,3.5639466666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::fill_,361914,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361914,39.810384114583336,2.076133333333334
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::copy_,361917,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361917,34.592936197916664,3.9269866666666684
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,361918,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",361918,30.796061197916668,6.493826666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::fill_,361925,"[[2048, 4, 8, 24], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361925,31.051106770833332,2.0462800000000008
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::copy_,361928,"[[2048, 4, 8, 12], [2048, 4, 8, 12], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361928,30.080240885416668,3.8852133333333336
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,361929,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",361929,32.438313802083336,6.381573333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::fill_,361936,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361936,31.913736979166668,4.954426666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::copy_,361939,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361939,39.016276041666664,35.262413333333306
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::fill_,361946,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361946,38.752115885416664,4.974026666666664
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::copy_,361949,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361949,34.590169270833336,12.593000000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,361950,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361950,30.930826822916668,9.019639999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::fill_,361957,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361957,30.81396484375,5.012879999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::copy_,361960,"[[2048, 4, 8, 72], [2048, 4, 8, 72], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361960,30.8251953125,14.887986666666672
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::fill_,361967,"[[2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",361967,34.505533854166664,5.02612
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::copy_,361970,"[[2048, 4, 8, 24], [2048, 4, 8, 24], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",361970,37.72705078125,6.688373333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,361971,"[[2048, 4, 8, 96], [2048, 4, 8, 96], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",361971,37.2470703125,9.06698666666667
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::cat,361974,"[[[2048, 4, 8, 96], [2048, 4, 8, 96], [2048, 4, 8, 96]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",361974,32.93798828125,75.97331999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mm,361988,"[[8192, 2304], [2304, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,361988,107.45670572916667,277.0208666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::mm,361992,"[[2304, 8192], [8192, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,361992,179.95589192708334,294.41506666666675
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::sum,361996,"[[8192, 2304], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",361996,107.47672526041667,25.685560000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,362000,"[[2304], [2304], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",362000,31.2099609375,1.636653333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,362008,"[[2304, 6144], [2304, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",362008,35.242024739583336,20.742240000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,record_param_comms,362016,"[[[2048, 4, 6144]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",362016,66.8056640625,3694.4475200000015
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::native_layer_norm_backward,362021,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",362021,53.876790364583336,140.71437333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::native_layer_norm_backward,362021,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",362021,47.412923177083336,88.78690666666665
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add,362025,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",362025,47.44482421875,79.06500000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,362028,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",362028,47.2099609375,1.8700800000000004
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,362031,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",362031,35.9130859375,1.6835999999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::native_layer_norm_backward,362034,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<c10::Half, float>(c10::Half const*, c10::Half const*, float const*, float const*, c10::Half const*, c10::Half*, int)",362034,35.531412760416664,137.49050666666662
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::native_layer_norm_backward,362034,"[[2048, 4, 6144], [2048, 4, 6144], [], [2048, 4, 1], [2048, 4, 1], [6144], [6144], []]","void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<c10::Half, float>(long, long, c10::Half const*, c10::Half const*, float const*, float const*, c10::Half*, c10::Half*)",362034,47.136067708333336,88.75871999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,362038,"[[2048, 4, 6144], [2048, 4, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",362038,46.8798828125,77.83526666666666
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,362045,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",362045,46.740397135416664,1.847453333333333
autograd::engine::evaluate_function: CheckpointFunctionBackward,361418,,aten::add_,362048,"[[6144], [6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",362048,30.698893229166668,1.6665333333333332
autograd::engine::evaluate_function: torch::autograd::CopySlices,362057,,aten::copy_,362061,"[[4, 2048, 6144], [4, 2048, 6144], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",362061,4913.559895833333,132.89657333333335
autograd::engine::evaluate_function: torch::autograd::CopySlices,362057,,aten::copy_,362066,"[[4, 2048, 6144], [4, 2048, 6144], []]",Memcpy DtoD (Device -> Device),362066,39.68115234375,70.95197333333331
autograd::engine::evaluate_function: torch::autograd::CopySlices,362057,,aten::copy_,362074,"[[4, 2048, 6144], [4, 2048, 6144], []]",Memcpy DtoD (Device -> Device),362074,39.3798828125,71.47328
autograd::engine::evaluate_function: torch::autograd::CopySlices,362057,,aten::masked_fill_,362081,"[[4, 2048, 6144], [4, 2048, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",362081,39.477864583333336,139.25896000000003
autograd::engine::evaluate_function: torch::autograd::CopySlices,362057,,aten::copy_,362084,"[[4, 2048, 6144], [4, 2048, 6144], []]",Memcpy DtoD (Device -> Device),362084,39.93505859375,72.35657333333334
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::arange,362096,"[[], [], [], [0]]","void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)",362096,44.256184895833336,1.4007333333333338
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortHistogramKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, unsigned long long, at_cuda_detail::cub::detail::identity_decomposer_t>(unsigned long long*, long const*, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",362088,157.9169921875,3.670573333333335
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(unsigned long long*)",362088,35.552083333333336,1.5820666666666663
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",362088,93.24690755208333,8.620746666666667
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",362088,96.15901692708333,8.088693333333335
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",362088,99.32633463541667,7.901373333333334
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",362088,97.748046875,7.861306666666669
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",362088,96.24544270833333,7.7102266666666655
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",362088,96.27685546875,7.69993333333333
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",362088,94.29329427083333,7.727733333333336
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy900, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int, at_cuda_detail::cub::detail::identity_decomposer_t)",362088,97.61051432291667,7.701666666666668
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::fill_,362101,"[[6400, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",362101,31.13427734375,24.680706666666673
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, true>, long*>(at_cuda_detail::cub::ScanTileState<int, true>, int, long*)",362088,46.65478515625,1.7028133333333333
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceUniqueByKeySweepKernel<at_cuda_detail::cub::DeviceUniqueByKeyPolicy<long const*, thrust::THRUST_200302_500_800_860_890_900_NS::counting_iterator<int, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default> >::Policy900, long const*, thrust::THRUST_200302_500_800_860_890_900_NS::counting_iterator<int, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, cuda::std::__4::equal_to<void>, int>(long const*, thrust::THRUST_200302_500_800_860_890_900_NS::counting_iterator<int, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default, thrust::THRUST_200302_500_800_860_890_900_NS::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, cuda::std::__4::equal_to<void>, int, int)",362088,35.27392578125,4.792706666666667
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::krn_partials_per_segment<long>(long*, long const*, long const*, long)",362088,36.352864583333336,1.8623866666666664
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceScanInitKernel<at_cuda_detail::cub::ScanTileState<long, true> >(at_cuda_detail::cub::ScanTileState<long, true>, int)",362088,31.871907552083332,1.3328666666666664
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at_cuda_detail::cub::DeviceScanKernel<at_cuda_detail::cub::DeviceScanPolicy<long, at::cuda::cub::(anonymous namespace)::SumOp<long> >::Policy900, long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int, long>(long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, int, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int)",362088,31.7548828125,2.985786666666667
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::compute_num_of_partial_segments<long>(long const*, long const*, long const*, long*)",362088,31.744303385416668,1.4587733333333333
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::krn_partial_segment_offset<long>(long*, long const*, long const*, long const*, long const*)",362088,31.83935546875,3.1150933333333337
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::compute_grad_weight<c10::Half, long>(long const*, c10::Half const*, long const*, long, long, long const*, long const*, at::AccumulateType<c10::Half, true>::type*, long)",362088,31.43359375,198.21364000000003
autograd::engine::evaluate_function: EmbeddingBackward0,362085,,aten::embedding_dense_backward,362088,"[[4, 2048, 6144], [4, 2048], [], [], []]","void at::native::(anonymous namespace)::sum_and_scatter<c10::Half, long>(long const*, c10::Half*, long, long const*, long const*, at::AccumulateType<c10::Half, true>::type const*, long const*, long const*, long, long)",362088,47.007649739583336,132.65130666666667
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,362109,,aten::add_,362111,"[[6400, 6144], [6400, 6144], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",362111,42.52685546875,62.067119999999996
