cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
aten::clone,107,"[[33554432], []]",aten::copy_,109,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),109,0,47.38310555555554
aten::to,112,"[[], [], [], [], [], []]",aten::copy_,115,"[[], [], []]",Memcpy HtoD (Pageable -> Device),115,9272.671061197916,0.7405249999999965
aten::linalg_vector_norm,119,"[[4096, 4, 4096], [], [], [], []]",aten::linalg_vector_norm,119,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",119,9220.53369140625,48.65280833333331
aten::mul,120,"[[4096, 4, 1], []]",aten::mul,120,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",120,147.31673177083334,1.693413888888886
aten::add,121,"[[4096, 4, 1], [], []]",aten::add,121,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",121,1221.47314453125,1.3759944444444396
aten::div,122,"[[4096, 4, 4096], [4096, 4, 1]]",aten::div,122,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",122,2581.7666015625,182.5424833333332
aten::mul,123,"[[4096], [4096, 4, 4096]]",aten::mul,123,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",123,191.638671875,172.59569444444455
aten::linear,128,"[[4096, 4, 4096], [6144, 4096], []]",aten::mm,135,"[[16384, 4096], [4096, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,135,619.2438151041666,1075.2766638888886
aten::to,148,"[[4096, 1, 1, 128], [], [], [], [], [], [], []]",aten::copy_,151,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),151,556.5843098958334,6.174099999999996
aten::to,152,"[[4096, 1, 1, 128], [], [], [], [], [], [], []]",aten::copy_,155,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),155,5320.4345703125,6.2070083333333335
None,None,None,None,None,None,kernel_0,165,13529.17724609375,36.90336944444444
None,None,None,None,None,None,kernel_1,173,231.40462239583334,61.962188888888875
None,None,None,None,None,None,kernel_0,183,219.20947265625,39.59301111111112
None,None,None,None,None,None,kernel_1,191,185.52360026041666,62.12229166666668
FlashAttnFunc,209,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128], [], [], [], [], [], [], []]",FlashAttnFunc,209,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128], [], [], [], [], [], [], []]","void flash_fwd_kernel<Flash_fwd_kernel_traits<128, 128, 64, 4, false, false, cutlass::half_t, Flash_kernel_traits<128, 128, 64, 4, cutlass::half_t> >, false, true, false, false, true, true, false>(Flash_fwd_params)",209,8826.36865234375,854.0178750000001
aten::linear,219,"[[4096, 4, 2048], [4096, 2048], []]",aten::mm,226,"[[16384, 2048], [2048, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,226,695.7392578125,334.3872777777778
_ReduceFromModelParallelRegion,228,"[[4096, 4, 4096]]",nccl:all_reduce,231,"[[4096, 4, 4096]]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",230,298.7486979166667,2989.567102777778
aten::add,236,"[[4096, 4, 4096], [4096, 4, 4096], []]",aten::add,236,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",236,186.14388020833334,112.92270555555551
aten::linalg_vector_norm,237,"[[4096, 4, 4096], [], [], [], []]",aten::linalg_vector_norm,237,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",237,172.76692708333334,50.62105277777781
aten::mul,238,"[[4096, 4, 1], []]",aten::mul,238,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",238,178.55908203125,1.8642472222222204
aten::add,239,"[[4096, 4, 1], [], []]",aten::add,239,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",239,136.61767578125,1.3740333333333299
aten::div,240,"[[4096, 4, 4096], [4096, 4, 1]]",aten::div,240,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",240,135.10107421875,181.60931944444448
aten::mul,241,"[[4096], [4096, 4, 4096]]",aten::mul,241,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",241,190.77327473958334,172.47804166666677
aten::to,244,"[[], [], [], [], [], []]",aten::copy_,247,"[[], [], []]",Memcpy HtoD (Pageable -> Device),247,102.81575520833333,0.7556416666666652
aten::linear,254,"[[4096, 4, 4096], [8192, 4096], []]",aten::mm,261,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,261,18630.651204427082,1441.7777611111107
aten::add,263,"[[4096, 4, 8192], [8192], []]",aten::add,263,"[[4096, 4, 8192], [8192], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",263,173.95166015625,338.83763333333326
aten::gelu,264,"[[4096, 4, 8192], []]",aten::gelu,264,"[[4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",264,173.81233723958334,217.35271388888873
aten::linear,265,"[[4096, 4, 8192], [4096, 8192], []]",aten::mm,272,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x256x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,272,396.6686197916667,1280.9032444444442
_ReduceFromModelParallelRegion,274,"[[4096, 4, 4096]]",nccl:all_reduce,277,"[[4096, 4, 4096]]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",276,312.8850911458333,3004.272969444446
aten::add,284,"[[4096, 4, 4096], [4096, 4, 4096], []]",aten::add,284,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",284,186.42789713541666,173.9055555555556
aten::add,286,"[[4096, 4, 4096], [4096, 4, 4096], []]",aten::add,286,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",286,174.35888671875,110.36583611111114
