cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
aten::clone,139457,"[[33554432], []]",aten::copy_,139459,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),139459,0,47.37840937499999
aten::to,139462,"[[], [], [], [], [], []]",aten::copy_,139465,"[[], [], []]",Memcpy HtoD (Pageable -> Device),139465,8543.851725260416,0.7837968750000025
aten::linalg_vector_norm,139469,"[[4096, 4, 4096], [], [], [], []]",aten::linalg_vector_norm,139469,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",139469,8455.46435546875,48.731059375000015
aten::mul,139470,"[[4096, 4, 1], []]",aten::mul,139470,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",139470,139.20003255208334,1.69809375
aten::add,139471,"[[4096, 4, 1], [], []]",aten::add,139471,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",139471,1258.44482421875,1.3822906249999947
aten::div,139472,"[[4096, 4, 4096], [4096, 4, 1]]",aten::div,139472,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",139472,2409.5017903645835,182.64497187500015
aten::mul,139473,"[[4096], [4096, 4, 4096]]",aten::mul,139473,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",139473,169.77018229166666,172.57790000000017
aten::linear,139478,"[[4096, 4, 4096], [6144, 4096], []]",aten::mm,139485,"[[16384, 4096], [4096, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,139485,361.8841145833333,1075.5634937500001
aten::to,139498,"[[4096, 1, 1, 128], [], [], [], [], [], [], []]",aten::copy_,139501,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),139501,501.1396484375,6.599865624999997
aten::to,139502,"[[4096, 1, 1, 128], [], [], [], [], [], [], []]",aten::copy_,139505,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),139505,4711.96240234375,6.119534374999997
None,None,None,None,None,None,kernel_0,139515,13082.53564453125,36.625303124999974
None,None,None,None,None,None,kernel_1,139523,389.11767578125,61.88508750000002
None,None,None,None,None,None,kernel_0,139533,486.9939778645833,39.48741562500001
None,None,None,None,None,None,kernel_1,139541,133.90836588541666,62.02988124999998
FlashAttnFunc,139559,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128], [], [], [], [], [], [], []]",FlashAttnFunc,139559,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128], [], [], [], [], [], [], []]","void flash_fwd_kernel<Flash_fwd_kernel_traits<128, 128, 64, 4, false, false, cutlass::half_t, Flash_kernel_traits<128, 128, 64, 4, cutlass::half_t> >, false, true, false, false, true, true, false>(Flash_fwd_params)",139559,10209.078450520834,853.8463218750006
aten::linear,139569,"[[4096, 4, 2048], [4096, 2048], []]",aten::mm,139576,"[[16384, 2048], [2048, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,139576,622.0654296875,333.7691843750001
_ReduceFromModelParallelRegion,139578,"[[4096, 4, 4096]]",nccl:all_reduce,139581,"[[4096, 4, 4096]]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",139580,268.77734375,3065.9222812499984
aten::add,139586,"[[4096, 4, 4096], [4096, 4, 4096], []]",aten::add,139586,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",139586,165.30078125,112.957303125
aten::linalg_vector_norm,139587,"[[4096, 4, 4096], [], [], [], []]",aten::linalg_vector_norm,139587,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",139587,153.62044270833334,50.616193749999994
aten::mul,139588,"[[4096, 4, 1], []]",aten::mul,139588,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",139588,158.28076171875,1.872784374999999
aten::add,139589,"[[4096, 4, 1], [], []]",aten::add,139589,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",139589,121.38818359375,1.3781812499999966
aten::div,139590,"[[4096, 4, 4096], [4096, 4, 1]]",aten::div,139590,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",139590,120.44514973958333,181.6608750000001
aten::mul,139591,"[[4096], [4096, 4, 4096]]",aten::mul,139591,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",139591,171.29345703125,172.4664750000001
aten::to,139594,"[[], [], [], [], [], []]",aten::copy_,139597,"[[], [], []]",Memcpy HtoD (Pageable -> Device),139597,91.39290364583333,0.767900000000001
aten::linear,139604,"[[4096, 4, 4096], [8192, 4096], []]",aten::mm,139611,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,139611,17754.608561197918,1449.1849406249996
aten::add,139613,"[[4096, 4, 8192], [8192], []]",aten::add,139613,"[[4096, 4, 8192], [8192], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",139613,154.87874348958334,338.8502749999999
aten::gelu,139614,"[[4096, 4, 8192], []]",aten::gelu,139614,"[[4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",139614,156.56412760416666,217.38022187500005
aten::linear,139615,"[[4096, 4, 8192], [4096, 8192], []]",aten::mm,139622,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x256x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,139622,358.0224609375,1287.3306874999998
_ReduceFromModelParallelRegion,139624,"[[4096, 4, 4096]]",nccl:all_reduce,139627,"[[4096, 4, 4096]]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",139626,278.0999348958333,3057.178215625
aten::add,139634,"[[4096, 4, 4096], [4096, 4, 4096], []]",aten::add,139634,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",139634,166.43098958333334,173.96749375000002
aten::add,139636,"[[4096, 4, 4096], [4096, 4, 4096], []]",aten::add,139636,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",139636,155.40250651041666,110.35743437499994
