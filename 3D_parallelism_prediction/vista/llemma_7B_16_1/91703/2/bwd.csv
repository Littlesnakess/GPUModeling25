cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
aten::ones_like,48413,"[[], [], [], [], [], []]",aten::fill_,48416,"[[], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)",48416,0,0.9526857142857147
autograd::engine::evaluate_function: MulBackward0,47061,,aten::mul,47063,"[[], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",47063,1399.8580729166667,1.3394000000000001
autograd::engine::evaluate_function: DivBackward0,47064,,aten::div,47066,"[[], []]","void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",47066,572.7605794270834,1.3449142857142857
autograd::engine::evaluate_function: DivBackward0,47067,,aten::div,47069,"[[], []]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::DivFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::DivFunctor<float> >, std::array<char*, 3ul>)",47069,427.35595703125,1.4335714285714287
autograd::engine::evaluate_function: MulBackward0,47074,,aten::mul,47076,"[[16384], [16384]]","void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",47076,904.8107096354166,2.2857142857142856
autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward,47081,,aten::arange,47086,"[[], [], [], [0]]","void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)",47086,1247.9563802083333,1.2735714285714288
autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward,47081,,aten::index,47088,"[[16384, 25216], []]","void at::native::index_elementwise_kernel<128, 4, at::native::gpu_index_kernel<at::native::index_kernel_impl<at::native::OpaqueType<4> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1}>(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>, at::native::index_kernel_impl<at::native::OpaqueType<4> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1} const&)::{lambda(int)#1}>(long, at::native::gpu_index_kernel<at::native::index_kernel_impl<at::native::OpaqueType<4> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1}>(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>, at::native::index_kernel_impl<at::native::OpaqueType<4> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1} const&)::{lambda(int)#1})",47088,567.8235677083334,8.588714285714289
autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward,47081,,aten::copy_,47098,"[[16384], [16384], []]","void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, std::array<char*, 2ul>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1> >(int, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, std::array<char*, 2ul>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1>)",47098,459.7706705729167,3.594857142857143
autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward,47081,,aten::sub,47100,"[[], [16384], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnOther_add<float>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnOther_add<float>, std::array<char*, 2ul>)",47100,464.9226888020833,1.3284571428571432
autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward,47081,,aten::sub_,47101,"[[16384], [16384], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",47101,284.0074869791667,1.3421714285714288
autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward,47081,,aten::_index_put_impl_,47103,"[[16384, 25216], [], [16384], [], []]","void at::native::index_elementwise_kernel<128, 4, at::native::gpu_index_kernel<at::native::index_put_kernel_impl<at::native::OpaqueType<4> >(at::TensorIterator&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1}>(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>, at::native::index_put_kernel_impl<at::native::OpaqueType<4> >(at::TensorIterator&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1} const&)::{lambda(int)#1}>(long, at::native::gpu_index_kernel<at::native::index_put_kernel_impl<at::native::OpaqueType<4> >(at::TensorIterator&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1}>(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>, at::native::index_put_kernel_impl<at::native::OpaqueType<4> >(at::TensorIterator&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1} const&)::{lambda(int)#1})",47103,547.4889322916666,5.407971428571428
autograd::engine::evaluate_function: _VocabParallelCrossEntropyBackward,47081,,aten::mul_,48647,"[[4, 4096, 25216], [4, 4096, 1]]","void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",48647,413.1383463541667,1287.3608000000002
autograd::engine::evaluate_function: ToCopyBackward0,48648,,aten::copy_,48653,"[[4, 4096, 25216], [4, 4096, 25216], []]","void at::native::vectorized_elementwise_kernel<4, at::native::float16_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda(float)#1}, std::array<char*, 2ul> >(int, at::native::float16_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda(float)#1}, std::array<char*, 2ul>)",48653,16.597493489583332,670.9396285714288
autograd::engine::evaluate_function: MmBackward0,48658,,aten::mm,48663,"[[25216, 16384], [16384, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,48663,47.06103515625,3576.1128285714285
autograd::engine::evaluate_function: MmBackward0,48658,,aten::mm,48670,"[[16384, 25216], [25216, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,48670,52.469075520833336,3646.4050000000007
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,48680,,aten::add_,48682,"[[25216, 4096], [25216, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",48682,17.322591145833332,163.3628
autograd::engine::evaluate_function: _CopyToModelParallelRegionBackward,48683,,record_param_comms,48686,"[[[4, 4096, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",48686,24.565266927083332,2991.1891714285707
autograd::engine::evaluate_function: MulBackward0,48689,,aten::mul,48691,"[[4, 4096, 4096], [4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",48691,17.535807291666668,173.82205714285715
autograd::engine::evaluate_function: MulBackward0,48689,,aten::mul,48692,"[[4, 4096, 4096], [4, 4096, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",48692,18.294108072916668,110.42362857142861
autograd::engine::evaluate_function: MulBackward0,48689,,aten::sum,48693,"[[4, 4096, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",48693,49.108072916666664,58.37097142857143
autograd::engine::evaluate_function: torch::autograd::AccumulateGrad,48695,,aten::add_,48697,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",48697,21.929850260416668,1.7673142857142858
autograd::engine::evaluate_function: DivBackward0,48698,,aten::neg,48700,"[[4, 4096, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",48700,14.68896484375,81.64577142857142
autograd::engine::evaluate_function: DivBackward0,48698,,aten::div,48701,"[[4, 4096, 4096], [4, 4096, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",48701,19.79638671875,184.86939999999996
autograd::engine::evaluate_function: DivBackward0,48698,,aten::div,48702,"[[4, 4096, 4096], [4, 4096, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",48702,21.76904296875,184.0585142857143
autograd::engine::evaluate_function: DivBackward0,48698,,aten::mul,48703,"[[4, 4096, 4096], [4, 4096, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",48703,21.428385416666668,110.18208571428572
autograd::engine::evaluate_function: DivBackward0,48698,,aten::div,48704,"[[4, 4096, 4096], [4, 4096, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",48704,19.339029947916668,189.21405714285717
autograd::engine::evaluate_function: DivBackward0,48698,,aten::sum,48705,"[[4, 4096, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",48705,19.850748697916668,51.229714285714294
autograd::engine::evaluate_function: MulBackward0,48708,,aten::mul,48710,"[[4, 4096, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",48710,21.034342447916668,1.8779142857142859
autograd::engine::evaluate_function: LinalgVectorNormBackward0,48711,,aten::div,48713,"[[4, 4096, 4096], [4, 4096, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",48713,16.27734375,181.43439999999998
autograd::engine::evaluate_function: LinalgVectorNormBackward0,48711,,aten::eq,48714,"[[4, 4096, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",48714,19.637044270833332,1.906257142857143
autograd::engine::evaluate_function: LinalgVectorNormBackward0,48711,,aten::masked_fill_,48715,"[[4, 4096, 4096], [4, 4096, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",48715,14.410481770833334,188.81902857142862
autograd::engine::evaluate_function: LinalgVectorNormBackward0,48711,,aten::mul,48718,"[[4, 4096, 1], [4, 4096, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",48718,20.746907552083332,173.58711428571425
autograd::engine::evaluate_function: LinalgVectorNormBackward0,48711,,aten::add_,48719,"[[4, 4096, 4096], [4, 4096, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",48719,21.045084635416668,108.60694285714288
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::fill_,48731,"[[1, 1, 4096, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",48731,17.438313802083332,6.568085714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::fill_,48735,"[[67108864], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",48735,996.5252278645834,41.078314285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::copy_,48742,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),48742,339.7083333333333,49.94508571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,record_param_comms,48744,"[[[33554432]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",48744,838.2625325520834,1744.0692571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::copy_,48751,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),48751,18.100748697916668,48.652342857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::copy_,48754,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),48754,17.65283203125,48.56905714285713
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::copy_,48771,"[[], [], []]",Memcpy HtoD (Pageable -> Device),48771,10.451985677083334,0.7360000000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::linalg_vector_norm,48775,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",48775,1109.8238932291667,51.375028571428565
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,48776,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",48776,15.307291666666666,1.6703714285714288
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add,48777,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",48777,294.525390625,1.3960571428571427
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::div,48778,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",48778,319.66455078125,183.1998857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,48779,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",48779,17.961588541666668,172.83937142857144
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mm,48791,"[[16384, 4096], [4096, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,48791,39.060221354166664,1088.0533142857141
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::copy_,48807,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),48807,60.853678385416664,6.080828571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::copy_,48811,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),48811,515.7174479166666,5.589914285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::neg,48821,"[[4096, 1, 1, 128], [4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",48821,1311.7501627604167,42.782771428571436
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::cat,48833,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",48833,339.1316731770833,140.62565714285716
None,None,None,None,None,None,kernel_1,48834,17.002766927083332,61.26297142857145
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::neg,48844,"[[4096, 4, 16, 128], [4096, 1, 1, 128], [4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",48844,16.841959635416668,45.37545714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::cat,48855,"[[4096, 4, 16, 128], [[4096, 4, 16, 64], [4096, 4, 16, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",48855,202.41878255208334,140.0872285714286
None,None,None,None,None,None,kernel_1,48856,16.745930989583332,61.13854285714287
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,FlashAttnFunc,48874,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128], [], [], [], [], [], [], []]","void flash_fwd_kernel<Flash_fwd_kernel_traits<128, 128, 64, 4, false, false, cutlass::half_t, Flash_kernel_traits<128, 128, 64, 4, cutlass::half_t> >, false, true, false, false, true, true, false>(Flash_fwd_params)",48874,55.027506510416664,854.3753714285712
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mm,48891,"[[16384, 2048], [2048, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,48891,70.76123046875,335.16065714285713
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,record_param_comms,48895,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",48895,26.5498046875,3001.213371428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add,48901,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",48901,17.7802734375,112.90942857142858
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::linalg_vector_norm,48902,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",48902,16.480305989583332,50.68471428571431
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,48903,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",48903,17.226725260416668,1.8697142857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add,48904,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",48904,13.31201171875,1.3650285714285721
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::div,48905,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",48905,13.25732421875,181.90431428571432
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,48906,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",48906,18.15380859375,172.55134285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::copy_,48912,"[[], [], []]",Memcpy HtoD (Pageable -> Device),48912,9.792317708333334,0.7661428571428575
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mm,48926,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,48926,2052.7672526041665,1465.4362571428574
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add,48928,"[[4096, 4, 8192], [8192], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",48928,16.841796875,339.43688571428567
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::gelu,48929,"[[4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",48929,16.8642578125,218.01642857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mm,48937,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x256x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,48937,44.42529296875,1280.8394285714282
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,record_param_comms,48941,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",48941,29.781575520833332,2993.9220285714277
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add,48949,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",48949,17.684733072916668,174.29662857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add,48951,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",48951,18.399576822916668,110.47551428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::sum,48958,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",48958,47.231608072916664,58.14262857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,48962,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",48962,16.896321614583332,1.8376285714285716
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::copy_,48971,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",48971,12.94921875,171.68820000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mm,48978,"[[4096, 16384], [16384, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,48978,49.066080729166664,1257.4840857142858
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mm,48985,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,48985,53.769694010416664,1285.9228571428569
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,48997,"[[4096, 8192], [4096, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",48997,21.961100260416668,52.791342857142844
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::gelu_backward,49000,"[[4096, 4, 8192], [4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul>)",49000,19.45556640625,289.6490571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::sum,49003,"[[4096, 4, 8192], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",49003,48.618489583333336,88.81277142857144
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,49007,"[[8192], [8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49007,17.71728515625,1.8614571428571436
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mm,49017,"[[8192, 16384], [16384, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,49017,48.73583984375,1250.5895142857141
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mm,49024,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,49024,49.8125,1266.821
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,49036,"[[8192, 4096], [8192, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49036,18.784016927083332,52.05231428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,record_param_comms,49040,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",49040,35.028483072916664,3031.0818571428567
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,49045,"[[4096, 4, 4096], [4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49045,25.02392578125,173.7188285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,49046,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",49046,18.208170572916668,110.44628571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::sum,49047,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",49047,47.0810546875,58.27702857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,49051,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49051,18.037923177083332,1.8257999999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::neg,49054,"[[4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",49054,13.099283854166666,81.5990857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::div,49055,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49055,19.861002604166668,184.84737142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::div,49056,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49056,21.61083984375,183.9349142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,49057,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",49057,20.255859375,110.30931428571431
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::div,49058,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49058,19.530110677083332,188.9853428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::sum,49059,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",49059,18.25048828125,51.084228571428575
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add,49060,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",49060,16.81005859375,199.99519999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,49065,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",49065,16.906901041666668,1.8925714285714288
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::div,49068,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49068,12.810221354166666,183.11662857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::eq,49069,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",49069,20.266764322916668,1.9172571428571437
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::masked_fill_,49070,"[[4096, 4, 4096], [4096, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",49070,17.225911458333332,188.90679999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,49073,"[[4096, 4, 1], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49073,19.84033203125,173.5606571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,49074,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",49074,19.987955729166668,224.26371428571431
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::copy_,49085,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49085,18.463541666666668,174.75657142857136
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mm,49092,"[[4096, 16384], [16384, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,49092,17.013509114583332,325.9830857142858
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mm,49099,"[[16384, 4096], [4096, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,49099,52.585611979166664,334.73211428571426
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,49111,"[[4096, 2048], [4096, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49111,17.599772135416668,13.214971428571427
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,FlashAttnFuncBackward,49125,"[[4, 4096, 16, 128]]","void flash_bwd_dot_do_o_kernel<true, Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> > >(Flash_bwd_params)",49125,15.988444010416666,78.05085714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,FlashAttnFuncBackward,49125,"[[4, 4096, 16, 128]]","void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> >, false, true, false, false, true, true>(Flash_bwd_params)",49125,22.015950520833332,2317.3778571428566
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,FlashAttnFuncBackward,49125,"[[4, 4096, 16, 128]]","void flash_bwd_convert_dq_kernel<Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> > >(Flash_bwd_params, int)",49125,20.458821614583332,70.2665714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,49164,"[[4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49164,20.213541666666668,96.83831428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,49168,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], [4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49168,18.18701171875,96.35919999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::neg,49171,"[[4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49171,17.0771484375,44.505114285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::fill_,49178,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",49178,16.906901041666668,21.391285714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::copy_,49181,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49181,16.925944010416668,46.06408571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,49182,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49182,19.689290364583332,55.40597142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::fill_,49189,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",49189,21.579264322916668,21.349371428571423
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::copy_,49192,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49192,20.298828125,45.86822857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,49193,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49193,19.60595703125,55.518571428571434
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,49197,"[[4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49197,18.218587239583332,96.78702857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,49201,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], [4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49201,16.82080078125,96.27968571428569
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::neg,49204,"[[4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49204,17.013834635416668,44.52145714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::fill_,49211,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",49211,16.896158854166668,21.32285714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::copy_,49214,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49214,20.255208333333332,45.91037142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,49215,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49215,21.589518229166668,55.43262857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::fill_,49222,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",49222,19.91455078125,21.275142857142864
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::copy_,49225,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49225,19.78662109375,45.88654285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,49226,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49226,18.282063802083332,55.51034285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::cat,49229,"[[[4096, 4, 16, 128], [4096, 4, 16, 128], [4096, 4, 16, 128]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy_contig<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 128, 1>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",49229,16.821614583333332,254.98794285714294
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mm,49243,"[[6144, 16384], [16384, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,49243,46.974446614583336,937.2179142857141
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mm,49250,"[[16384, 6144], [6144, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,49250,53.770670572916664,955.2409714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,49262,"[[6144, 4096], [6144, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49262,20.372884114583332,38.95274285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,record_param_comms,49266,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",49266,30.603190104166668,3004.5998571428577
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,49271,"[[4096, 4, 4096], [4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49271,25.172200520833332,173.6885714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,49272,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",49272,18.19677734375,110.40982857142859
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::sum,49273,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",49273,47.561848958333336,58.05837142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,49277,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49277,21.7919921875,1.8468285714285717
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::neg,49280,"[[4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",49280,14.421223958333334,81.63397142857146
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::div,49281,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49281,19.818196614583332,184.89402857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::div,49282,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49282,19.744466145833332,184.04554285714283
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,49283,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",49283,21.513671875,110.33842857142858
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::div,49284,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49284,21.055989583333332,186.40254285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::sum,49285,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",49285,20.3310546875,50.8237142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,49286,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",49286,19.934733072916668,220.87631428571427
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,49291,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",49291,21.663736979166668,1.868771428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::div,49294,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49294,15.807291666666666,183.60214285714287
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::eq,49295,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",49295,20.2998046875,1.8769999999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::masked_fill_,49296,"[[4096, 4, 4096], [4096, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",49296,14.400065104166666,188.8565142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::mul,49299,"[[4096, 4, 1], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49299,20.842610677083332,173.6439714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::add_,49300,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",49300,21.173014322916668,224.29837142857144
autograd::engine::evaluate_function: CheckpointFunctionBackward,48726,,aten::copy_,49305,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49305,16.778483072916668,174.73551428571432
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::fill_,49311,"[[1, 1, 4096, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",49311,1690.9576822916667,6.442914285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::fill_,49315,"[[67108864], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",49315,1158.8478190104167,41.106742857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::copy_,49322,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),49322,285.28662109375,49.89671428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,record_param_comms,49324,"[[[33554432]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",49324,822.5496419270834,1750.152857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::copy_,49331,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),49331,17.982747395833332,48.509685714285716
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::copy_,49334,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),49334,17.483561197916668,48.62117142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::copy_,49351,"[[], [], []]",Memcpy HtoD (Pageable -> Device),49351,10.12255859375,0.7323428571428575
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::linalg_vector_norm,49355,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",49355,1106.4431966145833,51.346571428571416
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49356,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",49356,14.99755859375,1.674971428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add,49357,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",49357,298.6741536458333,1.3814571428571427
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::div,49358,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49358,321.8531901041667,183.45131428571432
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49359,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49359,18.111653645833332,172.83285714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mm,49371,"[[16384, 4096], [4096, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,49371,38.570475260416664,1087.3282571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::copy_,49387,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),49387,58.3671875,5.562457142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::copy_,49391,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),49391,529.6484375,5.160199999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::neg,49401,"[[4096, 1, 1, 128], [4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49401,1295.2496744791667,42.817371428571434
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::cat,49413,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",49413,301.4905598958333,140.56702857142855
None,None,None,None,None,None,kernel_1,49414,16.789225260416668,61.321485714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::neg,49424,"[[4096, 4, 16, 128], [4096, 1, 1, 128], [4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49424,17.09814453125,45.2374
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::cat,49435,"[[4096, 4, 16, 128], [[4096, 4, 16, 64], [4096, 4, 16, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",49435,16.735514322916668,139.8860857142857
None,None,None,None,None,None,kernel_1,49436,16.790364583333332,60.984942857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,FlashAttnFunc,49454,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128], [], [], [], [], [], [], []]","void flash_fwd_kernel<Flash_fwd_kernel_traits<128, 128, 64, 4, false, false, cutlass::half_t, Flash_kernel_traits<128, 128, 64, 4, cutlass::half_t> >, false, true, false, false, true, true, false>(Flash_fwd_params)",49454,17.610026041666668,851.6462857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mm,49471,"[[16384, 2048], [2048, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,49471,70.15397135416667,334.82968571428586
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,record_param_comms,49475,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",49475,25.888346354166668,3004.2470000000003
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add,49481,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49481,17.803059895833332,113.14257142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::linalg_vector_norm,49482,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",49482,16.532552083333332,50.41125714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49483,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",49483,17.184244791666668,1.8651428571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add,49484,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",49484,13.3330078125,1.361371428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::div,49485,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49485,13.215169270833334,181.95548571428577
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49486,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49486,19.413411458333332,172.70314285714284
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::copy_,49492,"[[], [], []]",Memcpy HtoD (Pageable -> Device),49492,9.9404296875,0.7652571428571432
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mm,49506,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,49506,2018.8693033854167,1462.838914285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add,49508,"[[4096, 4, 8192], [8192], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",49508,16.52197265625,339.44048571428567
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::gelu,49509,"[[4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",49509,16.6083984375,218.00094285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mm,49517,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x256x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,49517,43.44384765625,1280.406
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,record_param_comms,49521,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",49521,29.760579427083332,3005.409771428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add,49529,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",49529,17.90869140625,174.20431428571425
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add,49531,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49531,16.587239583333332,110.31102857142858
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::sum,49538,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",49538,45.31201171875,58.29600000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49542,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49542,17.194173177083332,1.8212285714285712
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mm,49554,"[[4096, 16384], [16384, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,49554,47.626627604166664,1265.4722857142858
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mm,49561,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,49561,48.415201822916664,1294.7072285714287
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49573,"[[4096, 8192], [4096, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49573,21.9619140625,52.690514285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::gelu_backward,49576,"[[4096, 4, 8192], [4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul>)",49576,19.914388020833332,289.0758
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::sum,49579,"[[4096, 4, 8192], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",49579,47.253580729166664,88.74234285714287
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49583,"[[8192], [8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49583,17.311197916666668,1.877942857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mm,49593,"[[8192, 16384], [16384, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,49593,47.039225260416664,1248.521514285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mm,49600,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,49600,48.436848958333336,1271.4196285714288
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49612,"[[8192, 4096], [8192, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49612,19.019694010416668,52.142971428571435
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,record_param_comms,49616,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",49616,37.567545572916664,3089.7316285714287
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49621,"[[4096, 4, 4096], [4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49621,23.296223958333332,173.7151714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49622,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",49622,16.7998046875,110.37780000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::sum,49623,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",49623,46.698079427083336,58.34
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49627,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49627,16.949055989583332,1.8294857142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::neg,49630,"[[4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",49630,14.32568359375,81.69051428571427
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::div,49631,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49631,21.514485677083332,184.93797142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::div,49632,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49632,21.268229166666668,183.99625714285716
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49633,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",49633,20.202799479166668,110.30094285714284
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::div,49634,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49634,18.495768229166668,186.42274285714288
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::sum,49635,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",49635,17.173177083333332,50.93894285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add,49636,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49636,17.00244140625,105.86034285714288
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49641,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",49641,17.930013020833332,1.9601999999999995
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::div,49644,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49644,14.356770833333334,183.6350857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::eq,49645,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",49645,21.396647135416668,1.9264000000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::masked_fill_,49646,"[[4096, 4, 4096], [4096, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",49646,17.258626302083332,188.91594285714282
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49649,"[[4096, 4, 1], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49649,19.924641927083332,173.72528571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49650,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49650,18.314290364583332,108.88105714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mm,49664,"[[4096, 16384], [16384, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,49664,17.2900390625,324.7975428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mm,49671,"[[16384, 4096], [4096, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,49671,52.64990234375,335.905
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49683,"[[4096, 2048], [4096, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49683,17.258138020833332,13.234114285714288
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,FlashAttnFuncBackward,49697,"[[4, 4096, 16, 128]]","void flash_bwd_dot_do_o_kernel<true, Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> > >(Flash_bwd_params)",49697,14.133626302083334,77.76374285714287
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,FlashAttnFuncBackward,49697,"[[4, 4096, 16, 128]]","void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> >, false, true, false, false, true, true>(Flash_bwd_params)",49697,21.685221354166668,2313.0634
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,FlashAttnFuncBackward,49697,"[[4, 4096, 16, 128]]","void flash_bwd_convert_dq_kernel<Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> > >(Flash_bwd_params, int)",49697,22.058430989583332,70.20717142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49736,"[[4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49736,20.138834635416668,96.94802857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49740,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], [4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49740,18.249186197916668,96.47437142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::neg,49743,"[[4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49743,16.79052734375,44.56914285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::fill_,49750,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",49750,16.500651041666668,21.41051428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::copy_,49753,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49753,16.89599609375,46.006400000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49754,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49754,18.474772135416668,55.40962857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::fill_,49761,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",49761,21.2373046875,21.340142857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::copy_,49764,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49764,21.098795572916668,45.843628571428575
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49765,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49765,20.1064453125,55.50565714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49769,"[[4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49769,18.186360677083332,96.884
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49773,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], [4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49773,16.4052734375,96.28971428571427
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::neg,49776,"[[4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49776,17.215006510416668,44.49685714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::fill_,49783,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",49783,17.173502604166668,21.348342857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::copy_,49786,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49786,18.314778645833332,45.8171142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49787,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49787,21.728190104166668,55.409742857142845
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::fill_,49794,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",49794,20.971028645833332,21.274257142857138
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::copy_,49797,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49797,20.171061197916668,45.88568571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49798,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49798,18.00439453125,55.48648571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::cat,49801,"[[[4096, 4, 16, 128], [4096, 4, 16, 128], [4096, 4, 16, 128]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy_contig<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 128, 1>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",49801,16.5546875,254.89102857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mm,49815,"[[6144, 16384], [16384, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,49815,46.326009114583336,936.8494285714289
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mm,49822,"[[16384, 6144], [6144, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,49822,53.107584635416664,953.8842857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49834,"[[6144, 4096], [6144, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49834,18.75146484375,39.00028571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,record_param_comms,49838,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",49838,31.391438802083332,2995.822771428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49843,"[[4096, 4, 4096], [4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49843,25.08740234375,173.67777142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49844,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",49844,19.988932291666668,110.32925714285716
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::sum,49845,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",49845,48.57470703125,58.03842857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49849,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49849,20.010416666666668,1.8669428571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::neg,49852,"[[4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",49852,16.127766927083332,81.61374285714288
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::div,49853,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49853,21.5458984375,184.72945714285711
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::div,49854,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49854,19.63720703125,184.06934285714283
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49855,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",49855,19.722330729166668,110.17942857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::div,49856,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49856,21.129720052083332,186.51231428571424
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::sum,49857,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",49857,21.472493489583332,51.00262857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49858,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49858,19.775065104166668,104.7157714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49863,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",49863,20.235026041666668,1.8953142857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::div,49866,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49866,15.796875,184.1068
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::eq,49867,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",49867,20.9912109375,1.9099428571428567
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::masked_fill_,49868,"[[4096, 4, 4096], [4096, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",49868,14.6875,188.86748571428578
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::mul,49871,"[[4096, 4, 1], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49871,19.936197916666668,173.57425714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49306,,aten::add_,49872,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",49872,16.853190104166668,108.91142857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::fill_,49882,"[[1, 1, 4096, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",49882,1616.2906901041667,6.45748571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::fill_,49886,"[[67108864], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",49886,1171.3154296875,41.080371428571425
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::copy_,49893,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),49893,283.0159505208333,49.92485714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,record_param_comms,49895,"[[[33554432]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",49895,802.7428385416666,1791.6317428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::copy_,49902,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),49902,18.3466796875,48.577228571428584
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::copy_,49905,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),49905,17.482259114583332,48.51065714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::copy_,49922,"[[], [], []]",Memcpy HtoD (Pageable -> Device),49922,10.175944010416666,0.7195428571428575
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::linalg_vector_norm,49926,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",49926,1081.21484375,51.46639999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,49927,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",49927,13.706380208333334,1.6822857142857144
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add,49928,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",49928,275.56103515625,1.407057142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::div,49929,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",49929,318.1611328125,183.06085714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,49930,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",49930,17.94091796875,172.73042857142858
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mm,49942,"[[16384, 4096], [4096, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,49942,39.956217447916664,1084.2279714285717
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::copy_,49958,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),49958,56.7568359375,6.277457142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::copy_,49962,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),49962,517.0296223958334,6.737257142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::neg,49972,"[[4096, 1, 1, 128], [4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49972,1289.0213216145833,42.72868571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::cat,49984,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",49984,280.28564453125,140.60917142857141
None,None,None,None,None,None,kernel_1,49985,16.811197916666668,61.06917142857141
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::neg,49995,"[[4096, 4, 16, 128], [4096, 1, 1, 128], [4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",49995,17.36474609375,45.45311428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::cat,50006,"[[4096, 4, 16, 128], [[4096, 4, 16, 64], [4096, 4, 16, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",50006,16.821451822916668,139.93460000000002
None,None,None,None,None,None,kernel_1,50007,16.939127604166668,61.37340000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,FlashAttnFunc,50025,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128], [], [], [], [], [], [], []]","void flash_fwd_kernel<Flash_fwd_kernel_traits<128, 128, 64, 4, false, false, cutlass::half_t, Flash_kernel_traits<128, 128, 64, 4, cutlass::half_t> >, false, true, false, false, true, true, false>(Flash_fwd_params)",50025,16.703287760416668,850.6707428571427
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mm,50042,"[[16384, 2048], [2048, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,50042,69.91943359375,334.7475142857144
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,record_param_comms,50046,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",50046,27.636881510416668,2947.639457142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add,50052,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50052,17.90966796875,113.07039999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::linalg_vector_norm,50053,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",50053,16.426106770833332,50.65248571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50054,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",50054,17.003092447916668,1.8724571428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add,50055,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",50055,13.354817708333334,1.379657142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::div,50056,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50056,13.118489583333334,181.77631428571434
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50057,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50057,18.239908854166668,172.52948571428578
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::copy_,50063,"[[], [], []]",Memcpy HtoD (Pageable -> Device),50063,9.8447265625,0.7642857142857146
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mm,50077,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,50077,1962.9462890625,1459.5592571428574
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add,50079,"[[4096, 4, 8192], [8192], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",50079,16.767252604166668,339.2833428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::gelu,50080,"[[4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",50080,16.512369791666668,217.8160571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mm,50088,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x256x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50088,44.12744140625,1278.6598285714288
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,record_param_comms,50092,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",50092,29.7705078125,3008.7231142857136
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add,50100,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",50100,17.972819010416668,174.20797142857145
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add,50102,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50102,16.800455729166668,110.37502857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::sum,50109,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",50109,45.397298177083336,58.39379999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50113,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50113,17.4931640625,1.8614571428571431
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mm,50125,"[[4096, 16384], [16384, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50125,47.7646484375,1263.9866857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mm,50132,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50132,48.371744791666664,1294.813257142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50144,"[[4096, 8192], [4096, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50144,20.352376302083332,52.79297142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::gelu_backward,50147,"[[4096, 4, 8192], [4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul>)",50147,18.52734375,288.77585714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::sum,50150,"[[4096, 4, 8192], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",50150,46.964680989583336,88.97457142857144
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50154,"[[8192], [8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50154,17.355305989583332,1.837685714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mm,50164,"[[8192, 16384], [16384, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50164,47.338541666666664,1246.6565142857144
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mm,50171,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50171,50.01611328125,1270.8746571428576
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50183,"[[8192, 4096], [8192, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50183,20.212890625,52.00594285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,record_param_comms,50187,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",50187,37.002604166666664,3079.8748285714278
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50192,"[[4096, 4, 4096], [4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50192,23.499348958333332,173.7106
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50193,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",50193,16.831868489583332,110.34031428571427
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::sum,50194,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",50194,45.56689453125,58.176228571428574
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50198,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50198,17.716959635416668,1.8404571428571432
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::neg,50201,"[[4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",50201,14.99658203125,81.5296
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::div,50202,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50202,19.722493489583332,184.94245714285717
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::div,50203,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50203,19.957845052083332,183.99802857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50204,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",50204,21.58935546875,110.19591428571431
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::div,50205,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50205,19.75537109375,186.1593714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::sum,50206,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",50206,16.8427734375,51.079628571428564
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add,50207,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50207,16.99169921875,105.92800000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50212,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",50212,17.13037109375,1.9264000000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::div,50215,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50215,14.197591145833334,183.58657142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::eq,50216,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",50216,20.032389322916668,1.9200000000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::masked_fill_,50217,"[[4096, 4, 4096], [4096, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",50217,14.76171875,188.8565142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50220,"[[4096, 4, 1], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50220,21.568359375,173.70691428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50221,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50221,19.732259114583332,108.76411428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mm,50235,"[[4096, 16384], [16384, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50235,17.076985677083332,324.6558857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mm,50242,"[[16384, 4096], [4096, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,50242,52.298177083333336,336.3739714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50254,"[[4096, 2048], [4096, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50254,16.970052083333332,13.162028571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,FlashAttnFuncBackward,50268,"[[4, 4096, 16, 128]]","void flash_bwd_dot_do_o_kernel<true, Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> > >(Flash_bwd_params)",50268,14.0048828125,77.82402857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,FlashAttnFuncBackward,50268,"[[4, 4096, 16, 128]]","void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> >, false, true, false, false, true, true>(Flash_bwd_params)",50268,20.181315104166668,2307.9993142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,FlashAttnFuncBackward,50268,"[[4, 4096, 16, 128]]","void flash_bwd_convert_dq_kernel<Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> > >(Flash_bwd_params, int)",50268,20.201334635416668,70.25848571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50307,"[[4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50307,21.76025390625,96.81999999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50311,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], [4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50311,20.021321614583332,96.44425714285711
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::neg,50314,"[[4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",50314,16.970377604166668,44.478571428571435
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::fill_,50321,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",50321,17.173665364583332,21.423342857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::copy_,50324,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",50324,17.150390625,45.86642857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50325,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50325,18.581705729166668,55.58982857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::fill_,50332,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",50332,20.009765625,21.313600000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::copy_,50335,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",50335,20.011393229166668,45.77774285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50336,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50336,21.503580729166668,55.53311428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50340,"[[4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50340,20.191080729166668,96.7953142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50344,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], [4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50344,17.02490234375,96.31625714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::neg,50347,"[[4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",50347,16.629231770833332,44.440171428571425
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::fill_,50354,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",50354,16.565755208333332,21.343828571428578
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::copy_,50357,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",50357,18.569173177083332,45.84082857142859
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50358,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50358,19.498372395833332,55.54508571428574
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::fill_,50365,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",50365,20.01025390625,21.305400000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::copy_,50368,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",50368,21.535970052083332,45.82257142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50369,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50369,20.21337890625,55.51934285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::cat,50372,"[[[4096, 4, 16, 128], [4096, 4, 16, 128], [4096, 4, 16, 128]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy_contig<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 128, 1>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",50372,16.554361979166668,254.77765714285712
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mm,50386,"[[6144, 16384], [16384, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50386,46.260416666666664,934.6286857142858
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mm,50393,"[[16384, 6144], [6144, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50393,51.423990885416664,951.5016285714283
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50405,"[[6144, 4096], [6144, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50405,19.188802083333332,38.90785714285713
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,record_param_comms,50409,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",50409,31.487955729166668,2996.103571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50414,"[[4096, 4, 4096], [4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50414,25.130045572916668,173.7234
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50415,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",50415,18.548665364583332,110.32197142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::sum,50416,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",50416,49.770670572916664,58.365514285714276
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50420,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50420,22.037272135416668,1.8221714285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::neg,50423,"[[4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",50423,14.506510416666666,81.60911428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::div,50424,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50424,19.913899739583332,184.77697142857147
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::div,50425,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50425,21.557454427083332,184.0290857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50426,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",50426,21.311686197916668,110.29288571428575
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::div,50427,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50427,19.786783854166668,186.53788571428575
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::sum,50428,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",50428,19.967610677083332,50.979057142857144
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50429,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50429,21.439615885416668,104.78705714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50434,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",50434,21.36376953125,1.921742857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::div,50437,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50437,14.335286458333334,184.17274285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::eq,50438,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",50438,19.90380859375,1.9391714285714288
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::masked_fill_,50439,"[[4096, 4, 4096], [4096, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",50439,16.06396484375,188.85922857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::mul,50442,"[[4096, 4, 1], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50442,21.162760416666668,173.6338857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,49877,,aten::add_,50443,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50443,16.6494140625,108.78048571428575
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::fill_,50453,"[[1, 1, 4096, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",50453,1576.7626953125,6.458428571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::fill_,50457,"[[67108864], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",50457,1113.2989908854167,41.1004
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::copy_,50464,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),50464,297.3738606770833,49.90114285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,record_param_comms,50466,"[[[33554432]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",50466,767.6722005208334,1785.3422857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::copy_,50473,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),50473,17.599772135416668,48.591999999999985
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::copy_,50476,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),50476,18.186848958333332,48.51602857142859
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::copy_,50493,"[[], [], []]",Memcpy HtoD (Pageable -> Device),50493,10.388997395833334,0.7231714285714289
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::linalg_vector_norm,50497,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",50497,1080.24609375,51.2168
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50498,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",50498,13.7607421875,1.6713142857142862
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add,50499,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",50499,255.82649739583334,1.385085714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::div,50500,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50500,305.9173177083333,183.1276
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50501,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50501,18.656412760416668,172.67925714285718
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mm,50513,"[[16384, 4096], [4096, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,50513,39.635579427083336,1083.1217714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::copy_,50529,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),50529,45.727701822916664,6.678771428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::copy_,50533,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),50533,499.7732747395833,6.7784571428571425
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::neg,50543,"[[4096, 1, 1, 128], [4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",50543,1261.55322265625,42.718600000000016
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::cat,50555,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",50555,254.37679036458334,140.63117142857143
None,None,None,None,None,None,kernel_1,50556,16.94921875,61.25934285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::neg,50566,"[[4096, 4, 16, 128], [4096, 1, 1, 128], [4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",50566,17.173502604166668,45.32228571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::cat,50577,"[[4096, 4, 16, 128], [[4096, 4, 16, 64], [4096, 4, 16, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",50577,16.479329427083332,139.66680000000002
None,None,None,None,None,None,kernel_1,50578,16.82177734375,61.19960000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,FlashAttnFunc,50596,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128], [], [], [], [], [], [], []]","void flash_fwd_kernel<Flash_fwd_kernel_traits<128, 128, 64, 4, false, false, cutlass::half_t, Flash_kernel_traits<128, 128, 64, 4, cutlass::half_t> >, false, true, false, false, true, true, false>(Flash_fwd_params)",50596,16.60791015625,847.7578857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mm,50613,"[[16384, 2048], [2048, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,50613,69.48177083333333,334.2135142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,record_param_comms,50617,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",50617,26.30419921875,2956.3873428571424
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add,50623,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50623,17.97265625,113.04105714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::linalg_vector_norm,50624,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",50624,16.724446614583332,50.66748571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50625,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",50625,17.206217447916668,1.8651142857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add,50626,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",50626,13.183919270833334,1.3722857142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::div,50627,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50627,13.151041666666666,181.791
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50628,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50628,19.999837239583332,172.55859999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::copy_,50634,"[[], [], []]",Memcpy HtoD (Pageable -> Device),50634,9.962076822916666,0.7753142857142862
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mm,50648,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,50648,1950.73095703125,1457.0431714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add,50650,"[[4096, 4, 8192], [8192], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",50650,16.820963541666668,339.29797142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::gelu,50651,"[[4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",50651,16.917805989583332,217.9331714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mm,50659,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x256x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50659,44.03076171875,1277.6039142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,record_param_comms,50663,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",50663,28.7666015625,3012.863942857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add,50671,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",50671,17.888020833333332,174.07362857142863
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add,50673,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50673,16.715494791666668,110.43625714285716
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::sum,50680,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",50680,43.602701822916664,58.44162857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,50684,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50684,17.14111328125,1.8257999999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mm,50696,"[[4096, 16384], [16384, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50696,46.624348958333336,1262.7211142857145
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mm,50703,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50703,48.222981770833336,1294.2426285714284
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,50715,"[[4096, 8192], [4096, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50715,21.482259114583332,52.802342857142875
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::gelu_backward,50718,"[[4096, 4, 8192], [4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul>)",50718,19.903971354166668,288.6661714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::sum,50721,"[[4096, 4, 8192], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",50721,46.61376953125,88.88682857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,50725,"[[8192], [8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50725,16.810221354166668,1.8641999999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mm,50735,"[[8192, 16384], [16384, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50735,46.069173177083336,1244.409057142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mm,50742,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50742,49.033854166666664,1269.9686285714283
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,50754,"[[8192, 4096], [8192, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50754,18.613118489583332,52.0698
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,record_param_comms,50758,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",50758,36.693359375,3082.6013142857137
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50763,"[[4096, 4, 4096], [4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50763,23.40283203125,173.5368857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50764,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",50764,16.852376302083332,110.3641142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::sum,50765,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",50765,46.623372395833336,58.091342857142834
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,50769,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50769,17.225748697916668,1.8138857142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::neg,50772,"[[4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",50772,14.324055989583334,81.5836857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::div,50773,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50773,21.237467447916668,184.86748571428566
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::div,50774,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50774,21.439778645833332,184.02551428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50775,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",50775,20.169759114583332,110.38871428571431
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::div,50776,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50776,18.090983072916668,186.03685714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::sum,50777,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",50777,16.89599609375,50.899542857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add,50778,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50778,17.152018229166668,105.87408571428573
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50783,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",50783,16.799967447916668,1.8943999999999992
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::div,50786,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50786,14.409830729166666,183.6222571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::eq,50787,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",50787,21.343912760416668,1.9254857142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::masked_fill_,50788,"[[4096, 4, 4096], [4096, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",50788,16.78857421875,188.90954285714287
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50791,"[[4096, 4, 1], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50791,19.6162109375,173.69957142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,50792,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50792,18.112630208333332,108.78339999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mm,50806,"[[4096, 16384], [16384, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50806,17.013020833333332,323.46900000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mm,50813,"[[16384, 4096], [4096, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,50813,53.503092447916664,335.83551428571434
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,50825,"[[4096, 2048], [4096, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50825,17.333170572916668,13.159085714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,FlashAttnFuncBackward,50839,"[[4, 4096, 16, 128]]","void flash_bwd_dot_do_o_kernel<true, Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> > >(Flash_bwd_params)",50839,14.22998046875,78.0564
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,FlashAttnFuncBackward,50839,"[[4, 4096, 16, 128]]","void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> >, false, true, false, false, true, true>(Flash_bwd_params)",50839,21.6201171875,2302.9397142857138
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,FlashAttnFuncBackward,50839,"[[4, 4096, 16, 128]]","void flash_bwd_convert_dq_kernel<Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> > >(Flash_bwd_params, int)",50839,21.844563802083332,70.03162857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50878,"[[4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50878,19.904459635416668,96.72768571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50882,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], [4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50882,18.313313802083332,96.45245714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::neg,50885,"[[4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",50885,17.17333984375,44.65137142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::fill_,50892,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",50892,16.745930989583332,21.426971428571434
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::copy_,50895,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",50895,16.777669270833332,45.88208571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,50896,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50896,18.090983072916668,55.539485714285725
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::fill_,50903,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",50903,21.269694010416668,21.33111428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::copy_,50906,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",50906,21.408203125,45.9048
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,50907,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50907,19.59521484375,55.378600000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50911,"[[4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50911,18.697591145833332,96.88125714285712
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50915,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], [4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50915,17.012858072916668,96.3628857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::neg,50918,"[[4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",50918,16.789388020833332,44.55534285714287
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::fill_,50925,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",50925,16.960286458333332,21.31280000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::copy_,50928,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",50928,18.079264322916668,45.84628571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,50929,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50929,21.237955729166668,55.52045714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::fill_,50936,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",50936,21.460611979166668,21.277742857142854
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::copy_,50939,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",50939,19.872233072916668,45.909485714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,50940,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50940,18.400227864583332,55.36585714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::cat,50943,"[[[4096, 4, 16, 128], [4096, 4, 16, 128], [4096, 4, 16, 128]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy_contig<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 128, 1>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",50943,16.532389322916668,254.99794285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mm,50957,"[[6144, 16384], [16384, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50957,48.479654947916664,933.7308857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mm,50964,"[[16384, 6144], [6144, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,50964,53.301595052083336,949.8833714285718
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,50976,"[[6144, 4096], [6144, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50976,18.879069010416668,38.89328571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,record_param_comms,50980,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",50980,37.097981770833336,2982.332628571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50985,"[[4096, 4, 4096], [4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",50985,24.927897135416668,173.48922857142853
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50986,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",50986,19.626627604166668,110.24900000000002
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::sum,50987,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",50987,47.99951171875,58.12691428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,50991,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",50991,19.91455078125,1.8349142857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::neg,50994,"[[4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",50994,16.1494140625,81.64665714285717
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::div,50995,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50995,21.09912109375,184.66911428571433
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::div,50996,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50996,20.169759114583332,184.0035428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,50997,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",50997,19.509114583333332,110.27905714285717
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::div,50998,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",50998,22.046549479166668,186.62851428571432
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::sum,50999,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",50999,21.332194010416668,50.96265714285713
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,51000,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51000,19.94677734375,104.63702857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,51005,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",51005,19.775553385416668,1.8815714285714287
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::div,51008,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51008,15.967610677083334,184.14705714285708
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::eq,51009,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",51009,21.322102864583332,1.883428571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::masked_fill_,51010,"[[4096, 4, 4096], [4096, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",51010,14.484700520833334,188.88485714285713
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::mul,51013,"[[4096, 4, 1], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51013,19.626627604166668,173.6584
autograd::engine::evaluate_function: CheckpointFunctionBackward,50448,,aten::add_,51014,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51014,16.841796875,108.79162857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::fill_,51024,"[[1, 1, 4096, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",51024,1582.0538736979167,6.457514285714284
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::fill_,51028,"[[67108864], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",51028,1085.9303385416667,41.086542857142845
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::copy_,51035,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),51035,257.3103841145833,49.90648571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,record_param_comms,51037,"[[[33554432]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",51037,760.39892578125,1781.1859714285717
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::copy_,51044,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),51044,18.026529947916668,48.61125714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::copy_,51047,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),51047,17.876302083333332,48.6292857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::copy_,51064,"[[], [], []]",Memcpy HtoD (Pageable -> Device),51064,10.548990885416666,0.727771428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::linalg_vector_norm,51068,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",51068,1034.3048502604167,51.39785714285713
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51069,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",51069,13.504231770833334,1.6859428571428574
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add,51070,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",51070,237.44856770833334,1.369571428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::div,51071,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51071,302.2141927083333,182.70614285714288
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51072,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51072,19.541178385416668,172.6555428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mm,51084,"[[16384, 4096], [4096, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,51084,39.50830078125,1079.0313142857144
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::copy_,51100,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),51100,57.215983072916664,6.609200000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::copy_,51104,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),51104,508.0812174479167,5.313771428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::neg,51114,"[[4096, 1, 1, 128], [4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",51114,1250.65234375,42.70954285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::cat,51126,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",51126,260.8191731770833,140.4701714285714
None,None,None,None,None,None,kernel_1,51127,16.99267578125,61.14122857142858
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::neg,51137,"[[4096, 4, 16, 128], [4096, 1, 1, 128], [4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",51137,16.6826171875,45.376457142857134
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::cat,51148,"[[4096, 4, 16, 128], [[4096, 4, 16, 64], [4096, 4, 16, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",51148,16.960286458333332,139.67940000000002
None,None,None,None,None,None,kernel_1,51149,16.8525390625,61.078342857142864
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,FlashAttnFunc,51167,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128], [], [], [], [], [], [], []]","void flash_fwd_kernel<Flash_fwd_kernel_traits<128, 128, 64, 4, false, false, cutlass::half_t, Flash_kernel_traits<128, 128, 64, 4, cutlass::half_t> >, false, true, false, false, true, true, false>(Flash_fwd_params)",51167,16.575358072916668,849.2719142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mm,51184,"[[16384, 2048], [2048, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,51184,70.86962890625,333.4829142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,record_param_comms,51188,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",51188,26.335286458333332,2952.8939142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add,51194,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51194,17.920084635416668,112.9222
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::linalg_vector_norm,51195,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",51195,16.82080078125,50.9124
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51196,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",51196,17.00244140625,1.869657142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add,51197,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",51197,13.41943359375,1.3888000000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::div,51198,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51198,13.277669270833334,181.6127428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51199,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51199,18.037434895833332,172.4196
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::copy_,51205,"[[], [], []]",Memcpy HtoD (Pageable -> Device),51205,9.85498046875,0.7643428571428575
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mm,51219,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,51219,1966.9036458333333,1453.108114285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add,51221,"[[4096, 4, 8192], [8192], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",51221,16.958984375,338.9458285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::gelu,51222,"[[4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",51222,16.916829427083332,217.49439999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mm,51230,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x256x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,51230,43.775716145833336,1275.940742857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,record_param_comms,51234,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",51234,29.98388671875,3026.5130857142854
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add,51242,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",51242,17.866536458333332,173.94562857142859
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add,51244,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51244,17.055826822916668,110.21957142857146
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::sum,51251,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",51251,45.674641927083336,58.53285714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51255,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51255,17.6533203125,1.8815428571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mm,51267,"[[4096, 16384], [16384, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,51267,46.410807291666664,1261.6131428571425
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mm,51274,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,51274,48.372233072916664,1293.5669999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51286,"[[4096, 8192], [4096, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51286,20.212890625,52.74908571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::gelu_backward,51289,"[[4096, 4, 8192], [4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul>)",51289,18.314778645833332,288.2931714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::sum,51292,"[[4096, 4, 8192], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",51292,47.956705729166664,88.9581142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51296,"[[8192], [8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51296,17.557779947916668,1.8532285714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mm,51306,"[[8192, 16384], [16384, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,51306,47.893229166666664,1242.6191428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mm,51313,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,51313,49.598795572916664,1269.0589142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51325,"[[8192, 4096], [8192, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51325,20.38427734375,51.97114285714289
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,record_param_comms,51329,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",51329,36.201497395833336,3100.948885714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51334,"[[4096, 4, 4096], [4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51334,23.785970052083332,173.47202857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51335,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",51335,16.480305989583332,110.35402857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::sum,51336,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",51336,47.305013020833336,58.15631428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51340,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51340,17.098307291666668,1.8614857142857146
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::neg,51343,"[[4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",51343,14.634440104166666,81.64665714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::div,51344,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51344,19.766438802083332,184.79894285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::div,51345,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51345,19.76416015625,184.02819999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51346,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",51346,21.3642578125,110.18214285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::div,51347,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51347,19.967610677083332,185.8047714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::sum,51348,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",51348,16.8955078125,50.952457142857135
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add,51349,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51349,16.83251953125,105.89057142857145
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51354,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",51354,17.396158854166668,1.9264000000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::div,51357,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51357,14.45263671875,183.57657142857136
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::eq,51358,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",51358,19.541341145833332,1.9053142857142864
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::masked_fill_,51359,"[[4096, 4, 4096], [4096, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",51359,14.516764322916666,188.8647428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51362,"[[4096, 4, 1], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51362,21.259765625,173.6356
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51363,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51363,19.68994140625,108.71117142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mm,51377,"[[4096, 16384], [16384, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,51377,17.301595052083332,323.4606857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mm,51384,"[[16384, 4096], [4096, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,51384,53.043782552083336,336.22420000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51396,"[[4096, 2048], [4096, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51396,17.375651041666668,13.162771428571425
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,FlashAttnFuncBackward,51410,"[[4, 4096, 16, 128]]","void flash_bwd_dot_do_o_kernel<true, Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> > >(Flash_bwd_params)",51410,14.22900390625,77.78117142857144
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,FlashAttnFuncBackward,51410,"[[4, 4096, 16, 128]]","void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> >, false, true, false, false, true, true>(Flash_bwd_params)",51410,20.54443359375,2300.4435428571433
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,FlashAttnFuncBackward,51410,"[[4, 4096, 16, 128]]","void flash_bwd_convert_dq_kernel<Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> > >(Flash_bwd_params, int)",51410,19.817545572916668,70.13419999999999
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51449,"[[4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51449,21.759765625,96.66722857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51453,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], [4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51453,19.744303385416668,96.3445714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::neg,51456,"[[4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",51456,16.863444010416668,44.53902857142858
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::fill_,51463,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",51463,16.927408854166668,21.415142857142854
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::copy_,51466,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",51466,16.70361328125,45.86454285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51467,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51467,18.431315104166668,55.516771428571445
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::fill_,51474,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",51474,20.117513020833332,21.27145714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::copy_,51477,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",51477,19.4453125,45.81262857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51478,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51478,21.4931640625,55.34562857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51482,"[[4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51482,19.679850260416668,96.809
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51486,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], [4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51486,16.639973958333332,96.30071428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::neg,51489,"[[4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",51489,16.853352864583332,44.47874285714287
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::fill_,51496,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",51496,16.884440104166668,21.329914285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::copy_,51499,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",51499,18.410970052083332,45.79705714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51500,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51500,19.9033203125,55.4782
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::fill_,51507,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",51507,19.935546875,21.3438
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::copy_,51510,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",51510,21.35595703125,45.916828571428574
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51511,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51511,19.83984375,55.44991428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::cat,51514,"[[[4096, 4, 16, 128], [4096, 4, 16, 128], [4096, 4, 16, 128]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy_contig<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 128, 1>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",51514,16.50146484375,255.04268571428568
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mm,51528,"[[6144, 16384], [16384, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,51528,47.742513020833336,933.3780285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mm,51535,"[[16384, 6144], [6144, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,51535,55.273763020833336,950.2975714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51547,"[[6144, 4096], [6144, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51547,18.965169270833332,38.92082857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,record_param_comms,51551,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",51551,33.642578125,2999.630628571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51556,"[[4096, 4, 4096], [4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51556,25.38623046875,173.49662857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51557,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",51557,18.08984375,110.50405714285712
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::sum,51558,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",51558,49.833170572916664,57.76208571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51562,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51562,21.812337239583332,1.810257142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::neg,51565,"[[4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",51565,14.400390625,81.63122857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::div,51566,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51566,19.3056640625,184.8291714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::div,51567,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51567,21.790690104166668,184.09779999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51568,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",51568,21.525390625,110.10891428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::div,51569,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51569,19.891927083333332,186.68600000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::sum,51570,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",51570,19.75537109375,50.8019142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51571,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51571,21.8662109375,104.62794285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51576,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",51576,21.472493489583332,1.9629428571428569
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::div,51579,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51579,14.282063802083334,184.13702857142854
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::eq,51580,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",51580,19.562174479166668,1.865114285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::masked_fill_,51581,"[[4096, 4, 4096], [4096, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",51581,16.148763020833332,188.9095142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::mul,51584,"[[4096, 4, 1], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51584,20.991861979166668,173.6950571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,51019,,aten::add_,51585,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51585,16.831868489583332,108.76042857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::fill_,51595,"[[1, 1, 4096, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<bool>, std::array<char*, 1ul> >(int, at::native::FillFunctor<bool>, std::array<char*, 1ul>)",51595,1546.7347005208333,6.473114285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::fill_,51599,"[[67108864], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",51599,1074.2071940104167,41.11045714285713
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::copy_,51606,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),51606,299.13134765625,49.86288571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,record_param_comms,51608,"[[[33554432]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",51608,738.96728515625,1775.2843999999998
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::copy_,51615,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),51615,18.1015625,48.519742857142866
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::copy_,51618,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),51618,17.58837890625,48.54891428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::copy_,51635,"[[], [], []]",Memcpy HtoD (Pageable -> Device),51635,10.121907552083334,0.719514285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::linalg_vector_norm,51639,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",51639,1035.2003580729167,51.31565714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,51640,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",51640,13.215006510416666,1.6713142857142862
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add,51641,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",51641,218.44026692708334,1.3686857142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::div,51642,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51642,303.0348307291667,182.5672
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,51643,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51643,18.346842447916668,172.63265714285708
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mm,51655,"[[16384, 4096], [4096, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,51655,38.730305989583336,1078.934342857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::copy_,51671,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),51671,52.746419270833336,7.171542857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::copy_,51675,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),51675,543.29052734375,6.715342857142858
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::neg,51685,"[[4096, 1, 1, 128], [4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",51685,1235.42236328125,42.73591428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::cat,51697,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",51697,247.9443359375,140.34497142857148
None,None,None,None,None,None,kernel_1,51698,16.682454427083332,61.36171428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::neg,51708,"[[4096, 4, 16, 128], [4096, 1, 1, 128], [4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",51708,17.02392578125,45.313285714285705
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::cat,51719,"[[4096, 4, 16, 128], [[4096, 4, 16, 64], [4096, 4, 16, 64]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 64, 64>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",51719,16.927408854166668,139.71328571428572
None,None,None,None,None,None,kernel_1,51720,16.8212890625,61.108342857142844
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,FlashAttnFunc,51738,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128], [], [], [], [], [], [], []]","void flash_fwd_kernel<Flash_fwd_kernel_traits<128, 128, 64, 4, false, false, cutlass::half_t, Flash_kernel_traits<128, 128, 64, 4, cutlass::half_t> >, false, true, false, false, true, true, false>(Flash_fwd_params)",51738,16.938802083333332,852.0942285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mm,51755,"[[16384, 2048], [2048, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,51755,70.30305989583333,333.4337142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,record_param_comms,51759,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",51759,26.72900390625,2951.127485714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add,51765,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51765,17.802083333333332,113.10974285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::linalg_vector_norm,51766,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",51766,16.84228515625,50.5914857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,51767,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",51767,17.173990885416668,1.8403999999999996
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add,51768,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",51768,13.35400390625,1.372314285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::div,51769,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51769,13.17138671875,181.7425714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,51770,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51770,19.48779296875,172.46354285714284
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::copy_,51776,"[[], [], []]",Memcpy HtoD (Pageable -> Device),51776,9.9619140625,0.7752857142857147
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mm,51790,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,51790,1940.0538736979167,1452.260628571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add,51792,"[[4096, 4, 8192], [8192], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",51792,16.638997395833332,338.96525714285707
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::gelu,51793,"[[4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",51793,17.057291666666668,217.56648571428573
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mm,51801,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x256x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,51801,43.860026041666664,1275.7433142857144
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,record_param_comms,51805,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",51805,31.103515625,3030.1244000000006
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add,51813,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",51813,17.984375,174.00045714285721
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add,51815,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51815,16.798990885416668,110.31377142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::sum,51822,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",51822,45.78125,58.17365714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,51826,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51826,17.503743489583332,1.8212
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mm,51838,"[[4096, 16384], [16384, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize128x256x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,51838,48.874837239583336,1261.7465142857145
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mm,51845,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,51845,51.657877604166664,1293.8138
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,51857,"[[4096, 8192], [4096, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51857,21.759928385416668,52.69262857142858
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::gelu_backward,51860,"[[4096, 4, 8192], [4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul> >(int, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half, c10::Half)#1}, std::array<char*, 3ul>)",51860,19.658203125,287.98222857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::sum,51863,"[[4096, 4, 8192], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",51863,47.44482421875,88.80640000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,51867,"[[8192], [8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51867,17.56787109375,1.8815714285714282
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mm,51877,"[[8192, 16384], [16384, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,51877,48.425618489583336,1241.9488285714287
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mm,51884,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,51884,51.402018229166664,1269.0827428571429
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,51896,"[[8192, 4096], [8192, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51896,18.923014322916668,51.99945714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,record_param_comms,51900,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",51900,37.705729166666664,3098.4220285714287
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,51905,"[[4096, 4, 4096], [4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51905,23.339029947916668,173.51222857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,51906,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",51906,16.735677083333332,110.23968571428574
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::sum,51907,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",51907,48.648763020833336,58.27862857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,51911,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51911,16.94921875,1.8093714285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::neg,51914,"[[4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",51914,14.560546875,81.71162857142855
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::div,51915,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51915,21.47119140625,184.6645428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::div,51916,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51916,21.759602864583332,183.87094285714284
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,51917,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",51917,19.711263020833332,110.27448571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::div,51918,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51918,19.104166666666668,185.58428571428567
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::sum,51919,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",51919,16.77880859375,51.21305714285713
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add,51920,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51920,16.97021484375,105.92802857142858
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,51925,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",51925,16.62939453125,1.8944
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::div,51928,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",51928,14.452311197916666,183.63508571428568
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::eq,51929,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",51929,21.31201171875,1.9044285714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::masked_fill_,51930,"[[4096, 4, 4096], [4096, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",51930,17.2578125,188.86565714285717
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,51933,"[[4096, 4, 1], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",51933,19.72265625,173.56791428571424
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,51934,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51934,18.645182291666668,108.8455714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mm,51948,"[[4096, 16384], [16384, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,51948,17.141276041666668,323.1993714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mm,51955,"[[16384, 4096], [4096, 2048]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,51955,53.972330729166664,335.5814
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,51967,"[[4096, 2048], [4096, 2048], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",51967,17.183430989583332,13.241457142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,FlashAttnFuncBackward,51981,"[[4, 4096, 16, 128]]","void flash_bwd_dot_do_o_kernel<true, Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> > >(Flash_bwd_params)",51981,14.100911458333334,77.71708571428573
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,FlashAttnFuncBackward,51981,"[[4, 4096, 16, 128]]","void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> >, false, true, false, false, true, true>(Flash_bwd_params)",51981,21.525227864583332,2299.6517714285715
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,FlashAttnFuncBackward,51981,"[[4, 4096, 16, 128]]","void flash_bwd_convert_dq_kernel<Flash_bwd_kernel_traits<128, 64, 128, 8, 2, 4, 2, false, false, cutlass::half_t, Flash_kernel_traits<128, 64, 128, 8, cutlass::half_t> > >(Flash_bwd_params, int)",51981,21.716796875,70.2320857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,52020,"[[4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",52020,20.394856770833332,96.69014285714282
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,52024,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], [4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",52024,18.091796875,96.42682857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::neg,52027,"[[4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",52027,16.906901041666668,44.52611428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::fill_,52034,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",52034,16.554361979166668,21.397771428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::copy_,52037,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",52037,16.649739583333332,45.83440000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,52038,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",52038,18.538411458333332,55.61822857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::fill_,52045,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",52045,21.514322916666668,21.298000000000005
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::copy_,52048,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",52048,21.22705078125,45.77328571428571
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,52049,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",52049,20.28759765625,55.44522857142858
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,52053,"[[4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",52053,18.122721354166668,96.88125714285714
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,52057,"[[[4096, 4, 16, 64], [4096, 4, 16, 64]], [4096, 4, 16, 128], [4096, 1, 1, 128]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",52057,16.779459635416668,96.30254285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::neg,52060,"[[4096, 4, 16, 64]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",52060,16.73583984375,44.371714285714276
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::fill_,52067,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",52067,16.629720052083332,21.324571428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::copy_,52070,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",52070,17.941731770833332,45.78142857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,52071,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",52071,21.62109375,55.57788571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::fill_,52078,"[[4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul> >(int, at::native::FillFunctor<c10::Half>, std::array<char*, 1ul>)",52078,21.98291015625,21.281571428571425
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::copy_,52081,"[[4096, 4, 16, 64], [4096, 4, 16, 64], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})",52081,20.320963541666668,45.749571428571436
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,52082,"[[4096, 4, 16, 128], [4096, 4, 16, 128], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",52082,18.345540364583332,55.63271428571428
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::cat,52085,"[[[4096, 4, 16, 128], [4096, 4, 16, 128], [4096, 4, 16, 128]], []]","void at::native::(anonymous namespace)::CatArrayBatchedCopy_contig<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 4, 128, 1>(at::native::(anonymous namespace)::OpaqueType<2u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<2u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",52085,16.587076822916668,254.74377142857142
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mm,52099,"[[6144, 16384], [16384, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize256x128x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,52099,47.168131510416664,932.4956857142856
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mm,52106,"[[16384, 6144], [6144, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_nn_n_tilesize256x128x32_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,52106,54.217936197916664,949.5542285714288
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,52118,"[[6144, 4096], [6144, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",52118,18.603352864583332,38.85308571428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,record_param_comms,52122,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",52122,34.334798177083336,2977.322371428572
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,52127,"[[4096, 4, 4096], [4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",52127,25.376302083333332,173.34848571428577
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,52128,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",52128,19.529134114583332,110.47300000000001
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::sum,52129,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<128, 4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",52129,49.087727864583336,57.89745714285712
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,52133,"[[4096], [4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",52133,19.8388671875,1.8596571428571427
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::neg,52136,"[[4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",52136,15.828776041666666,81.71442857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::div,52137,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",52137,21.20458984375,184.7888857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::div,52138,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",52138,19.690104166666668,184.02545714285716
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,52139,"[[4096, 4, 4096], [4096, 4, 4096]]","void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul> >(int, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 3ul>)",52139,19.75390625,110.24782857142857
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::div,52140,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",52140,21.642740885416668,186.4337142857143
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::sum,52141,"[[4096, 4, 4096], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, c10::Half, 4>)",52141,21.736490885416668,50.68674285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,52142,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",52142,20.107096354166668,104.71659999999997
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,52147,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",52147,19.70166015625,1.890714285714286
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::div,52150,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",52150,15.754069010416666,184.24125714285717
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::eq,52151,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, bool, at::native::(anonymous namespace)::CompareEqFunctor<c10::Half> >, std::array<char*, 2ul>)",52151,21.706868489583332,1.8724285714285713
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::masked_fill_,52152,"[[4096, 4, 4096], [4096, 4, 1], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})",52152,14.463216145833334,188.8638
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::mul,52155,"[[4096, 4, 1], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",52155,19.903971354166668,173.7490285714285
autograd::engine::evaluate_function: CheckpointFunctionBackward,51590,,aten::add_,52156,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",52156,17.045084635416668,108.80697142857142
