cpu_op_0,cpu_op_0_id,cpu_op_0_input_dim,cpu_op_1,cpu_op_1_id,cpu_op_1_input_dim,kernel,kernel_id,kernel_overhead(us),kernel_dur(us)
aten::clone,223,"[[33554432], []]",aten::copy_,225,"[[33554432], [33554432], []]",Memcpy DtoD (Device -> Device),225,0,47.48761666666671
aten::to,228,"[[], [], [], [], [], []]",aten::copy_,231,"[[], [], []]",Memcpy HtoD (Pageable -> Device),231,6367.0673828125,0.7357208333333319
aten::linalg_vector_norm,235,"[[4096, 4, 4096], [], [], [], []]",aten::linalg_vector_norm,235,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",235,6195.260416666667,51.243487499999986
aten::mul,236,"[[4096, 4, 1], []]",aten::mul,236,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",236,106.07845052083333,1.7717125
aten::add,237,"[[4096, 4, 1], [], []]",aten::add,237,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",237,633.0930989583334,1.3878458333333314
aten::div,238,"[[4096, 4, 4096], [4096, 4, 1]]",aten::div,238,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",238,1752.5598958333333,183.32379166666655
aten::mul,239,"[[4096], [4096, 4, 4096]]",aten::mul,239,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",239,128.24251302083334,172.90059166666657
aten::linear,244,"[[4096, 4, 4096], [6144, 4096], []]",aten::mm,251,"[[16384, 4096], [4096, 6144]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_off_kernel__5x_cublas,251,270.8028971354167,1089.0228916666665
aten::to,264,"[[4096, 1, 1, 128], [], [], [], [], [], [], []]",aten::copy_,267,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),267,377.1681315104167,6.488354166666671
aten::to,268,"[[4096, 1, 1, 128], [], [], [], [], [], [], []]",aten::copy_,271,"[[4096, 1, 1, 128], [4096, 1, 1, 128], []]",Memcpy HtoD (Pageable -> Device),271,3493.4485677083335,5.88832083333333
None,None,None,None,None,None,kernel_0,281,9425.744791666666,36.8065708333333
None,None,None,None,None,None,kernel_1,289,222.21549479166666,61.98502500000003
None,None,None,None,None,None,kernel_0,299,231.68929036458334,39.493583333333355
None,None,None,None,None,None,kernel_1,307,104.95947265625,62.03814166666662
FlashAttnFunc,325,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128], [], [], [], [], [], [], []]",FlashAttnFunc,325,"[[4, 4096, 16, 128], [4, 4096, 16, 128], [4, 4096, 16, 128], [], [], [], [], [], [], []]","void flash_fwd_kernel<Flash_fwd_kernel_traits<128, 128, 64, 4, false, false, cutlass::half_t, Flash_kernel_traits<128, 128, 64, 4, cutlass::half_t> >, false, true, false, false, true, true, false>(Flash_fwd_params)",325,6888.80029296875,863.0021500000003
aten::linear,335,"[[4096, 4, 2048], [4096, 2048], []]",aten::mm,342,"[[16384, 2048], [2048, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,342,452.42822265625,335.51017499999983
_ReduceFromModelParallelRegion,344,"[[4096, 4, 4096]]",record_param_comms,346,"[[[4096, 4, 4096]], [], [], [], [], [], [], [], [], []]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",346,219.05924479166666,2983.712395833332
aten::add,352,"[[4096, 4, 4096], [4096, 4, 4096], []]",aten::add,352,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",352,123.2939453125,112.99963333333335
aten::linalg_vector_norm,353,"[[4096, 4, 4096], [], [], [], []]",aten::linalg_vector_norm,353,"[[4096, 4, 4096], [], [], [], []]","void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",353,115.6025390625,50.66606249999997
aten::mul,354,"[[4096, 4, 1], []]",aten::mul,354,"[[4096, 4, 1], []]","void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)",354,117.65478515625,1.8445083333333308
aten::add,355,"[[4096, 4, 1], [], []]",aten::add,355,"[[4096, 4, 1], [], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, std::array<char*, 2ul>)",355,94.037109375,1.3690416666666645
aten::div,356,"[[4096, 4, 4096], [4096, 4, 1]]",aten::div,356,"[[4096, 4, 4096], [4096, 4, 1]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",356,89.93196614583333,182.10406666666663
aten::mul,357,"[[4096], [4096, 4, 4096]]",aten::mul,357,"[[4096], [4096, 4, 4096]]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",357,127.22054036458333,172.71872499999986
aten::to,360,"[[], [], [], [], [], []]",aten::copy_,363,"[[], [], []]",Memcpy HtoD (Pageable -> Device),363,68.00764973958333,0.7333208333333322
aten::linear,370,"[[4096, 4, 4096], [8192, 4096], []]",aten::mm,377,"[[16384, 4096], [4096, 8192]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x128x64_warpgroupsize1x1x1_execute_segment_k_on_kernel__5x_cublas,377,12919.844563802084,1465.9616999999996
aten::add,379,"[[4096, 4, 8192], [8192], []]",aten::add,379,"[[4096, 4, 8192], [8192], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",379,102.98567708333333,339.4012041666668
aten::gelu,380,"[[4096, 4, 8192], []]",aten::gelu,380,"[[4096, 4, 8192], []]","void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, std::array<char*, 2ul>)",380,103.490234375,218.1176666666666
aten::linear,381,"[[4096, 4, 8192], [4096, 8192], []]",aten::mm,388,"[[16384, 8192], [8192, 4096]]",sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize128x256x64_warpgroupsize2x1x1_execute_segment_k_off_kernel__5x_cublas,388,265.4033203125,1280.9635875000008
_ReduceFromModelParallelRegion,390,"[[4096, 4, 4096]]",nccl:all_reduce,393,"[[4096, 4, 4096]]","ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",392,209.10725911458334,3006.720674999999
aten::add,400,"[[4096, 4, 4096], [4096, 4, 4096], []]",aten::add,400,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",400,123.96630859375,174.39656249999993
aten::add,402,"[[4096, 4, 4096], [4096, 4, 4096], []]",aten::add,402,"[[4096, 4, 4096], [4096, 4, 4096], []]","void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<c10::Half>, std::array<char*, 3ul>)",402,115.02978515625,110.34573333333327
